/* tslint:disable */
/* eslint-disable */
// Generated by Microsoft Kiota
// @ts-ignore
import { createUntypedNodeFromDiscriminatorValue, type AdditionalDataHolder, type ApiError, type Guid, type Parsable, type ParseNode, type SerializationWriter, type UntypedNode } from '@microsoft/kiota-abstractions';

export interface Account extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The total number of Droplets current user or team may have active at one time.
     */
    dropletLimit?: number | null;
    /**
     * The email address used by the current user to register for DigitalOcean.
     */
    email?: string | null;
    /**
     * If true, the user has verified their account via email. False otherwise.
     */
    emailVerified?: boolean | null;
    /**
     * The total number of Floating IPs the current user or team may have.
     */
    floatingIpLimit?: number | null;
    /**
     * The display name for the current user.
     */
    name?: string | null;
    /**
     * This value is one of "active", "warning" or "locked".
     */
    status?: Account_status | null;
    /**
     * A human-readable message giving more details about the status of the account.
     */
    statusMessage?: string | null;
    /**
     * When authorized in a team context, includes information about the current team.
     */
    team?: Account_team | null;
    /**
     * The unique universal identifier for the current user.
     */
    uuid?: string | null;
}
export type Account_status = (typeof Account_statusObject)[keyof typeof Account_statusObject];
/**
 * When authorized in a team context, includes information about the current team.
 */
export interface Account_team extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name for the current team.
     */
    name?: string | null;
    /**
     * The unique universal identifier for the current team.
     */
    uuid?: string | null;
}
export interface Action extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the action was completed.
     */
    completedAt?: Date | null;
    /**
     * A unique numeric ID that can be used to identify and reference an action.
     */
    id?: number | null;
    /**
     * The region property
     */
    region?: Region | null;
    /**
     * A human-readable string that is used as a unique identifier for each region.
     */
    regionSlug?: string | null;
    /**
     * A unique identifier for the resource that the action is associated with.
     */
    resourceId?: number | null;
    /**
     * The type of resource that the action is associated with.
     */
    resourceType?: string | null;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the action was initiated.
     */
    startedAt?: Date | null;
    /**
     * The current status of the action. This can be "in-progress", "completed", or "errored".
     */
    status?: Action_status | null;
    /**
     * This is the type of action that the object represents. For example, this could be "transfer" to represent the state of an image transfer action.
     */
    type?: string | null;
}
/**
 * The linked actions can be used to check the status of a Droplet's create event.
 */
export interface Action_link extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A URL that can be used to access the action.
     */
    href?: string | null;
    /**
     * A unique numeric ID that can be used to identify and reference an action.
     */
    id?: number | null;
    /**
     * A string specifying the type of the related action.
     */
    rel?: string | null;
}
export type Action_status = (typeof Action_statusObject)[keyof typeof Action_statusObject];
export interface Alert extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The comparison operator used against the alert's threshold.
     */
    comparison?: Alert_comparison | null;
    /**
     * A unique ID that can be used to identify and reference the alert.
     */
    id?: Guid | null;
    /**
     * A human-friendly display name.
     */
    name?: string | null;
    /**
     * The notification settings for a trigger alert.
     */
    notifications?: Notification | null;
    /**
     * Period of time the threshold must be exceeded to trigger the alert.
     */
    period?: Alert_period | null;
    /**
     * The threshold at which the alert will enter a trigger state. The specific threshold is dependent on the alert type.
     */
    threshold?: number | null;
    /**
     * The type of alert.
     */
    type?: Alert_type | null;
}
export type Alert_comparison = (typeof Alert_comparisonObject)[keyof typeof Alert_comparisonObject];
export type Alert_period = (typeof Alert_periodObject)[keyof typeof Alert_periodObject];
export interface Alert_policy extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The alerts property
     */
    alerts?: Alerts | null;
    /**
     * The compare property
     */
    compare?: Alert_policy_compare | null;
    /**
     * The description property
     */
    description?: string | null;
    /**
     * The enabled property
     */
    enabled?: boolean | null;
    /**
     * The entities property
     */
    entities?: string[] | null;
    /**
     * The tags property
     */
    tags?: string[] | null;
    /**
     * The type property
     */
    type?: Alert_policy_type | null;
    /**
     * The uuid property
     */
    uuid?: string | null;
    /**
     * The value property
     */
    value?: number | null;
    /**
     * The window property
     */
    window?: Alert_policy_window | null;
}
export type Alert_policy_compare = (typeof Alert_policy_compareObject)[keyof typeof Alert_policy_compareObject];
export interface Alert_policy_request extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The alerts property
     */
    alerts?: Alerts | null;
    /**
     * The compare property
     */
    compare?: Alert_policy_request_compare | null;
    /**
     * The description property
     */
    description?: string | null;
    /**
     * The enabled property
     */
    enabled?: boolean | null;
    /**
     * The entities property
     */
    entities?: string[] | null;
    /**
     * The tags property
     */
    tags?: string[] | null;
    /**
     * The type property
     */
    type?: Alert_policy_request_type | null;
    /**
     * The value property
     */
    value?: number | null;
    /**
     * The window property
     */
    window?: Alert_policy_request_window | null;
}
export type Alert_policy_request_compare = (typeof Alert_policy_request_compareObject)[keyof typeof Alert_policy_request_compareObject];
export type Alert_policy_request_type = (typeof Alert_policy_request_typeObject)[keyof typeof Alert_policy_request_typeObject];
export type Alert_policy_request_window = (typeof Alert_policy_request_windowObject)[keyof typeof Alert_policy_request_windowObject];
export type Alert_policy_type = (typeof Alert_policy_typeObject)[keyof typeof Alert_policy_typeObject];
export type Alert_policy_window = (typeof Alert_policy_windowObject)[keyof typeof Alert_policy_windowObject];
export type Alert_type = (typeof Alert_typeObject)[keyof typeof Alert_typeObject];
export interface Alert_updatable extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The comparison operator used against the alert's threshold.
     */
    comparison?: Alert_updatable_comparison | null;
    /**
     * A human-friendly display name.
     */
    name?: string | null;
    /**
     * The notification settings for a trigger alert.
     */
    notifications?: Notification | null;
    /**
     * Period of time the threshold must be exceeded to trigger the alert.
     */
    period?: Alert_updatable_period | null;
    /**
     * The threshold at which the alert will enter a trigger state. The specific threshold is dependent on the alert type.
     */
    threshold?: number | null;
    /**
     * The type of alert.
     */
    type?: Alert_updatable_type | null;
}
export type Alert_updatable_comparison = (typeof Alert_updatable_comparisonObject)[keyof typeof Alert_updatable_comparisonObject];
export type Alert_updatable_period = (typeof Alert_updatable_periodObject)[keyof typeof Alert_updatable_periodObject];
export type Alert_updatable_type = (typeof Alert_updatable_typeObject)[keyof typeof Alert_updatable_typeObject];
export interface Alerts extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An email to notify on an alert trigger.
     */
    email?: string[] | null;
    /**
     * Slack integration details.
     */
    slack?: Slack_details[] | null;
}
/**
 * An Agent
 */
export interface ApiAgent extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Anthropic API Key Info
     */
    anthropicApiKey?: ApiAnthropicAPIKeyInfo | null;
    /**
     * Api key infos
     */
    apiKeyInfos?: ApiAgentAPIKeyInfo[] | null;
    /**
     * Api keys
     */
    apiKeys?: ApiAgentAPIKey[] | null;
    /**
     * A Chatbot
     */
    chatbot?: ApiChatbot | null;
    /**
     * Chatbot identifiers
     */
    chatbotIdentifiers?: ApiAgentChatbotIdentifier[] | null;
    /**
     * Child agents
     */
    childAgents?: ApiAgent[] | null;
    /**
     * Creation date / time
     */
    createdAt?: Date | null;
    /**
     * Description of deployment
     */
    deployment?: ApiDeployment | null;
    /**
     * Description of agent
     */
    description?: string | null;
    /**
     * The functions property
     */
    functions?: ApiAgentFunction[] | null;
    /**
     * The guardrails the agent is attached to
     */
    guardrails?: ApiAgentGuardrail[] | null;
    /**
     * The if_case property
     */
    ifCase?: string | null;
    /**
     * Agent instruction. Instructions help your agent to perform its job effectively. See [Write Effective Agent Instructions](https://docs.digitalocean.com/products/genai-platform/concepts/best-practices/#agent-instructions) for best practices.
     */
    instruction?: string | null;
    /**
     * The k property
     */
    k?: number | null;
    /**
     * Knowledge bases
     */
    knowledgeBases?: ApiKnowledgeBase[] | null;
    /**
     * The max_tokens property
     */
    maxTokens?: number | null;
    /**
     * Description of a Model
     */
    model?: ApiModel | null;
    /**
     * Agent name
     */
    name?: string | null;
    /**
     * Parent agents
     */
    parentAgents?: ApiAgent[] | null;
    /**
     * The project_id property
     */
    projectId?: string | null;
    /**
     * Region code
     */
    region?: string | null;
    /**
     * Creation of route date / time
     */
    routeCreatedAt?: Date | null;
    /**
     * The route_created_by property
     */
    routeCreatedBy?: string | null;
    /**
     * Route name
     */
    routeName?: string | null;
    /**
     * The route_uuid property
     */
    routeUuid?: string | null;
    /**
     * Agent tag to organize related resources
     */
    tags?: string[] | null;
    /**
     * The temperature property
     */
    temperature?: number | null;
    /**
     * Represents an AgentTemplate entity
     */
    template?: ApiAgentTemplate | null;
    /**
     * The top_p property
     */
    topP?: number | null;
    /**
     * Last modified
     */
    updatedAt?: Date | null;
    /**
     * Access your agent under this url
     */
    url?: string | null;
    /**
     * Id of user that created the agent
     */
    userId?: string | null;
    /**
     * Unique agent id
     */
    uuid?: string | null;
}
/**
 * Agent API Key
 */
export interface ApiAgentAPIKey extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Api key
     */
    apiKey?: string | null;
}
/**
 * Agent API Key Info
 */
export interface ApiAgentAPIKeyInfo extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Creation date
     */
    createdAt?: Date | null;
    /**
     * Created by
     */
    createdBy?: string | null;
    /**
     * Deleted date
     */
    deletedAt?: Date | null;
    /**
     * Name
     */
    name?: string | null;
    /**
     * The secret_key property
     */
    secretKey?: string | null;
    /**
     * Uuid
     */
    uuid?: string | null;
}
/**
 * Agent Chatbot Identifier
 */
export interface ApiAgentChatbotIdentifier extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Agent chatbot identifier
     */
    agentChatbotIdentifier?: string | null;
}
/**
 * Description missing
 */
export interface ApiAgentFunction extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Api key
     */
    apiKey?: string | null;
    /**
     * Creation date / time
     */
    createdAt?: Date | null;
    /**
     * Agent description
     */
    description?: string | null;
    /**
     * The faas_name property
     */
    faasName?: string | null;
    /**
     * The faas_namespace property
     */
    faasNamespace?: string | null;
    /**
     * The input_schema property
     */
    inputSchema?: ApiAgentFunction_input_schema | null;
    /**
     * Name
     */
    name?: string | null;
    /**
     * The output_schema property
     */
    outputSchema?: ApiAgentFunction_output_schema | null;
    /**
     * Last modified
     */
    updatedAt?: Date | null;
    /**
     * Download your agent here
     */
    url?: string | null;
    /**
     * Unique id
     */
    uuid?: string | null;
}
export interface ApiAgentFunction_input_schema extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
}
export interface ApiAgentFunction_output_schema extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
}
/**
 * A Agent Guardrail
 */
export interface ApiAgentGuardrail extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The agent_uuid property
     */
    agentUuid?: string | null;
    /**
     * The created_at property
     */
    createdAt?: Date | null;
    /**
     * The default_response property
     */
    defaultResponse?: string | null;
    /**
     * The description property
     */
    description?: string | null;
    /**
     * The guardrail_uuid property
     */
    guardrailUuid?: string | null;
    /**
     * The is_attached property
     */
    isAttached?: boolean | null;
    /**
     * The is_default property
     */
    isDefault?: boolean | null;
    /**
     * The metadata property
     */
    metadata?: ApiAgentGuardrail_metadata | null;
    /**
     * The name property
     */
    name?: string | null;
    /**
     * The priority property
     */
    priority?: number | null;
    /**
     * The type property
     */
    type?: ApiGuardrailType | null;
    /**
     * The updated_at property
     */
    updatedAt?: Date | null;
    /**
     * The uuid property
     */
    uuid?: string | null;
}
export interface ApiAgentGuardrail_metadata extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
}
/**
 * A GenAI Agent's configuration
 */
export interface ApiAgentPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A Chatbot
     */
    chatbot?: ApiChatbot | null;
    /**
     * Chatbot identifiers
     */
    chatbotIdentifiers?: ApiAgentChatbotIdentifier[] | null;
    /**
     * Creation date / time
     */
    createdAt?: Date | null;
    /**
     * Description of deployment
     */
    deployment?: ApiDeployment | null;
    /**
     * Description of agent
     */
    description?: string | null;
    /**
     * Instructions to the agent on how to use the route
     */
    ifCase?: string | null;
    /**
     * Agent instruction. Instructions help your agent to perform its job effectively. See [Write Effective Agent Instructions](https://docs.digitalocean.com/products/genai-platform/concepts/best-practices/#agent-instructions) for best practices.
     */
    instruction?: string | null;
    /**
     * How many results should be considered from an attached knowledge base
     */
    k?: number | null;
    /**
     * Specifies the maximum number of tokens the model can process in a single input or output, set as a number between 1 and 512. This determines the length of each response.
     */
    maxTokens?: number | null;
    /**
     * Description of a Model
     */
    model?: ApiModel | null;
    /**
     * Agent name
     */
    name?: string | null;
    /**
     * The DigitalOcean project ID associated with the agent
     */
    projectId?: string | null;
    /**
     * Region code
     */
    region?: string | null;
    /**
     * Creation of route date / time
     */
    routeCreatedAt?: Date | null;
    /**
     * Id of user that created the route
     */
    routeCreatedBy?: string | null;
    /**
     * Route name
     */
    routeName?: string | null;
    /**
     * Route uuid
     */
    routeUuid?: string | null;
    /**
     * A set of abitrary tags to organize your agent
     */
    tags?: string[] | null;
    /**
     * Controls the modelâ€™s creativity, specified as a number between 0 and 1. Lower values produce more predictable and conservative responses, while higher values encourage creativity and variation.
     */
    temperature?: number | null;
    /**
     * Represents an AgentTemplate entity
     */
    template?: ApiAgentTemplate | null;
    /**
     * Defines the cumulative probability threshold for word selection, specified as a number between 0 and 1. Higher values allow for more diverse outputs, while lower values ensure focused and coherent responses.
     */
    topP?: number | null;
    /**
     * Last modified
     */
    updatedAt?: Date | null;
    /**
     * Access your agent under this url
     */
    url?: string | null;
    /**
     * Id of user that created the agent
     */
    userId?: string | null;
    /**
     * Unique agent id
     */
    uuid?: string | null;
}
/**
 * Represents an AgentTemplate entity
 */
export interface ApiAgentTemplate extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The agent template's creation date
     */
    createdAt?: Date | null;
    /**
     * Description of the agent template
     */
    description?: string | null;
    /**
     * Instructions for the agent template
     */
    instruction?: string | null;
    /**
     * The 'k' value for the agent template
     */
    k?: number | null;
    /**
     * List of knowledge bases associated with the agent template
     */
    knowledgeBases?: ApiKnowledgeBase[] | null;
    /**
     * The max_tokens setting for the agent template
     */
    maxTokens?: number | null;
    /**
     * Description of a Model
     */
    model?: ApiModel | null;
    /**
     * Name of the agent template
     */
    name?: string | null;
    /**
     * The temperature setting for the agent template
     */
    temperature?: number | null;
    /**
     * The top_p setting for the agent template
     */
    topP?: number | null;
    /**
     * The agent template's last updated date
     */
    updatedAt?: Date | null;
    /**
     * Unique id
     */
    uuid?: string | null;
}
/**
 * Agreement Description
 */
export interface ApiAgreement extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The description property
     */
    description?: string | null;
    /**
     * The name property
     */
    name?: string | null;
    /**
     * The url property
     */
    url?: string | null;
    /**
     * The uuid property
     */
    uuid?: string | null;
}
/**
 * Anthropic API Key Info
 */
export interface ApiAnthropicAPIKeyInfo extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Key creation date
     */
    createdAt?: Date | null;
    /**
     * Created by user id from DO
     */
    createdBy?: string | null;
    /**
     * Key deleted date
     */
    deletedAt?: Date | null;
    /**
     * Name
     */
    name?: string | null;
    /**
     * Key last updated date
     */
    updatedAt?: Date | null;
    /**
     * Uuid
     */
    uuid?: string | null;
}
export type ApiBatchJobPhase = (typeof ApiBatchJobPhaseObject)[keyof typeof ApiBatchJobPhaseObject];
/**
 * CancelKnowledgeBaseIndexingJobInputPublic description
 */
export interface ApiCancelKnowledgeBaseIndexingJobInputPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A unique identifier for an indexing job.
     */
    uuid?: string | null;
}
/**
 * CancelKnowledgeBaseIndexingJobOutput description
 */
export interface ApiCancelKnowledgeBaseIndexingJobOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * IndexingJob description
     */
    job?: ApiIndexingJob | null;
}
/**
 * A Chatbot
 */
export interface ApiChatbot extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The button_background_color property
     */
    buttonBackgroundColor?: string | null;
    /**
     * The logo property
     */
    logo?: string | null;
    /**
     * Name of chatbot
     */
    name?: string | null;
    /**
     * The primary_color property
     */
    primaryColor?: string | null;
    /**
     * The secondary_color property
     */
    secondaryColor?: string | null;
    /**
     * The starting_message property
     */
    startingMessage?: string | null;
}
export type ApiCrawlingOption = (typeof ApiCrawlingOptionObject)[keyof typeof ApiCrawlingOptionObject];
export interface ApiCreateAgentAPIKeyInputPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Agent id
     */
    agentUuid?: string | null;
    /**
     * A human friendly name to identify the key
     */
    name?: string | null;
}
export interface ApiCreateAgentAPIKeyOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Agent API Key Info
     */
    apiKeyInfo?: ApiAgentAPIKeyInfo | null;
}
/**
 * Parameters for Agent Creation
 */
export interface ApiCreateAgentInputPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Optional Anthropic API key ID to use with Anthropic models
     */
    anthropicKeyUuid?: string | null;
    /**
     * A text description of the agent, not used in inference
     */
    description?: string | null;
    /**
     * Agent instruction. Instructions help your agent to perform its job effectively. See [Write Effective Agent Instructions](https://docs.digitalocean.com/products/genai-platform/concepts/best-practices/#agent-instructions) for best practices.
     */
    instruction?: string | null;
    /**
     * Ids of the knowledge base(s) to attach to the agent
     */
    knowledgeBaseUuid?: string[] | null;
    /**
     * Identifier for the foundation model.
     */
    modelUuid?: string | null;
    /**
     * Agent name
     */
    name?: string | null;
    /**
     * The id of the DigitalOcean project this agent will belong to
     */
    projectId?: string | null;
    /**
     * The DigitalOcean region to deploy your agent in
     */
    region?: string | null;
    /**
     * Agent tag to organize related resources
     */
    tags?: string[] | null;
}
/**
 * Information about a newly created Agent
 */
export interface ApiCreateAgentOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An Agent
     */
    agent?: ApiAgent | null;
}
/**
 * CreateAnthropicAPIKeyInputPublic is used to create a new Anthropic API key for a specific agent.
 */
export interface ApiCreateAnthropicAPIKeyInputPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Anthropic API key
     */
    apiKey?: string | null;
    /**
     * Name of the key
     */
    name?: string | null;
}
/**
 * CreateAnthropicAPIKeyOutput is used to return the newly created Anthropic API key.
 */
export interface ApiCreateAnthropicAPIKeyOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Anthropic API Key Info
     */
    apiKeyInfo?: ApiAnthropicAPIKeyInfo | null;
}
/**
 * Data to create a knowledge base data source
 */
export interface ApiCreateKnowledgeBaseDataSourceInputPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * File to upload as data source for knowledge base.
     */
    fileUploadDataSource?: ApiFileUploadDataSource | null;
    /**
     * Knowledge base id
     */
    knowledgeBaseUuid?: string | null;
    /**
     * Spaces Bucket Data Source
     */
    spacesDataSource?: ApiSpacesDataSource | null;
}
/**
 * Information about a newly created knowldege base data source
 */
export interface ApiCreateKnowledgeBaseDataSourceOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Data Source configuration for Knowledge Bases
     */
    knowledgeBaseDataSource?: ApiKnowledgeBaseDataSource | null;
}
/**
 * Data to create a new knowledge base.
 */
export interface ApiCreateKnowledgeBaseInputPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Identifier of the DigitalOcean OpenSearch database this knowledge base will use, optional.If not provided, we create a new database for the knowledge base inthe same region as the knowledge base.
     */
    databaseId?: string | null;
    /**
     * The data sources to use for this knowledge base. See [Organize Data Sources](https://docs.digitalocean.com/products/genai-platform/concepts/best-practices/#spaces-buckets) for more information on data sources best practices.
     */
    datasources?: ApiKBDataSource[] | null;
    /**
     * Identifier for the [embedding model](https://docs.digitalocean.com/products/genai-platform/details/models/#embedding-models).
     */
    embeddingModelUuid?: string | null;
    /**
     * Name of the knowledge base.
     */
    name?: string | null;
    /**
     * Identifier of the DigitalOcean project this knowledge base will belong to.
     */
    projectId?: string | null;
    /**
     * The datacenter region to deploy the knowledge base in.
     */
    region?: string | null;
    /**
     * Tags to organize your knowledge base.
     */
    tags?: string[] | null;
    /**
     * The VPC to deploy the knowledge base database in
     */
    vpcUuid?: string | null;
}
/**
 * Information about a newly created knowledge base
 */
export interface ApiCreateKnowledgeBaseOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Knowledgebase Description
     */
    knowledgeBase?: ApiKnowledgeBase | null;
}
export interface ApiDeleteAgentAPIKeyOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Agent API Key Info
     */
    apiKeyInfo?: ApiAgentAPIKeyInfo | null;
}
/**
 * Info about a deleted agent
 */
export interface ApiDeleteAgentOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An Agent
     */
    agent?: ApiAgent | null;
}
/**
 * DeleteAnthropicAPIKeyOutput is used to return the deleted Anthropic API key.
 */
export interface ApiDeleteAnthropicAPIKeyOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Anthropic API Key Info
     */
    apiKeyInfo?: ApiAnthropicAPIKeyInfo | null;
}
/**
 * Information about a newly deleted knowledge base data source
 */
export interface ApiDeleteKnowledgeBaseDataSourceOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Data source id
     */
    dataSourceUuid?: string | null;
    /**
     * Knowledge base id
     */
    knowledgeBaseUuid?: string | null;
}
/**
 * Information about a deleted knowledge base
 */
export interface ApiDeleteKnowledgeBaseOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The id of the deleted knowledge base
     */
    uuid?: string | null;
}
/**
 * Description of deployment
 */
export interface ApiDeployment extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Creation date / time
     */
    createdAt?: Date | null;
    /**
     * Name
     */
    name?: string | null;
    /**
     * The status property
     */
    status?: ApiDeploymentStatus | null;
    /**
     * Last modified
     */
    updatedAt?: Date | null;
    /**
     * Access your deployed agent here
     */
    url?: string | null;
    /**
     * Unique id
     */
    uuid?: string | null;
    /**
     * - VISIBILITY_UNKNOWN: The status of the deployment is unknown - VISIBILITY_DISABLED: The deployment is disabled and will no longer service requests - VISIBILITY_PLAYGROUND: Deprecated: No longer a valid state - VISIBILITY_PUBLIC: The deployment is public and will service requests from the public internet - VISIBILITY_PRIVATE: The deployment is private and will only service requests from other agents, or through API keys
     */
    visibility?: ApiDeploymentVisibility | null;
}
export type ApiDeploymentStatus = (typeof ApiDeploymentStatusObject)[keyof typeof ApiDeploymentStatusObject];
export type ApiDeploymentVisibility = (typeof ApiDeploymentVisibilityObject)[keyof typeof ApiDeploymentVisibilityObject];
/**
 * File to upload as data source for knowledge base.
 */
export interface ApiFileUploadDataSource extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The original file name
     */
    originalFileName?: string | null;
    /**
     * The size of the file in bytes
     */
    sizeInBytes?: string | null;
    /**
     * The object key the file was stored as
     */
    storedObjectKey?: string | null;
}
/**
 * One Agent
 */
export interface ApiGetAgentOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An Agent
     */
    agent?: ApiAgent | null;
}
export interface ApiGetAnthropicAPIKeyOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Anthropic API Key Info
     */
    apiKeyInfo?: ApiAnthropicAPIKeyInfo | null;
}
/**
 * Child list for an agent
 */
export interface ApiGetChildrenOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Child agents
     */
    children?: ApiAgent[] | null;
}
/**
 * GetKnowledgeBaseIndexingJobOutput description
 */
export interface ApiGetKnowledgeBaseIndexingJobOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * IndexingJob description
     */
    job?: ApiIndexingJob | null;
}
/**
 * The knowledge base
 */
export interface ApiGetKnowledgeBaseOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The database_status property
     */
    databaseStatus?: DbaasClusterStatus | null;
    /**
     * Knowledgebase Description
     */
    knowledgeBase?: ApiKnowledgeBase | null;
}
export type ApiGuardrailType = (typeof ApiGuardrailTypeObject)[keyof typeof ApiGuardrailTypeObject];
export interface ApiIndexedDataSource extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Timestamp when data source completed indexing
     */
    completedAt?: Date | null;
    /**
     * Uuid of the indexed data source
     */
    dataSourceUuid?: string | null;
    /**
     * Total count of files that have been indexed
     */
    indexedFileCount?: string | null;
    /**
     * Timestamp when data source started indexing
     */
    startedAt?: Date | null;
    /**
     * Total size of files in data source in bytes
     */
    totalBytes?: string | null;
    /**
     * Total size of files in data source in bytes that have been indexed
     */
    totalBytesIndexed?: string | null;
    /**
     * Total file count in the data source
     */
    totalFileCount?: string | null;
}
/**
 * IndexingJob description
 */
export interface ApiIndexingJob extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Number of datasources indexed completed
     */
    completedDatasources?: number | null;
    /**
     * Creation date / time
     */
    createdAt?: Date | null;
    /**
     * The data_source_uuids property
     */
    dataSourceUuids?: string[] | null;
    /**
     * The finished_at property
     */
    finishedAt?: Date | null;
    /**
     * Knowledge base id
     */
    knowledgeBaseUuid?: string | null;
    /**
     * The phase property
     */
    phase?: ApiBatchJobPhase | null;
    /**
     * The started_at property
     */
    startedAt?: Date | null;
    /**
     * Number of tokens
     */
    tokens?: number | null;
    /**
     * Number of datasources being indexed
     */
    totalDatasources?: number | null;
    /**
     * Last modified
     */
    updatedAt?: Date | null;
    /**
     * Unique id
     */
    uuid?: string | null;
}
export interface ApiKBDataSource extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Deprecated, moved to data_source_details
     */
    bucketName?: string | null;
    /**
     * Deprecated, moved to data_source_details
     */
    bucketRegion?: string | null;
    /**
     * File to upload as data source for knowledge base.
     */
    fileUploadDataSource?: ApiFileUploadDataSource | null;
    /**
     * The item_path property
     */
    itemPath?: string | null;
    /**
     * Spaces Bucket Data Source
     */
    spacesDataSource?: ApiSpacesDataSource | null;
    /**
     * WebCrawlerDataSource
     */
    webCrawlerDataSource?: ApiWebCrawlerDataSource | null;
}
/**
 * Knowledgebase Description
 */
export interface ApiKnowledgeBase extends AdditionalDataHolder, Parsable {
    /**
     * Time when the knowledge base was added to the agent
     */
    addedToAgentAt?: Date | null;
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Creation date / time
     */
    createdAt?: Date | null;
    /**
     * The database_id property
     */
    databaseId?: string | null;
    /**
     * The embedding_model_uuid property
     */
    embeddingModelUuid?: string | null;
    /**
     * Whether the knowledge base is public or not
     */
    isPublic?: boolean | null;
    /**
     * IndexingJob description
     */
    lastIndexingJob?: ApiIndexingJob | null;
    /**
     * Name of knowledge base
     */
    name?: string | null;
    /**
     * The project_id property
     */
    projectId?: string | null;
    /**
     * Region code
     */
    region?: string | null;
    /**
     * Tags to organize related resources
     */
    tags?: string[] | null;
    /**
     * Last modified
     */
    updatedAt?: Date | null;
    /**
     * Id of user that created the knowledge base
     */
    userId?: string | null;
    /**
     * Unique id for knowledge base
     */
    uuid?: string | null;
}
/**
 * Data Source configuration for Knowledge Bases
 */
export interface ApiKnowledgeBaseDataSource extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Name of storage bucket - Deprecated, moved to data_source_details
     */
    bucketName?: string | null;
    /**
     * Creation date / time
     */
    createdAt?: Date | null;
    /**
     * File to upload as data source for knowledge base.
     */
    fileUploadDataSource?: ApiFileUploadDataSource | null;
    /**
     * Path of folder or object in bucket - Deprecated, moved to data_source_details
     */
    itemPath?: string | null;
    /**
     * IndexingJob description
     */
    lastIndexingJob?: ApiIndexingJob | null;
    /**
     * Region code - Deprecated, moved to data_source_details
     */
    region?: string | null;
    /**
     * Spaces Bucket Data Source
     */
    spacesDataSource?: ApiSpacesDataSource | null;
    /**
     * Last modified
     */
    updatedAt?: Date | null;
    /**
     * Unique id of knowledge base
     */
    uuid?: string | null;
    /**
     * WebCrawlerDataSource
     */
    webCrawlerDataSource?: ApiWebCrawlerDataSource | null;
}
/**
 * Information for a agent function link
 */
export interface ApiLinkAgentFunctionInputPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Agent id
     */
    agentUuid?: string | null;
    /**
     * Function description
     */
    description?: string | null;
    /**
     * The name of the function in the DigitalOcean functions platform
     */
    faasName?: string | null;
    /**
     * The namespace of the function in the DigitalOcean functions platform
     */
    faasNamespace?: string | null;
    /**
     * Function name
     */
    functionName?: string | null;
    /**
     * Describe the input schema for the function so the agent may call it
     */
    inputSchema?: ApiLinkAgentFunctionInputPublic_input_schema | null;
    /**
     * Describe the output schema for the function so the agent handle its response
     */
    outputSchema?: ApiLinkAgentFunctionInputPublic_output_schema | null;
}
/**
 * Describe the input schema for the function so the agent may call it
 */
export interface ApiLinkAgentFunctionInputPublic_input_schema extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
}
/**
 * Describe the output schema for the function so the agent handle its response
 */
export interface ApiLinkAgentFunctionInputPublic_output_schema extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
}
/**
 * Information about a newly function linked agent
 */
export interface ApiLinkAgentFunctionOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An Agent
     */
    agent?: ApiAgent | null;
}
/**
 * Information for linking an agent
 */
export interface ApiLinkAgentInputPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Routed agent id
     */
    childAgentUuid?: string | null;
    /**
     * The if_case property
     */
    ifCase?: string | null;
    /**
     * A unique identifier for the parent agent.
     */
    parentAgentUuid?: string | null;
    /**
     * Name of route
     */
    routeName?: string | null;
}
/**
 * Information about a newly linked agent
 */
export interface ApiLinkAgentOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Routed agent id
     */
    childAgentUuid?: string | null;
    /**
     * A unique identifier for the parent agent.
     */
    parentAgentUuid?: string | null;
}
/**
 * Information about a linked knowledge base
 */
export interface ApiLinkKnowledgeBaseOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An Agent
     */
    agent?: ApiAgent | null;
}
/**
 * Links to other pages
 */
export interface ApiLinks extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Information about how to reach other pages
     */
    pages?: ApiPages | null;
}
export interface ApiListAgentAPIKeysOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Api key infos
     */
    apiKeyInfos?: ApiAgentAPIKeyInfo[] | null;
    /**
     * Links to other pages
     */
    links?: ApiLinks | null;
    /**
     * Meta information about the data set
     */
    meta?: ApiMeta | null;
}
/**
 * List of Agents that linked to a specific Anthropic Key
 */
export interface ApiListAgentsByAnthropicKeyOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The agents property
     */
    agents?: ApiAgent[] | null;
    /**
     * Links to other pages
     */
    links?: ApiLinks | null;
    /**
     * Meta information about the data set
     */
    meta?: ApiMeta | null;
}
/**
 * List of Agents
 */
export interface ApiListAgentsOutputPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Agents
     */
    agents?: ApiAgentPublic[] | null;
    /**
     * Links to other pages
     */
    links?: ApiLinks | null;
    /**
     * Meta information about the data set
     */
    meta?: ApiMeta | null;
}
/**
 * ListAnthropicAPIKeysOutput is used to return the list of Anthropic API keys for a specific agent.
 */
export interface ApiListAnthropicAPIKeysOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Api key infos
     */
    apiKeyInfos?: ApiAnthropicAPIKeyInfo[] | null;
    /**
     * Links to other pages
     */
    links?: ApiLinks | null;
    /**
     * Meta information about the data set
     */
    meta?: ApiMeta | null;
}
export interface ApiListIndexingJobDataSourcesOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The indexed_data_sources property
     */
    indexedDataSources?: ApiIndexedDataSource[] | null;
}
/**
 * A list of knowledge base data sources
 */
export interface ApiListKnowledgeBaseDataSourcesOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The data sources
     */
    knowledgeBaseDataSources?: ApiKnowledgeBaseDataSource[] | null;
    /**
     * Links to other pages
     */
    links?: ApiLinks | null;
    /**
     * Meta information about the data set
     */
    meta?: ApiMeta | null;
}
/**
 * Indexing jobs
 */
export interface ApiListKnowledgeBaseIndexingJobsOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The indexing jobs
     */
    jobs?: ApiIndexingJob[] | null;
    /**
     * Links to other pages
     */
    links?: ApiLinks | null;
    /**
     * Meta information about the data set
     */
    meta?: ApiMeta | null;
}
/**
 * List of knowledge bases
 */
export interface ApiListKnowledgeBasesOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The knowledge bases
     */
    knowledgeBases?: ApiKnowledgeBase[] | null;
    /**
     * Links to other pages
     */
    links?: ApiLinks | null;
    /**
     * Meta information about the data set
     */
    meta?: ApiMeta | null;
}
/**
 * A list of models
 */
export interface ApiListModelsOutputPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Links to other pages
     */
    links?: ApiLinks | null;
    /**
     * Meta information about the data set
     */
    meta?: ApiMeta | null;
    /**
     * The models
     */
    models?: ApiModelPublic[] | null;
}
/**
 * Region Codes
 */
export interface ApiListRegionsOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Region code
     */
    regions?: GenaiapiRegion[] | null;
}
/**
 * Meta information about the data set
 */
export interface ApiMeta extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The current page
     */
    page?: number | null;
    /**
     * Total number of pages
     */
    pages?: number | null;
    /**
     * Total amount of items over all pages
     */
    total?: number | null;
}
/**
 * Description of a Model
 */
export interface ApiModel extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Agreement Description
     */
    agreement?: ApiAgreement | null;
    /**
     * Creation date / time
     */
    createdAt?: Date | null;
    /**
     * Internally used name
     */
    inferenceName?: string | null;
    /**
     * Internally used version
     */
    inferenceVersion?: string | null;
    /**
     * True if it is a foundational model provided by do
     */
    isFoundational?: boolean | null;
    /**
     * Additional meta data
     */
    metadata?: ApiModel_metadata | null;
    /**
     * Name of the model
     */
    name?: string | null;
    /**
     * Unique id of the model, this model is based on
     */
    parentUuid?: string | null;
    /**
     * The provider property
     */
    provider?: ApiModelProvider | null;
    /**
     * Last modified
     */
    updatedAt?: Date | null;
    /**
     * Model has been fully uploaded
     */
    uploadComplete?: boolean | null;
    /**
     * Download url
     */
    url?: string | null;
    /**
     * Unique id
     */
    uuid?: string | null;
    /**
     * Version Information about a Model
     */
    version?: ApiModelVersion | null;
}
/**
 * Additional meta data
 */
export interface ApiModel_metadata extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
}
export type ApiModelProvider = (typeof ApiModelProviderObject)[keyof typeof ApiModelProviderObject];
/**
 * A machine learning model stored on the GenAI platform
 */
export interface ApiModelPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Agreement Description
     */
    agreement?: ApiAgreement | null;
    /**
     * Creation date / time
     */
    createdAt?: Date | null;
    /**
     * True if it is a foundational model provided by do
     */
    isFoundational?: boolean | null;
    /**
     * Name of the model
     */
    name?: string | null;
    /**
     * Unique id of the model, this model is based on
     */
    parentUuid?: string | null;
    /**
     * Last modified
     */
    updatedAt?: Date | null;
    /**
     * Model has been fully uploaded
     */
    uploadComplete?: boolean | null;
    /**
     * Download url
     */
    url?: string | null;
    /**
     * Unique id
     */
    uuid?: string | null;
    /**
     * Version Information about a Model
     */
    version?: ApiModelVersion | null;
}
/**
 * Version Information about a Model
 */
export interface ApiModelVersion extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Major version number
     */
    major?: number | null;
    /**
     * Minor version number
     */
    minor?: number | null;
    /**
     * Patch version number
     */
    patch?: number | null;
}
/**
 * Information about how to reach other pages
 */
export interface ApiPages extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * First page
     */
    first?: string | null;
    /**
     * Last page
     */
    last?: string | null;
    /**
     * Next page
     */
    next?: string | null;
    /**
     * Previous page
     */
    previous?: string | null;
}
export interface ApiRegenerateAgentAPIKeyOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Agent API Key Info
     */
    apiKeyInfo?: ApiAgentAPIKeyInfo | null;
}
/**
 * Spaces Bucket Data Source
 */
export interface ApiSpacesDataSource extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Spaces bucket name
     */
    bucketName?: string | null;
    /**
     * The item_path property
     */
    itemPath?: string | null;
    /**
     * Region of bucket
     */
    region?: string | null;
}
/**
 * StartKnowledgeBaseIndexingJobInputPublic description
 */
export interface ApiStartKnowledgeBaseIndexingJobInputPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * List of data source ids to index, if none are provided, all data sources will be indexed
     */
    dataSourceUuids?: string[] | null;
    /**
     * Knowledge base id
     */
    knowledgeBaseUuid?: string | null;
}
/**
 * StartKnowledgeBaseIndexingJobOutput description
 */
export interface ApiStartKnowledgeBaseIndexingJobOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * IndexingJob description
     */
    job?: ApiIndexingJob | null;
}
/**
 * Information about a newly unlinked agent
 */
export interface ApiUnlinkAgentFunctionOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An Agent
     */
    agent?: ApiAgent | null;
}
/**
 * Information about a removed linkage
 */
export interface ApiUnlinkAgentOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Routed agent id
     */
    childAgentUuid?: string | null;
    /**
     * Pagent agent id
     */
    parentAgentUuid?: string | null;
}
/**
 * Informatinon about a unlinked knowledge base
 */
export interface ApiUnlinkKnowledgeBaseOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An Agent
     */
    agent?: ApiAgent | null;
}
export interface ApiUpdateAgentAPIKeyInputPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Agent id
     */
    agentUuid?: string | null;
    /**
     * Api key id
     */
    apiKeyUuid?: string | null;
    /**
     * Name
     */
    name?: string | null;
}
export interface ApiUpdateAgentAPIKeyOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Agent API Key Info
     */
    apiKeyInfo?: ApiAgentAPIKeyInfo | null;
}
/**
 * UpdateAgentDeploymentVisbilityOutput description
 */
export interface ApiUpdateAgentDeploymentVisbilityOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An Agent
     */
    agent?: ApiAgent | null;
}
/**
 * UpdateAgentDeploymentVisibilityInputPublic description
 */
export interface ApiUpdateAgentDeploymentVisibilityInputPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Unique id
     */
    uuid?: string | null;
    /**
     * - VISIBILITY_UNKNOWN: The status of the deployment is unknown - VISIBILITY_DISABLED: The deployment is disabled and will no longer service requests - VISIBILITY_PLAYGROUND: Deprecated: No longer a valid state - VISIBILITY_PUBLIC: The deployment is public and will service requests from the public internet - VISIBILITY_PRIVATE: The deployment is private and will only service requests from other agents, or through API keys
     */
    visibility?: ApiDeploymentVisibility | null;
}
/**
 * Information about updating an agent function
 */
export interface ApiUpdateAgentFunctionInputPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Agent id
     */
    agentUuid?: string | null;
    /**
     * Funciton description
     */
    description?: string | null;
    /**
     * The name of the function in the DigitalOcean functions platform
     */
    faasName?: string | null;
    /**
     * The namespace of the function in the DigitalOcean functions platform
     */
    faasNamespace?: string | null;
    /**
     * Function name
     */
    functionName?: string | null;
    /**
     * Function id
     */
    functionUuid?: string | null;
    /**
     * Describe the input schema for the function so the agent may call it
     */
    inputSchema?: ApiUpdateAgentFunctionInputPublic_input_schema | null;
    /**
     * Describe the output schema for the function so the agent handle its response
     */
    outputSchema?: ApiUpdateAgentFunctionInputPublic_output_schema | null;
}
/**
 * Describe the input schema for the function so the agent may call it
 */
export interface ApiUpdateAgentFunctionInputPublic_input_schema extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
}
/**
 * Describe the output schema for the function so the agent handle its response
 */
export interface ApiUpdateAgentFunctionInputPublic_output_schema extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
}
/**
 * The updated agent
 */
export interface ApiUpdateAgentFunctionOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An Agent
     */
    agent?: ApiAgent | null;
}
/**
 * Data to modify an existing Agent
 */
export interface ApiUpdateAgentInputPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Optional anthropic key uuid for use with anthropic models
     */
    anthropicKeyUuid?: string | null;
    /**
     * Agent description
     */
    description?: string | null;
    /**
     * Agent instruction. Instructions help your agent to perform its job effectively. See [Write Effective Agent Instructions](https://docs.digitalocean.com/products/genai-platform/concepts/best-practices/#agent-instructions) for best practices.
     */
    instruction?: string | null;
    /**
     * How many results should be considered from an attached knowledge base
     */
    k?: number | null;
    /**
     * Specifies the maximum number of tokens the model can process in a single input or output, set as a number between 1 and 512. This determines the length of each response.
     */
    maxTokens?: number | null;
    /**
     * Identifier for the foundation model.
     */
    modelUuid?: string | null;
    /**
     * Agent name
     */
    name?: string | null;
    /**
     * The id of the DigitalOcean project this agent will belong to
     */
    projectId?: string | null;
    /**
     * A set of abitrary tags to organize your agent
     */
    tags?: string[] | null;
    /**
     * Controls the modelâ€™s creativity, specified as a number between 0 and 1. Lower values produce more predictable and conservative responses, while higher values encourage creativity and variation.
     */
    temperature?: number | null;
    /**
     * Defines the cumulative probability threshold for word selection, specified as a number between 0 and 1. Higher values allow for more diverse outputs, while lower values ensure focused and coherent responses.
     */
    topP?: number | null;
    /**
     * Unique agent id
     */
    uuid?: string | null;
}
/**
 * Information about an updated agent
 */
export interface ApiUpdateAgentOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An Agent
     */
    agent?: ApiAgent | null;
}
/**
 * UpdateAnthropicAPIKeyInputPublic is used to update an existing Anthropic API key for a specific agent.
 */
export interface ApiUpdateAnthropicAPIKeyInputPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Anthropic API key
     */
    apiKey?: string | null;
    /**
     * API key ID
     */
    apiKeyUuid?: string | null;
    /**
     * Name of the key
     */
    name?: string | null;
}
/**
 * UpdateAnthropicAPIKeyOutput is used to return the updated Anthropic API key.
 */
export interface ApiUpdateAnthropicAPIKeyOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Anthropic API Key Info
     */
    apiKeyInfo?: ApiAnthropicAPIKeyInfo | null;
}
/**
 * Information about updating a knowledge base
 */
export interface ApiUpdateKnowledgeBaseInputPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The id of the DigitalOcean database this knowledge base will use, optiona.
     */
    databaseId?: string | null;
    /**
     * Identifier for the foundation model.
     */
    embeddingModelUuid?: string | null;
    /**
     * Knowledge base name
     */
    name?: string | null;
    /**
     * The id of the DigitalOcean project this knowledge base will belong to
     */
    projectId?: string | null;
    /**
     * Tags to organize your knowledge base.
     */
    tags?: string[] | null;
    /**
     * Knowledge base id
     */
    uuid?: string | null;
}
/**
 * Information about an updated knowledge base
 */
export interface ApiUpdateKnowledgeBaseOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Knowledgebase Description
     */
    knowledgeBase?: ApiKnowledgeBase | null;
}
/**
 * Information about updating the linkage of an agent
 */
export interface ApiUpdateLinkedAgentInputPublic extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Routed agent id
     */
    childAgentUuid?: string | null;
    /**
     * Describes the case in which the child agent should be used
     */
    ifCase?: string | null;
    /**
     * A unique identifier for the parent agent.
     */
    parentAgentUuid?: string | null;
    /**
     * Route name
     */
    routeName?: string | null;
    /**
     * Unique id of linkage
     */
    uuid?: string | null;
}
/**
 * Information about an updated linkage
 */
export interface ApiUpdateLinkedAgentOutput extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Routed agent id
     */
    childAgentUuid?: string | null;
    /**
     * A unique identifier for the parent agent.
     */
    parentAgentUuid?: string | null;
    /**
     * Unique id of linkage
     */
    uuid?: string | null;
}
/**
 * WebCrawlerDataSource
 */
export interface ApiWebCrawlerDataSource extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The base url to crawl.
     */
    baseUrl?: string | null;
    /**
     * Options for specifying how URLs found on pages should be handled. - UNKNOWN: Default unknown value - SCOPED: Only include the base URL. - PATH: Crawl the base URL and linked pages within the URL path. - DOMAIN: Crawl the base URL and linked pages within the same domain. - SUBDOMAINS: Crawl the base URL and linked pages for any subdomain.
     */
    crawlingOption?: ApiCrawlingOption | null;
    /**
     * Whether to ingest and index media (images, etc.) on web pages.
     */
    embedMedia?: boolean | null;
}
/**
 * An application's configuration and status.
 */
export interface App extends AdditionalDataHolder, Parsable {
    /**
     * The active_deployment property
     */
    activeDeployment?: Apps_deployment | null;
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The created_at property
     */
    createdAt?: Date | null;
    /**
     * The dedicated_ips property
     */
    dedicatedIps?: Apps_dedicated_egress_ip[] | null;
    /**
     * The default_ingress property
     */
    defaultIngress?: string | null;
    /**
     * The domains property
     */
    domains?: Apps_domain[] | null;
    /**
     * The id property
     */
    id?: string | null;
    /**
     * The in_progress_deployment property
     */
    inProgressDeployment?: Apps_deployment | null;
    /**
     * The last_deployment_created_at property
     */
    lastDeploymentCreatedAt?: Date | null;
    /**
     * The live_domain property
     */
    liveDomain?: string | null;
    /**
     * The live_url property
     */
    liveUrl?: string | null;
    /**
     * The live_url_base property
     */
    liveUrlBase?: string | null;
    /**
     * The owner_uuid property
     */
    ownerUuid?: string | null;
    /**
     * The pending_deployment property
     */
    pendingDeployment?: Apps_deployment | null;
    /**
     * The pinned_deployment property
     */
    pinnedDeployment?: Apps_deployment | null;
    /**
     * The project_id property
     */
    projectId?: string | null;
    /**
     * The region property
     */
    region?: Apps_region | null;
    /**
     * The desired configuration of an application.
     */
    spec?: App_spec | null;
    /**
     * The tier_slug property
     */
    tierSlug?: string | null;
    /**
     * The updated_at property
     */
    updatedAt?: Date | null;
}
export interface App_alert extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The component_name property
     */
    componentName?: string | null;
    /**
     * The emails property
     */
    emails?: string[] | null;
    /**
     * The id property
     */
    id?: string | null;
    /**
     * The phase property
     */
    phase?: App_alert_phase | null;
    /**
     * The progress property
     */
    progress?: App_alert_progress | null;
    /**
     * The slack_webhooks property
     */
    slackWebhooks?: App_alert_slack_webhook[] | null;
    /**
     * The spec property
     */
    spec?: App_alert_spec | null;
}
export type App_alert_phase = (typeof App_alert_phaseObject)[keyof typeof App_alert_phaseObject];
export interface App_alert_progress extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The steps property
     */
    steps?: App_alert_progress_step[] | null;
}
export interface App_alert_progress_step extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The ended_at property
     */
    endedAt?: Date | null;
    /**
     * The name property
     */
    name?: string | null;
    /**
     * The reason property
     */
    reason?: App_alert_progress_step_reason | null;
    /**
     * The started_at property
     */
    startedAt?: Date | null;
    /**
     * The status property
     */
    status?: App_alert_progress_step_status | null;
}
export interface App_alert_progress_step_reason extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The code property
     */
    code?: string | null;
    /**
     * The message property
     */
    message?: string | null;
}
export type App_alert_progress_step_status = (typeof App_alert_progress_step_statusObject)[keyof typeof App_alert_progress_step_statusObject];
export interface App_alert_slack_webhook extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The channel property
     */
    channel?: string | null;
    /**
     * The url property
     */
    url?: string | null;
}
export interface App_alert_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Is the alert disabled?
     */
    disabled?: boolean | null;
    /**
     * The operator property
     */
    operator?: App_alert_spec_operator | null;
    /**
     * The rule property
     */
    rule?: App_alert_spec_rule | null;
    /**
     * Threshold value for alert
     */
    value?: number | null;
    /**
     * The window property
     */
    window?: App_alert_spec_window | null;
}
export type App_alert_spec_operator = (typeof App_alert_spec_operatorObject)[keyof typeof App_alert_spec_operatorObject];
export type App_alert_spec_rule = (typeof App_alert_spec_ruleObject)[keyof typeof App_alert_spec_ruleObject];
export type App_alert_spec_window = (typeof App_alert_spec_windowObject)[keyof typeof App_alert_spec_windowObject];
export interface App_component_base extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The bitbucket property
     */
    bitbucket?: Apps_bitbucket_source_spec | null;
    /**
     * An optional build command to run while building this component from source.
     */
    buildCommand?: string | null;
    /**
     * The path to the Dockerfile relative to the root of the repo. If set, it will be used to build this component. Otherwise, App Platform will attempt to build it using buildpacks.
     */
    dockerfilePath?: string | null;
    /**
     * An environment slug describing the type of this app. For a full list, please refer to [the product documentation](https://docs.digitalocean.com/products/app-platform/).
     */
    environmentSlug?: string | null;
    /**
     * A list of environment variables made available to the component.
     */
    envs?: App_variable_definition[] | null;
    /**
     * The git property
     */
    git?: Apps_git_source_spec | null;
    /**
     * The github property
     */
    github?: Apps_github_source_spec | null;
    /**
     * The gitlab property
     */
    gitlab?: Apps_gitlab_source_spec | null;
    /**
     * The image property
     */
    image?: Apps_image_source_spec | null;
    /**
     * A list of configured log forwarding destinations.
     */
    logDestinations?: App_log_destination_definition[] | null;
    /**
     * The name. Must be unique across all components within the same app.
     */
    name?: string | null;
    /**
     * An optional run command to override the component's default.
     */
    runCommand?: string | null;
    /**
     * An optional path to the working directory to use for the build. For Dockerfile builds, this will be used as the build context. Must be relative to the root of the repo.
     */
    sourceDir?: string | null;
}
export interface App_database_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name of the underlying DigitalOcean DBaaS cluster. This is required for production databases. For dev databases, if cluster_name is not set, a new cluster will be provisioned.
     */
    clusterName?: string | null;
    /**
     * The name of the MySQL or PostgreSQL database to configure.
     */
    dbName?: string | null;
    /**
     * The name of the MySQL or PostgreSQL user to configure.
     */
    dbUser?: string | null;
    /**
     * - MYSQL: MySQL- PG: PostgreSQL- REDIS: Redis- MONGODB: MongoDB- KAFKA: Kafka- OPENSEARCH: OpenSearch
     */
    engine?: App_database_spec_engine | null;
    /**
     * The database's name. The name must be unique across all components within the same app and cannot use capital letters.
     */
    name?: string | null;
    /**
     * Whether this is a production or dev database.
     */
    production?: boolean | null;
    /**
     * The version of the database engine
     */
    version?: string | null;
}
export type App_database_spec_engine = (typeof App_database_spec_engineObject)[keyof typeof App_database_spec_engineObject];
export interface App_domain_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The hostname for the domain
     */
    domain?: string | null;
    /**
     * The minimum version of TLS a client application can use to access resources for the domain.  Must be one of the following values wrapped within quotations: `"1.2"` or `"1.3"`.
     */
    minimumTlsVersion?: App_domain_spec_minimum_tls_version | null;
    /**
     * - DEFAULT: The default `.ondigitalocean.app` domain assigned to this app- PRIMARY: The primary domain for this app that is displayed as the default in the control panel, used in bindable environment variables, and any other places that reference an app's live URL. Only one domain may be set as primary.- ALIAS: A non-primary domain
     */
    type?: App_domain_spec_type | null;
    /**
     * Indicates whether the domain includes all sub-domains, in addition to the given domain
     */
    wildcard?: boolean | null;
    /**
     * Optional. If the domain uses DigitalOcean DNS and you would like AppPlatform to automatically manage it for you, set this to the name of thedomain on your account.For example, If the domain you are adding is `app.domain.com`, the zonecould be `domain.com`.
     */
    zone?: string | null;
}
export type App_domain_spec_minimum_tls_version = (typeof App_domain_spec_minimum_tls_versionObject)[keyof typeof App_domain_spec_minimum_tls_versionObject];
export type App_domain_spec_type = (typeof App_domain_spec_typeObject)[keyof typeof App_domain_spec_typeObject];
export interface App_domain_validation extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The txt_name property
     */
    txtName?: string | null;
    /**
     * The txt_value property
     */
    txtValue?: string | null;
}
/**
 * Specification for app egress configurations.
 */
export interface App_egress_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The type property
     */
    type?: App_egress_type_spec | null;
}
export type App_egress_type_spec = (typeof App_egress_type_specObject)[keyof typeof App_egress_type_specObject];
export interface App_functions_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The alerts property
     */
    alerts?: App_alert_spec[] | null;
    /**
     * The bitbucket property
     */
    bitbucket?: Apps_bitbucket_source_spec | null;
    /**
     * The cors property
     */
    cors?: Apps_cors_policy | null;
    /**
     * A list of environment variables made available to the component.
     */
    envs?: App_variable_definition[] | null;
    /**
     * The git property
     */
    git?: Apps_git_source_spec | null;
    /**
     * The github property
     */
    github?: Apps_github_source_spec | null;
    /**
     * The gitlab property
     */
    gitlab?: Apps_gitlab_source_spec | null;
    /**
     * A list of configured log forwarding destinations.
     */
    logDestinations?: App_log_destination_definition[] | null;
    /**
     * The name. Must be unique across all components within the same app.
     */
    name?: string | null;
    /**
     * (Deprecated - Use Ingress Rules instead). A list of HTTP routes that should be routed to this component.
     * @deprecated 
     */
    routes?: App_route_spec[] | null;
    /**
     * An optional path to the working directory to use for the build. For Dockerfile builds, this will be used as the build context. Must be relative to the root of the repo.
     */
    sourceDir?: string | null;
}
/**
 * Specification for app ingress configurations.
 */
export interface App_ingress_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Rules for configuring HTTP ingress for component routes, CORS, rewrites, and redirects.
     */
    rules?: App_ingress_spec_rule[] | null;
}
export interface App_ingress_spec_rule extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The component to route to. Only one of `component` or `redirect` may be set.
     */
    component?: App_ingress_spec_rule_routing_component | null;
    /**
     * The cors property
     */
    cors?: Apps_cors_policy | null;
    /**
     * The match configuration for the rule.
     */
    match?: App_ingress_spec_rule_match | null;
    /**
     * The redirect configuration for the rule. Only one of `component` or `redirect` may be set.
     */
    redirect?: App_ingress_spec_rule_routing_redirect | null;
}
/**
 * The match configuration for the rule.
 */
export interface App_ingress_spec_rule_match extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The path to match on.
     */
    path?: App_ingress_spec_rule_string_match | null;
}
/**
 * The component to route to. Only one of `component` or `redirect` may be set.
 */
export interface App_ingress_spec_rule_routing_component extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name of the component to route to.
     */
    name?: string | null;
    /**
     * An optional flag to preserve the path that is forwarded to the backend service. By default, the HTTP request path will be trimmed from the left when forwarded to the component. For example, a component with `path=/api` will have requests to `/api/list` trimmed to `/list`. If this value is `true`, the path will remain `/api/list`. Note: this is not applicable for Functions Components and is mutually exclusive with `rewrite`.
     */
    preservePathPrefix?: string | null;
    /**
     * An optional field that will rewrite the path of the component to be what is specified here. By default, the HTTP request path will be trimmed from the left when forwarded to the component. For example, a component with `path=/api` will have requests to `/api/list` trimmed to `/list`. If you specified the rewrite to be `/v1/`, requests to `/api/list` would be rewritten to `/v1/list`. Note: this is mutually exclusive with `preserve_path_prefix`.
     */
    rewrite?: string | null;
}
/**
 * The redirect configuration for the rule. Only one of `component` or `redirect` may be set.
 */
export interface App_ingress_spec_rule_routing_redirect extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The authority/host to redirect to. This can be a hostname or IP address. Note: use `port` to set the port.
     */
    authority?: string | null;
    /**
     * The port to redirect to.
     */
    port?: number | null;
    /**
     * The redirect code to use. Defaults to `302`. Supported values are 300, 301, 302, 303, 304, 307, 308.
     */
    redirectCode?: number | null;
    /**
     * The scheme to redirect to. Supported values are `http` or `https`. Default: `https`.
     */
    scheme?: string | null;
    /**
     * An optional URI path to redirect to. Note: if this is specified the whole URI of the original request will be overwritten to this value, irrespective of the original request URI being matched.
     */
    uri?: string | null;
}
/**
 * The path to match on.
 */
export interface App_ingress_spec_rule_string_match extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Prefix-based match. For example, `/api` will match `/api`, `/api/`, and any nested paths such as `/api/v1/endpoint`.
     */
    prefix?: string | null;
}
export interface App_job_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Configuration for automatically scaling this component based on metrics.
     */
    autoscaling?: App_job_spec_autoscaling | null;
    /**
     * The bitbucket property
     */
    bitbucket?: Apps_bitbucket_source_spec | null;
    /**
     * An optional build command to run while building this component from source.
     */
    buildCommand?: string | null;
    /**
     * The path to the Dockerfile relative to the root of the repo. If set, it will be used to build this component. Otherwise, App Platform will attempt to build it using buildpacks.
     */
    dockerfilePath?: string | null;
    /**
     * An environment slug describing the type of this app. For a full list, please refer to [the product documentation](https://docs.digitalocean.com/products/app-platform/).
     */
    environmentSlug?: string | null;
    /**
     * A list of environment variables made available to the component.
     */
    envs?: App_variable_definition[] | null;
    /**
     * The git property
     */
    git?: Apps_git_source_spec | null;
    /**
     * The github property
     */
    github?: Apps_github_source_spec | null;
    /**
     * The gitlab property
     */
    gitlab?: Apps_gitlab_source_spec | null;
    /**
     * The image property
     */
    image?: Apps_image_source_spec | null;
    /**
     * The amount of instances that this component should be scaled to. Default: 1. Must not be set if autoscaling is used.
     */
    instanceCount?: number | null;
    /**
     * The instance size to use for this component. Default: `apps-s-1vcpu-0.5gb`
     */
    instanceSizeSlug?: string | null;
    /**
     * - UNSPECIFIED: Default job type, will auto-complete to POST_DEPLOY kind.- PRE_DEPLOY: Indicates a job that runs before an app deployment.- POST_DEPLOY: Indicates a job that runs after an app deployment.- FAILED_DEPLOY: Indicates a job that runs after a component fails to deploy.
     */
    kind?: App_job_spec_kind | null;
    /**
     * A list of configured log forwarding destinations.
     */
    logDestinations?: App_log_destination_definition[] | null;
    /**
     * The name. Must be unique across all components within the same app.
     */
    name?: string | null;
    /**
     * An optional run command to override the component's default.
     */
    runCommand?: string | null;
    /**
     * An optional path to the working directory to use for the build. For Dockerfile builds, this will be used as the build context. Must be relative to the root of the repo.
     */
    sourceDir?: string | null;
    /**
     * The termination property
     */
    termination?: App_job_spec_termination | null;
}
/**
 * Configuration for automatically scaling this component based on metrics.
 */
export interface App_job_spec_autoscaling extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The maximum amount of instances for this component. Must be more than min_instance_count.
     */
    maxInstanceCount?: number | null;
    /**
     * The metrics that the component is scaled on.
     */
    metrics?: App_job_spec_autoscaling_metrics | null;
    /**
     * The minimum amount of instances for this component. Must be less than max_instance_count.
     */
    minInstanceCount?: number | null;
}
/**
 * The metrics that the component is scaled on.
 */
export interface App_job_spec_autoscaling_metrics extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Settings for scaling the component based on CPU utilization.
     */
    cpu?: App_job_spec_autoscaling_metrics_cpu | null;
}
/**
 * Settings for scaling the component based on CPU utilization.
 */
export interface App_job_spec_autoscaling_metrics_cpu extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The average target CPU utilization for the component.
     */
    percent?: number | null;
}
export type App_job_spec_instance_size_slug = string;
export type App_job_spec_kind = (typeof App_job_spec_kindObject)[keyof typeof App_job_spec_kindObject];
export interface App_job_spec_termination extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The number of seconds to wait between sending a TERM signal to a container and issuing a KILL which causes immediate shutdown. (Default 120)
     */
    gracePeriodSeconds?: number | null;
}
/**
 * DataDog configuration.
 */
export interface App_log_destination_datadog_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Datadog API key.
     */
    apiKey?: string | null;
    /**
     * Datadog HTTP log intake endpoint.
     */
    endpoint?: string | null;
}
export interface App_log_destination_definition extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * DataDog configuration.
     */
    datadog?: App_log_destination_datadog_spec | null;
    /**
     * Logtail configuration.
     */
    logtail?: App_log_destination_logtail_spec | null;
    /**
     * The name property
     */
    name?: string | null;
    /**
     * OpenSearch configuration.
     */
    openSearch?: App_log_destination_open_search_spec | null;
    /**
     * Papertrail configuration.
     */
    papertrail?: App_log_destination_papertrail_spec | null;
}
/**
 * Logtail configuration.
 */
export interface App_log_destination_logtail_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Logtail token.
     */
    token?: string | null;
}
/**
 * OpenSearch configuration.
 */
export interface App_log_destination_open_search_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Configure Username and/or Password for Basic authentication.
     */
    basicAuth?: App_log_destination_open_search_spec_basic_auth | null;
    /**
     * The name of a DigitalOcean DBaaS OpenSearch cluster to use as a log forwarding destination.Cannot be specified if `endpoint` is also specified.
     */
    clusterName?: string | null;
    /**
     * OpenSearch API Endpoint. Only HTTPS is supported. Format: https://<host>:<port>.Cannot be specified if `cluster_name` is also specified.
     */
    endpoint?: string | null;
    /**
     * The index name to use for the logs. If not set, the default index name is "logs".
     */
    indexName?: string | null;
}
/**
 * Configure Username and/or Password for Basic authentication.
 */
export interface App_log_destination_open_search_spec_basic_auth extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Password for user defined in User. Is required when `endpoint` is set.Cannot be set if using a DigitalOcean DBaaS OpenSearch cluster.
     */
    password?: UntypedNode | null;
    /**
     * Username to authenticate with. Only required when `endpoint` is set.Defaults to `doadmin` when `cluster_name` is set.
     */
    user?: string | null;
}
/**
 * Papertrail configuration.
 */
export interface App_log_destination_papertrail_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Papertrail syslog endpoint.
     */
    endpoint?: string | null;
}
/**
 * Specification to configure maintenance settings for the app, such as maintenance mode and archiving the app.
 */
export interface App_maintenance_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Indicates whether the app should be archived. Setting this to true implies that enabled is set to true.
     */
    archive?: boolean | null;
    /**
     * Indicates whether maintenance mode should be enabled for the app.
     */
    enabled?: boolean | null;
    /**
     * A custom offline page to display when maintenance mode is enabled or the app is archived.
     */
    offlinePageUrl?: string | null;
}
export interface App_metrics_bandwidth_usage extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A list of bandwidth usage details by app.
     */
    appBandwidthUsage?: App_metrics_bandwidth_usage_details[] | null;
    /**
     * The date for the metrics data.
     */
    date?: Date | null;
}
/**
 * Bandwidth usage for an app.
 */
export interface App_metrics_bandwidth_usage_details extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The ID of the app.
     */
    appId?: string | null;
    /**
     * The used bandwidth amount in bytes.
     */
    bandwidthBytes?: string | null;
}
export interface App_metrics_bandwidth_usage_request extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A list of app IDs to query bandwidth metrics for.
     */
    appIds?: string[] | null;
    /**
     * Optional day to query. Only the date component of the timestamp will be considered. Default: yesterday.
     */
    date?: Date | null;
}
export interface App_propose extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An optional ID of an existing app. If set, the spec will be treated as a proposed update to the specified app. The existing app is not modified using this method.
     */
    appId?: string | null;
    /**
     * The desired configuration of an application.
     */
    spec?: App_spec | null;
}
export interface App_propose_response extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The monthly cost of the proposed app in USD.
     */
    appCost?: number | null;
    /**
     * Indicates whether the app is a static app.
     */
    appIsStatic?: boolean | null;
    /**
     * Indicates whether the app name is available.
     */
    appNameAvailable?: boolean | null;
    /**
     * The suggested name if the proposed app name is unavailable.
     */
    appNameSuggestion?: string | null;
    /**
     * The monthly cost of the proposed app in USD using the previous pricing plan tier. For example, if you propose an app that uses the Professional tier, the `app_tier_downgrade_cost` field displays the monthly cost of the app if it were to use the Basic tier. If the proposed app already uses the lest expensive tier, the field is empty.
     * @deprecated 
     */
    appTierDowngradeCost?: number | null;
    /**
     * The maximum number of free static apps the account can have. We will charge you for any additional static apps.
     */
    existingStaticApps?: string | null;
    /**
     * The desired configuration of an application.
     */
    spec?: App_spec | null;
}
export interface App_response extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An application's configuration and status.
     */
    app?: App | null;
}
export interface App_rollback_validation_condition extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A code identifier that represents the failing condition.Failing conditions:  - `incompatible_phase` - indicates that the deployment's phase is not suitable for rollback.  - `incompatible_result` - indicates that the deployment's result is not suitable for rollback.  - `exceeded_revision_limit` - indicates that the app has exceeded the rollback revision limits for its tier.  - `app_pinned` - indicates that there is already a rollback in progress and the app is pinned.  - `database_config_conflict` - indicates that the deployment's database config is different than the current config.  - `region_conflict` - indicates that the deployment's region differs from the current app region.  Warning conditions:  - `static_site_requires_rebuild` - indicates that the deployment contains at least one static site that will require a rebuild.  - `image_source_missing_digest` - indicates that the deployment contains at least one component with an image source that is missing a digest.
     */
    code?: App_rollback_validation_condition_code | null;
    /**
     * The components property
     */
    components?: string[] | null;
    /**
     * A human-readable message describing the failing condition.
     */
    message?: string | null;
}
export type App_rollback_validation_condition_code = (typeof App_rollback_validation_condition_codeObject)[keyof typeof App_rollback_validation_condition_codeObject];
export interface App_route_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * (Deprecated - Use Ingress Rules instead). An HTTP path prefix. Paths must start with / and must be unique across all components within an app.
     */
    path?: string | null;
    /**
     * An optional flag to preserve the path that is forwarded to the backend service. By default, the HTTP request path will be trimmed from the left when forwarded to the component. For example, a component with `path=/api` will have requests to `/api/list` trimmed to `/list`. If this value is `true`, the path will remain `/api/list`.
     */
    preservePathPrefix?: boolean | null;
}
export interface App_service_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Configuration for automatically scaling this component based on metrics.
     */
    autoscaling?: App_service_spec_autoscaling | null;
    /**
     * The bitbucket property
     */
    bitbucket?: Apps_bitbucket_source_spec | null;
    /**
     * An optional build command to run while building this component from source.
     */
    buildCommand?: string | null;
    /**
     * The cors property
     */
    cors?: Apps_cors_policy | null;
    /**
     * The path to the Dockerfile relative to the root of the repo. If set, it will be used to build this component. Otherwise, App Platform will attempt to build it using buildpacks.
     */
    dockerfilePath?: string | null;
    /**
     * An environment slug describing the type of this app. For a full list, please refer to [the product documentation](https://docs.digitalocean.com/products/app-platform/).
     */
    environmentSlug?: string | null;
    /**
     * A list of environment variables made available to the component.
     */
    envs?: App_variable_definition[] | null;
    /**
     * The git property
     */
    git?: Apps_git_source_spec | null;
    /**
     * The github property
     */
    github?: Apps_github_source_spec | null;
    /**
     * The gitlab property
     */
    gitlab?: Apps_gitlab_source_spec | null;
    /**
     * The health_check property
     */
    healthCheck?: App_service_spec_health_check | null;
    /**
     * The internal port on which this service's run command will listen. Default: 8080If there is not an environment variable with the name `PORT`, one will be automatically added with its value set to the value of this field.
     */
    httpPort?: number | null;
    /**
     * The image property
     */
    image?: Apps_image_source_spec | null;
    /**
     * The amount of instances that this component should be scaled to. Default: 1. Must not be set if autoscaling is used.
     */
    instanceCount?: number | null;
    /**
     * The instance size to use for this component. Default: `apps-s-1vcpu-0.5gb`
     */
    instanceSizeSlug?: string | null;
    /**
     * The ports on which this service will listen for internal traffic.
     */
    internalPorts?: number[] | null;
    /**
     * A list of configured log forwarding destinations.
     */
    logDestinations?: App_log_destination_definition[] | null;
    /**
     * The name. Must be unique across all components within the same app.
     */
    name?: string | null;
    /**
     * The protocol which the service uses to serve traffic on the http_port.- `HTTP`: The app is serving the HTTP protocol. Default.- `HTTP2`: The app is serving the HTTP/2 protocol. Currently, this needs to be implemented in the service by serving HTTP/2 cleartext (h2c).
     */
    protocol?: App_service_spec_protocol | null;
    /**
     * (Deprecated - Use Ingress Rules instead). A list of HTTP routes that should be routed to this component.
     * @deprecated 
     */
    routes?: App_route_spec[] | null;
    /**
     * An optional run command to override the component's default.
     */
    runCommand?: string | null;
    /**
     * An optional path to the working directory to use for the build. For Dockerfile builds, this will be used as the build context. Must be relative to the root of the repo.
     */
    sourceDir?: string | null;
    /**
     * The termination property
     */
    termination?: App_service_spec_termination | null;
}
/**
 * Configuration for automatically scaling this component based on metrics.
 */
export interface App_service_spec_autoscaling extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The maximum amount of instances for this component. Must be more than min_instance_count.
     */
    maxInstanceCount?: number | null;
    /**
     * The metrics that the component is scaled on.
     */
    metrics?: App_service_spec_autoscaling_metrics | null;
    /**
     * The minimum amount of instances for this component. Must be less than max_instance_count.
     */
    minInstanceCount?: number | null;
}
/**
 * The metrics that the component is scaled on.
 */
export interface App_service_spec_autoscaling_metrics extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Settings for scaling the component based on CPU utilization.
     */
    cpu?: App_service_spec_autoscaling_metrics_cpu | null;
}
/**
 * Settings for scaling the component based on CPU utilization.
 */
export interface App_service_spec_autoscaling_metrics_cpu extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The average target CPU utilization for the component.
     */
    percent?: number | null;
}
export interface App_service_spec_health_check extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The number of failed health checks before considered unhealthy.
     */
    failureThreshold?: number | null;
    /**
     * The route path used for the HTTP health check ping. If not set, the HTTP health check will be disabled and a TCP health check used instead.
     */
    httpPath?: string | null;
    /**
     * The number of seconds to wait before beginning health checks.
     */
    initialDelaySeconds?: number | null;
    /**
     * The number of seconds to wait between health checks.
     */
    periodSeconds?: number | null;
    /**
     * The port on which the health check will be performed. If not set, the health check will be performed on the component's http_port.
     */
    port?: number | null;
    /**
     * The number of successful health checks before considered healthy.
     */
    successThreshold?: number | null;
    /**
     * The number of seconds after which the check times out.
     */
    timeoutSeconds?: number | null;
}
export type App_service_spec_instance_size_slug = string;
export type App_service_spec_protocol = (typeof App_service_spec_protocolObject)[keyof typeof App_service_spec_protocolObject];
export interface App_service_spec_termination extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The number of seconds to wait between selecting a container instance for termination and issuing the TERM signal. Selecting a container instance for termination begins an asynchronous drain of new requests on upstream load-balancers. (Default 15)
     */
    drainSeconds?: number | null;
    /**
     * The number of seconds to wait between sending a TERM signal to a container and issuing a KILL which causes immediate shutdown. (Default 120)
     */
    gracePeriodSeconds?: number | null;
}
/**
 * The desired configuration of an application.
 */
export interface App_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Database instances which can provide persistence to workloads within theapplication.
     */
    databases?: App_database_spec[] | null;
    /**
     * A set of hostnames where the application will be available.
     */
    domains?: App_domain_spec[] | null;
    /**
     * Specification for app egress configurations.
     */
    egress?: App_egress_spec | null;
    /**
     * Workloads which expose publicly-accessible HTTP services via Functions Components.
     */
    functions?: App_functions_spec[] | null;
    /**
     * Specification for app ingress configurations.
     */
    ingress?: App_ingress_spec | null;
    /**
     * Pre and post deployment workloads which do not expose publicly-accessible HTTP routes.
     */
    jobs?: App_job_spec[] | null;
    /**
     * Specification to configure maintenance settings for the app, such as maintenance mode and archiving the app.
     */
    maintenance?: App_maintenance_spec | null;
    /**
     * The name of the app. Must be unique across all apps in the same account.
     */
    name?: string | null;
    /**
     * The slug form of the geographical origin of the app. Default: `nearest available`
     */
    region?: App_spec_region | null;
    /**
     * Workloads which expose publicly-accessible HTTP services.
     */
    services?: App_service_spec[] | null;
    /**
     * Content which can be rendered to static web assets.
     */
    staticSites?: App_static_site_spec[] | null;
    /**
     * Workloads which do not expose publicly-accessible HTTP services.
     */
    workers?: App_worker_spec[] | null;
}
export type App_spec_region = (typeof App_spec_regionObject)[keyof typeof App_spec_regionObject];
export interface App_static_site_spec extends App_component_base, Parsable {
    /**
     * The name of the document to use as the fallback for any requests to documents that are not found when serving this static site. Only 1 of `catchall_document` or `error_document` can be set.
     */
    catchallDocument?: string | null;
    /**
     * The cors property
     */
    cors?: Apps_cors_policy | null;
    /**
     * The name of the error document to use when serving this static site. Default: 404.html. If no such file exists within the built assets, App Platform will supply one.
     */
    errorDocument?: string | null;
    /**
     * The name of the index document to use when serving this static site. Default: index.html
     */
    indexDocument?: string | null;
    /**
     * An optional path to where the built assets will be located, relative to the build context. If not set, App Platform will automatically scan for these directory names: `_static`, `dist`, `public`, `build`.
     */
    outputDir?: string | null;
    /**
     * (Deprecated - Use Ingress Rules instead). A list of HTTP routes that should be routed to this component.
     * @deprecated 
     */
    routes?: App_route_spec[] | null;
}
export interface App_variable_definition extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The variable name
     */
    key?: string | null;
    /**
     * - RUN_TIME: Made available only at run-time- BUILD_TIME: Made available only at build-time- RUN_AND_BUILD_TIME: Made available at both build and run-time
     */
    scope?: App_variable_definition_scope | null;
    /**
     * - GENERAL: A plain-text environment variable- SECRET: A secret encrypted environment variable
     */
    type?: App_variable_definition_type | null;
    /**
     * The value. If the type is `SECRET`, the value will be encrypted on first submission. On following submissions, the encrypted value should be used.
     */
    value?: string | null;
}
export type App_variable_definition_scope = (typeof App_variable_definition_scopeObject)[keyof typeof App_variable_definition_scopeObject];
export type App_variable_definition_type = (typeof App_variable_definition_typeObject)[keyof typeof App_variable_definition_typeObject];
export interface App_worker_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Configuration for automatically scaling this component based on metrics.
     */
    autoscaling?: App_worker_spec_autoscaling | null;
    /**
     * The bitbucket property
     */
    bitbucket?: Apps_bitbucket_source_spec | null;
    /**
     * An optional build command to run while building this component from source.
     */
    buildCommand?: string | null;
    /**
     * The path to the Dockerfile relative to the root of the repo. If set, it will be used to build this component. Otherwise, App Platform will attempt to build it using buildpacks.
     */
    dockerfilePath?: string | null;
    /**
     * An environment slug describing the type of this app. For a full list, please refer to [the product documentation](https://docs.digitalocean.com/products/app-platform/).
     */
    environmentSlug?: string | null;
    /**
     * A list of environment variables made available to the component.
     */
    envs?: App_variable_definition[] | null;
    /**
     * The git property
     */
    git?: Apps_git_source_spec | null;
    /**
     * The github property
     */
    github?: Apps_github_source_spec | null;
    /**
     * The gitlab property
     */
    gitlab?: Apps_gitlab_source_spec | null;
    /**
     * The image property
     */
    image?: Apps_image_source_spec | null;
    /**
     * The amount of instances that this component should be scaled to. Default: 1. Must not be set if autoscaling is used.
     */
    instanceCount?: number | null;
    /**
     * The instance size to use for this component. Default: `apps-s-1vcpu-0.5gb`
     */
    instanceSizeSlug?: string | null;
    /**
     * A list of configured log forwarding destinations.
     */
    logDestinations?: App_log_destination_definition[] | null;
    /**
     * The name. Must be unique across all components within the same app.
     */
    name?: string | null;
    /**
     * An optional run command to override the component's default.
     */
    runCommand?: string | null;
    /**
     * An optional path to the working directory to use for the build. For Dockerfile builds, this will be used as the build context. Must be relative to the root of the repo.
     */
    sourceDir?: string | null;
    /**
     * The termination property
     */
    termination?: App_worker_spec_termination | null;
}
/**
 * Configuration for automatically scaling this component based on metrics.
 */
export interface App_worker_spec_autoscaling extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The maximum amount of instances for this component. Must be more than min_instance_count.
     */
    maxInstanceCount?: number | null;
    /**
     * The metrics that the component is scaled on.
     */
    metrics?: App_worker_spec_autoscaling_metrics | null;
    /**
     * The minimum amount of instances for this component. Must be less than max_instance_count.
     */
    minInstanceCount?: number | null;
}
/**
 * The metrics that the component is scaled on.
 */
export interface App_worker_spec_autoscaling_metrics extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Settings for scaling the component based on CPU utilization.
     */
    cpu?: App_worker_spec_autoscaling_metrics_cpu | null;
}
/**
 * Settings for scaling the component based on CPU utilization.
 */
export interface App_worker_spec_autoscaling_metrics_cpu extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The average target CPU utilization for the component.
     */
    percent?: number | null;
}
export type App_worker_spec_instance_size_slug = string;
export interface App_worker_spec_termination extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The number of seconds to wait between sending a TERM signal to a container and issuing a KILL which causes immediate shutdown. (Default 120)
     */
    gracePeriodSeconds?: number | null;
}
export interface Apps_alert_response extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The alert property
     */
    alert?: App_alert | null;
}
export interface Apps_assign_app_alert_destinations_request extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The emails property
     */
    emails?: string[] | null;
    /**
     * The slack_webhooks property
     */
    slackWebhooks?: App_alert_slack_webhook[] | null;
}
export interface Apps_bitbucket_source_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name of the branch to use
     */
    branch?: string | null;
    /**
     * Whether to automatically deploy new commits made to the repo
     */
    deployOnPush?: boolean | null;
    /**
     * The name of the repo in the format owner/repo. Example: `digitalocean/sample-golang`
     */
    repo?: string | null;
}
export interface Apps_cors_policy extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Whether browsers should expose the response to the client-side JavaScript code when the requestâ€™s credentials mode is include. This configures the `Access-Control-Allow-Credentials` header.
     */
    allowCredentials?: boolean | null;
    /**
     * The set of allowed HTTP request headers. This configures the `Access-Control-Allow-Headers` header.
     */
    allowHeaders?: string[] | null;
    /**
     * The set of allowed HTTP methods. This configures the `Access-Control-Allow-Methods` header.
     */
    allowMethods?: string[] | null;
    /**
     * The set of allowed CORS origins.
     */
    allowOrigins?: Apps_string_match[] | null;
    /**
     * The set of HTTP response headers that browsers are allowed to access. This configures the `Access-Control-Expose-Headers` header.
     */
    exposeHeaders?: string[] | null;
    /**
     * An optional duration specifying how long browsers can cache the results of a preflight request. This configures the `Access-Control-Max-Age` header.
     */
    maxAge?: string | null;
}
export interface Apps_create_app_request extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The ID of the project the app should be assigned to. If omitted, it will be assigned to your default project.
     */
    projectId?: string | null;
    /**
     * The desired configuration of an application.
     */
    spec?: App_spec | null;
}
export interface Apps_create_deployment_request extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The force_build property
     */
    forceBuild?: boolean | null;
}
export interface Apps_dedicated_egress_ip extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The id property
     */
    id?: string | null;
    /**
     * The ip property
     */
    ip?: string | null;
    /**
     * The status property
     */
    status?: Apps_dedicated_egress_ip_status | null;
}
export type Apps_dedicated_egress_ip_status = (typeof Apps_dedicated_egress_ip_statusObject)[keyof typeof Apps_dedicated_egress_ip_statusObject];
export interface Apps_delete_app_response extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The id property
     */
    id?: string | null;
}
export interface Apps_deployment extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The cause property
     */
    cause?: string | null;
    /**
     * The cloned_from property
     */
    clonedFrom?: string | null;
    /**
     * The created_at property
     */
    createdAt?: Date | null;
    /**
     * The functions property
     */
    functions?: Apps_deployment_functions[] | null;
    /**
     * The id property
     */
    id?: string | null;
    /**
     * The jobs property
     */
    jobs?: Apps_deployment_job[] | null;
    /**
     * The phase property
     */
    phase?: Apps_deployment_phase | null;
    /**
     * The phase_last_updated_at property
     */
    phaseLastUpdatedAt?: Date | null;
    /**
     * The progress property
     */
    progress?: Apps_deployment_progress | null;
    /**
     * The services property
     */
    services?: Apps_deployment_service[] | null;
    /**
     * The desired configuration of an application.
     */
    spec?: App_spec | null;
    /**
     * The static_sites property
     */
    staticSites?: Apps_deployment_static_site[] | null;
    /**
     * The tier_slug property
     */
    tierSlug?: string | null;
    /**
     * The updated_at property
     */
    updatedAt?: Date | null;
    /**
     * The workers property
     */
    workers?: Apps_deployment_worker[] | null;
}
export interface Apps_deployment_functions extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name property
     */
    name?: string | null;
    /**
     * The namespace where the functions are deployed.
     */
    namespace?: string | null;
    /**
     * The commit hash of the repository that was used to build this functions component.
     */
    sourceCommitHash?: string | null;
}
export interface Apps_deployment_job extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name property
     */
    name?: string | null;
    /**
     * The source_commit_hash property
     */
    sourceCommitHash?: string | null;
}
export type Apps_deployment_phase = (typeof Apps_deployment_phaseObject)[keyof typeof Apps_deployment_phaseObject];
export interface Apps_deployment_progress extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The error_steps property
     */
    errorSteps?: number | null;
    /**
     * The pending_steps property
     */
    pendingSteps?: number | null;
    /**
     * The running_steps property
     */
    runningSteps?: number | null;
    /**
     * The steps property
     */
    steps?: Apps_deployment_progress_step[] | null;
    /**
     * The success_steps property
     */
    successSteps?: number | null;
    /**
     * The summary_steps property
     */
    summarySteps?: Apps_deployment_progress_step[] | null;
    /**
     * The total_steps property
     */
    totalSteps?: number | null;
}
export interface Apps_deployment_progress_step extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The component_name property
     */
    componentName?: string | null;
    /**
     * The ended_at property
     */
    endedAt?: Date | null;
    /**
     * The base of a human-readable description of the step intended to be combined with the component name for presentation. For example:`message_base` = "Building service"`component_name` = "api"
     */
    messageBase?: string | null;
    /**
     * The name property
     */
    name?: string | null;
    /**
     * The reason property
     */
    reason?: Apps_deployment_progress_step_reason | null;
    /**
     * The started_at property
     */
    startedAt?: Date | null;
    /**
     * The status property
     */
    status?: Apps_deployment_progress_step_status | null;
    /**
     * The steps property
     */
    steps?: Apps_deployment_progress_step_steps[] | null;
}
export interface Apps_deployment_progress_step_reason extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The code property
     */
    code?: string | null;
    /**
     * The message property
     */
    message?: string | null;
}
export type Apps_deployment_progress_step_status = (typeof Apps_deployment_progress_step_statusObject)[keyof typeof Apps_deployment_progress_step_statusObject];
export interface Apps_deployment_progress_step_steps extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
}
export interface Apps_deployment_response extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The deployment property
     */
    deployment?: Apps_deployment | null;
}
export interface Apps_deployment_service extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name property
     */
    name?: string | null;
    /**
     * The source_commit_hash property
     */
    sourceCommitHash?: string | null;
}
export interface Apps_deployment_static_site extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name property
     */
    name?: string | null;
    /**
     * The source_commit_hash property
     */
    sourceCommitHash?: string | null;
}
export interface Apps_deployment_worker extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name property
     */
    name?: string | null;
    /**
     * The source_commit_hash property
     */
    sourceCommitHash?: string | null;
}
export interface Apps_deployments_response extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The deployments property
     */
    deployments?: Apps_deployment[] | null;
    /**
     * The links property
     */
    links?: Page_links | null;
    /**
     * The meta property
     */
    meta?: Meta_properties | null;
}
export interface Apps_domain extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The certificate_expires_at property
     */
    certificateExpiresAt?: Date | null;
    /**
     * The id property
     */
    id?: string | null;
    /**
     * The phase property
     */
    phase?: Apps_domain_phase | null;
    /**
     * The progress property
     */
    progress?: Apps_domain_progress | null;
    /**
     * The rotate_validation_records property
     */
    rotateValidationRecords?: boolean | null;
    /**
     * The spec property
     */
    spec?: App_domain_spec | null;
    /**
     * The validations property
     */
    validations?: App_domain_validation[] | null;
}
export type Apps_domain_phase = (typeof Apps_domain_phaseObject)[keyof typeof Apps_domain_phaseObject];
export interface Apps_domain_progress extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The steps property
     */
    steps?: Apps_domain_progress_steps[] | null;
}
export interface Apps_domain_progress_steps extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
}
export interface Apps_get_exec_response extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A websocket URL that allows sending/receiving console input and receiving console output.
     */
    url?: string | null;
}
export interface Apps_get_instance_size_response extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The instance_size property
     */
    instanceSize?: Apps_instance_size | null;
}
export interface Apps_get_logs_response extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The historic_urls property
     */
    historicUrls?: string[] | null;
    /**
     * A URL of the real-time live logs. This URL may use either the `https://` or `wss://` protocols and will keep pushing live logs as they become available.
     */
    liveUrl?: string | null;
}
export interface Apps_git_source_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name of the branch to use
     */
    branch?: string | null;
    /**
     * The clone URL of the repo. Example: `https://github.com/digitalocean/sample-golang.git`
     */
    repoCloneUrl?: string | null;
}
export interface Apps_github_source_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name of the branch to use
     */
    branch?: string | null;
    /**
     * Whether to automatically deploy new commits made to the repo
     */
    deployOnPush?: boolean | null;
    /**
     * The name of the repo in the format owner/repo. Example: `digitalocean/sample-golang`
     */
    repo?: string | null;
}
export interface Apps_gitlab_source_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name of the branch to use
     */
    branch?: string | null;
    /**
     * Whether to automatically deploy new commits made to the repo
     */
    deployOnPush?: boolean | null;
    /**
     * The name of the repo in the format owner/repo. Example: `digitalocean/sample-golang`
     */
    repo?: string | null;
}
export interface Apps_image_source_spec extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The deploy_on_push property
     */
    deployOnPush?: Apps_image_source_spec_deploy_on_push | null;
    /**
     * The image digest. Cannot be specified if tag is provided.
     */
    digest?: string | null;
    /**
     * The registry name. Must be left empty for the `DOCR` registry type.
     */
    registry?: string | null;
    /**
     * The credentials to be able to pull the image. The value will be encrypted on first submission. On following submissions, the encrypted value should be used.- "$username:$access_token" for registries of type `DOCKER_HUB`.- "$username:$access_token" for registries of type `GHCR`.
     */
    registryCredentials?: string | null;
    /**
     * - DOCKER_HUB: The DockerHub container registry type.- DOCR: The DigitalOcean container registry type.- GHCR: The Github container registry type.
     */
    registryType?: Apps_image_source_spec_registry_type | null;
    /**
     * The repository name.
     */
    repository?: string | null;
    /**
     * The repository tag. Defaults to `latest` if not provided and no digest is provided. Cannot be specified if digest is provided.
     */
    tag?: string | null;
}
export interface Apps_image_source_spec_deploy_on_push extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Whether to automatically deploy new images. Can only be used for images hosted in DOCR and can only be used with an image tag, not a specific digest.
     */
    enabled?: boolean | null;
}
export type Apps_image_source_spec_registry_type = (typeof Apps_image_source_spec_registry_typeObject)[keyof typeof Apps_image_source_spec_registry_typeObject];
export interface Apps_instance_size extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The bandwidth_allowance_gib property
     */
    bandwidthAllowanceGib?: string | null;
    /**
     * The cpus property
     */
    cpus?: string | null;
    /**
     * The cpu_type property
     */
    cpuType?: Instance_size_cpu_type | null;
    /**
     * The deprecation_intent property
     */
    deprecationIntent?: boolean | null;
    /**
     * The memory_bytes property
     */
    memoryBytes?: string | null;
    /**
     * The name property
     */
    name?: string | null;
    /**
     * The scalable property
     */
    scalable?: boolean | null;
    /**
     * The single_instance_only property
     */
    singleInstanceOnly?: boolean | null;
    /**
     * The slug property
     */
    slug?: string | null;
    /**
     * The tier_downgrade_to property
     * @deprecated 
     */
    tierDowngradeTo?: string | null;
    /**
     * The tier_slug property
     */
    tierSlug?: string | null;
    /**
     * The tier_upgrade_to property
     * @deprecated 
     */
    tierUpgradeTo?: string | null;
    /**
     * The usd_per_month property
     */
    usdPerMonth?: string | null;
    /**
     * The usd_per_second property
     */
    usdPerSecond?: string | null;
}
export interface Apps_list_alerts_response extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The alerts property
     */
    alerts?: App_alert[] | null;
}
export interface Apps_list_instance_sizes_response extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The discount_percent property
     */
    discountPercent?: number | null;
    /**
     * The instance_sizes property
     */
    instanceSizes?: Apps_instance_size[] | null;
}
export interface Apps_list_regions_response extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The regions property
     */
    regions?: Apps_region[] | null;
}
export interface Apps_region extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The continent property
     */
    continent?: string | null;
    /**
     * The data_centers property
     */
    dataCenters?: string[] | null;
    /**
     * Whether or not the region is presented as the default.
     */
    defaultEscaped?: boolean | null;
    /**
     * The disabled property
     */
    disabled?: boolean | null;
    /**
     * The flag property
     */
    flag?: string | null;
    /**
     * The label property
     */
    label?: string | null;
    /**
     * The reason property
     */
    reason?: string | null;
    /**
     * The slug property
     */
    slug?: string | null;
}
export interface Apps_response extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The apps property
     */
    apps?: App[] | null;
    /**
     * The links property
     */
    links?: Page_links | null;
    /**
     * The meta property
     */
    meta?: Meta_properties | null;
}
export interface Apps_restart_request extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The components property
     */
    components?: string[] | null;
}
export interface Apps_rollback_app_request extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The ID of the deployment to rollback to.
     */
    deploymentId?: string | null;
    /**
     * Whether to skip pinning the rollback deployment. If false, the rollback deployment will be pinned and any new deployments including Auto Deploy on Push hooks will be disabled until the rollback is either manually committed or reverted via the CommitAppRollback or RevertAppRollback endpoints respectively. If true, the rollback will be immediately committed and the app will remain unpinned.
     */
    skipPin?: boolean | null;
}
export interface Apps_string_match extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Exact string match. Only 1 of `exact`, `prefix`, or `regex` must be set.
     */
    exact?: string | null;
    /**
     * Prefix-based match. Only 1 of `exact`, `prefix`, or `regex` must be set.
     * @deprecated 
     */
    prefix?: string | null;
    /**
     * RE2 style regex-based match. Only 1 of `exact`, `prefix`, or `regex` must be set. For more information about RE2 syntax, see: https://github.com/google/re2/wiki/Syntax
     */
    regex?: string | null;
}
export interface Apps_update_app_request extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The desired configuration of an application.
     */
    spec?: App_spec | null;
    /**
     * Whether or not to update the source versions (for example fetching a new commit or image digest) of all components. By default (when this is false) only newly added sources will be updated to avoid changes like updating the scale of a component from also updating the respective code.
     */
    updateAllSourceVersions?: boolean | null;
}
export interface Associated_kubernetes_resource extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The ID of a resource associated with a Kubernetes cluster.
     */
    id?: string | null;
    /**
     * The name of a resource associated with a Kubernetes cluster.
     */
    name?: string | null;
}
/**
 * An object containing the IDs of resources associated with a Kubernetes cluster.
 */
export interface Associated_kubernetes_resources extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A list of names and IDs for associated load balancers that can be destroyed along with the cluster.
     */
    loadBalancers?: Associated_kubernetes_resource[] | null;
    /**
     * A list of names and IDs for associated volumes that can be destroyed along with the cluster.
     */
    volumes?: Associated_kubernetes_resource[] | null;
    /**
     * A list of names and IDs for associated volume snapshots that can be destroyed along with the cluster.
     */
    volumeSnapshots?: Associated_kubernetes_resource[] | null;
}
/**
 * An objects containing information about a resource associated with a Droplet.
 */
export interface Associated_resource extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The cost of the resource in USD per month if the resource is retained after the Droplet is destroyed.
     */
    cost?: string | null;
    /**
     * The unique identifier for the resource associated with the Droplet.
     */
    id?: string | null;
    /**
     * The name of the resource associated with the Droplet.
     */
    name?: string | null;
}
/**
 * An objects containing information about a resources scheduled for deletion.
 */
export interface Associated_resource_status extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A time value given in ISO8601 combined date and time format indicating when the requested action was completed.
     */
    completedAt?: Date | null;
    /**
     * An object containing information about a resource scheduled for deletion.
     */
    droplet?: Destroyed_associated_resource | null;
    /**
     * A count of the associated resources that failed to be destroyed, if any.
     */
    failures?: number | null;
    /**
     * An object containing additional information about resource related to a Droplet requested to be destroyed.
     */
    resources?: Associated_resource_status_resources | null;
}
/**
 * An object containing additional information about resource related to a Droplet requested to be destroyed.
 */
export interface Associated_resource_status_resources extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The floating_ips property
     */
    floatingIps?: Destroyed_associated_resource[] | null;
    /**
     * The reserved_ips property
     */
    reservedIps?: Destroyed_associated_resource[] | null;
    /**
     * The snapshots property
     */
    snapshots?: Destroyed_associated_resource[] | null;
    /**
     * The volumes property
     */
    volumes?: Destroyed_associated_resource[] | null;
    /**
     * The volume_snapshots property
     */
    volumeSnapshots?: Destroyed_associated_resource[] | null;
}
export interface Autoscale_pool extends AdditionalDataHolder, Parsable {
    /**
     * The number of active Droplets in the autoscale pool.
     */
    activeResourcesCount?: number | null;
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The scaling configuration for an autoscale pool, which is how the pool scales up and down (either by resource utilization or static configuration).
     */
    config?: Autoscale_pool_dynamic_config | Autoscale_pool_static_config | null;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the autoscale pool was created.
     */
    createdAt?: Date | null;
    /**
     * The current_utilization property
     */
    currentUtilization?: Current_utilization | null;
    /**
     * The droplet_template property
     */
    dropletTemplate?: Autoscale_pool_droplet_template | null;
    /**
     * A unique identifier for each autoscale pool instance. This is automatically generated upon autoscale pool creation.
     */
    id?: string | null;
    /**
     * The human-readable name set for the autoscale pool.
     */
    name?: string | null;
    /**
     * The current status of the autoscale pool.
     */
    status?: Autoscale_pool_status | null;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the autoscale pool was last updated.
     */
    updatedAt?: Date | null;
}
export type Autoscale_pool_config = Autoscale_pool_dynamic_config | Autoscale_pool_static_config;
export interface Autoscale_pool_create extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The scaling configuration for an autoscale pool, which is how the pool scales up and down (either by resource utilization or static configuration).
     */
    config?: Autoscale_pool_dynamic_config | Autoscale_pool_static_config | null;
    /**
     * The droplet_template property
     */
    dropletTemplate?: Autoscale_pool_droplet_template | null;
    /**
     * The human-readable name of the autoscale pool. This field cannot be updated
     */
    name?: string | null;
}
export type Autoscale_pool_create_config = Autoscale_pool_dynamic_config | Autoscale_pool_static_config;
export interface Autoscale_pool_droplet_template extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The Droplet image to be used for all Droplets in the autoscale pool. You may specify the slug or the image ID.
     */
    image?: string | null;
    /**
     * Assigns a unique IPv6 address to each of the Droplets in the autoscale pool.
     */
    ipv6?: boolean | null;
    /**
     * The name(s) to be applied to all Droplets in the autoscale pool.
     */
    name?: string | null;
    /**
     * The project that the Droplets in the autoscale pool will belong to.
     */
    projectId?: string | null;
    /**
     * The datacenter in which all of the Droplets will be created.
     */
    region?: Autoscale_pool_droplet_template_region | null;
    /**
     * The Droplet size to be used for all Droplets in the autoscale pool.
     */
    size?: string | null;
    /**
     * The SSH keys to be installed on the Droplets in the autoscale pool. You can either specify the key ID or the fingerprint.
     */
    sshKeys?: string[] | null;
    /**
     * The tags to apply to each of the Droplets in the autoscale pool.
     */
    tags?: string[] | null;
    /**
     * A string containing user data that cloud-init consumes to configure a Droplet on first boot. User data is often a cloud-config file or Bash script. It must be plain text and may not exceed 64 KiB in size.
     */
    userData?: string | null;
    /**
     * The VPC where the Droplets in the autoscale pool will be created. The VPC must be in the region where you want to create the Droplets.
     */
    vpcUuid?: string | null;
    /**
     * Installs the Droplet agent. This must be set to true to monitor Droplets for resource utilization scaling.
     */
    withDropletAgent?: boolean | null;
}
export type Autoscale_pool_droplet_template_region = (typeof Autoscale_pool_droplet_template_regionObject)[keyof typeof Autoscale_pool_droplet_template_regionObject];
export interface Autoscale_pool_dynamic_config extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The number of minutes to wait between scaling events in an autoscale pool. Defaults to 10 minutes.
     */
    cooldownMinutes?: number | null;
    /**
     * The maximum number of Droplets in an autoscale pool.
     */
    maxInstances?: number | null;
    /**
     * The minimum number of Droplets in an autoscale pool.
     */
    minInstances?: number | null;
    /**
     * Target CPU utilization as a decimal.
     */
    targetCpuUtilization?: number | null;
    /**
     * Target memory utilization as a decimal.
     */
    targetMemoryUtilization?: number | null;
}
export interface Autoscale_pool_static_config extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Fixed number of instances in an autoscale pool.
     */
    targetNumberInstances?: number | null;
}
export type Autoscale_pool_status = (typeof Autoscale_pool_statusObject)[keyof typeof Autoscale_pool_statusObject];
export interface Backup extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A time value given in ISO8601 combined date and time format at which the backup was created.
     */
    createdAt?: Date | null;
    /**
     * The size of the database backup in GBs.
     */
    sizeGigabytes?: number | null;
}
export interface Backward_links extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * URI of the first page of the results.
     */
    first?: string | null;
    /**
     * URI of the previous page of the results.
     */
    prev?: string | null;
}
export interface Balance extends AdditionalDataHolder, Parsable {
    /**
     * Current balance of the customer's most recent billing activity.  Does not reflect `month_to_date_usage`.
     */
    accountBalance?: string | null;
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The time at which balances were most recently generated.
     */
    generatedAt?: Date | null;
    /**
     * Balance as of the `generated_at` time.  This value includes the `account_balance` and `month_to_date_usage`.
     */
    monthToDateBalance?: string | null;
    /**
     * Amount used in the current billing period as of the `generated_at` time.
     */
    monthToDateUsage?: string | null;
}
export interface Billing_address extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Street address line 1
     */
    addressLine1?: string | null;
    /**
     * Street address line 2
     */
    addressLine2?: string | null;
    /**
     * City
     */
    city?: string | null;
    /**
     * Country (ISO2) code
     */
    countryIso2Code?: string | null;
    /**
     * Timestamp billing address was created
     */
    createdAt?: string | null;
    /**
     * Postal code
     */
    postalCode?: string | null;
    /**
     * Region
     */
    region?: string | null;
    /**
     * Timestamp billing address was updated
     */
    updatedAt?: string | null;
}
export interface Billing_history extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Amount of the billing history entry.
     */
    amount?: string | null;
    /**
     * Time the billing history entry occurred.
     */
    date?: Date | null;
    /**
     * Description of the billing history entry.
     */
    description?: string | null;
    /**
     * ID of the invoice associated with the billing history entry, if  applicable.
     */
    invoiceId?: string | null;
    /**
     * UUID of the invoice associated with the billing history entry, if  applicable.
     */
    invoiceUuid?: string | null;
    /**
     * Type of billing history entry.
     */
    type?: Billing_history_type | null;
}
export type Billing_history_type = (typeof Billing_history_typeObject)[keyof typeof Billing_history_typeObject];
export interface Ca extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * base64 encoding of the certificate used to secure database connections
     */
    certificate?: string | null;
}
export interface Cdn_endpoint extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The ID of a DigitalOcean managed TLS certificate used for SSL when a custom subdomain is provided.
     */
    certificateId?: Guid | null;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the CDN endpoint was created.
     */
    createdAt?: Date | null;
    /**
     * The fully qualified domain name (FQDN) of the custom subdomain used with the CDN endpoint.
     */
    customDomain?: string | null;
    /**
     * The fully qualified domain name (FQDN) from which the CDN-backed content is served.
     */
    endpoint?: string | null;
    /**
     * A unique ID that can be used to identify and reference a CDN endpoint.
     */
    id?: Guid | null;
    /**
     * The fully qualified domain name (FQDN) for the origin server which provides the content for the CDN. This is currently restricted to a Space.
     */
    origin?: string | null;
    /**
     * The amount of time the content is cached by the CDN's edge servers in seconds. TTL must be one of 60, 600, 3600, 86400, or 604800. Defaults to 3600 (one hour) when excluded.
     */
    ttl?: number | null;
}
export interface Certificate extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the certificate was created.
     */
    createdAt?: Date | null;
    /**
     * An array of fully qualified domain names (FQDNs) for which the certificate was issued.
     */
    dnsNames?: string[] | null;
    /**
     * A unique ID that can be used to identify and reference a certificate.
     */
    id?: Guid | null;
    /**
     * A unique human-readable name referring to a certificate.
     */
    name?: string | null;
    /**
     * A time value given in ISO8601 combined date and time format that represents the certificate's expiration date.
     */
    notAfter?: Date | null;
    /**
     * A unique identifier generated from the SHA-1 fingerprint of the certificate.
     */
    sha1Fingerprint?: string | null;
    /**
     * A string representing the current state of the certificate. It may be `pending`, `verified`, or `error`.
     */
    state?: Certificate_state | null;
    /**
     * A string representing the type of the certificate. The value will be `custom` for a user-uploaded certificate or `lets_encrypt` for one automatically generated with Let's Encrypt.
     */
    type?: Certificate_type | null;
}
export interface Certificate_create_base extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A unique human-readable name referring to a certificate.
     */
    name?: string | null;
    /**
     * A string representing the type of the certificate. The value will be `custom` for a user-uploaded certificate or `lets_encrypt` for one automatically generated with Let's Encrypt.
     */
    type?: Certificate_create_base_type | null;
}
export type Certificate_create_base_type = (typeof Certificate_create_base_typeObject)[keyof typeof Certificate_create_base_typeObject];
export interface Certificate_request_custom extends Certificate_create_base, Parsable {
    /**
     * The full PEM-formatted trust chain between the certificate authority's certificate and your domain's SSL certificate.
     */
    certificateChain?: string | null;
    /**
     * The contents of a PEM-formatted public SSL certificate.
     */
    leafCertificate?: string | null;
    /**
     * The contents of a PEM-formatted private-key corresponding to the SSL certificate.
     */
    privateKey?: string | null;
}
export interface Certificate_request_lets_encrypt extends Certificate_create_base, Parsable {
    /**
     * An array of fully qualified domain names (FQDNs) for which the certificate was issued. A certificate covering all subdomains can be issued using a wildcard (e.g. `*.example.com`).
     */
    dnsNames?: string[] | null;
}
export type Certificate_state = (typeof Certificate_stateObject)[keyof typeof Certificate_stateObject];
export type Certificate_type = (typeof Certificate_typeObject)[keyof typeof Certificate_typeObject];
export interface Check extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A boolean value indicating whether the check is enabled/disabled.
     */
    enabled?: boolean | null;
    /**
     * A unique ID that can be used to identify and reference the check.
     */
    id?: Guid | null;
    /**
     * A human-friendly display name.
     */
    name?: string | null;
    /**
     * An array containing the selected regions to perform healthchecks from.
     */
    regions?: Check_regions[] | null;
    /**
     * The endpoint to perform healthchecks on.
     */
    target?: string | null;
    /**
     * The type of health check to perform.
     */
    type?: Check_type | null;
}
export type Check_regions = (typeof Check_regionsObject)[keyof typeof Check_regionsObject];
export type Check_type = (typeof Check_typeObject)[keyof typeof Check_typeObject];
export interface Check_updatable extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A boolean value indicating whether the check is enabled/disabled.
     */
    enabled?: boolean | null;
    /**
     * A human-friendly display name.
     */
    name?: string | null;
    /**
     * An array containing the selected regions to perform healthchecks from.
     */
    regions?: Check_updatable_regions[] | null;
    /**
     * The endpoint to perform healthchecks on.
     */
    target?: string | null;
    /**
     * The type of health check to perform.
     */
    type?: Check_updatable_type | null;
}
export type Check_updatable_regions = (typeof Check_updatable_regionsObject)[keyof typeof Check_updatable_regionsObject];
export type Check_updatable_type = (typeof Check_updatable_typeObject)[keyof typeof Check_updatable_typeObject];
export interface Cluster extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A boolean value indicating whether the cluster will be automatically upgraded to new patch releases during its maintenance window.
     */
    autoUpgrade?: boolean | null;
    /**
     * An object specifying custom cluster autoscaler configuration.
     */
    clusterAutoscalerConfiguration?: Cluster_autoscaler_configuration | null;
    /**
     * The range of IP addresses for the overlay network of the Kubernetes cluster in CIDR notation.
     */
    clusterSubnet?: string | null;
    /**
     * An object specifying the control plane firewall for the Kubernetes cluster. Control plane firewall is in early availability (invite only).
     */
    controlPlaneFirewall?: Control_plane_firewall | null;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the Kubernetes cluster was created.
     */
    createdAt?: Date | null;
    /**
     * The base URL of the API server on the Kubernetes master node.
     */
    endpoint?: string | null;
    /**
     * A boolean value indicating whether the control plane is run in a highly available configuration in the cluster. Highly available control planes incur less downtime. The property cannot be disabled.
     */
    ha?: boolean | null;
    /**
     * A unique ID that can be used to identify and reference a Kubernetes cluster.
     */
    id?: Guid | null;
    /**
     * The public IPv4 address of the Kubernetes master node. This will not be set if high availability is configured on the cluster (v1.21+)
     */
    ipv4?: string | null;
    /**
     * An object specifying the maintenance window policy for the Kubernetes cluster.
     */
    maintenancePolicy?: Maintenance_policy | null;
    /**
     * A human-readable name for a Kubernetes cluster.
     */
    name?: string | null;
    /**
     * An object specifying the details of the worker nodes available to the Kubernetes cluster.
     */
    nodePools?: Kubernetes_node_pool[] | null;
    /**
     * The slug identifier for the region where the Kubernetes cluster is located.
     */
    region?: string | null;
    /**
     * A read-only boolean value indicating if a container registry is integrated with the cluster.
     */
    registryEnabled?: boolean | null;
    /**
     * An object specifying whether the routing-agent component should be enabled for the Kubernetes cluster.
     */
    routingAgent?: Routing_agent | null;
    /**
     * The range of assignable IP addresses for services running in the Kubernetes cluster in CIDR notation.
     */
    serviceSubnet?: string | null;
    /**
     * An object containing a `state` attribute whose value is set to a string indicating the current status of the cluster.
     */
    status?: Cluster_status | null;
    /**
     * A boolean value indicating whether surge upgrade is enabled/disabled for the cluster. Surge upgrade makes cluster upgrades fast and reliable by bringing up new nodes before destroying the outdated nodes.
     */
    surgeUpgrade?: boolean | null;
    /**
     * An array of tags applied to the Kubernetes cluster. All clusters are automatically tagged `k8s` and `k8s:$K8S_CLUSTER_ID`.
     */
    tags?: string[] | null;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the Kubernetes cluster was last updated.
     */
    updatedAt?: Date | null;
    /**
     * The slug identifier for the version of Kubernetes used for the cluster. If set to a minor version (e.g. "1.14"), the latest version within it will be used (e.g. "1.14.6-do.1"); if set to "latest", the latest published version will be used. See the `/v2/kubernetes/options` endpoint to find all currently available versions.
     */
    version?: string | null;
    /**
     * A string specifying the UUID of the VPC to which the Kubernetes cluster is assigned.
     */
    vpcUuid?: Guid | null;
}
/**
 * An object specifying custom cluster autoscaler configuration.
 */
export interface Cluster_autoscaler_configuration extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Used to customize how long a node is unneeded before being scaled down.
     */
    scaleDownUnneededTime?: string | null;
    /**
     * Used to customize when cluster autoscaler scales down non-empty nodes by setting the node utilization threshold.
     */
    scaleDownUtilizationThreshold?: number | null;
}
export interface Cluster_registries extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An array containing the UUIDs of Kubernetes clusters.
     */
    clusterUuids?: string[] | null;
}
/**
 * An object containing a `state` attribute whose value is set to a string indicating the current status of the cluster.
 */
export interface Cluster_status extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An optional message providing additional information about the current cluster state.
     */
    message?: string | null;
    /**
     * A string indicating the current status of the cluster.
     */
    state?: Cluster_status_state | null;
}
export type Cluster_status_state = (typeof Cluster_status_stateObject)[keyof typeof Cluster_status_stateObject];
export interface Cluster_update extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A boolean value indicating whether the cluster will be automatically upgraded to new patch releases during its maintenance window.
     */
    autoUpgrade?: boolean | null;
    /**
     * An object specifying custom cluster autoscaler configuration.
     */
    clusterAutoscalerConfiguration?: Cluster_autoscaler_configuration | null;
    /**
     * An object specifying the control plane firewall for the Kubernetes cluster. Control plane firewall is in early availability (invite only).
     */
    controlPlaneFirewall?: Control_plane_firewall | null;
    /**
     * A boolean value indicating whether the control plane is run in a highly available configuration in the cluster. Highly available control planes incur less downtime. The property cannot be disabled.
     */
    ha?: boolean | null;
    /**
     * An object specifying the maintenance window policy for the Kubernetes cluster.
     */
    maintenancePolicy?: Maintenance_policy | null;
    /**
     * A human-readable name for a Kubernetes cluster.
     */
    name?: string | null;
    /**
     * An object specifying whether the routing-agent component should be enabled for the Kubernetes cluster.
     */
    routingAgent?: Routing_agent | null;
    /**
     * A boolean value indicating whether surge upgrade is enabled/disabled for the cluster. Surge upgrade makes cluster upgrades fast and reliable by bringing up new nodes before destroying the outdated nodes.
     */
    surgeUpgrade?: boolean | null;
    /**
     * An array of tags applied to the Kubernetes cluster. All clusters are automatically tagged `k8s` and `k8s:$K8S_CLUSTER_ID`.
     */
    tags?: string[] | null;
}
export interface Clusterlint_request extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An array of checks that will be run when clusterlint executes checks.
     */
    excludeChecks?: string[] | null;
    /**
     * An array of check groups that will be omitted when clusterlint executes checks.
     */
    excludeGroups?: string[] | null;
    /**
     * An array of checks that will be run when clusterlint executes checks.
     */
    includeChecks?: string[] | null;
    /**
     * An array of check groups that will be run when clusterlint executes checks.
     */
    includeGroups?: string[] | null;
}
export interface Clusterlint_results extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the schedule clusterlint run request was completed.
     */
    completedAt?: Date | null;
    /**
     * An array of diagnostics reporting potential problems for the given cluster.
     */
    diagnostics?: Clusterlint_results_diagnostics[] | null;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the schedule clusterlint run request was made.
     */
    requestedAt?: Date | null;
    /**
     * Id of the clusterlint run that can be used later to fetch the diagnostics.
     */
    runId?: string | null;
}
export interface Clusterlint_results_diagnostics extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The clusterlint check that resulted in the diagnostic.
     */
    checkName?: string | null;
    /**
     * Feedback about the object for users to fix.
     */
    message?: string | null;
    /**
     * Metadata about the Kubernetes API object the diagnostic is reported on.
     */
    object?: Clusterlint_results_diagnostics_object | null;
    /**
     * Can be one of error, warning or suggestion.
     */
    severity?: string | null;
}
/**
 * Metadata about the Kubernetes API object the diagnostic is reported on.
 */
export interface Clusterlint_results_diagnostics_object extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The kind of Kubernetes API object
     */
    kind?: string | null;
    /**
     * Name of the object
     */
    name?: string | null;
    /**
     * The namespace the object resides in the cluster.
     */
    namespace?: string | null;
}
export interface Connection_pool extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The connection property
     */
    connection?: Database_connection | null;
    /**
     * The database for use with the connection pool.
     */
    db?: string | null;
    /**
     * The PGBouncer transaction mode for the connection pool. The allowed values are session, transaction, and statement.
     */
    mode?: string | null;
    /**
     * A unique name for the connection pool. Must be between 3 and 60 characters.
     */
    name?: string | null;
    /**
     * The private_connection property
     */
    privateConnection?: Database_connection | null;
    /**
     * The desired size of the PGBouncer connection pool. The maximum allowed size is determined by the size of the cluster's primary node. 25 backend server connections are allowed for every 1GB of RAM. Three are reserved for maintenance. For example, a primary node with 1 GB of RAM allows for a maximum of 22 backend server connections while one with 4 GB would allow for 97. Note that these are shared across all connection pools in a cluster.
     */
    size?: number | null;
    /**
     * The standby_connection property
     */
    standbyConnection?: Database_connection | null;
    /**
     * The standby_private_connection property
     */
    standbyPrivateConnection?: Database_connection | null;
    /**
     * The name of the user for use with the connection pool. When excluded, all sessions connect to the database as the inbound user.
     */
    user?: string | null;
}
export interface Connection_pool_update extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The database for use with the connection pool.
     */
    db?: string | null;
    /**
     * The PGBouncer transaction mode for the connection pool. The allowed values are session, transaction, and statement.
     */
    mode?: string | null;
    /**
     * The desired size of the PGBouncer connection pool. The maximum allowed size is determined by the size of the cluster's primary node. 25 backend server connections are allowed for every 1GB of RAM. Three are reserved for maintenance. For example, a primary node with 1 GB of RAM allows for a maximum of 22 backend server connections while one with 4 GB would allow for 97. Note that these are shared across all connection pools in a cluster.
     */
    size?: number | null;
    /**
     * The name of the user for use with the connection pool. When excluded, all sessions connect to the database as the inbound user.
     */
    user?: string | null;
}
export interface Connection_pools extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An array of connection pool objects.
     */
    pools?: Connection_pool[] | null;
}
/**
 * An object specifying the control plane firewall for the Kubernetes cluster. Control plane firewall is in early availability (invite only).
 */
export interface Control_plane_firewall extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An array of public addresses (IPv4 or CIDR) allowed to access the control plane.
     */
    allowedAddresses?: string[] | null;
    /**
     * Indicates whether the control plane firewall is enabled.
     */
    enabled?: boolean | null;
}
export interface Create_namespace extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The namespace's unique name.
     */
    label?: string | null;
    /**
     * The [datacenter region](https://docs.digitalocean.com/products/platform/availability-matrix/#available-datacenters) in which to create the namespace.
     */
    region?: string | null;
}
export interface Create_trigger extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Name of function(action) that exists in the given namespace.
     */
    functionEscaped?: string | null;
    /**
     * Indicates weather the trigger is paused or unpaused.
     */
    isEnabled?: boolean | null;
    /**
     * The trigger's unique name within the namespace.
     */
    name?: string | null;
    /**
     * Trigger details for SCHEDULED type, where body is optional.
     */
    scheduledDetails?: Scheduled_details | null;
    /**
     * One of different type of triggers. Currently only SCHEDULED is supported.
     */
    type?: string | null;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Account_team}
 */
// @ts-ignore
export function createAccount_teamFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAccount_team;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Account}
 */
// @ts-ignore
export function createAccountFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAccount;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Action_link}
 */
// @ts-ignore
export function createAction_linkFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAction_link;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Action}
 */
// @ts-ignore
export function createActionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAction;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Alert_policy_request}
 */
// @ts-ignore
export function createAlert_policy_requestFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAlert_policy_request;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Alert_policy}
 */
// @ts-ignore
export function createAlert_policyFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAlert_policy;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Alert_updatable}
 */
// @ts-ignore
export function createAlert_updatableFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAlert_updatable;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Alert}
 */
// @ts-ignore
export function createAlertFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAlert;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Alerts}
 */
// @ts-ignore
export function createAlertsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAlerts;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiAgentAPIKey}
 */
// @ts-ignore
export function createApiAgentAPIKeyFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiAgentAPIKey;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiAgentAPIKeyInfo}
 */
// @ts-ignore
export function createApiAgentAPIKeyInfoFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiAgentAPIKeyInfo;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiAgentChatbotIdentifier}
 */
// @ts-ignore
export function createApiAgentChatbotIdentifierFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiAgentChatbotIdentifier;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiAgent}
 */
// @ts-ignore
export function createApiAgentFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiAgent;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiAgentFunction_input_schema}
 */
// @ts-ignore
export function createApiAgentFunction_input_schemaFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiAgentFunction_input_schema;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiAgentFunction_output_schema}
 */
// @ts-ignore
export function createApiAgentFunction_output_schemaFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiAgentFunction_output_schema;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiAgentFunction}
 */
// @ts-ignore
export function createApiAgentFunctionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiAgentFunction;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiAgentGuardrail_metadata}
 */
// @ts-ignore
export function createApiAgentGuardrail_metadataFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiAgentGuardrail_metadata;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiAgentGuardrail}
 */
// @ts-ignore
export function createApiAgentGuardrailFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiAgentGuardrail;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiAgentPublic}
 */
// @ts-ignore
export function createApiAgentPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiAgentPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiAgentTemplate}
 */
// @ts-ignore
export function createApiAgentTemplateFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiAgentTemplate;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiAgreement}
 */
// @ts-ignore
export function createApiAgreementFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiAgreement;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiAnthropicAPIKeyInfo}
 */
// @ts-ignore
export function createApiAnthropicAPIKeyInfoFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiAnthropicAPIKeyInfo;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiCancelKnowledgeBaseIndexingJobInputPublic}
 */
// @ts-ignore
export function createApiCancelKnowledgeBaseIndexingJobInputPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiCancelKnowledgeBaseIndexingJobInputPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiCancelKnowledgeBaseIndexingJobOutput}
 */
// @ts-ignore
export function createApiCancelKnowledgeBaseIndexingJobOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiCancelKnowledgeBaseIndexingJobOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiChatbot}
 */
// @ts-ignore
export function createApiChatbotFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiChatbot;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiCreateAgentAPIKeyInputPublic}
 */
// @ts-ignore
export function createApiCreateAgentAPIKeyInputPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiCreateAgentAPIKeyInputPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiCreateAgentAPIKeyOutput}
 */
// @ts-ignore
export function createApiCreateAgentAPIKeyOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiCreateAgentAPIKeyOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiCreateAgentInputPublic}
 */
// @ts-ignore
export function createApiCreateAgentInputPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiCreateAgentInputPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiCreateAgentOutput}
 */
// @ts-ignore
export function createApiCreateAgentOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiCreateAgentOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiCreateAnthropicAPIKeyInputPublic}
 */
// @ts-ignore
export function createApiCreateAnthropicAPIKeyInputPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiCreateAnthropicAPIKeyInputPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiCreateAnthropicAPIKeyOutput}
 */
// @ts-ignore
export function createApiCreateAnthropicAPIKeyOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiCreateAnthropicAPIKeyOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiCreateKnowledgeBaseDataSourceInputPublic}
 */
// @ts-ignore
export function createApiCreateKnowledgeBaseDataSourceInputPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiCreateKnowledgeBaseDataSourceInputPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiCreateKnowledgeBaseDataSourceOutput}
 */
// @ts-ignore
export function createApiCreateKnowledgeBaseDataSourceOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiCreateKnowledgeBaseDataSourceOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiCreateKnowledgeBaseInputPublic}
 */
// @ts-ignore
export function createApiCreateKnowledgeBaseInputPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiCreateKnowledgeBaseInputPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiCreateKnowledgeBaseOutput}
 */
// @ts-ignore
export function createApiCreateKnowledgeBaseOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiCreateKnowledgeBaseOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiDeleteAgentAPIKeyOutput}
 */
// @ts-ignore
export function createApiDeleteAgentAPIKeyOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiDeleteAgentAPIKeyOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiDeleteAgentOutput}
 */
// @ts-ignore
export function createApiDeleteAgentOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiDeleteAgentOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiDeleteAnthropicAPIKeyOutput}
 */
// @ts-ignore
export function createApiDeleteAnthropicAPIKeyOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiDeleteAnthropicAPIKeyOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiDeleteKnowledgeBaseDataSourceOutput}
 */
// @ts-ignore
export function createApiDeleteKnowledgeBaseDataSourceOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiDeleteKnowledgeBaseDataSourceOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiDeleteKnowledgeBaseOutput}
 */
// @ts-ignore
export function createApiDeleteKnowledgeBaseOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiDeleteKnowledgeBaseOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiDeployment}
 */
// @ts-ignore
export function createApiDeploymentFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiDeployment;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiFileUploadDataSource}
 */
// @ts-ignore
export function createApiFileUploadDataSourceFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiFileUploadDataSource;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiGetAgentOutput}
 */
// @ts-ignore
export function createApiGetAgentOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiGetAgentOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiGetAnthropicAPIKeyOutput}
 */
// @ts-ignore
export function createApiGetAnthropicAPIKeyOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiGetAnthropicAPIKeyOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiGetChildrenOutput}
 */
// @ts-ignore
export function createApiGetChildrenOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiGetChildrenOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiGetKnowledgeBaseIndexingJobOutput}
 */
// @ts-ignore
export function createApiGetKnowledgeBaseIndexingJobOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiGetKnowledgeBaseIndexingJobOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiGetKnowledgeBaseOutput}
 */
// @ts-ignore
export function createApiGetKnowledgeBaseOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiGetKnowledgeBaseOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiIndexedDataSource}
 */
// @ts-ignore
export function createApiIndexedDataSourceFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiIndexedDataSource;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiIndexingJob}
 */
// @ts-ignore
export function createApiIndexingJobFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiIndexingJob;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiKBDataSource}
 */
// @ts-ignore
export function createApiKBDataSourceFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiKBDataSource;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiKnowledgeBaseDataSource}
 */
// @ts-ignore
export function createApiKnowledgeBaseDataSourceFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiKnowledgeBaseDataSource;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiKnowledgeBase}
 */
// @ts-ignore
export function createApiKnowledgeBaseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiKnowledgeBase;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiLinkAgentFunctionInputPublic_input_schema}
 */
// @ts-ignore
export function createApiLinkAgentFunctionInputPublic_input_schemaFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiLinkAgentFunctionInputPublic_input_schema;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiLinkAgentFunctionInputPublic_output_schema}
 */
// @ts-ignore
export function createApiLinkAgentFunctionInputPublic_output_schemaFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiLinkAgentFunctionInputPublic_output_schema;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiLinkAgentFunctionInputPublic}
 */
// @ts-ignore
export function createApiLinkAgentFunctionInputPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiLinkAgentFunctionInputPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiLinkAgentFunctionOutput}
 */
// @ts-ignore
export function createApiLinkAgentFunctionOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiLinkAgentFunctionOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiLinkAgentInputPublic}
 */
// @ts-ignore
export function createApiLinkAgentInputPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiLinkAgentInputPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiLinkAgentOutput}
 */
// @ts-ignore
export function createApiLinkAgentOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiLinkAgentOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiLinkKnowledgeBaseOutput}
 */
// @ts-ignore
export function createApiLinkKnowledgeBaseOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiLinkKnowledgeBaseOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiLinks}
 */
// @ts-ignore
export function createApiLinksFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiLinks;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiListAgentAPIKeysOutput}
 */
// @ts-ignore
export function createApiListAgentAPIKeysOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiListAgentAPIKeysOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiListAgentsByAnthropicKeyOutput}
 */
// @ts-ignore
export function createApiListAgentsByAnthropicKeyOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiListAgentsByAnthropicKeyOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiListAgentsOutputPublic}
 */
// @ts-ignore
export function createApiListAgentsOutputPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiListAgentsOutputPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiListAnthropicAPIKeysOutput}
 */
// @ts-ignore
export function createApiListAnthropicAPIKeysOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiListAnthropicAPIKeysOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiListIndexingJobDataSourcesOutput}
 */
// @ts-ignore
export function createApiListIndexingJobDataSourcesOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiListIndexingJobDataSourcesOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiListKnowledgeBaseDataSourcesOutput}
 */
// @ts-ignore
export function createApiListKnowledgeBaseDataSourcesOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiListKnowledgeBaseDataSourcesOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiListKnowledgeBaseIndexingJobsOutput}
 */
// @ts-ignore
export function createApiListKnowledgeBaseIndexingJobsOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiListKnowledgeBaseIndexingJobsOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiListKnowledgeBasesOutput}
 */
// @ts-ignore
export function createApiListKnowledgeBasesOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiListKnowledgeBasesOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiListModelsOutputPublic}
 */
// @ts-ignore
export function createApiListModelsOutputPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiListModelsOutputPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiListRegionsOutput}
 */
// @ts-ignore
export function createApiListRegionsOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiListRegionsOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiMeta}
 */
// @ts-ignore
export function createApiMetaFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiMeta;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiModel_metadata}
 */
// @ts-ignore
export function createApiModel_metadataFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiModel_metadata;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiModel}
 */
// @ts-ignore
export function createApiModelFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiModel;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiModelPublic}
 */
// @ts-ignore
export function createApiModelPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiModelPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiModelVersion}
 */
// @ts-ignore
export function createApiModelVersionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiModelVersion;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiPages}
 */
// @ts-ignore
export function createApiPagesFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiPages;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiRegenerateAgentAPIKeyOutput}
 */
// @ts-ignore
export function createApiRegenerateAgentAPIKeyOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiRegenerateAgentAPIKeyOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiSpacesDataSource}
 */
// @ts-ignore
export function createApiSpacesDataSourceFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiSpacesDataSource;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiStartKnowledgeBaseIndexingJobInputPublic}
 */
// @ts-ignore
export function createApiStartKnowledgeBaseIndexingJobInputPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiStartKnowledgeBaseIndexingJobInputPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiStartKnowledgeBaseIndexingJobOutput}
 */
// @ts-ignore
export function createApiStartKnowledgeBaseIndexingJobOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiStartKnowledgeBaseIndexingJobOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiUnlinkAgentFunctionOutput}
 */
// @ts-ignore
export function createApiUnlinkAgentFunctionOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiUnlinkAgentFunctionOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiUnlinkAgentOutput}
 */
// @ts-ignore
export function createApiUnlinkAgentOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiUnlinkAgentOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiUnlinkKnowledgeBaseOutput}
 */
// @ts-ignore
export function createApiUnlinkKnowledgeBaseOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiUnlinkKnowledgeBaseOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiUpdateAgentAPIKeyInputPublic}
 */
// @ts-ignore
export function createApiUpdateAgentAPIKeyInputPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiUpdateAgentAPIKeyInputPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiUpdateAgentAPIKeyOutput}
 */
// @ts-ignore
export function createApiUpdateAgentAPIKeyOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiUpdateAgentAPIKeyOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiUpdateAgentDeploymentVisbilityOutput}
 */
// @ts-ignore
export function createApiUpdateAgentDeploymentVisbilityOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiUpdateAgentDeploymentVisbilityOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiUpdateAgentDeploymentVisibilityInputPublic}
 */
// @ts-ignore
export function createApiUpdateAgentDeploymentVisibilityInputPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiUpdateAgentDeploymentVisibilityInputPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiUpdateAgentFunctionInputPublic_input_schema}
 */
// @ts-ignore
export function createApiUpdateAgentFunctionInputPublic_input_schemaFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiUpdateAgentFunctionInputPublic_input_schema;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiUpdateAgentFunctionInputPublic_output_schema}
 */
// @ts-ignore
export function createApiUpdateAgentFunctionInputPublic_output_schemaFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiUpdateAgentFunctionInputPublic_output_schema;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiUpdateAgentFunctionInputPublic}
 */
// @ts-ignore
export function createApiUpdateAgentFunctionInputPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiUpdateAgentFunctionInputPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiUpdateAgentFunctionOutput}
 */
// @ts-ignore
export function createApiUpdateAgentFunctionOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiUpdateAgentFunctionOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiUpdateAgentInputPublic}
 */
// @ts-ignore
export function createApiUpdateAgentInputPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiUpdateAgentInputPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiUpdateAgentOutput}
 */
// @ts-ignore
export function createApiUpdateAgentOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiUpdateAgentOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiUpdateAnthropicAPIKeyInputPublic}
 */
// @ts-ignore
export function createApiUpdateAnthropicAPIKeyInputPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiUpdateAnthropicAPIKeyInputPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiUpdateAnthropicAPIKeyOutput}
 */
// @ts-ignore
export function createApiUpdateAnthropicAPIKeyOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiUpdateAnthropicAPIKeyOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiUpdateKnowledgeBaseInputPublic}
 */
// @ts-ignore
export function createApiUpdateKnowledgeBaseInputPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiUpdateKnowledgeBaseInputPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiUpdateKnowledgeBaseOutput}
 */
// @ts-ignore
export function createApiUpdateKnowledgeBaseOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiUpdateKnowledgeBaseOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiUpdateLinkedAgentInputPublic}
 */
// @ts-ignore
export function createApiUpdateLinkedAgentInputPublicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiUpdateLinkedAgentInputPublic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiUpdateLinkedAgentOutput}
 */
// @ts-ignore
export function createApiUpdateLinkedAgentOutputFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiUpdateLinkedAgentOutput;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ApiWebCrawlerDataSource}
 */
// @ts-ignore
export function createApiWebCrawlerDataSourceFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApiWebCrawlerDataSource;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_alert_progress_step_reason}
 */
// @ts-ignore
export function createApp_alert_progress_step_reasonFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_alert_progress_step_reason;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_alert_progress_step}
 */
// @ts-ignore
export function createApp_alert_progress_stepFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_alert_progress_step;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_alert_progress}
 */
// @ts-ignore
export function createApp_alert_progressFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_alert_progress;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_alert_slack_webhook}
 */
// @ts-ignore
export function createApp_alert_slack_webhookFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_alert_slack_webhook;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_alert_spec}
 */
// @ts-ignore
export function createApp_alert_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_alert_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_alert}
 */
// @ts-ignore
export function createApp_alertFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_alert;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_component_base}
 */
// @ts-ignore
export function createApp_component_baseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_component_base;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_database_spec}
 */
// @ts-ignore
export function createApp_database_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_database_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_domain_spec}
 */
// @ts-ignore
export function createApp_domain_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_domain_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_domain_validation}
 */
// @ts-ignore
export function createApp_domain_validationFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_domain_validation;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_egress_spec}
 */
// @ts-ignore
export function createApp_egress_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_egress_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_functions_spec}
 */
// @ts-ignore
export function createApp_functions_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_functions_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_ingress_spec_rule_match}
 */
// @ts-ignore
export function createApp_ingress_spec_rule_matchFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_ingress_spec_rule_match;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_ingress_spec_rule_routing_component}
 */
// @ts-ignore
export function createApp_ingress_spec_rule_routing_componentFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_ingress_spec_rule_routing_component;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_ingress_spec_rule_routing_redirect}
 */
// @ts-ignore
export function createApp_ingress_spec_rule_routing_redirectFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_ingress_spec_rule_routing_redirect;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_ingress_spec_rule_string_match}
 */
// @ts-ignore
export function createApp_ingress_spec_rule_string_matchFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_ingress_spec_rule_string_match;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_ingress_spec_rule}
 */
// @ts-ignore
export function createApp_ingress_spec_ruleFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_ingress_spec_rule;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_ingress_spec}
 */
// @ts-ignore
export function createApp_ingress_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_ingress_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_job_spec_autoscaling_metrics_cpu}
 */
// @ts-ignore
export function createApp_job_spec_autoscaling_metrics_cpuFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_job_spec_autoscaling_metrics_cpu;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_job_spec_autoscaling_metrics}
 */
// @ts-ignore
export function createApp_job_spec_autoscaling_metricsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_job_spec_autoscaling_metrics;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_job_spec_autoscaling}
 */
// @ts-ignore
export function createApp_job_spec_autoscalingFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_job_spec_autoscaling;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {string}
 */
// @ts-ignore
export function createApp_job_spec_instance_size_slugFromDiscriminatorValue(parseNode: ParseNode | undefined) : string | undefined {
    return parseNode?.getStringValue();
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_job_spec_termination}
 */
// @ts-ignore
export function createApp_job_spec_terminationFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_job_spec_termination;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_job_spec}
 */
// @ts-ignore
export function createApp_job_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_job_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_log_destination_datadog_spec}
 */
// @ts-ignore
export function createApp_log_destination_datadog_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_log_destination_datadog_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_log_destination_definition}
 */
// @ts-ignore
export function createApp_log_destination_definitionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_log_destination_definition;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_log_destination_logtail_spec}
 */
// @ts-ignore
export function createApp_log_destination_logtail_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_log_destination_logtail_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_log_destination_open_search_spec_basic_auth}
 */
// @ts-ignore
export function createApp_log_destination_open_search_spec_basic_authFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_log_destination_open_search_spec_basic_auth;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_log_destination_open_search_spec}
 */
// @ts-ignore
export function createApp_log_destination_open_search_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_log_destination_open_search_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_log_destination_papertrail_spec}
 */
// @ts-ignore
export function createApp_log_destination_papertrail_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_log_destination_papertrail_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_maintenance_spec}
 */
// @ts-ignore
export function createApp_maintenance_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_maintenance_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_metrics_bandwidth_usage_details}
 */
// @ts-ignore
export function createApp_metrics_bandwidth_usage_detailsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_metrics_bandwidth_usage_details;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_metrics_bandwidth_usage_request}
 */
// @ts-ignore
export function createApp_metrics_bandwidth_usage_requestFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_metrics_bandwidth_usage_request;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_metrics_bandwidth_usage}
 */
// @ts-ignore
export function createApp_metrics_bandwidth_usageFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_metrics_bandwidth_usage;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_propose_response}
 */
// @ts-ignore
export function createApp_propose_responseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_propose_response;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_propose}
 */
// @ts-ignore
export function createApp_proposeFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_propose;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_response}
 */
// @ts-ignore
export function createApp_responseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_response;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_rollback_validation_condition}
 */
// @ts-ignore
export function createApp_rollback_validation_conditionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_rollback_validation_condition;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_route_spec}
 */
// @ts-ignore
export function createApp_route_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_route_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_service_spec_autoscaling_metrics_cpu}
 */
// @ts-ignore
export function createApp_service_spec_autoscaling_metrics_cpuFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_service_spec_autoscaling_metrics_cpu;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_service_spec_autoscaling_metrics}
 */
// @ts-ignore
export function createApp_service_spec_autoscaling_metricsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_service_spec_autoscaling_metrics;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_service_spec_autoscaling}
 */
// @ts-ignore
export function createApp_service_spec_autoscalingFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_service_spec_autoscaling;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_service_spec_health_check}
 */
// @ts-ignore
export function createApp_service_spec_health_checkFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_service_spec_health_check;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {string}
 */
// @ts-ignore
export function createApp_service_spec_instance_size_slugFromDiscriminatorValue(parseNode: ParseNode | undefined) : string | undefined {
    return parseNode?.getStringValue();
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_service_spec_termination}
 */
// @ts-ignore
export function createApp_service_spec_terminationFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_service_spec_termination;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_service_spec}
 */
// @ts-ignore
export function createApp_service_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_service_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_spec}
 */
// @ts-ignore
export function createApp_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_static_site_spec}
 */
// @ts-ignore
export function createApp_static_site_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_static_site_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_variable_definition}
 */
// @ts-ignore
export function createApp_variable_definitionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_variable_definition;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_worker_spec_autoscaling_metrics_cpu}
 */
// @ts-ignore
export function createApp_worker_spec_autoscaling_metrics_cpuFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_worker_spec_autoscaling_metrics_cpu;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_worker_spec_autoscaling_metrics}
 */
// @ts-ignore
export function createApp_worker_spec_autoscaling_metricsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_worker_spec_autoscaling_metrics;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_worker_spec_autoscaling}
 */
// @ts-ignore
export function createApp_worker_spec_autoscalingFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_worker_spec_autoscaling;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {string}
 */
// @ts-ignore
export function createApp_worker_spec_instance_size_slugFromDiscriminatorValue(parseNode: ParseNode | undefined) : string | undefined {
    return parseNode?.getStringValue();
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_worker_spec_termination}
 */
// @ts-ignore
export function createApp_worker_spec_terminationFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_worker_spec_termination;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App_worker_spec}
 */
// @ts-ignore
export function createApp_worker_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp_worker_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {App}
 */
// @ts-ignore
export function createAppFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApp;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_alert_response}
 */
// @ts-ignore
export function createApps_alert_responseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_alert_response;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_assign_app_alert_destinations_request}
 */
// @ts-ignore
export function createApps_assign_app_alert_destinations_requestFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_assign_app_alert_destinations_request;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_bitbucket_source_spec}
 */
// @ts-ignore
export function createApps_bitbucket_source_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_bitbucket_source_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_cors_policy}
 */
// @ts-ignore
export function createApps_cors_policyFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_cors_policy;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_create_app_request}
 */
// @ts-ignore
export function createApps_create_app_requestFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_create_app_request;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_create_deployment_request}
 */
// @ts-ignore
export function createApps_create_deployment_requestFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_create_deployment_request;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_dedicated_egress_ip}
 */
// @ts-ignore
export function createApps_dedicated_egress_ipFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_dedicated_egress_ip;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_delete_app_response}
 */
// @ts-ignore
export function createApps_delete_app_responseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_delete_app_response;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_deployment_functions}
 */
// @ts-ignore
export function createApps_deployment_functionsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_deployment_functions;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_deployment_job}
 */
// @ts-ignore
export function createApps_deployment_jobFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_deployment_job;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_deployment_progress_step_reason}
 */
// @ts-ignore
export function createApps_deployment_progress_step_reasonFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_deployment_progress_step_reason;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_deployment_progress_step_steps}
 */
// @ts-ignore
export function createApps_deployment_progress_step_stepsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_deployment_progress_step_steps;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_deployment_progress_step}
 */
// @ts-ignore
export function createApps_deployment_progress_stepFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_deployment_progress_step;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_deployment_progress}
 */
// @ts-ignore
export function createApps_deployment_progressFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_deployment_progress;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_deployment_response}
 */
// @ts-ignore
export function createApps_deployment_responseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_deployment_response;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_deployment_service}
 */
// @ts-ignore
export function createApps_deployment_serviceFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_deployment_service;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_deployment_static_site}
 */
// @ts-ignore
export function createApps_deployment_static_siteFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_deployment_static_site;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_deployment_worker}
 */
// @ts-ignore
export function createApps_deployment_workerFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_deployment_worker;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_deployment}
 */
// @ts-ignore
export function createApps_deploymentFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_deployment;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_deployments_response}
 */
// @ts-ignore
export function createApps_deployments_responseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_deployments_response;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_domain_progress_steps}
 */
// @ts-ignore
export function createApps_domain_progress_stepsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_domain_progress_steps;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_domain_progress}
 */
// @ts-ignore
export function createApps_domain_progressFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_domain_progress;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_domain}
 */
// @ts-ignore
export function createApps_domainFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_domain;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_get_exec_response}
 */
// @ts-ignore
export function createApps_get_exec_responseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_get_exec_response;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_get_instance_size_response}
 */
// @ts-ignore
export function createApps_get_instance_size_responseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_get_instance_size_response;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_get_logs_response}
 */
// @ts-ignore
export function createApps_get_logs_responseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_get_logs_response;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_git_source_spec}
 */
// @ts-ignore
export function createApps_git_source_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_git_source_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_github_source_spec}
 */
// @ts-ignore
export function createApps_github_source_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_github_source_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_gitlab_source_spec}
 */
// @ts-ignore
export function createApps_gitlab_source_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_gitlab_source_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_image_source_spec_deploy_on_push}
 */
// @ts-ignore
export function createApps_image_source_spec_deploy_on_pushFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_image_source_spec_deploy_on_push;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_image_source_spec}
 */
// @ts-ignore
export function createApps_image_source_specFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_image_source_spec;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_instance_size}
 */
// @ts-ignore
export function createApps_instance_sizeFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_instance_size;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_list_alerts_response}
 */
// @ts-ignore
export function createApps_list_alerts_responseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_list_alerts_response;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_list_instance_sizes_response}
 */
// @ts-ignore
export function createApps_list_instance_sizes_responseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_list_instance_sizes_response;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_list_regions_response}
 */
// @ts-ignore
export function createApps_list_regions_responseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_list_regions_response;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_region}
 */
// @ts-ignore
export function createApps_regionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_region;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_response}
 */
// @ts-ignore
export function createApps_responseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_response;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_restart_request}
 */
// @ts-ignore
export function createApps_restart_requestFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_restart_request;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_rollback_app_request}
 */
// @ts-ignore
export function createApps_rollback_app_requestFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_rollback_app_request;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_string_match}
 */
// @ts-ignore
export function createApps_string_matchFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_string_match;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Apps_update_app_request}
 */
// @ts-ignore
export function createApps_update_app_requestFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoApps_update_app_request;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Associated_kubernetes_resource}
 */
// @ts-ignore
export function createAssociated_kubernetes_resourceFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAssociated_kubernetes_resource;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Associated_kubernetes_resources}
 */
// @ts-ignore
export function createAssociated_kubernetes_resourcesFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAssociated_kubernetes_resources;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Associated_resource_status_resources}
 */
// @ts-ignore
export function createAssociated_resource_status_resourcesFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAssociated_resource_status_resources;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Associated_resource_status}
 */
// @ts-ignore
export function createAssociated_resource_statusFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAssociated_resource_status;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Associated_resource}
 */
// @ts-ignore
export function createAssociated_resourceFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAssociated_resource;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Autoscale_pool_dynamic_config | Autoscale_pool_static_config}
 */
// @ts-ignore
export function createAutoscale_pool_configFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAutoscale_pool_config;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Autoscale_pool_dynamic_config | Autoscale_pool_static_config}
 */
// @ts-ignore
export function createAutoscale_pool_create_configFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAutoscale_pool_create_config;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Autoscale_pool_create}
 */
// @ts-ignore
export function createAutoscale_pool_createFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAutoscale_pool_create;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Autoscale_pool_droplet_template}
 */
// @ts-ignore
export function createAutoscale_pool_droplet_templateFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAutoscale_pool_droplet_template;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Autoscale_pool_dynamic_config}
 */
// @ts-ignore
export function createAutoscale_pool_dynamic_configFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAutoscale_pool_dynamic_config;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Autoscale_pool_static_config}
 */
// @ts-ignore
export function createAutoscale_pool_static_configFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAutoscale_pool_static_config;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Autoscale_pool}
 */
// @ts-ignore
export function createAutoscale_poolFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoAutoscale_pool;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Backup}
 */
// @ts-ignore
export function createBackupFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoBackup;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Backward_links}
 */
// @ts-ignore
export function createBackward_linksFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoBackward_links;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Balance}
 */
// @ts-ignore
export function createBalanceFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoBalance;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Billing_address}
 */
// @ts-ignore
export function createBilling_addressFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoBilling_address;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Billing_history}
 */
// @ts-ignore
export function createBilling_historyFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoBilling_history;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Ca}
 */
// @ts-ignore
export function createCaFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoCa;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Cdn_endpoint}
 */
// @ts-ignore
export function createCdn_endpointFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoCdn_endpoint;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Certificate_create_base}
 */
// @ts-ignore
export function createCertificate_create_baseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoCertificate_create_base;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Certificate_request_custom}
 */
// @ts-ignore
export function createCertificate_request_customFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoCertificate_request_custom;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Certificate_request_lets_encrypt}
 */
// @ts-ignore
export function createCertificate_request_lets_encryptFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoCertificate_request_lets_encrypt;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Certificate}
 */
// @ts-ignore
export function createCertificateFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoCertificate;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Check_updatable}
 */
// @ts-ignore
export function createCheck_updatableFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoCheck_updatable;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Check}
 */
// @ts-ignore
export function createCheckFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoCheck;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Cluster_autoscaler_configuration}
 */
// @ts-ignore
export function createCluster_autoscaler_configurationFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoCluster_autoscaler_configuration;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Cluster_registries}
 */
// @ts-ignore
export function createCluster_registriesFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoCluster_registries;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Cluster_status}
 */
// @ts-ignore
export function createCluster_statusFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoCluster_status;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Cluster_update}
 */
// @ts-ignore
export function createCluster_updateFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoCluster_update;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Cluster}
 */
// @ts-ignore
export function createClusterFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoCluster;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Clusterlint_request}
 */
// @ts-ignore
export function createClusterlint_requestFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoClusterlint_request;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Clusterlint_results_diagnostics_object}
 */
// @ts-ignore
export function createClusterlint_results_diagnostics_objectFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoClusterlint_results_diagnostics_object;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Clusterlint_results_diagnostics}
 */
// @ts-ignore
export function createClusterlint_results_diagnosticsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoClusterlint_results_diagnostics;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Clusterlint_results}
 */
// @ts-ignore
export function createClusterlint_resultsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoClusterlint_results;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Connection_pool_update}
 */
// @ts-ignore
export function createConnection_pool_updateFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoConnection_pool_update;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Connection_pool}
 */
// @ts-ignore
export function createConnection_poolFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoConnection_pool;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Connection_pools}
 */
// @ts-ignore
export function createConnection_poolsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoConnection_pools;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Control_plane_firewall}
 */
// @ts-ignore
export function createControl_plane_firewallFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoControl_plane_firewall;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Create_namespace}
 */
// @ts-ignore
export function createCreate_namespaceFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoCreate_namespace;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Create_trigger}
 */
// @ts-ignore
export function createCreate_triggerFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoCreate_trigger;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Credentials}
 */
// @ts-ignore
export function createCredentialsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoCredentials;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Current_utilization}
 */
// @ts-ignore
export function createCurrent_utilizationFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoCurrent_utilization;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Database_backup}
 */
// @ts-ignore
export function createDatabase_backupFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDatabase_backup;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Database_cluster_resize}
 */
// @ts-ignore
export function createDatabase_cluster_resizeFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDatabase_cluster_resize;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Database_cluster}
 */
// @ts-ignore
export function createDatabase_clusterFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDatabase_cluster;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kafka_advanced_config | Mongo_advanced_config | Mysql_advanced_config | Opensearch_advanced_config | Postgres_advanced_config | Redis_advanced_config}
 */
// @ts-ignore
export function createDatabase_config_configFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDatabase_config_config;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Database_config}
 */
// @ts-ignore
export function createDatabase_configFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDatabase_config;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Database_connection}
 */
// @ts-ignore
export function createDatabase_connectionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDatabase_connection;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Database_layout_option}
 */
// @ts-ignore
export function createDatabase_layout_optionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDatabase_layout_option;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Database_maintenance_window}
 */
// @ts-ignore
export function createDatabase_maintenance_windowFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDatabase_maintenance_window;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Database_metrics_credentials}
 */
// @ts-ignore
export function createDatabase_metrics_credentialsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDatabase_metrics_credentials;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Database_replica}
 */
// @ts-ignore
export function createDatabase_replicaFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDatabase_replica;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Database_service_endpoint}
 */
// @ts-ignore
export function createDatabase_service_endpointFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDatabase_service_endpoint;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Database_user}
 */
// @ts-ignore
export function createDatabase_userFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDatabase_user;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Database_version_availability}
 */
// @ts-ignore
export function createDatabase_version_availabilityFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDatabase_version_availability;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Database}
 */
// @ts-ignore
export function createDatabaseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDatabase;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Databases_basic_auth_credentials}
 */
// @ts-ignore
export function createDatabases_basic_auth_credentialsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDatabases_basic_auth_credentials;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Destination_omit_credentials}
 */
// @ts-ignore
export function createDestination_omit_credentialsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDestination_omit_credentials;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Destination_request}
 */
// @ts-ignore
export function createDestination_requestFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDestination_request;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Destination}
 */
// @ts-ignore
export function createDestinationFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDestination;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Destroy_associated_kubernetes_resources}
 */
// @ts-ignore
export function createDestroy_associated_kubernetes_resourcesFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDestroy_associated_kubernetes_resources;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Destroyed_associated_resource}
 */
// @ts-ignore
export function createDestroyed_associated_resourceFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDestroyed_associated_resource;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Disk_info_size}
 */
// @ts-ignore
export function createDisk_info_sizeFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDisk_info_size;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Disk_info}
 */
// @ts-ignore
export function createDisk_infoFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDisk_info;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Docker_credentials_auths_registryDigitaloceanCom}
 */
// @ts-ignore
export function createDocker_credentials_auths_registryDigitaloceanComFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDocker_credentials_auths_registryDigitaloceanCom;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Docker_credentials_auths}
 */
// @ts-ignore
export function createDocker_credentials_authsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDocker_credentials_auths;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Docker_credentials}
 */
// @ts-ignore
export function createDocker_credentialsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDocker_credentials;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Domain_record_aaaa}
 */
// @ts-ignore
export function createDomain_record_aaaaFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDomain_record_aaaa;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Domain_record_a}
 */
// @ts-ignore
export function createDomain_record_aFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDomain_record_a;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Domain_record_caa}
 */
// @ts-ignore
export function createDomain_record_caaFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDomain_record_caa;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Domain_record_cname}
 */
// @ts-ignore
export function createDomain_record_cnameFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDomain_record_cname;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Domain_record_mx}
 */
// @ts-ignore
export function createDomain_record_mxFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDomain_record_mx;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Domain_record_ns}
 */
// @ts-ignore
export function createDomain_record_nsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDomain_record_ns;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Domain_record_soa}
 */
// @ts-ignore
export function createDomain_record_soaFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDomain_record_soa;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Domain_record_srv}
 */
// @ts-ignore
export function createDomain_record_srvFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDomain_record_srv;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Domain_record_txt}
 */
// @ts-ignore
export function createDomain_record_txtFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDomain_record_txt;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Domain_record}
 */
// @ts-ignore
export function createDomain_recordFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDomain_record;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Domain}
 */
// @ts-ignore
export function createDomainFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDomain;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Domains}
 */
// @ts-ignore
export function createDomainsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDomains;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Droplet_action_change_backup_policy}
 */
// @ts-ignore
export function createDroplet_action_change_backup_policyFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDroplet_action_change_backup_policy;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Droplet_action_change_kernel}
 */
// @ts-ignore
export function createDroplet_action_change_kernelFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDroplet_action_change_kernel;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Droplet_action_enable_backups}
 */
// @ts-ignore
export function createDroplet_action_enable_backupsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDroplet_action_enable_backups;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {number | string}
 */
// @ts-ignore
export function createDroplet_action_rebuild_imageFromDiscriminatorValue(parseNode: ParseNode | undefined) : number | string | undefined {
    return parseNode?.getNumberValue() ?? parseNode?.getStringValue();
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Droplet_action_rebuild}
 */
// @ts-ignore
export function createDroplet_action_rebuildFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDroplet_action_rebuild;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Droplet_action_rename}
 */
// @ts-ignore
export function createDroplet_action_renameFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDroplet_action_rename;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Droplet_action_resize}
 */
// @ts-ignore
export function createDroplet_action_resizeFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDroplet_action_resize;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Droplet_action_restore}
 */
// @ts-ignore
export function createDroplet_action_restoreFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDroplet_action_restore;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Droplet_action_snapshot}
 */
// @ts-ignore
export function createDroplet_action_snapshotFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDroplet_action_snapshot;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Droplet_action}
 */
// @ts-ignore
export function createDroplet_actionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDroplet_action;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Droplet_backup_policy_record}
 */
// @ts-ignore
export function createDroplet_backup_policy_recordFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDroplet_backup_policy_record;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Droplet_backup_policy}
 */
// @ts-ignore
export function createDroplet_backup_policyFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDroplet_backup_policy;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {number | string}
 */
// @ts-ignore
export function createDroplet_create_imageFromDiscriminatorValue(parseNode: ParseNode | undefined) : number | string | undefined {
    return parseNode?.getNumberValue() ?? parseNode?.getStringValue();
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Droplet_create}
 */
// @ts-ignore
export function createDroplet_createFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDroplet_create;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Droplet_multi_create}
 */
// @ts-ignore
export function createDroplet_multi_createFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDroplet_multi_create;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Droplet_networks}
 */
// @ts-ignore
export function createDroplet_networksFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDroplet_networks;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Droplet_next_backup_window}
 */
// @ts-ignore
export function createDroplet_next_backup_windowFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDroplet_next_backup_window;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Droplet_single_create}
 */
// @ts-ignore
export function createDroplet_single_createFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDroplet_single_create;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Droplet_snapshot}
 */
// @ts-ignore
export function createDroplet_snapshotFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDroplet_snapshot;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Droplet}
 */
// @ts-ignore
export function createDropletFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoDroplet;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Elasticsearch_logsink}
 */
// @ts-ignore
export function createElasticsearch_logsinkFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoElasticsearch_logsink;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Error_with_root_causes}
 */
// @ts-ignore
export function createError_with_root_causesFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoError_with_root_causes;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {ErrorEscaped}
 */
// @ts-ignore
export function createErrorEscapedFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoErrorEscaped;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Events_logs}
 */
// @ts-ignore
export function createEvents_logsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoEvents_logs;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Firewall_pending_changes}
 */
// @ts-ignore
export function createFirewall_pending_changesFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoFirewall_pending_changes;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Firewall_rule_base}
 */
// @ts-ignore
export function createFirewall_rule_baseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoFirewall_rule_base;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Firewall_rule_target}
 */
// @ts-ignore
export function createFirewall_rule_targetFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoFirewall_rule_target;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Firewall_rule}
 */
// @ts-ignore
export function createFirewall_ruleFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoFirewall_rule;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Firewall_rules_inbound_rules}
 */
// @ts-ignore
export function createFirewall_rules_inbound_rulesFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoFirewall_rules_inbound_rules;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Firewall_rules_outbound_rules}
 */
// @ts-ignore
export function createFirewall_rules_outbound_rulesFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoFirewall_rules_outbound_rules;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Firewall_rules}
 */
// @ts-ignore
export function createFirewall_rulesFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoFirewall_rules;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Firewall}
 */
// @ts-ignore
export function createFirewallFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoFirewall;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Floating_ip_action_assign}
 */
// @ts-ignore
export function createFloating_ip_action_assignFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoFloating_ip_action_assign;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Floating_ip_action_unassign}
 */
// @ts-ignore
export function createFloating_ip_action_unassignFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoFloating_ip_action_unassign;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Floating_ip_createMember1}
 */
// @ts-ignore
export function createFloating_ip_createMember1FromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoFloating_ip_createMember1;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Floating_ip_createMember2}
 */
// @ts-ignore
export function createFloating_ip_createMember2FromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoFloating_ip_createMember2;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Floating_ip}
 */
// @ts-ignore
export function createFloating_ipFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoFloating_ip;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {FloatingIPsAction}
 */
// @ts-ignore
export function createFloatingIPsActionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    if(!parseNode) throw new Error("parseNode cannot be undefined");
    const mappingValueNode = parseNode?.getChildNode("type");
    if (mappingValueNode) {
        const mappingValue = mappingValueNode.getStringValue();
        if (mappingValue) {
            switch (mappingValue) {
                case "assign":
                    return deserializeIntoFloating_ip_action_assign;
                case "unassign":
                    return deserializeIntoFloating_ip_action_unassign;
            }
        }
    }
    return deserializeIntoFloatingIPsAction;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Forward_links}
 */
// @ts-ignore
export function createForward_linksFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoForward_links;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Forwarding_rule}
 */
// @ts-ignore
export function createForwarding_ruleFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoForwarding_rule;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Garbage_collection}
 */
// @ts-ignore
export function createGarbage_collectionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoGarbage_collection;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {GenaiapiRegion}
 */
// @ts-ignore
export function createGenaiapiRegionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoGenaiapiRegion;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Glb_settings_cdn}
 */
// @ts-ignore
export function createGlb_settings_cdnFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoGlb_settings_cdn;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Glb_settings_region_priorities}
 */
// @ts-ignore
export function createGlb_settings_region_prioritiesFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoGlb_settings_region_priorities;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Glb_settings}
 */
// @ts-ignore
export function createGlb_settingsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoGlb_settings;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Gpu_info_vram}
 */
// @ts-ignore
export function createGpu_info_vramFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoGpu_info_vram;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Gpu_info}
 */
// @ts-ignore
export function createGpu_infoFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoGpu_info;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Grant}
 */
// @ts-ignore
export function createGrantFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoGrant;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Health_check}
 */
// @ts-ignore
export function createHealth_checkFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoHealth_check;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {History}
 */
// @ts-ignore
export function createHistoryFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoHistory;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Image_action_base}
 */
// @ts-ignore
export function createImage_action_baseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoImage_action_base;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Image_action_transfer}
 */
// @ts-ignore
export function createImage_action_transferFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoImage_action_transfer;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Image_new_custom}
 */
// @ts-ignore
export function createImage_new_customFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoImage_new_custom;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Image_update}
 */
// @ts-ignore
export function createImage_updateFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoImage_update;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Image}
 */
// @ts-ignore
export function createImageFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoImage;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Invoice_item}
 */
// @ts-ignore
export function createInvoice_itemFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoInvoice_item;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Invoice_preview}
 */
// @ts-ignore
export function createInvoice_previewFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoInvoice_preview;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Invoice_summary}
 */
// @ts-ignore
export function createInvoice_summaryFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoInvoice_summary;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kafka_advanced_config}
 */
// @ts-ignore
export function createKafka_advanced_configFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKafka_advanced_config;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kafka_topic_base}
 */
// @ts-ignore
export function createKafka_topic_baseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKafka_topic_base;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kafka_topic_config}
 */
// @ts-ignore
export function createKafka_topic_configFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKafka_topic_config;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kafka_topic_create}
 */
// @ts-ignore
export function createKafka_topic_createFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKafka_topic_create;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kafka_topic_partition_consumer_groups}
 */
// @ts-ignore
export function createKafka_topic_partition_consumer_groupsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKafka_topic_partition_consumer_groups;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kafka_topic_partition}
 */
// @ts-ignore
export function createKafka_topic_partitionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKafka_topic_partition;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kafka_topic_update}
 */
// @ts-ignore
export function createKafka_topic_updateFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKafka_topic_update;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kafka_topic_verbose}
 */
// @ts-ignore
export function createKafka_topic_verboseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKafka_topic_verbose;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kafka_topic}
 */
// @ts-ignore
export function createKafka_topicFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKafka_topic;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kernel}
 */
// @ts-ignore
export function createKernelFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKernel;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Key_create_response}
 */
// @ts-ignore
export function createKey_create_responseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKey_create_response;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Key}
 */
// @ts-ignore
export function createKeyFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKey;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kubernetes_node_pool_labels}
 */
// @ts-ignore
export function createKubernetes_node_pool_labelsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKubernetes_node_pool_labels;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kubernetes_node_pool_taint}
 */
// @ts-ignore
export function createKubernetes_node_pool_taintFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKubernetes_node_pool_taint;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kubernetes_node_pool_update_labels}
 */
// @ts-ignore
export function createKubernetes_node_pool_update_labelsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKubernetes_node_pool_update_labels;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kubernetes_node_pool_update}
 */
// @ts-ignore
export function createKubernetes_node_pool_updateFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKubernetes_node_pool_update;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kubernetes_node_pool}
 */
// @ts-ignore
export function createKubernetes_node_poolFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKubernetes_node_pool;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kubernetes_options_options}
 */
// @ts-ignore
export function createKubernetes_options_optionsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKubernetes_options_options;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kubernetes_options}
 */
// @ts-ignore
export function createKubernetes_optionsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKubernetes_options;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kubernetes_region}
 */
// @ts-ignore
export function createKubernetes_regionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKubernetes_region;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kubernetes_size}
 */
// @ts-ignore
export function createKubernetes_sizeFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKubernetes_size;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Kubernetes_version}
 */
// @ts-ignore
export function createKubernetes_versionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoKubernetes_version;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Lb_firewall}
 */
// @ts-ignore
export function createLb_firewallFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoLb_firewall;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Load_balancer_base}
 */
// @ts-ignore
export function createLoad_balancer_baseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoLoad_balancer_base;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Load_balancer_region}
 */
// @ts-ignore
export function createLoad_balancer_regionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoLoad_balancer_region;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Load_balancer}
 */
// @ts-ignore
export function createLoad_balancerFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoLoad_balancer;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Logsink_base_verbose}
 */
// @ts-ignore
export function createLogsink_base_verboseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoLogsink_base_verbose;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Logsink_base}
 */
// @ts-ignore
export function createLogsink_baseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoLogsink_base;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Elasticsearch_logsink | Opensearch_logsink | Rsyslog_logsink}
 */
// @ts-ignore
export function createLogsink_create_configFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoLogsink_create_config;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Logsink_create}
 */
// @ts-ignore
export function createLogsink_createFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoLogsink_create;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Elasticsearch_logsink | Opensearch_logsink | Rsyslog_logsink}
 */
// @ts-ignore
export function createLogsink_update_configFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoLogsink_update_config;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Logsink_update}
 */
// @ts-ignore
export function createLogsink_updateFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoLogsink_update;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Elasticsearch_logsink | Opensearch_logsink | Rsyslog_logsink}
 */
// @ts-ignore
export function createLogsink_verbose_configFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoLogsink_verbose_config;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Logsink_verbose}
 */
// @ts-ignore
export function createLogsink_verboseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoLogsink_verbose;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Maintenance_policy}
 */
// @ts-ignore
export function createMaintenance_policyFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoMaintenance_policy;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Member_current_utilization}
 */
// @ts-ignore
export function createMember_current_utilizationFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoMember_current_utilization;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Member}
 */
// @ts-ignore
export function createMemberFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoMember;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Meta_properties}
 */
// @ts-ignore
export function createMeta_propertiesFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoMeta_properties;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Metrics_data}
 */
// @ts-ignore
export function createMetrics_dataFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoMetrics_data;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Metrics_result_metric}
 */
// @ts-ignore
export function createMetrics_result_metricFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoMetrics_result_metric;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Metrics_result}
 */
// @ts-ignore
export function createMetrics_resultFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoMetrics_result;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Metrics}
 */
// @ts-ignore
export function createMetricsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoMetrics;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Mongo_advanced_config}
 */
// @ts-ignore
export function createMongo_advanced_configFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoMongo_advanced_config;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Mysql_advanced_config}
 */
// @ts-ignore
export function createMysql_advanced_configFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoMysql_advanced_config;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Mysql_settings}
 */
// @ts-ignore
export function createMysql_settingsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoMysql_settings;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Namespace_info}
 */
// @ts-ignore
export function createNamespace_infoFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoNamespace_info;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Neighbor_ids}
 */
// @ts-ignore
export function createNeighbor_idsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoNeighbor_ids;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Network_v4}
 */
// @ts-ignore
export function createNetwork_v4FromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoNetwork_v4;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Network_v6}
 */
// @ts-ignore
export function createNetwork_v6FromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoNetwork_v6;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Node_status}
 */
// @ts-ignore
export function createNode_statusFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoNode_status;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Node}
 */
// @ts-ignore
export function createNodeFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoNode;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Notification_slack}
 */
// @ts-ignore
export function createNotification_slackFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoNotification_slack;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Notification}
 */
// @ts-ignore
export function createNotificationFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoNotification;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {OneClicks_create}
 */
// @ts-ignore
export function createOneClicks_createFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOneClicks_create;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {OneClicks}
 */
// @ts-ignore
export function createOneClicksFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOneClicks;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Online_migration}
 */
// @ts-ignore
export function createOnline_migrationFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOnline_migration;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Opensearch_advanced_config}
 */
// @ts-ignore
export function createOpensearch_advanced_configFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOpensearch_advanced_config;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Opensearch_config_credentials}
 */
// @ts-ignore
export function createOpensearch_config_credentialsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOpensearch_config_credentials;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Opensearch_config_omit_credentials}
 */
// @ts-ignore
export function createOpensearch_config_omit_credentialsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOpensearch_config_omit_credentials;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Opensearch_config_request_credentials}
 */
// @ts-ignore
export function createOpensearch_config_request_credentialsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOpensearch_config_request_credentials;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Opensearch_config_request}
 */
// @ts-ignore
export function createOpensearch_config_requestFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOpensearch_config_request;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Opensearch_config}
 */
// @ts-ignore
export function createOpensearch_configFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOpensearch_config;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Opensearch_connection}
 */
// @ts-ignore
export function createOpensearch_connectionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOpensearch_connection;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Opensearch_index_base}
 */
// @ts-ignore
export function createOpensearch_index_baseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOpensearch_index_base;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Opensearch_index}
 */
// @ts-ignore
export function createOpensearch_indexFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOpensearch_index;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Opensearch_logsink}
 */
// @ts-ignore
export function createOpensearch_logsinkFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOpensearch_logsink;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Options_options_kafka}
 */
// @ts-ignore
export function createOptions_options_kafkaFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOptions_options_kafka;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Options_options_mongodb}
 */
// @ts-ignore
export function createOptions_options_mongodbFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOptions_options_mongodb;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Options_options_mysql}
 */
// @ts-ignore
export function createOptions_options_mysqlFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOptions_options_mysql;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Options_options_opensearch}
 */
// @ts-ignore
export function createOptions_options_opensearchFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOptions_options_opensearch;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Options_options_pg}
 */
// @ts-ignore
export function createOptions_options_pgFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOptions_options_pg;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Options_options_redis}
 */
// @ts-ignore
export function createOptions_options_redisFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOptions_options_redis;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Options_options}
 */
// @ts-ignore
export function createOptions_optionsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOptions_options;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Options_version_availability}
 */
// @ts-ignore
export function createOptions_version_availabilityFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOptions_version_availability;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Options}
 */
// @ts-ignore
export function createOptionsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoOptions;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Backward_links | Forward_links | Page_links_pagesMember1}
 */
// @ts-ignore
export function createPage_links_pagesFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoPage_links_pages;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Page_links_pagesMember1}
 */
// @ts-ignore
export function createPage_links_pagesMember1FromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoPage_links_pagesMember1;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Page_links}
 */
// @ts-ignore
export function createPage_linksFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoPage_links;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Pgbouncer_advanced_config}
 */
// @ts-ignore
export function createPgbouncer_advanced_configFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoPgbouncer_advanced_config;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Postgres_advanced_config}
 */
// @ts-ignore
export function createPostgres_advanced_configFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoPostgres_advanced_config;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Previous_outage}
 */
// @ts-ignore
export function createPrevious_outageFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoPrevious_outage;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Product_charge_item}
 */
// @ts-ignore
export function createProduct_charge_itemFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoProduct_charge_item;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Product_usage_charges}
 */
// @ts-ignore
export function createProduct_usage_chargesFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoProduct_usage_charges;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Project_assignment}
 */
// @ts-ignore
export function createProject_assignmentFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoProject_assignment;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Project_base}
 */
// @ts-ignore
export function createProject_baseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoProject_base;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Project}
 */
// @ts-ignore
export function createProjectFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoProject;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Purge_cache}
 */
// @ts-ignore
export function createPurge_cacheFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoPurge_cache;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Redis_advanced_config}
 */
// @ts-ignore
export function createRedis_advanced_configFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoRedis_advanced_config;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Region_state}
 */
// @ts-ignore
export function createRegion_stateFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoRegion_state;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Regional_state}
 */
// @ts-ignore
export function createRegional_stateFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoRegional_state;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Region}
 */
// @ts-ignore
export function createRegionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoRegion;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Registry_create}
 */
// @ts-ignore
export function createRegistry_createFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoRegistry_create;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Registry}
 */
// @ts-ignore
export function createRegistryFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoRegistry;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Repository_blob}
 */
// @ts-ignore
export function createRepository_blobFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoRepository_blob;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Repository_manifest}
 */
// @ts-ignore
export function createRepository_manifestFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoRepository_manifest;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Repository_tag}
 */
// @ts-ignore
export function createRepository_tagFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoRepository_tag;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Repository_v2}
 */
// @ts-ignore
export function createRepository_v2FromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoRepository_v2;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Repository}
 */
// @ts-ignore
export function createRepositoryFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoRepository;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Reserved_ip_action_assign}
 */
// @ts-ignore
export function createReserved_ip_action_assignFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoReserved_ip_action_assign;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Reserved_ip_action_type}
 */
// @ts-ignore
export function createReserved_ip_action_typeFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    if(!parseNode) throw new Error("parseNode cannot be undefined");
    const mappingValueNode = parseNode?.getChildNode("type");
    if (mappingValueNode) {
        const mappingValue = mappingValueNode.getStringValue();
        if (mappingValue) {
            switch (mappingValue) {
                case "assign":
                    return deserializeIntoReserved_ip_action_assign;
                case "unassign":
                    return deserializeIntoReserved_ip_action_unassign;
            }
        }
    }
    return deserializeIntoReserved_ip_action_type;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Reserved_ip_action_unassign}
 */
// @ts-ignore
export function createReserved_ip_action_unassignFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoReserved_ip_action_unassign;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Reserved_ip_createMember1}
 */
// @ts-ignore
export function createReserved_ip_createMember1FromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoReserved_ip_createMember1;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Reserved_ip_createMember2}
 */
// @ts-ignore
export function createReserved_ip_createMember2FromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoReserved_ip_createMember2;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Reserved_ip}
 */
// @ts-ignore
export function createReserved_ipFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoReserved_ip;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Reserved_ipv6_action_assign}
 */
// @ts-ignore
export function createReserved_ipv6_action_assignFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoReserved_ipv6_action_assign;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Reserved_ipv6_action_type}
 */
// @ts-ignore
export function createReserved_ipv6_action_typeFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    if(!parseNode) throw new Error("parseNode cannot be undefined");
    const mappingValueNode = parseNode?.getChildNode("type");
    if (mappingValueNode) {
        const mappingValue = mappingValueNode.getStringValue();
        if (mappingValue) {
            switch (mappingValue) {
                case "assign":
                    return deserializeIntoReserved_ipv6_action_assign;
                case "unassign":
                    return deserializeIntoReserved_ipv6_action_unassign;
            }
        }
    }
    return deserializeIntoReserved_ipv6_action_type;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Reserved_ipv6_action_unassign}
 */
// @ts-ignore
export function createReserved_ipv6_action_unassignFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoReserved_ipv6_action_unassign;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Reserved_ipv6_create}
 */
// @ts-ignore
export function createReserved_ipv6_createFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoReserved_ipv6_create;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Reserved_ipv6}
 */
// @ts-ignore
export function createReserved_ipv6FromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoReserved_ipv6;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Resource_links}
 */
// @ts-ignore
export function createResource_linksFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoResource_links;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Resource}
 */
// @ts-ignore
export function createResourceFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoResource;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Routing_agent}
 */
// @ts-ignore
export function createRouting_agentFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoRouting_agent;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Rsyslog_logsink}
 */
// @ts-ignore
export function createRsyslog_logsinkFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoRsyslog_logsink;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Scheduled_details_body}
 */
// @ts-ignore
export function createScheduled_details_bodyFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoScheduled_details_body;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Scheduled_details}
 */
// @ts-ignore
export function createScheduled_detailsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoScheduled_details;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Selective_destroy_associated_resource}
 */
// @ts-ignore
export function createSelective_destroy_associated_resourceFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoSelective_destroy_associated_resource;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Simple_charge}
 */
// @ts-ignore
export function createSimple_chargeFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoSimple_charge;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Sink_resource}
 */
// @ts-ignore
export function createSink_resourceFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoSink_resource;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Sinks_response}
 */
// @ts-ignore
export function createSinks_responseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoSinks_response;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Size}
 */
// @ts-ignore
export function createSizeFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoSize;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Slack_details}
 */
// @ts-ignore
export function createSlack_detailsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoSlack_details;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Snapshots_base}
 */
// @ts-ignore
export function createSnapshots_baseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoSnapshots_base;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Snapshots}
 */
// @ts-ignore
export function createSnapshotsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoSnapshots;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Source_database_source}
 */
// @ts-ignore
export function createSource_database_sourceFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoSource_database_source;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Source_database}
 */
// @ts-ignore
export function createSource_databaseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoSource_database;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Sql_mode}
 */
// @ts-ignore
export function createSql_modeFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoSql_mode;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {SshKeys}
 */
// @ts-ignore
export function createSshKeysFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoSshKeys;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {State}
 */
// @ts-ignore
export function createStateFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoState;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Sticky_sessions}
 */
// @ts-ignore
export function createSticky_sessionsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoSticky_sessions;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Subscription_tier_base}
 */
// @ts-ignore
export function createSubscription_tier_baseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoSubscription_tier_base;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Subscription}
 */
// @ts-ignore
export function createSubscriptionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoSubscription;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Supported_droplet_backup_policy}
 */
// @ts-ignore
export function createSupported_droplet_backup_policyFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoSupported_droplet_backup_policy;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Tags_metadata}
 */
// @ts-ignore
export function createTags_metadataFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoTags_metadata;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Tags_resource_resources}
 */
// @ts-ignore
export function createTags_resource_resourcesFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoTags_resource_resources;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Tags_resource}
 */
// @ts-ignore
export function createTags_resourceFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoTags_resource;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Tags_resources}
 */
// @ts-ignore
export function createTags_resourcesFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoTags_resources;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Tags}
 */
// @ts-ignore
export function createTagsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoTags;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Timescaledb_advanced_config}
 */
// @ts-ignore
export function createTimescaledb_advanced_configFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoTimescaledb_advanced_config;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Trigger_info_scheduled_runs}
 */
// @ts-ignore
export function createTrigger_info_scheduled_runsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoTrigger_info_scheduled_runs;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Trigger_info}
 */
// @ts-ignore
export function createTrigger_infoFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoTrigger_info;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Update_endpoint}
 */
// @ts-ignore
export function createUpdate_endpointFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoUpdate_endpoint;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Update_registry}
 */
// @ts-ignore
export function createUpdate_registryFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoUpdate_registry;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Update_trigger}
 */
// @ts-ignore
export function createUpdate_triggerFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoUpdate_trigger;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {User_kubernetes_cluster_user}
 */
// @ts-ignore
export function createUser_kubernetes_cluster_userFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoUser_kubernetes_cluster_user;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {User_settings_acl}
 */
// @ts-ignore
export function createUser_settings_aclFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoUser_settings_acl;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {User_settings_opensearch_acl}
 */
// @ts-ignore
export function createUser_settings_opensearch_aclFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoUser_settings_opensearch_acl;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {User_settings}
 */
// @ts-ignore
export function createUser_settingsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoUser_settings;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {User}
 */
// @ts-ignore
export function createUserFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoUser;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Validate_registry}
 */
// @ts-ignore
export function createValidate_registryFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoValidate_registry;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Version2}
 */
// @ts-ignore
export function createVersion2FromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoVersion2;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Volume_action_post_attach}
 */
// @ts-ignore
export function createVolume_action_post_attachFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoVolume_action_post_attach;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Volume_action_post_base}
 */
// @ts-ignore
export function createVolume_action_post_baseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoVolume_action_post_base;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Volume_action_post_detach}
 */
// @ts-ignore
export function createVolume_action_post_detachFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoVolume_action_post_detach;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Volume_action_post_resize}
 */
// @ts-ignore
export function createVolume_action_post_resizeFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoVolume_action_post_resize;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Volume_base}
 */
// @ts-ignore
export function createVolume_baseFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoVolume_base;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Volume_full}
 */
// @ts-ignore
export function createVolume_fullFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoVolume_full;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {VolumeAction}
 */
// @ts-ignore
export function createVolumeActionFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoVolumeAction;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Volumes_ext4}
 */
// @ts-ignore
export function createVolumes_ext4FromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoVolumes_ext4;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Volumes_xfs}
 */
// @ts-ignore
export function createVolumes_xfsFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoVolumes_xfs;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Vpc_member}
 */
// @ts-ignore
export function createVpc_memberFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoVpc_member;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Vpc_peering_updatable}
 */
// @ts-ignore
export function createVpc_peering_updatableFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoVpc_peering_updatable;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Vpc_peering}
 */
// @ts-ignore
export function createVpc_peeringFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoVpc_peering;
}
/**
 * Creates a new instance of the appropriate class based on discriminator value
 * @param parseNode The parse node to use to read the discriminator value and create the object
 * @returns {Vpc}
 */
// @ts-ignore
export function createVpcFromDiscriminatorValue(parseNode: ParseNode | undefined) : ((instance?: Parsable) => Record<string, (node: ParseNode) => void>) {
    return deserializeIntoVpc;
}
export interface Credentials extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A base64 encoding of bytes representing the certificate authority data for accessing the cluster.
     */
    certificateAuthorityData?: ArrayBuffer | null;
    /**
     * A base64 encoding of bytes representing the x509 clientcertificate data for access the cluster. This is only returned for clusterswithout support for token-based authentication.Newly created Kubernetes clusters do not return credentials usingcertificate-based authentication. For additional information,[see here](https://docs.digitalocean.com/products/kubernetes/how-to/connect-to-cluster/#authenticate).
     * @deprecated 
     */
    clientCertificateData?: ArrayBuffer | null;
    /**
     * A base64 encoding of bytes representing the x509 client keydata for access the cluster. This is only returned for clusters withoutsupport for token-based authentication.Newly created Kubernetes clusters do not return credentials usingcertificate-based authentication. For additional information,[see here](https://docs.digitalocean.com/products/kubernetes/how-to/connect-to-cluster/#authenticate).
     * @deprecated 
     */
    clientKeyData?: ArrayBuffer | null;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the access token expires.
     */
    expiresAt?: Date | null;
    /**
     * The URL used to access the cluster API server.
     */
    server?: string | null;
    /**
     * An access token used to authenticate with the cluster. This is only returned for clusters with support for token-based authentication.
     */
    token?: string | null;
}
export interface Current_utilization extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The average CPU utilization of the autoscale pool.
     */
    cpu?: number | null;
    /**
     * The average memory utilization of the autoscale pool.
     */
    memory?: number | null;
}
export interface Database extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name of the database.
     */
    name?: string | null;
}
export interface Database_backup extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The timestamp of an existing database cluster backup in ISO8601 combined date and time format. The most recent backup will be used if excluded.
     */
    backupCreatedAt?: Date | null;
    /**
     * The name of an existing database cluster from which the backup will be restored.
     */
    databaseName?: string | null;
}
export interface Database_cluster extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The connection property
     */
    connection?: Database_connection | null;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the database cluster was created.
     */
    createdAt?: Date | null;
    /**
     * An array of strings containing the names of databases created in the database cluster.
     */
    dbNames?: string[] | null;
    /**
     * A slug representing the database engine used for the cluster. The possible values are: "pg" for PostgreSQL, "mysql" for MySQL, "redis" for Redis, "mongodb" for MongoDB, "kafka" for Kafka, and "opensearch" for OpenSearch.
     */
    engine?: Database_cluster_engine | null;
    /**
     * A unique ID that can be used to identify and reference a database cluster.
     */
    id?: Guid | null;
    /**
     * The maintenance_window property
     */
    maintenanceWindow?: Database_maintenance_window | null;
    /**
     * Public hostname and port of the cluster's metrics endpoint(s). Includes one record for the cluster's primary node and a second entry for the cluster's standby node(s).
     */
    metricsEndpoints?: Database_service_endpoint[] | null;
    /**
     * A unique, human-readable name referring to a database cluster.
     */
    name?: string | null;
    /**
     * The number of nodes in the database cluster.
     */
    numNodes?: number | null;
    /**
     * The private_connection property
     */
    privateConnection?: Database_connection | null;
    /**
     * A string specifying the UUID of the VPC to which the database cluster will be assigned. If excluded, the cluster when creating a new database cluster, it will be assigned to your account's default VPC for the region.
     */
    privateNetworkUuid?: string | null;
    /**
     * The ID of the project that the database cluster is assigned to. If excluded when creating a new database cluster, it will be assigned to your default project.
     */
    projectId?: Guid | null;
    /**
     * The slug identifier for the region where the database cluster is located.
     */
    region?: string | null;
    /**
     * The rules property
     */
    rules?: Firewall_rule[] | null;
    /**
     * A string representing the semantic version of the database engine in use for the cluster.
     */
    semanticVersion?: string | null;
    /**
     * The slug identifier representing the size of the nodes in the database cluster.
     */
    size?: string | null;
    /**
     * The standby_connection property
     */
    standbyConnection?: Database_connection | null;
    /**
     * The standby_private_connection property
     */
    standbyPrivateConnection?: Database_connection | null;
    /**
     * A string representing the current status of the database cluster.
     */
    status?: Database_cluster_status | null;
    /**
     * Additional storage added to the cluster, in MiB. If null, no additional storage is added to the cluster, beyond what is provided as a base amount from the 'size' and any previously added additional storage.
     */
    storageSizeMib?: number | null;
    /**
     * An array of tags that have been applied to the database cluster.
     */
    tags?: string[] | null;
    /**
     * The connection details for OpenSearch dashboard. 
     */
    uiConnection?: Opensearch_connection | null;
    /**
     * The users property
     */
    users?: Database_user[] | null;
    /**
     * A string representing the version of the database engine in use for the cluster.
     */
    version?: string | null;
    /**
     * A timestamp referring to the date when the particular version will no longer be available for creating new clusters. If null, the version does not have an end of availability timeline.
     */
    versionEndOfAvailability?: string | null;
    /**
     * A timestamp referring to the date when the particular version will no longer be supported. If null, the version does not have an end of life timeline.
     */
    versionEndOfLife?: string | null;
}
export type Database_cluster_engine = (typeof Database_cluster_engineObject)[keyof typeof Database_cluster_engineObject];
export interface Database_cluster_resize extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The number of nodes in the database cluster. Valid values are are 1-3. In addition to the primary node, up to two standby nodes may be added for highly available configurations.
     */
    numNodes?: number | null;
    /**
     * A slug identifier representing desired the size of the nodes in the database cluster.
     */
    size?: string | null;
    /**
     * Additional storage added to the cluster, in MiB. If null, no additional storage is added to the cluster, beyond what is provided as a base amount from the 'size' and any previously added additional storage.
     */
    storageSizeMib?: number | null;
}
export type Database_cluster_status = (typeof Database_cluster_statusObject)[keyof typeof Database_cluster_statusObject];
export interface Database_config extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The config property
     */
    config?: Kafka_advanced_config | Mongo_advanced_config | Mysql_advanced_config | Opensearch_advanced_config | Postgres_advanced_config | Redis_advanced_config | null;
}
export type Database_config_config = Kafka_advanced_config | Mongo_advanced_config | Mysql_advanced_config | Opensearch_advanced_config | Postgres_advanced_config | Redis_advanced_config;
export interface Database_connection extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name of the default database.
     */
    database?: string | null;
    /**
     * The FQDN pointing to the database cluster's current primary node.
     */
    host?: string | null;
    /**
     * The randomly generated password for the default user.
     */
    password?: string | null;
    /**
     * The port on which the database cluster is listening.
     */
    port?: number | null;
    /**
     * A boolean value indicating if the connection should be made over SSL.
     */
    ssl?: boolean | null;
    /**
     * A connection string in the format accepted by the `psql` command. This is provided as a convenience and should be able to be constructed by the other attributes.
     */
    uri?: string | null;
    /**
     * The default user for the database.
     */
    user?: string | null;
}
export interface Database_layout_option extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The num_nodes property
     */
    numNodes?: number | null;
    /**
     * An array of objects containing the slugs available with various node counts
     */
    sizes?: string[] | null;
}
export interface Database_maintenance_window extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The day of the week on which to apply maintenance updates.
     */
    day?: string | null;
    /**
     * A list of strings, each containing information about a pending maintenance update.
     */
    description?: string[] | null;
    /**
     * The hour in UTC at which maintenance updates will be applied in 24 hour format.
     */
    hour?: string | null;
    /**
     * A boolean value indicating whether any maintenance is scheduled to be performed in the next window.
     */
    pending?: boolean | null;
}
export interface Database_metrics_credentials extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The credentials property
     */
    credentials?: Databases_basic_auth_credentials | null;
}
export interface Database_replica extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The connection property
     */
    connection?: Database_connection | null;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the database cluster was created.
     */
    createdAt?: Date | null;
    /**
     * A unique ID that can be used to identify and reference a database replica.
     */
    id?: Guid | null;
    /**
     * The name to give the read-only replicating
     */
    name?: string | null;
    /**
     * The private_connection property
     */
    privateConnection?: Database_connection | null;
    /**
     * A string specifying the UUID of the VPC to which the read-only replica will be assigned. If excluded, the replica will be assigned to your account's default VPC for the region.
     */
    privateNetworkUuid?: string | null;
    /**
     * A slug identifier for the region where the read-only replica will be located. If excluded, the replica will be placed in the same region as the cluster.
     */
    region?: string | null;
    /**
     * A slug identifier representing the size of the node for the read-only replica. The size of the replica must be at least as large as the node size for the database cluster from which it is replicating.
     */
    size?: string | null;
    /**
     * A string representing the current status of the database cluster.
     */
    status?: Database_replica_status | null;
    /**
     * Additional storage added to the cluster, in MiB. If null, no additional storage is added to the cluster, beyond what is provided as a base amount from the 'size' and any previously added additional storage.
     */
    storageSizeMib?: number | null;
    /**
     * A flat array of tag names as strings to apply to the read-only replica after it is created. Tag names can either be existing or new tags.
     */
    tags?: string[] | null;
}
export type Database_replica_status = (typeof Database_replica_statusObject)[keyof typeof Database_replica_statusObject];
export interface Database_service_endpoint extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A FQDN pointing to the database cluster's node(s).
     */
    host?: string | null;
    /**
     * The port on which a service is listening.
     */
    port?: number | null;
}
export interface Database_user extends AdditionalDataHolder, Parsable {
    /**
     * Access certificate for TLS client authentication. (Kafka only)
     */
    accessCert?: string | null;
    /**
     * Access key for TLS client authentication. (Kafka only)
     */
    accessKey?: string | null;
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The mysql_settings property
     */
    mysqlSettings?: Mysql_settings | null;
    /**
     * The name of a database user.
     */
    name?: string | null;
    /**
     * A randomly generated password for the database user.
     */
    password?: string | null;
    /**
     * A string representing the database user's role. The value will be either"primary" or "normal".
     */
    role?: Database_user_role | null;
    /**
     * The settings property
     */
    settings?: User_settings | null;
}
export type Database_user_role = (typeof Database_user_roleObject)[keyof typeof Database_user_roleObject];
export interface Database_version_availability extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A timestamp referring to the date when the particular version will no longer be available for creating new clusters. If null, the version does not have an end of availability timeline.
     */
    endOfAvailability?: string | null;
    /**
     * A timestamp referring to the date when the particular version will no longer be supported. If null, the version does not have an end of life timeline.
     */
    endOfLife?: string | null;
    /**
     * The engine version.
     */
    version?: string | null;
}
export interface Databases_basic_auth_credentials extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * basic authentication password for metrics HTTP endpoint
     */
    basicAuthPassword?: string | null;
    /**
     * basic authentication username for metrics HTTP endpoint
     */
    basicAuthUsername?: string | null;
}
export type DbaasClusterStatus = (typeof DbaasClusterStatusObject)[keyof typeof DbaasClusterStatusObject];
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAccount(account: Partial<Account> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "droplet_limit": n => { account.dropletLimit = n.getNumberValue(); },
        "email": n => { account.email = n.getStringValue(); },
        "email_verified": n => { account.emailVerified = n.getBooleanValue(); },
        "floating_ip_limit": n => { account.floatingIpLimit = n.getNumberValue(); },
        "name": n => { account.name = n.getStringValue(); },
        "status": n => { account.status = n.getEnumValue<Account_status>(Account_statusObject) ?? Account_statusObject.Active; },
        "status_message": n => { account.statusMessage = n.getStringValue(); },
        "team": n => { account.team = n.getObjectValue<Account_team>(createAccount_teamFromDiscriminatorValue); },
        "uuid": n => { account.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAccount_team(account_team: Partial<Account_team> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "name": n => { account_team.name = n.getStringValue(); },
        "uuid": n => { account_team.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAction(action: Partial<Action> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "completed_at": n => { action.completedAt = n.getDateValue(); },
        "id": n => { action.id = n.getNumberValue(); },
        "region": n => { action.region = n.getObjectValue<Region>(createRegionFromDiscriminatorValue); },
        "region_slug": n => { action.regionSlug = n.getStringValue(); },
        "resource_id": n => { action.resourceId = n.getNumberValue(); },
        "resource_type": n => { action.resourceType = n.getStringValue(); },
        "started_at": n => { action.startedAt = n.getDateValue(); },
        "status": n => { action.status = n.getEnumValue<Action_status>(Action_statusObject) ?? Action_statusObject.InProgress; },
        "type": n => { action.type = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAction_link(action_link: Partial<Action_link> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "href": n => { action_link.href = n.getStringValue(); },
        "id": n => { action_link.id = n.getNumberValue(); },
        "rel": n => { action_link.rel = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAlert(alert: Partial<Alert> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "comparison": n => { alert.comparison = n.getEnumValue<Alert_comparison>(Alert_comparisonObject); },
        "id": n => { alert.id = n.getGuidValue(); },
        "name": n => { alert.name = n.getStringValue(); },
        "notifications": n => { alert.notifications = n.getObjectValue<Notification>(createNotificationFromDiscriminatorValue); },
        "period": n => { alert.period = n.getEnumValue<Alert_period>(Alert_periodObject); },
        "threshold": n => { alert.threshold = n.getNumberValue(); },
        "type": n => { alert.type = n.getEnumValue<Alert_type>(Alert_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAlert_policy(alert_policy: Partial<Alert_policy> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "alerts": n => { alert_policy.alerts = n.getObjectValue<Alerts>(createAlertsFromDiscriminatorValue); },
        "compare": n => { alert_policy.compare = n.getEnumValue<Alert_policy_compare>(Alert_policy_compareObject); },
        "description": n => { alert_policy.description = n.getStringValue(); },
        "enabled": n => { alert_policy.enabled = n.getBooleanValue(); },
        "entities": n => { alert_policy.entities = n.getCollectionOfPrimitiveValues<string>(); },
        "tags": n => { alert_policy.tags = n.getCollectionOfPrimitiveValues<string>(); },
        "type": n => { alert_policy.type = n.getEnumValue<Alert_policy_type>(Alert_policy_typeObject); },
        "uuid": n => { alert_policy.uuid = n.getStringValue(); },
        "value": n => { alert_policy.value = n.getNumberValue(); },
        "window": n => { alert_policy.window = n.getEnumValue<Alert_policy_window>(Alert_policy_windowObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAlert_policy_request(alert_policy_request: Partial<Alert_policy_request> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "alerts": n => { alert_policy_request.alerts = n.getObjectValue<Alerts>(createAlertsFromDiscriminatorValue); },
        "compare": n => { alert_policy_request.compare = n.getEnumValue<Alert_policy_request_compare>(Alert_policy_request_compareObject); },
        "description": n => { alert_policy_request.description = n.getStringValue(); },
        "enabled": n => { alert_policy_request.enabled = n.getBooleanValue(); },
        "entities": n => { alert_policy_request.entities = n.getCollectionOfPrimitiveValues<string>(); },
        "tags": n => { alert_policy_request.tags = n.getCollectionOfPrimitiveValues<string>(); },
        "type": n => { alert_policy_request.type = n.getEnumValue<Alert_policy_request_type>(Alert_policy_request_typeObject); },
        "value": n => { alert_policy_request.value = n.getNumberValue(); },
        "window": n => { alert_policy_request.window = n.getEnumValue<Alert_policy_request_window>(Alert_policy_request_windowObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAlert_updatable(alert_updatable: Partial<Alert_updatable> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "comparison": n => { alert_updatable.comparison = n.getEnumValue<Alert_updatable_comparison>(Alert_updatable_comparisonObject); },
        "name": n => { alert_updatable.name = n.getStringValue(); },
        "notifications": n => { alert_updatable.notifications = n.getObjectValue<Notification>(createNotificationFromDiscriminatorValue); },
        "period": n => { alert_updatable.period = n.getEnumValue<Alert_updatable_period>(Alert_updatable_periodObject); },
        "threshold": n => { alert_updatable.threshold = n.getNumberValue(); },
        "type": n => { alert_updatable.type = n.getEnumValue<Alert_updatable_type>(Alert_updatable_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAlerts(alerts: Partial<Alerts> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "email": n => { alerts.email = n.getCollectionOfPrimitiveValues<string>(); },
        "slack": n => { alerts.slack = n.getCollectionOfObjectValues<Slack_details>(createSlack_detailsFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiAgent(apiAgent: Partial<ApiAgent> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "anthropic_api_key": n => { apiAgent.anthropicApiKey = n.getObjectValue<ApiAnthropicAPIKeyInfo>(createApiAnthropicAPIKeyInfoFromDiscriminatorValue); },
        "api_key_infos": n => { apiAgent.apiKeyInfos = n.getCollectionOfObjectValues<ApiAgentAPIKeyInfo>(createApiAgentAPIKeyInfoFromDiscriminatorValue); },
        "api_keys": n => { apiAgent.apiKeys = n.getCollectionOfObjectValues<ApiAgentAPIKey>(createApiAgentAPIKeyFromDiscriminatorValue); },
        "chatbot": n => { apiAgent.chatbot = n.getObjectValue<ApiChatbot>(createApiChatbotFromDiscriminatorValue); },
        "chatbot_identifiers": n => { apiAgent.chatbotIdentifiers = n.getCollectionOfObjectValues<ApiAgentChatbotIdentifier>(createApiAgentChatbotIdentifierFromDiscriminatorValue); },
        "child_agents": n => { apiAgent.childAgents = n.getCollectionOfObjectValues<ApiAgent>(createApiAgentFromDiscriminatorValue); },
        "created_at": n => { apiAgent.createdAt = n.getDateValue(); },
        "deployment": n => { apiAgent.deployment = n.getObjectValue<ApiDeployment>(createApiDeploymentFromDiscriminatorValue); },
        "description": n => { apiAgent.description = n.getStringValue(); },
        "functions": n => { apiAgent.functions = n.getCollectionOfObjectValues<ApiAgentFunction>(createApiAgentFunctionFromDiscriminatorValue); },
        "guardrails": n => { apiAgent.guardrails = n.getCollectionOfObjectValues<ApiAgentGuardrail>(createApiAgentGuardrailFromDiscriminatorValue); },
        "if_case": n => { apiAgent.ifCase = n.getStringValue(); },
        "instruction": n => { apiAgent.instruction = n.getStringValue(); },
        "k": n => { apiAgent.k = n.getNumberValue(); },
        "knowledge_bases": n => { apiAgent.knowledgeBases = n.getCollectionOfObjectValues<ApiKnowledgeBase>(createApiKnowledgeBaseFromDiscriminatorValue); },
        "max_tokens": n => { apiAgent.maxTokens = n.getNumberValue(); },
        "model": n => { apiAgent.model = n.getObjectValue<ApiModel>(createApiModelFromDiscriminatorValue); },
        "name": n => { apiAgent.name = n.getStringValue(); },
        "parent_agents": n => { apiAgent.parentAgents = n.getCollectionOfObjectValues<ApiAgent>(createApiAgentFromDiscriminatorValue); },
        "project_id": n => { apiAgent.projectId = n.getStringValue(); },
        "region": n => { apiAgent.region = n.getStringValue(); },
        "route_created_at": n => { apiAgent.routeCreatedAt = n.getDateValue(); },
        "route_created_by": n => { apiAgent.routeCreatedBy = n.getStringValue(); },
        "route_name": n => { apiAgent.routeName = n.getStringValue(); },
        "route_uuid": n => { apiAgent.routeUuid = n.getStringValue(); },
        "tags": n => { apiAgent.tags = n.getCollectionOfPrimitiveValues<string>(); },
        "temperature": n => { apiAgent.temperature = n.getNumberValue(); },
        "template": n => { apiAgent.template = n.getObjectValue<ApiAgentTemplate>(createApiAgentTemplateFromDiscriminatorValue); },
        "top_p": n => { apiAgent.topP = n.getNumberValue(); },
        "updated_at": n => { apiAgent.updatedAt = n.getDateValue(); },
        "url": n => { apiAgent.url = n.getStringValue(); },
        "user_id": n => { apiAgent.userId = n.getStringValue(); },
        "uuid": n => { apiAgent.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiAgentAPIKey(apiAgentAPIKey: Partial<ApiAgentAPIKey> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "api_key": n => { apiAgentAPIKey.apiKey = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiAgentAPIKeyInfo(apiAgentAPIKeyInfo: Partial<ApiAgentAPIKeyInfo> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { apiAgentAPIKeyInfo.createdAt = n.getDateValue(); },
        "created_by": n => { apiAgentAPIKeyInfo.createdBy = n.getStringValue(); },
        "deleted_at": n => { apiAgentAPIKeyInfo.deletedAt = n.getDateValue(); },
        "name": n => { apiAgentAPIKeyInfo.name = n.getStringValue(); },
        "secret_key": n => { apiAgentAPIKeyInfo.secretKey = n.getStringValue(); },
        "uuid": n => { apiAgentAPIKeyInfo.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiAgentChatbotIdentifier(apiAgentChatbotIdentifier: Partial<ApiAgentChatbotIdentifier> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agent_chatbot_identifier": n => { apiAgentChatbotIdentifier.agentChatbotIdentifier = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiAgentFunction(apiAgentFunction: Partial<ApiAgentFunction> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "api_key": n => { apiAgentFunction.apiKey = n.getStringValue(); },
        "created_at": n => { apiAgentFunction.createdAt = n.getDateValue(); },
        "description": n => { apiAgentFunction.description = n.getStringValue(); },
        "faas_name": n => { apiAgentFunction.faasName = n.getStringValue(); },
        "faas_namespace": n => { apiAgentFunction.faasNamespace = n.getStringValue(); },
        "input_schema": n => { apiAgentFunction.inputSchema = n.getObjectValue<ApiAgentFunction_input_schema>(createApiAgentFunction_input_schemaFromDiscriminatorValue); },
        "name": n => { apiAgentFunction.name = n.getStringValue(); },
        "output_schema": n => { apiAgentFunction.outputSchema = n.getObjectValue<ApiAgentFunction_output_schema>(createApiAgentFunction_output_schemaFromDiscriminatorValue); },
        "updated_at": n => { apiAgentFunction.updatedAt = n.getDateValue(); },
        "url": n => { apiAgentFunction.url = n.getStringValue(); },
        "uuid": n => { apiAgentFunction.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiAgentFunction_input_schema(apiAgentFunction_input_schema: Partial<ApiAgentFunction_input_schema> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiAgentFunction_output_schema(apiAgentFunction_output_schema: Partial<ApiAgentFunction_output_schema> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiAgentGuardrail(apiAgentGuardrail: Partial<ApiAgentGuardrail> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agent_uuid": n => { apiAgentGuardrail.agentUuid = n.getStringValue(); },
        "created_at": n => { apiAgentGuardrail.createdAt = n.getDateValue(); },
        "default_response": n => { apiAgentGuardrail.defaultResponse = n.getStringValue(); },
        "description": n => { apiAgentGuardrail.description = n.getStringValue(); },
        "guardrail_uuid": n => { apiAgentGuardrail.guardrailUuid = n.getStringValue(); },
        "is_attached": n => { apiAgentGuardrail.isAttached = n.getBooleanValue(); },
        "is_default": n => { apiAgentGuardrail.isDefault = n.getBooleanValue(); },
        "metadata": n => { apiAgentGuardrail.metadata = n.getObjectValue<ApiAgentGuardrail_metadata>(createApiAgentGuardrail_metadataFromDiscriminatorValue); },
        "name": n => { apiAgentGuardrail.name = n.getStringValue(); },
        "priority": n => { apiAgentGuardrail.priority = n.getNumberValue(); },
        "type": n => { apiAgentGuardrail.type = n.getEnumValue<ApiGuardrailType>(ApiGuardrailTypeObject) ?? ApiGuardrailTypeObject.GUARDRAIL_TYPE_UNKNOWN; },
        "updated_at": n => { apiAgentGuardrail.updatedAt = n.getDateValue(); },
        "uuid": n => { apiAgentGuardrail.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiAgentGuardrail_metadata(apiAgentGuardrail_metadata: Partial<ApiAgentGuardrail_metadata> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiAgentPublic(apiAgentPublic: Partial<ApiAgentPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "chatbot": n => { apiAgentPublic.chatbot = n.getObjectValue<ApiChatbot>(createApiChatbotFromDiscriminatorValue); },
        "chatbot_identifiers": n => { apiAgentPublic.chatbotIdentifiers = n.getCollectionOfObjectValues<ApiAgentChatbotIdentifier>(createApiAgentChatbotIdentifierFromDiscriminatorValue); },
        "created_at": n => { apiAgentPublic.createdAt = n.getDateValue(); },
        "deployment": n => { apiAgentPublic.deployment = n.getObjectValue<ApiDeployment>(createApiDeploymentFromDiscriminatorValue); },
        "description": n => { apiAgentPublic.description = n.getStringValue(); },
        "if_case": n => { apiAgentPublic.ifCase = n.getStringValue(); },
        "instruction": n => { apiAgentPublic.instruction = n.getStringValue(); },
        "k": n => { apiAgentPublic.k = n.getNumberValue(); },
        "max_tokens": n => { apiAgentPublic.maxTokens = n.getNumberValue(); },
        "model": n => { apiAgentPublic.model = n.getObjectValue<ApiModel>(createApiModelFromDiscriminatorValue); },
        "name": n => { apiAgentPublic.name = n.getStringValue(); },
        "project_id": n => { apiAgentPublic.projectId = n.getStringValue(); },
        "region": n => { apiAgentPublic.region = n.getStringValue(); },
        "route_created_at": n => { apiAgentPublic.routeCreatedAt = n.getDateValue(); },
        "route_created_by": n => { apiAgentPublic.routeCreatedBy = n.getStringValue(); },
        "route_name": n => { apiAgentPublic.routeName = n.getStringValue(); },
        "route_uuid": n => { apiAgentPublic.routeUuid = n.getStringValue(); },
        "tags": n => { apiAgentPublic.tags = n.getCollectionOfPrimitiveValues<string>(); },
        "temperature": n => { apiAgentPublic.temperature = n.getNumberValue(); },
        "template": n => { apiAgentPublic.template = n.getObjectValue<ApiAgentTemplate>(createApiAgentTemplateFromDiscriminatorValue); },
        "top_p": n => { apiAgentPublic.topP = n.getNumberValue(); },
        "updated_at": n => { apiAgentPublic.updatedAt = n.getDateValue(); },
        "url": n => { apiAgentPublic.url = n.getStringValue(); },
        "user_id": n => { apiAgentPublic.userId = n.getStringValue(); },
        "uuid": n => { apiAgentPublic.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiAgentTemplate(apiAgentTemplate: Partial<ApiAgentTemplate> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { apiAgentTemplate.createdAt = n.getDateValue(); },
        "description": n => { apiAgentTemplate.description = n.getStringValue(); },
        "instruction": n => { apiAgentTemplate.instruction = n.getStringValue(); },
        "k": n => { apiAgentTemplate.k = n.getNumberValue(); },
        "knowledge_bases": n => { apiAgentTemplate.knowledgeBases = n.getCollectionOfObjectValues<ApiKnowledgeBase>(createApiKnowledgeBaseFromDiscriminatorValue); },
        "max_tokens": n => { apiAgentTemplate.maxTokens = n.getNumberValue(); },
        "model": n => { apiAgentTemplate.model = n.getObjectValue<ApiModel>(createApiModelFromDiscriminatorValue); },
        "name": n => { apiAgentTemplate.name = n.getStringValue(); },
        "temperature": n => { apiAgentTemplate.temperature = n.getNumberValue(); },
        "top_p": n => { apiAgentTemplate.topP = n.getNumberValue(); },
        "updated_at": n => { apiAgentTemplate.updatedAt = n.getDateValue(); },
        "uuid": n => { apiAgentTemplate.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiAgreement(apiAgreement: Partial<ApiAgreement> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "description": n => { apiAgreement.description = n.getStringValue(); },
        "name": n => { apiAgreement.name = n.getStringValue(); },
        "url": n => { apiAgreement.url = n.getStringValue(); },
        "uuid": n => { apiAgreement.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiAnthropicAPIKeyInfo(apiAnthropicAPIKeyInfo: Partial<ApiAnthropicAPIKeyInfo> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { apiAnthropicAPIKeyInfo.createdAt = n.getDateValue(); },
        "created_by": n => { apiAnthropicAPIKeyInfo.createdBy = n.getStringValue(); },
        "deleted_at": n => { apiAnthropicAPIKeyInfo.deletedAt = n.getDateValue(); },
        "name": n => { apiAnthropicAPIKeyInfo.name = n.getStringValue(); },
        "updated_at": n => { apiAnthropicAPIKeyInfo.updatedAt = n.getDateValue(); },
        "uuid": n => { apiAnthropicAPIKeyInfo.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiCancelKnowledgeBaseIndexingJobInputPublic(apiCancelKnowledgeBaseIndexingJobInputPublic: Partial<ApiCancelKnowledgeBaseIndexingJobInputPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "uuid": n => { apiCancelKnowledgeBaseIndexingJobInputPublic.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiCancelKnowledgeBaseIndexingJobOutput(apiCancelKnowledgeBaseIndexingJobOutput: Partial<ApiCancelKnowledgeBaseIndexingJobOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "job": n => { apiCancelKnowledgeBaseIndexingJobOutput.job = n.getObjectValue<ApiIndexingJob>(createApiIndexingJobFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiChatbot(apiChatbot: Partial<ApiChatbot> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "button_background_color": n => { apiChatbot.buttonBackgroundColor = n.getStringValue(); },
        "logo": n => { apiChatbot.logo = n.getStringValue(); },
        "name": n => { apiChatbot.name = n.getStringValue(); },
        "primary_color": n => { apiChatbot.primaryColor = n.getStringValue(); },
        "secondary_color": n => { apiChatbot.secondaryColor = n.getStringValue(); },
        "starting_message": n => { apiChatbot.startingMessage = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiCreateAgentAPIKeyInputPublic(apiCreateAgentAPIKeyInputPublic: Partial<ApiCreateAgentAPIKeyInputPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agent_uuid": n => { apiCreateAgentAPIKeyInputPublic.agentUuid = n.getStringValue(); },
        "name": n => { apiCreateAgentAPIKeyInputPublic.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiCreateAgentAPIKeyOutput(apiCreateAgentAPIKeyOutput: Partial<ApiCreateAgentAPIKeyOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "api_key_info": n => { apiCreateAgentAPIKeyOutput.apiKeyInfo = n.getObjectValue<ApiAgentAPIKeyInfo>(createApiAgentAPIKeyInfoFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiCreateAgentInputPublic(apiCreateAgentInputPublic: Partial<ApiCreateAgentInputPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "anthropic_key_uuid": n => { apiCreateAgentInputPublic.anthropicKeyUuid = n.getStringValue(); },
        "description": n => { apiCreateAgentInputPublic.description = n.getStringValue(); },
        "instruction": n => { apiCreateAgentInputPublic.instruction = n.getStringValue(); },
        "knowledge_base_uuid": n => { apiCreateAgentInputPublic.knowledgeBaseUuid = n.getCollectionOfPrimitiveValues<string>(); },
        "model_uuid": n => { apiCreateAgentInputPublic.modelUuid = n.getStringValue(); },
        "name": n => { apiCreateAgentInputPublic.name = n.getStringValue(); },
        "project_id": n => { apiCreateAgentInputPublic.projectId = n.getStringValue(); },
        "region": n => { apiCreateAgentInputPublic.region = n.getStringValue(); },
        "tags": n => { apiCreateAgentInputPublic.tags = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiCreateAgentOutput(apiCreateAgentOutput: Partial<ApiCreateAgentOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agent": n => { apiCreateAgentOutput.agent = n.getObjectValue<ApiAgent>(createApiAgentFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiCreateAnthropicAPIKeyInputPublic(apiCreateAnthropicAPIKeyInputPublic: Partial<ApiCreateAnthropicAPIKeyInputPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "api_key": n => { apiCreateAnthropicAPIKeyInputPublic.apiKey = n.getStringValue(); },
        "name": n => { apiCreateAnthropicAPIKeyInputPublic.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiCreateAnthropicAPIKeyOutput(apiCreateAnthropicAPIKeyOutput: Partial<ApiCreateAnthropicAPIKeyOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "api_key_info": n => { apiCreateAnthropicAPIKeyOutput.apiKeyInfo = n.getObjectValue<ApiAnthropicAPIKeyInfo>(createApiAnthropicAPIKeyInfoFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiCreateKnowledgeBaseDataSourceInputPublic(apiCreateKnowledgeBaseDataSourceInputPublic: Partial<ApiCreateKnowledgeBaseDataSourceInputPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "file_upload_data_source": n => { apiCreateKnowledgeBaseDataSourceInputPublic.fileUploadDataSource = n.getObjectValue<ApiFileUploadDataSource>(createApiFileUploadDataSourceFromDiscriminatorValue); },
        "knowledge_base_uuid": n => { apiCreateKnowledgeBaseDataSourceInputPublic.knowledgeBaseUuid = n.getStringValue(); },
        "spaces_data_source": n => { apiCreateKnowledgeBaseDataSourceInputPublic.spacesDataSource = n.getObjectValue<ApiSpacesDataSource>(createApiSpacesDataSourceFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiCreateKnowledgeBaseDataSourceOutput(apiCreateKnowledgeBaseDataSourceOutput: Partial<ApiCreateKnowledgeBaseDataSourceOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "knowledge_base_data_source": n => { apiCreateKnowledgeBaseDataSourceOutput.knowledgeBaseDataSource = n.getObjectValue<ApiKnowledgeBaseDataSource>(createApiKnowledgeBaseDataSourceFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiCreateKnowledgeBaseInputPublic(apiCreateKnowledgeBaseInputPublic: Partial<ApiCreateKnowledgeBaseInputPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "database_id": n => { apiCreateKnowledgeBaseInputPublic.databaseId = n.getStringValue(); },
        "datasources": n => { apiCreateKnowledgeBaseInputPublic.datasources = n.getCollectionOfObjectValues<ApiKBDataSource>(createApiKBDataSourceFromDiscriminatorValue); },
        "embedding_model_uuid": n => { apiCreateKnowledgeBaseInputPublic.embeddingModelUuid = n.getStringValue(); },
        "name": n => { apiCreateKnowledgeBaseInputPublic.name = n.getStringValue(); },
        "project_id": n => { apiCreateKnowledgeBaseInputPublic.projectId = n.getStringValue(); },
        "region": n => { apiCreateKnowledgeBaseInputPublic.region = n.getStringValue(); },
        "tags": n => { apiCreateKnowledgeBaseInputPublic.tags = n.getCollectionOfPrimitiveValues<string>(); },
        "vpc_uuid": n => { apiCreateKnowledgeBaseInputPublic.vpcUuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiCreateKnowledgeBaseOutput(apiCreateKnowledgeBaseOutput: Partial<ApiCreateKnowledgeBaseOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "knowledge_base": n => { apiCreateKnowledgeBaseOutput.knowledgeBase = n.getObjectValue<ApiKnowledgeBase>(createApiKnowledgeBaseFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiDeleteAgentAPIKeyOutput(apiDeleteAgentAPIKeyOutput: Partial<ApiDeleteAgentAPIKeyOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "api_key_info": n => { apiDeleteAgentAPIKeyOutput.apiKeyInfo = n.getObjectValue<ApiAgentAPIKeyInfo>(createApiAgentAPIKeyInfoFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiDeleteAgentOutput(apiDeleteAgentOutput: Partial<ApiDeleteAgentOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agent": n => { apiDeleteAgentOutput.agent = n.getObjectValue<ApiAgent>(createApiAgentFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiDeleteAnthropicAPIKeyOutput(apiDeleteAnthropicAPIKeyOutput: Partial<ApiDeleteAnthropicAPIKeyOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "api_key_info": n => { apiDeleteAnthropicAPIKeyOutput.apiKeyInfo = n.getObjectValue<ApiAnthropicAPIKeyInfo>(createApiAnthropicAPIKeyInfoFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiDeleteKnowledgeBaseDataSourceOutput(apiDeleteKnowledgeBaseDataSourceOutput: Partial<ApiDeleteKnowledgeBaseDataSourceOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "data_source_uuid": n => { apiDeleteKnowledgeBaseDataSourceOutput.dataSourceUuid = n.getStringValue(); },
        "knowledge_base_uuid": n => { apiDeleteKnowledgeBaseDataSourceOutput.knowledgeBaseUuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiDeleteKnowledgeBaseOutput(apiDeleteKnowledgeBaseOutput: Partial<ApiDeleteKnowledgeBaseOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "uuid": n => { apiDeleteKnowledgeBaseOutput.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiDeployment(apiDeployment: Partial<ApiDeployment> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { apiDeployment.createdAt = n.getDateValue(); },
        "name": n => { apiDeployment.name = n.getStringValue(); },
        "status": n => { apiDeployment.status = n.getEnumValue<ApiDeploymentStatus>(ApiDeploymentStatusObject) ?? ApiDeploymentStatusObject.STATUS_UNKNOWN; },
        "updated_at": n => { apiDeployment.updatedAt = n.getDateValue(); },
        "url": n => { apiDeployment.url = n.getStringValue(); },
        "uuid": n => { apiDeployment.uuid = n.getStringValue(); },
        "visibility": n => { apiDeployment.visibility = n.getEnumValue<ApiDeploymentVisibility>(ApiDeploymentVisibilityObject) ?? ApiDeploymentVisibilityObject.VISIBILITY_UNKNOWN; },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiFileUploadDataSource(apiFileUploadDataSource: Partial<ApiFileUploadDataSource> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "original_file_name": n => { apiFileUploadDataSource.originalFileName = n.getStringValue(); },
        "size_in_bytes": n => { apiFileUploadDataSource.sizeInBytes = n.getStringValue(); },
        "stored_object_key": n => { apiFileUploadDataSource.storedObjectKey = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiGetAgentOutput(apiGetAgentOutput: Partial<ApiGetAgentOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agent": n => { apiGetAgentOutput.agent = n.getObjectValue<ApiAgent>(createApiAgentFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiGetAnthropicAPIKeyOutput(apiGetAnthropicAPIKeyOutput: Partial<ApiGetAnthropicAPIKeyOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "api_key_info": n => { apiGetAnthropicAPIKeyOutput.apiKeyInfo = n.getObjectValue<ApiAnthropicAPIKeyInfo>(createApiAnthropicAPIKeyInfoFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiGetChildrenOutput(apiGetChildrenOutput: Partial<ApiGetChildrenOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "children": n => { apiGetChildrenOutput.children = n.getCollectionOfObjectValues<ApiAgent>(createApiAgentFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiGetKnowledgeBaseIndexingJobOutput(apiGetKnowledgeBaseIndexingJobOutput: Partial<ApiGetKnowledgeBaseIndexingJobOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "job": n => { apiGetKnowledgeBaseIndexingJobOutput.job = n.getObjectValue<ApiIndexingJob>(createApiIndexingJobFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiGetKnowledgeBaseOutput(apiGetKnowledgeBaseOutput: Partial<ApiGetKnowledgeBaseOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "database_status": n => { apiGetKnowledgeBaseOutput.databaseStatus = n.getEnumValue<DbaasClusterStatus>(DbaasClusterStatusObject) ?? DbaasClusterStatusObject.CREATING; },
        "knowledge_base": n => { apiGetKnowledgeBaseOutput.knowledgeBase = n.getObjectValue<ApiKnowledgeBase>(createApiKnowledgeBaseFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiIndexedDataSource(apiIndexedDataSource: Partial<ApiIndexedDataSource> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "completed_at": n => { apiIndexedDataSource.completedAt = n.getDateValue(); },
        "data_source_uuid": n => { apiIndexedDataSource.dataSourceUuid = n.getStringValue(); },
        "indexed_file_count": n => { apiIndexedDataSource.indexedFileCount = n.getStringValue(); },
        "started_at": n => { apiIndexedDataSource.startedAt = n.getDateValue(); },
        "total_bytes": n => { apiIndexedDataSource.totalBytes = n.getStringValue(); },
        "total_bytes_indexed": n => { apiIndexedDataSource.totalBytesIndexed = n.getStringValue(); },
        "total_file_count": n => { apiIndexedDataSource.totalFileCount = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiIndexingJob(apiIndexingJob: Partial<ApiIndexingJob> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "completed_datasources": n => { apiIndexingJob.completedDatasources = n.getNumberValue(); },
        "created_at": n => { apiIndexingJob.createdAt = n.getDateValue(); },
        "data_source_uuids": n => { apiIndexingJob.dataSourceUuids = n.getCollectionOfPrimitiveValues<string>(); },
        "finished_at": n => { apiIndexingJob.finishedAt = n.getDateValue(); },
        "knowledge_base_uuid": n => { apiIndexingJob.knowledgeBaseUuid = n.getStringValue(); },
        "phase": n => { apiIndexingJob.phase = n.getEnumValue<ApiBatchJobPhase>(ApiBatchJobPhaseObject) ?? ApiBatchJobPhaseObject.BATCH_JOB_PHASE_UNKNOWN; },
        "started_at": n => { apiIndexingJob.startedAt = n.getDateValue(); },
        "tokens": n => { apiIndexingJob.tokens = n.getNumberValue(); },
        "total_datasources": n => { apiIndexingJob.totalDatasources = n.getNumberValue(); },
        "updated_at": n => { apiIndexingJob.updatedAt = n.getDateValue(); },
        "uuid": n => { apiIndexingJob.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiKBDataSource(apiKBDataSource: Partial<ApiKBDataSource> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "bucket_name": n => { apiKBDataSource.bucketName = n.getStringValue(); },
        "bucket_region": n => { apiKBDataSource.bucketRegion = n.getStringValue(); },
        "file_upload_data_source": n => { apiKBDataSource.fileUploadDataSource = n.getObjectValue<ApiFileUploadDataSource>(createApiFileUploadDataSourceFromDiscriminatorValue); },
        "item_path": n => { apiKBDataSource.itemPath = n.getStringValue(); },
        "spaces_data_source": n => { apiKBDataSource.spacesDataSource = n.getObjectValue<ApiSpacesDataSource>(createApiSpacesDataSourceFromDiscriminatorValue); },
        "web_crawler_data_source": n => { apiKBDataSource.webCrawlerDataSource = n.getObjectValue<ApiWebCrawlerDataSource>(createApiWebCrawlerDataSourceFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiKnowledgeBase(apiKnowledgeBase: Partial<ApiKnowledgeBase> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "added_to_agent_at": n => { apiKnowledgeBase.addedToAgentAt = n.getDateValue(); },
        "created_at": n => { apiKnowledgeBase.createdAt = n.getDateValue(); },
        "database_id": n => { apiKnowledgeBase.databaseId = n.getStringValue(); },
        "embedding_model_uuid": n => { apiKnowledgeBase.embeddingModelUuid = n.getStringValue(); },
        "is_public": n => { apiKnowledgeBase.isPublic = n.getBooleanValue(); },
        "last_indexing_job": n => { apiKnowledgeBase.lastIndexingJob = n.getObjectValue<ApiIndexingJob>(createApiIndexingJobFromDiscriminatorValue); },
        "name": n => { apiKnowledgeBase.name = n.getStringValue(); },
        "project_id": n => { apiKnowledgeBase.projectId = n.getStringValue(); },
        "region": n => { apiKnowledgeBase.region = n.getStringValue(); },
        "tags": n => { apiKnowledgeBase.tags = n.getCollectionOfPrimitiveValues<string>(); },
        "updated_at": n => { apiKnowledgeBase.updatedAt = n.getDateValue(); },
        "user_id": n => { apiKnowledgeBase.userId = n.getStringValue(); },
        "uuid": n => { apiKnowledgeBase.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiKnowledgeBaseDataSource(apiKnowledgeBaseDataSource: Partial<ApiKnowledgeBaseDataSource> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "bucket_name": n => { apiKnowledgeBaseDataSource.bucketName = n.getStringValue(); },
        "created_at": n => { apiKnowledgeBaseDataSource.createdAt = n.getDateValue(); },
        "file_upload_data_source": n => { apiKnowledgeBaseDataSource.fileUploadDataSource = n.getObjectValue<ApiFileUploadDataSource>(createApiFileUploadDataSourceFromDiscriminatorValue); },
        "item_path": n => { apiKnowledgeBaseDataSource.itemPath = n.getStringValue(); },
        "last_indexing_job": n => { apiKnowledgeBaseDataSource.lastIndexingJob = n.getObjectValue<ApiIndexingJob>(createApiIndexingJobFromDiscriminatorValue); },
        "region": n => { apiKnowledgeBaseDataSource.region = n.getStringValue(); },
        "spaces_data_source": n => { apiKnowledgeBaseDataSource.spacesDataSource = n.getObjectValue<ApiSpacesDataSource>(createApiSpacesDataSourceFromDiscriminatorValue); },
        "updated_at": n => { apiKnowledgeBaseDataSource.updatedAt = n.getDateValue(); },
        "uuid": n => { apiKnowledgeBaseDataSource.uuid = n.getStringValue(); },
        "web_crawler_data_source": n => { apiKnowledgeBaseDataSource.webCrawlerDataSource = n.getObjectValue<ApiWebCrawlerDataSource>(createApiWebCrawlerDataSourceFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiLinkAgentFunctionInputPublic(apiLinkAgentFunctionInputPublic: Partial<ApiLinkAgentFunctionInputPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agent_uuid": n => { apiLinkAgentFunctionInputPublic.agentUuid = n.getStringValue(); },
        "description": n => { apiLinkAgentFunctionInputPublic.description = n.getStringValue(); },
        "faas_name": n => { apiLinkAgentFunctionInputPublic.faasName = n.getStringValue(); },
        "faas_namespace": n => { apiLinkAgentFunctionInputPublic.faasNamespace = n.getStringValue(); },
        "function_name": n => { apiLinkAgentFunctionInputPublic.functionName = n.getStringValue(); },
        "input_schema": n => { apiLinkAgentFunctionInputPublic.inputSchema = n.getObjectValue<ApiLinkAgentFunctionInputPublic_input_schema>(createApiLinkAgentFunctionInputPublic_input_schemaFromDiscriminatorValue); },
        "output_schema": n => { apiLinkAgentFunctionInputPublic.outputSchema = n.getObjectValue<ApiLinkAgentFunctionInputPublic_output_schema>(createApiLinkAgentFunctionInputPublic_output_schemaFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiLinkAgentFunctionInputPublic_input_schema(apiLinkAgentFunctionInputPublic_input_schema: Partial<ApiLinkAgentFunctionInputPublic_input_schema> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiLinkAgentFunctionInputPublic_output_schema(apiLinkAgentFunctionInputPublic_output_schema: Partial<ApiLinkAgentFunctionInputPublic_output_schema> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiLinkAgentFunctionOutput(apiLinkAgentFunctionOutput: Partial<ApiLinkAgentFunctionOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agent": n => { apiLinkAgentFunctionOutput.agent = n.getObjectValue<ApiAgent>(createApiAgentFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiLinkAgentInputPublic(apiLinkAgentInputPublic: Partial<ApiLinkAgentInputPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "child_agent_uuid": n => { apiLinkAgentInputPublic.childAgentUuid = n.getStringValue(); },
        "if_case": n => { apiLinkAgentInputPublic.ifCase = n.getStringValue(); },
        "parent_agent_uuid": n => { apiLinkAgentInputPublic.parentAgentUuid = n.getStringValue(); },
        "route_name": n => { apiLinkAgentInputPublic.routeName = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiLinkAgentOutput(apiLinkAgentOutput: Partial<ApiLinkAgentOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "child_agent_uuid": n => { apiLinkAgentOutput.childAgentUuid = n.getStringValue(); },
        "parent_agent_uuid": n => { apiLinkAgentOutput.parentAgentUuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiLinkKnowledgeBaseOutput(apiLinkKnowledgeBaseOutput: Partial<ApiLinkKnowledgeBaseOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agent": n => { apiLinkKnowledgeBaseOutput.agent = n.getObjectValue<ApiAgent>(createApiAgentFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiLinks(apiLinks: Partial<ApiLinks> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "pages": n => { apiLinks.pages = n.getObjectValue<ApiPages>(createApiPagesFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiListAgentAPIKeysOutput(apiListAgentAPIKeysOutput: Partial<ApiListAgentAPIKeysOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "api_key_infos": n => { apiListAgentAPIKeysOutput.apiKeyInfos = n.getCollectionOfObjectValues<ApiAgentAPIKeyInfo>(createApiAgentAPIKeyInfoFromDiscriminatorValue); },
        "links": n => { apiListAgentAPIKeysOutput.links = n.getObjectValue<ApiLinks>(createApiLinksFromDiscriminatorValue); },
        "meta": n => { apiListAgentAPIKeysOutput.meta = n.getObjectValue<ApiMeta>(createApiMetaFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiListAgentsByAnthropicKeyOutput(apiListAgentsByAnthropicKeyOutput: Partial<ApiListAgentsByAnthropicKeyOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agents": n => { apiListAgentsByAnthropicKeyOutput.agents = n.getCollectionOfObjectValues<ApiAgent>(createApiAgentFromDiscriminatorValue); },
        "links": n => { apiListAgentsByAnthropicKeyOutput.links = n.getObjectValue<ApiLinks>(createApiLinksFromDiscriminatorValue); },
        "meta": n => { apiListAgentsByAnthropicKeyOutput.meta = n.getObjectValue<ApiMeta>(createApiMetaFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiListAgentsOutputPublic(apiListAgentsOutputPublic: Partial<ApiListAgentsOutputPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agents": n => { apiListAgentsOutputPublic.agents = n.getCollectionOfObjectValues<ApiAgentPublic>(createApiAgentPublicFromDiscriminatorValue); },
        "links": n => { apiListAgentsOutputPublic.links = n.getObjectValue<ApiLinks>(createApiLinksFromDiscriminatorValue); },
        "meta": n => { apiListAgentsOutputPublic.meta = n.getObjectValue<ApiMeta>(createApiMetaFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiListAnthropicAPIKeysOutput(apiListAnthropicAPIKeysOutput: Partial<ApiListAnthropicAPIKeysOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "api_key_infos": n => { apiListAnthropicAPIKeysOutput.apiKeyInfos = n.getCollectionOfObjectValues<ApiAnthropicAPIKeyInfo>(createApiAnthropicAPIKeyInfoFromDiscriminatorValue); },
        "links": n => { apiListAnthropicAPIKeysOutput.links = n.getObjectValue<ApiLinks>(createApiLinksFromDiscriminatorValue); },
        "meta": n => { apiListAnthropicAPIKeysOutput.meta = n.getObjectValue<ApiMeta>(createApiMetaFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiListIndexingJobDataSourcesOutput(apiListIndexingJobDataSourcesOutput: Partial<ApiListIndexingJobDataSourcesOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "indexed_data_sources": n => { apiListIndexingJobDataSourcesOutput.indexedDataSources = n.getCollectionOfObjectValues<ApiIndexedDataSource>(createApiIndexedDataSourceFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiListKnowledgeBaseDataSourcesOutput(apiListKnowledgeBaseDataSourcesOutput: Partial<ApiListKnowledgeBaseDataSourcesOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "knowledge_base_data_sources": n => { apiListKnowledgeBaseDataSourcesOutput.knowledgeBaseDataSources = n.getCollectionOfObjectValues<ApiKnowledgeBaseDataSource>(createApiKnowledgeBaseDataSourceFromDiscriminatorValue); },
        "links": n => { apiListKnowledgeBaseDataSourcesOutput.links = n.getObjectValue<ApiLinks>(createApiLinksFromDiscriminatorValue); },
        "meta": n => { apiListKnowledgeBaseDataSourcesOutput.meta = n.getObjectValue<ApiMeta>(createApiMetaFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiListKnowledgeBaseIndexingJobsOutput(apiListKnowledgeBaseIndexingJobsOutput: Partial<ApiListKnowledgeBaseIndexingJobsOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "jobs": n => { apiListKnowledgeBaseIndexingJobsOutput.jobs = n.getCollectionOfObjectValues<ApiIndexingJob>(createApiIndexingJobFromDiscriminatorValue); },
        "links": n => { apiListKnowledgeBaseIndexingJobsOutput.links = n.getObjectValue<ApiLinks>(createApiLinksFromDiscriminatorValue); },
        "meta": n => { apiListKnowledgeBaseIndexingJobsOutput.meta = n.getObjectValue<ApiMeta>(createApiMetaFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiListKnowledgeBasesOutput(apiListKnowledgeBasesOutput: Partial<ApiListKnowledgeBasesOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "knowledge_bases": n => { apiListKnowledgeBasesOutput.knowledgeBases = n.getCollectionOfObjectValues<ApiKnowledgeBase>(createApiKnowledgeBaseFromDiscriminatorValue); },
        "links": n => { apiListKnowledgeBasesOutput.links = n.getObjectValue<ApiLinks>(createApiLinksFromDiscriminatorValue); },
        "meta": n => { apiListKnowledgeBasesOutput.meta = n.getObjectValue<ApiMeta>(createApiMetaFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiListModelsOutputPublic(apiListModelsOutputPublic: Partial<ApiListModelsOutputPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "links": n => { apiListModelsOutputPublic.links = n.getObjectValue<ApiLinks>(createApiLinksFromDiscriminatorValue); },
        "meta": n => { apiListModelsOutputPublic.meta = n.getObjectValue<ApiMeta>(createApiMetaFromDiscriminatorValue); },
        "models": n => { apiListModelsOutputPublic.models = n.getCollectionOfObjectValues<ApiModelPublic>(createApiModelPublicFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiListRegionsOutput(apiListRegionsOutput: Partial<ApiListRegionsOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "regions": n => { apiListRegionsOutput.regions = n.getCollectionOfObjectValues<GenaiapiRegion>(createGenaiapiRegionFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiMeta(apiMeta: Partial<ApiMeta> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "page": n => { apiMeta.page = n.getNumberValue(); },
        "pages": n => { apiMeta.pages = n.getNumberValue(); },
        "total": n => { apiMeta.total = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiModel(apiModel: Partial<ApiModel> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agreement": n => { apiModel.agreement = n.getObjectValue<ApiAgreement>(createApiAgreementFromDiscriminatorValue); },
        "created_at": n => { apiModel.createdAt = n.getDateValue(); },
        "inference_name": n => { apiModel.inferenceName = n.getStringValue(); },
        "inference_version": n => { apiModel.inferenceVersion = n.getStringValue(); },
        "is_foundational": n => { apiModel.isFoundational = n.getBooleanValue(); },
        "metadata": n => { apiModel.metadata = n.getObjectValue<ApiModel_metadata>(createApiModel_metadataFromDiscriminatorValue); },
        "name": n => { apiModel.name = n.getStringValue(); },
        "parent_uuid": n => { apiModel.parentUuid = n.getStringValue(); },
        "provider": n => { apiModel.provider = n.getEnumValue<ApiModelProvider>(ApiModelProviderObject) ?? ApiModelProviderObject.MODEL_PROVIDER_DIGITALOCEAN; },
        "updated_at": n => { apiModel.updatedAt = n.getDateValue(); },
        "upload_complete": n => { apiModel.uploadComplete = n.getBooleanValue(); },
        "url": n => { apiModel.url = n.getStringValue(); },
        "uuid": n => { apiModel.uuid = n.getStringValue(); },
        "version": n => { apiModel.version = n.getObjectValue<ApiModelVersion>(createApiModelVersionFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiModel_metadata(apiModel_metadata: Partial<ApiModel_metadata> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiModelPublic(apiModelPublic: Partial<ApiModelPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agreement": n => { apiModelPublic.agreement = n.getObjectValue<ApiAgreement>(createApiAgreementFromDiscriminatorValue); },
        "created_at": n => { apiModelPublic.createdAt = n.getDateValue(); },
        "is_foundational": n => { apiModelPublic.isFoundational = n.getBooleanValue(); },
        "name": n => { apiModelPublic.name = n.getStringValue(); },
        "parent_uuid": n => { apiModelPublic.parentUuid = n.getStringValue(); },
        "updated_at": n => { apiModelPublic.updatedAt = n.getDateValue(); },
        "upload_complete": n => { apiModelPublic.uploadComplete = n.getBooleanValue(); },
        "url": n => { apiModelPublic.url = n.getStringValue(); },
        "uuid": n => { apiModelPublic.uuid = n.getStringValue(); },
        "version": n => { apiModelPublic.version = n.getObjectValue<ApiModelVersion>(createApiModelVersionFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiModelVersion(apiModelVersion: Partial<ApiModelVersion> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "major": n => { apiModelVersion.major = n.getNumberValue(); },
        "minor": n => { apiModelVersion.minor = n.getNumberValue(); },
        "patch": n => { apiModelVersion.patch = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiPages(apiPages: Partial<ApiPages> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "first": n => { apiPages.first = n.getStringValue(); },
        "last": n => { apiPages.last = n.getStringValue(); },
        "next": n => { apiPages.next = n.getStringValue(); },
        "previous": n => { apiPages.previous = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiRegenerateAgentAPIKeyOutput(apiRegenerateAgentAPIKeyOutput: Partial<ApiRegenerateAgentAPIKeyOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "api_key_info": n => { apiRegenerateAgentAPIKeyOutput.apiKeyInfo = n.getObjectValue<ApiAgentAPIKeyInfo>(createApiAgentAPIKeyInfoFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiSpacesDataSource(apiSpacesDataSource: Partial<ApiSpacesDataSource> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "bucket_name": n => { apiSpacesDataSource.bucketName = n.getStringValue(); },
        "item_path": n => { apiSpacesDataSource.itemPath = n.getStringValue(); },
        "region": n => { apiSpacesDataSource.region = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiStartKnowledgeBaseIndexingJobInputPublic(apiStartKnowledgeBaseIndexingJobInputPublic: Partial<ApiStartKnowledgeBaseIndexingJobInputPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "data_source_uuids": n => { apiStartKnowledgeBaseIndexingJobInputPublic.dataSourceUuids = n.getCollectionOfPrimitiveValues<string>(); },
        "knowledge_base_uuid": n => { apiStartKnowledgeBaseIndexingJobInputPublic.knowledgeBaseUuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiStartKnowledgeBaseIndexingJobOutput(apiStartKnowledgeBaseIndexingJobOutput: Partial<ApiStartKnowledgeBaseIndexingJobOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "job": n => { apiStartKnowledgeBaseIndexingJobOutput.job = n.getObjectValue<ApiIndexingJob>(createApiIndexingJobFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiUnlinkAgentFunctionOutput(apiUnlinkAgentFunctionOutput: Partial<ApiUnlinkAgentFunctionOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agent": n => { apiUnlinkAgentFunctionOutput.agent = n.getObjectValue<ApiAgent>(createApiAgentFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiUnlinkAgentOutput(apiUnlinkAgentOutput: Partial<ApiUnlinkAgentOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "child_agent_uuid": n => { apiUnlinkAgentOutput.childAgentUuid = n.getStringValue(); },
        "parent_agent_uuid": n => { apiUnlinkAgentOutput.parentAgentUuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiUnlinkKnowledgeBaseOutput(apiUnlinkKnowledgeBaseOutput: Partial<ApiUnlinkKnowledgeBaseOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agent": n => { apiUnlinkKnowledgeBaseOutput.agent = n.getObjectValue<ApiAgent>(createApiAgentFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiUpdateAgentAPIKeyInputPublic(apiUpdateAgentAPIKeyInputPublic: Partial<ApiUpdateAgentAPIKeyInputPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agent_uuid": n => { apiUpdateAgentAPIKeyInputPublic.agentUuid = n.getStringValue(); },
        "api_key_uuid": n => { apiUpdateAgentAPIKeyInputPublic.apiKeyUuid = n.getStringValue(); },
        "name": n => { apiUpdateAgentAPIKeyInputPublic.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiUpdateAgentAPIKeyOutput(apiUpdateAgentAPIKeyOutput: Partial<ApiUpdateAgentAPIKeyOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "api_key_info": n => { apiUpdateAgentAPIKeyOutput.apiKeyInfo = n.getObjectValue<ApiAgentAPIKeyInfo>(createApiAgentAPIKeyInfoFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiUpdateAgentDeploymentVisbilityOutput(apiUpdateAgentDeploymentVisbilityOutput: Partial<ApiUpdateAgentDeploymentVisbilityOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agent": n => { apiUpdateAgentDeploymentVisbilityOutput.agent = n.getObjectValue<ApiAgent>(createApiAgentFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiUpdateAgentDeploymentVisibilityInputPublic(apiUpdateAgentDeploymentVisibilityInputPublic: Partial<ApiUpdateAgentDeploymentVisibilityInputPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "uuid": n => { apiUpdateAgentDeploymentVisibilityInputPublic.uuid = n.getStringValue(); },
        "visibility": n => { apiUpdateAgentDeploymentVisibilityInputPublic.visibility = n.getEnumValue<ApiDeploymentVisibility>(ApiDeploymentVisibilityObject) ?? ApiDeploymentVisibilityObject.VISIBILITY_UNKNOWN; },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiUpdateAgentFunctionInputPublic(apiUpdateAgentFunctionInputPublic: Partial<ApiUpdateAgentFunctionInputPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agent_uuid": n => { apiUpdateAgentFunctionInputPublic.agentUuid = n.getStringValue(); },
        "description": n => { apiUpdateAgentFunctionInputPublic.description = n.getStringValue(); },
        "faas_name": n => { apiUpdateAgentFunctionInputPublic.faasName = n.getStringValue(); },
        "faas_namespace": n => { apiUpdateAgentFunctionInputPublic.faasNamespace = n.getStringValue(); },
        "function_name": n => { apiUpdateAgentFunctionInputPublic.functionName = n.getStringValue(); },
        "function_uuid": n => { apiUpdateAgentFunctionInputPublic.functionUuid = n.getStringValue(); },
        "input_schema": n => { apiUpdateAgentFunctionInputPublic.inputSchema = n.getObjectValue<ApiUpdateAgentFunctionInputPublic_input_schema>(createApiUpdateAgentFunctionInputPublic_input_schemaFromDiscriminatorValue); },
        "output_schema": n => { apiUpdateAgentFunctionInputPublic.outputSchema = n.getObjectValue<ApiUpdateAgentFunctionInputPublic_output_schema>(createApiUpdateAgentFunctionInputPublic_output_schemaFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiUpdateAgentFunctionInputPublic_input_schema(apiUpdateAgentFunctionInputPublic_input_schema: Partial<ApiUpdateAgentFunctionInputPublic_input_schema> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiUpdateAgentFunctionInputPublic_output_schema(apiUpdateAgentFunctionInputPublic_output_schema: Partial<ApiUpdateAgentFunctionInputPublic_output_schema> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiUpdateAgentFunctionOutput(apiUpdateAgentFunctionOutput: Partial<ApiUpdateAgentFunctionOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agent": n => { apiUpdateAgentFunctionOutput.agent = n.getObjectValue<ApiAgent>(createApiAgentFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiUpdateAgentInputPublic(apiUpdateAgentInputPublic: Partial<ApiUpdateAgentInputPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "anthropic_key_uuid": n => { apiUpdateAgentInputPublic.anthropicKeyUuid = n.getStringValue(); },
        "description": n => { apiUpdateAgentInputPublic.description = n.getStringValue(); },
        "instruction": n => { apiUpdateAgentInputPublic.instruction = n.getStringValue(); },
        "k": n => { apiUpdateAgentInputPublic.k = n.getNumberValue(); },
        "max_tokens": n => { apiUpdateAgentInputPublic.maxTokens = n.getNumberValue(); },
        "model_uuid": n => { apiUpdateAgentInputPublic.modelUuid = n.getStringValue(); },
        "name": n => { apiUpdateAgentInputPublic.name = n.getStringValue(); },
        "project_id": n => { apiUpdateAgentInputPublic.projectId = n.getStringValue(); },
        "tags": n => { apiUpdateAgentInputPublic.tags = n.getCollectionOfPrimitiveValues<string>(); },
        "temperature": n => { apiUpdateAgentInputPublic.temperature = n.getNumberValue(); },
        "top_p": n => { apiUpdateAgentInputPublic.topP = n.getNumberValue(); },
        "uuid": n => { apiUpdateAgentInputPublic.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiUpdateAgentOutput(apiUpdateAgentOutput: Partial<ApiUpdateAgentOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "agent": n => { apiUpdateAgentOutput.agent = n.getObjectValue<ApiAgent>(createApiAgentFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiUpdateAnthropicAPIKeyInputPublic(apiUpdateAnthropicAPIKeyInputPublic: Partial<ApiUpdateAnthropicAPIKeyInputPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "api_key": n => { apiUpdateAnthropicAPIKeyInputPublic.apiKey = n.getStringValue(); },
        "api_key_uuid": n => { apiUpdateAnthropicAPIKeyInputPublic.apiKeyUuid = n.getStringValue(); },
        "name": n => { apiUpdateAnthropicAPIKeyInputPublic.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiUpdateAnthropicAPIKeyOutput(apiUpdateAnthropicAPIKeyOutput: Partial<ApiUpdateAnthropicAPIKeyOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "api_key_info": n => { apiUpdateAnthropicAPIKeyOutput.apiKeyInfo = n.getObjectValue<ApiAnthropicAPIKeyInfo>(createApiAnthropicAPIKeyInfoFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiUpdateKnowledgeBaseInputPublic(apiUpdateKnowledgeBaseInputPublic: Partial<ApiUpdateKnowledgeBaseInputPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "database_id": n => { apiUpdateKnowledgeBaseInputPublic.databaseId = n.getStringValue(); },
        "embedding_model_uuid": n => { apiUpdateKnowledgeBaseInputPublic.embeddingModelUuid = n.getStringValue(); },
        "name": n => { apiUpdateKnowledgeBaseInputPublic.name = n.getStringValue(); },
        "project_id": n => { apiUpdateKnowledgeBaseInputPublic.projectId = n.getStringValue(); },
        "tags": n => { apiUpdateKnowledgeBaseInputPublic.tags = n.getCollectionOfPrimitiveValues<string>(); },
        "uuid": n => { apiUpdateKnowledgeBaseInputPublic.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiUpdateKnowledgeBaseOutput(apiUpdateKnowledgeBaseOutput: Partial<ApiUpdateKnowledgeBaseOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "knowledge_base": n => { apiUpdateKnowledgeBaseOutput.knowledgeBase = n.getObjectValue<ApiKnowledgeBase>(createApiKnowledgeBaseFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiUpdateLinkedAgentInputPublic(apiUpdateLinkedAgentInputPublic: Partial<ApiUpdateLinkedAgentInputPublic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "child_agent_uuid": n => { apiUpdateLinkedAgentInputPublic.childAgentUuid = n.getStringValue(); },
        "if_case": n => { apiUpdateLinkedAgentInputPublic.ifCase = n.getStringValue(); },
        "parent_agent_uuid": n => { apiUpdateLinkedAgentInputPublic.parentAgentUuid = n.getStringValue(); },
        "route_name": n => { apiUpdateLinkedAgentInputPublic.routeName = n.getStringValue(); },
        "uuid": n => { apiUpdateLinkedAgentInputPublic.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiUpdateLinkedAgentOutput(apiUpdateLinkedAgentOutput: Partial<ApiUpdateLinkedAgentOutput> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "child_agent_uuid": n => { apiUpdateLinkedAgentOutput.childAgentUuid = n.getStringValue(); },
        "parent_agent_uuid": n => { apiUpdateLinkedAgentOutput.parentAgentUuid = n.getStringValue(); },
        "uuid": n => { apiUpdateLinkedAgentOutput.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApiWebCrawlerDataSource(apiWebCrawlerDataSource: Partial<ApiWebCrawlerDataSource> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "base_url": n => { apiWebCrawlerDataSource.baseUrl = n.getStringValue(); },
        "crawling_option": n => { apiWebCrawlerDataSource.crawlingOption = n.getEnumValue<ApiCrawlingOption>(ApiCrawlingOptionObject) ?? ApiCrawlingOptionObject.UNKNOWN; },
        "embed_media": n => { apiWebCrawlerDataSource.embedMedia = n.getBooleanValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp(app: Partial<App> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "active_deployment": n => { app.activeDeployment = n.getObjectValue<Apps_deployment>(createApps_deploymentFromDiscriminatorValue); },
        "created_at": n => { app.createdAt = n.getDateValue(); },
        "dedicated_ips": n => { app.dedicatedIps = n.getCollectionOfObjectValues<Apps_dedicated_egress_ip>(createApps_dedicated_egress_ipFromDiscriminatorValue); },
        "default_ingress": n => { app.defaultIngress = n.getStringValue(); },
        "domains": n => { app.domains = n.getCollectionOfObjectValues<Apps_domain>(createApps_domainFromDiscriminatorValue); },
        "id": n => { app.id = n.getStringValue(); },
        "in_progress_deployment": n => { app.inProgressDeployment = n.getObjectValue<Apps_deployment>(createApps_deploymentFromDiscriminatorValue); },
        "last_deployment_created_at": n => { app.lastDeploymentCreatedAt = n.getDateValue(); },
        "live_domain": n => { app.liveDomain = n.getStringValue(); },
        "live_url": n => { app.liveUrl = n.getStringValue(); },
        "live_url_base": n => { app.liveUrlBase = n.getStringValue(); },
        "owner_uuid": n => { app.ownerUuid = n.getStringValue(); },
        "pending_deployment": n => { app.pendingDeployment = n.getObjectValue<Apps_deployment>(createApps_deploymentFromDiscriminatorValue); },
        "pinned_deployment": n => { app.pinnedDeployment = n.getObjectValue<Apps_deployment>(createApps_deploymentFromDiscriminatorValue); },
        "project_id": n => { app.projectId = n.getStringValue(); },
        "region": n => { app.region = n.getObjectValue<Apps_region>(createApps_regionFromDiscriminatorValue); },
        "spec": n => { app.spec = n.getObjectValue<App_spec>(createApp_specFromDiscriminatorValue); },
        "tier_slug": n => { app.tierSlug = n.getStringValue(); },
        "updated_at": n => { app.updatedAt = n.getDateValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_alert(app_alert: Partial<App_alert> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "component_name": n => { app_alert.componentName = n.getStringValue(); },
        "emails": n => { app_alert.emails = n.getCollectionOfPrimitiveValues<string>(); },
        "id": n => { app_alert.id = n.getStringValue(); },
        "phase": n => { app_alert.phase = n.getEnumValue<App_alert_phase>(App_alert_phaseObject) ?? App_alert_phaseObject.UNKNOWN; },
        "progress": n => { app_alert.progress = n.getObjectValue<App_alert_progress>(createApp_alert_progressFromDiscriminatorValue); },
        "slack_webhooks": n => { app_alert.slackWebhooks = n.getCollectionOfObjectValues<App_alert_slack_webhook>(createApp_alert_slack_webhookFromDiscriminatorValue); },
        "spec": n => { app_alert.spec = n.getObjectValue<App_alert_spec>(createApp_alert_specFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_alert_progress(app_alert_progress: Partial<App_alert_progress> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "steps": n => { app_alert_progress.steps = n.getCollectionOfObjectValues<App_alert_progress_step>(createApp_alert_progress_stepFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_alert_progress_step(app_alert_progress_step: Partial<App_alert_progress_step> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "ended_at": n => { app_alert_progress_step.endedAt = n.getDateValue(); },
        "name": n => { app_alert_progress_step.name = n.getStringValue(); },
        "reason": n => { app_alert_progress_step.reason = n.getObjectValue<App_alert_progress_step_reason>(createApp_alert_progress_step_reasonFromDiscriminatorValue); },
        "started_at": n => { app_alert_progress_step.startedAt = n.getDateValue(); },
        "status": n => { app_alert_progress_step.status = n.getEnumValue<App_alert_progress_step_status>(App_alert_progress_step_statusObject) ?? App_alert_progress_step_statusObject.UNKNOWN; },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_alert_progress_step_reason(app_alert_progress_step_reason: Partial<App_alert_progress_step_reason> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "code": n => { app_alert_progress_step_reason.code = n.getStringValue(); },
        "message": n => { app_alert_progress_step_reason.message = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_alert_slack_webhook(app_alert_slack_webhook: Partial<App_alert_slack_webhook> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "channel": n => { app_alert_slack_webhook.channel = n.getStringValue(); },
        "url": n => { app_alert_slack_webhook.url = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_alert_spec(app_alert_spec: Partial<App_alert_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "disabled": n => { app_alert_spec.disabled = n.getBooleanValue(); },
        "operator": n => { app_alert_spec.operator = n.getEnumValue<App_alert_spec_operator>(App_alert_spec_operatorObject) ?? App_alert_spec_operatorObject.UNSPECIFIED_OPERATOR; },
        "rule": n => { app_alert_spec.rule = n.getEnumValue<App_alert_spec_rule>(App_alert_spec_ruleObject) ?? App_alert_spec_ruleObject.UNSPECIFIED_RULE; },
        "value": n => { app_alert_spec.value = n.getNumberValue(); },
        "window": n => { app_alert_spec.window = n.getEnumValue<App_alert_spec_window>(App_alert_spec_windowObject) ?? App_alert_spec_windowObject.UNSPECIFIED_WINDOW; },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_component_base(app_component_base: Partial<App_component_base> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "bitbucket": n => { app_component_base.bitbucket = n.getObjectValue<Apps_bitbucket_source_spec>(createApps_bitbucket_source_specFromDiscriminatorValue); },
        "build_command": n => { app_component_base.buildCommand = n.getStringValue(); },
        "dockerfile_path": n => { app_component_base.dockerfilePath = n.getStringValue(); },
        "environment_slug": n => { app_component_base.environmentSlug = n.getStringValue(); },
        "envs": n => { app_component_base.envs = n.getCollectionOfObjectValues<App_variable_definition>(createApp_variable_definitionFromDiscriminatorValue); },
        "git": n => { app_component_base.git = n.getObjectValue<Apps_git_source_spec>(createApps_git_source_specFromDiscriminatorValue); },
        "github": n => { app_component_base.github = n.getObjectValue<Apps_github_source_spec>(createApps_github_source_specFromDiscriminatorValue); },
        "gitlab": n => { app_component_base.gitlab = n.getObjectValue<Apps_gitlab_source_spec>(createApps_gitlab_source_specFromDiscriminatorValue); },
        "image": n => { app_component_base.image = n.getObjectValue<Apps_image_source_spec>(createApps_image_source_specFromDiscriminatorValue); },
        "log_destinations": n => { app_component_base.logDestinations = n.getCollectionOfObjectValues<App_log_destination_definition>(createApp_log_destination_definitionFromDiscriminatorValue); },
        "name": n => { app_component_base.name = n.getStringValue(); },
        "run_command": n => { app_component_base.runCommand = n.getStringValue(); },
        "source_dir": n => { app_component_base.sourceDir = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_database_spec(app_database_spec: Partial<App_database_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "cluster_name": n => { app_database_spec.clusterName = n.getStringValue(); },
        "db_name": n => { app_database_spec.dbName = n.getStringValue(); },
        "db_user": n => { app_database_spec.dbUser = n.getStringValue(); },
        "engine": n => { app_database_spec.engine = n.getEnumValue<App_database_spec_engine>(App_database_spec_engineObject) ?? App_database_spec_engineObject.UNSET; },
        "name": n => { app_database_spec.name = n.getStringValue(); },
        "production": n => { app_database_spec.production = n.getBooleanValue(); },
        "version": n => { app_database_spec.version = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_domain_spec(app_domain_spec: Partial<App_domain_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "domain": n => { app_domain_spec.domain = n.getStringValue(); },
        "minimum_tls_version": n => { app_domain_spec.minimumTlsVersion = n.getEnumValue<App_domain_spec_minimum_tls_version>(App_domain_spec_minimum_tls_versionObject); },
        "type": n => { app_domain_spec.type = n.getEnumValue<App_domain_spec_type>(App_domain_spec_typeObject) ?? App_domain_spec_typeObject.UNSPECIFIED; },
        "wildcard": n => { app_domain_spec.wildcard = n.getBooleanValue(); },
        "zone": n => { app_domain_spec.zone = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_domain_validation(app_domain_validation: Partial<App_domain_validation> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "txt_name": n => { app_domain_validation.txtName = n.getStringValue(); },
        "txt_value": n => { app_domain_validation.txtValue = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_egress_spec(app_egress_spec: Partial<App_egress_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "type": n => { app_egress_spec.type = n.getEnumValue<App_egress_type_spec>(App_egress_type_specObject) ?? App_egress_type_specObject.AUTOASSIGN; },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_functions_spec(app_functions_spec: Partial<App_functions_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "alerts": n => { app_functions_spec.alerts = n.getCollectionOfObjectValues<App_alert_spec>(createApp_alert_specFromDiscriminatorValue); },
        "bitbucket": n => { app_functions_spec.bitbucket = n.getObjectValue<Apps_bitbucket_source_spec>(createApps_bitbucket_source_specFromDiscriminatorValue); },
        "cors": n => { app_functions_spec.cors = n.getObjectValue<Apps_cors_policy>(createApps_cors_policyFromDiscriminatorValue); },
        "envs": n => { app_functions_spec.envs = n.getCollectionOfObjectValues<App_variable_definition>(createApp_variable_definitionFromDiscriminatorValue); },
        "git": n => { app_functions_spec.git = n.getObjectValue<Apps_git_source_spec>(createApps_git_source_specFromDiscriminatorValue); },
        "github": n => { app_functions_spec.github = n.getObjectValue<Apps_github_source_spec>(createApps_github_source_specFromDiscriminatorValue); },
        "gitlab": n => { app_functions_spec.gitlab = n.getObjectValue<Apps_gitlab_source_spec>(createApps_gitlab_source_specFromDiscriminatorValue); },
        "log_destinations": n => { app_functions_spec.logDestinations = n.getCollectionOfObjectValues<App_log_destination_definition>(createApp_log_destination_definitionFromDiscriminatorValue); },
        "name": n => { app_functions_spec.name = n.getStringValue(); },
        "routes": n => { app_functions_spec.routes = n.getCollectionOfObjectValues<App_route_spec>(createApp_route_specFromDiscriminatorValue); },
        "source_dir": n => { app_functions_spec.sourceDir = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_ingress_spec(app_ingress_spec: Partial<App_ingress_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "rules": n => { app_ingress_spec.rules = n.getCollectionOfObjectValues<App_ingress_spec_rule>(createApp_ingress_spec_ruleFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_ingress_spec_rule(app_ingress_spec_rule: Partial<App_ingress_spec_rule> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "component": n => { app_ingress_spec_rule.component = n.getObjectValue<App_ingress_spec_rule_routing_component>(createApp_ingress_spec_rule_routing_componentFromDiscriminatorValue); },
        "cors": n => { app_ingress_spec_rule.cors = n.getObjectValue<Apps_cors_policy>(createApps_cors_policyFromDiscriminatorValue); },
        "match": n => { app_ingress_spec_rule.match = n.getObjectValue<App_ingress_spec_rule_match>(createApp_ingress_spec_rule_matchFromDiscriminatorValue); },
        "redirect": n => { app_ingress_spec_rule.redirect = n.getObjectValue<App_ingress_spec_rule_routing_redirect>(createApp_ingress_spec_rule_routing_redirectFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_ingress_spec_rule_match(app_ingress_spec_rule_match: Partial<App_ingress_spec_rule_match> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "path": n => { app_ingress_spec_rule_match.path = n.getObjectValue<App_ingress_spec_rule_string_match>(createApp_ingress_spec_rule_string_matchFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_ingress_spec_rule_routing_component(app_ingress_spec_rule_routing_component: Partial<App_ingress_spec_rule_routing_component> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "name": n => { app_ingress_spec_rule_routing_component.name = n.getStringValue(); },
        "preserve_path_prefix": n => { app_ingress_spec_rule_routing_component.preservePathPrefix = n.getStringValue(); },
        "rewrite": n => { app_ingress_spec_rule_routing_component.rewrite = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_ingress_spec_rule_routing_redirect(app_ingress_spec_rule_routing_redirect: Partial<App_ingress_spec_rule_routing_redirect> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "authority": n => { app_ingress_spec_rule_routing_redirect.authority = n.getStringValue(); },
        "port": n => { app_ingress_spec_rule_routing_redirect.port = n.getNumberValue(); },
        "redirect_code": n => { app_ingress_spec_rule_routing_redirect.redirectCode = n.getNumberValue(); },
        "scheme": n => { app_ingress_spec_rule_routing_redirect.scheme = n.getStringValue(); },
        "uri": n => { app_ingress_spec_rule_routing_redirect.uri = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_ingress_spec_rule_string_match(app_ingress_spec_rule_string_match: Partial<App_ingress_spec_rule_string_match> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "prefix": n => { app_ingress_spec_rule_string_match.prefix = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_job_spec(app_job_spec: Partial<App_job_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "autoscaling": n => { app_job_spec.autoscaling = n.getObjectValue<App_job_spec_autoscaling>(createApp_job_spec_autoscalingFromDiscriminatorValue); },
        "bitbucket": n => { app_job_spec.bitbucket = n.getObjectValue<Apps_bitbucket_source_spec>(createApps_bitbucket_source_specFromDiscriminatorValue); },
        "build_command": n => { app_job_spec.buildCommand = n.getStringValue(); },
        "dockerfile_path": n => { app_job_spec.dockerfilePath = n.getStringValue(); },
        "environment_slug": n => { app_job_spec.environmentSlug = n.getStringValue(); },
        "envs": n => { app_job_spec.envs = n.getCollectionOfObjectValues<App_variable_definition>(createApp_variable_definitionFromDiscriminatorValue); },
        "git": n => { app_job_spec.git = n.getObjectValue<Apps_git_source_spec>(createApps_git_source_specFromDiscriminatorValue); },
        "github": n => { app_job_spec.github = n.getObjectValue<Apps_github_source_spec>(createApps_github_source_specFromDiscriminatorValue); },
        "gitlab": n => { app_job_spec.gitlab = n.getObjectValue<Apps_gitlab_source_spec>(createApps_gitlab_source_specFromDiscriminatorValue); },
        "image": n => { app_job_spec.image = n.getObjectValue<Apps_image_source_spec>(createApps_image_source_specFromDiscriminatorValue); },
        "instance_count": n => { app_job_spec.instanceCount = n.getNumberValue(); },
        "instance_size_slug": n => { app_job_spec.instanceSizeSlug = n.getStringValue(); },
        "kind": n => { app_job_spec.kind = n.getEnumValue<App_job_spec_kind>(App_job_spec_kindObject) ?? App_job_spec_kindObject.UNSPECIFIED; },
        "log_destinations": n => { app_job_spec.logDestinations = n.getCollectionOfObjectValues<App_log_destination_definition>(createApp_log_destination_definitionFromDiscriminatorValue); },
        "name": n => { app_job_spec.name = n.getStringValue(); },
        "run_command": n => { app_job_spec.runCommand = n.getStringValue(); },
        "source_dir": n => { app_job_spec.sourceDir = n.getStringValue(); },
        "termination": n => { app_job_spec.termination = n.getObjectValue<App_job_spec_termination>(createApp_job_spec_terminationFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_job_spec_autoscaling(app_job_spec_autoscaling: Partial<App_job_spec_autoscaling> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "max_instance_count": n => { app_job_spec_autoscaling.maxInstanceCount = n.getNumberValue(); },
        "metrics": n => { app_job_spec_autoscaling.metrics = n.getObjectValue<App_job_spec_autoscaling_metrics>(createApp_job_spec_autoscaling_metricsFromDiscriminatorValue); },
        "min_instance_count": n => { app_job_spec_autoscaling.minInstanceCount = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_job_spec_autoscaling_metrics(app_job_spec_autoscaling_metrics: Partial<App_job_spec_autoscaling_metrics> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "cpu": n => { app_job_spec_autoscaling_metrics.cpu = n.getObjectValue<App_job_spec_autoscaling_metrics_cpu>(createApp_job_spec_autoscaling_metrics_cpuFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_job_spec_autoscaling_metrics_cpu(app_job_spec_autoscaling_metrics_cpu: Partial<App_job_spec_autoscaling_metrics_cpu> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "percent": n => { app_job_spec_autoscaling_metrics_cpu.percent = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_job_spec_termination(app_job_spec_termination: Partial<App_job_spec_termination> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "grace_period_seconds": n => { app_job_spec_termination.gracePeriodSeconds = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_log_destination_datadog_spec(app_log_destination_datadog_spec: Partial<App_log_destination_datadog_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "api_key": n => { app_log_destination_datadog_spec.apiKey = n.getStringValue(); },
        "endpoint": n => { app_log_destination_datadog_spec.endpoint = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_log_destination_definition(app_log_destination_definition: Partial<App_log_destination_definition> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "datadog": n => { app_log_destination_definition.datadog = n.getObjectValue<App_log_destination_datadog_spec>(createApp_log_destination_datadog_specFromDiscriminatorValue); },
        "logtail": n => { app_log_destination_definition.logtail = n.getObjectValue<App_log_destination_logtail_spec>(createApp_log_destination_logtail_specFromDiscriminatorValue); },
        "name": n => { app_log_destination_definition.name = n.getStringValue(); },
        "open_search": n => { app_log_destination_definition.openSearch = n.getObjectValue<App_log_destination_open_search_spec>(createApp_log_destination_open_search_specFromDiscriminatorValue); },
        "papertrail": n => { app_log_destination_definition.papertrail = n.getObjectValue<App_log_destination_papertrail_spec>(createApp_log_destination_papertrail_specFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_log_destination_logtail_spec(app_log_destination_logtail_spec: Partial<App_log_destination_logtail_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "token": n => { app_log_destination_logtail_spec.token = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_log_destination_open_search_spec(app_log_destination_open_search_spec: Partial<App_log_destination_open_search_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "basic_auth": n => { app_log_destination_open_search_spec.basicAuth = n.getObjectValue<App_log_destination_open_search_spec_basic_auth>(createApp_log_destination_open_search_spec_basic_authFromDiscriminatorValue); },
        "cluster_name": n => { app_log_destination_open_search_spec.clusterName = n.getStringValue(); },
        "endpoint": n => { app_log_destination_open_search_spec.endpoint = n.getStringValue(); },
        "index_name": n => { app_log_destination_open_search_spec.indexName = n.getStringValue() ?? "logs"; },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_log_destination_open_search_spec_basic_auth(app_log_destination_open_search_spec_basic_auth: Partial<App_log_destination_open_search_spec_basic_auth> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "password": n => { app_log_destination_open_search_spec_basic_auth.password = n.getObjectValue<UntypedNode>(createUntypedNodeFromDiscriminatorValue); },
        "user": n => { app_log_destination_open_search_spec_basic_auth.user = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_log_destination_papertrail_spec(app_log_destination_papertrail_spec: Partial<App_log_destination_papertrail_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "endpoint": n => { app_log_destination_papertrail_spec.endpoint = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_maintenance_spec(app_maintenance_spec: Partial<App_maintenance_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "archive": n => { app_maintenance_spec.archive = n.getBooleanValue(); },
        "enabled": n => { app_maintenance_spec.enabled = n.getBooleanValue(); },
        "offline_page_url": n => { app_maintenance_spec.offlinePageUrl = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_metrics_bandwidth_usage(app_metrics_bandwidth_usage: Partial<App_metrics_bandwidth_usage> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "app_bandwidth_usage": n => { app_metrics_bandwidth_usage.appBandwidthUsage = n.getCollectionOfObjectValues<App_metrics_bandwidth_usage_details>(createApp_metrics_bandwidth_usage_detailsFromDiscriminatorValue); },
        "date": n => { app_metrics_bandwidth_usage.date = n.getDateValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_metrics_bandwidth_usage_details(app_metrics_bandwidth_usage_details: Partial<App_metrics_bandwidth_usage_details> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "app_id": n => { app_metrics_bandwidth_usage_details.appId = n.getStringValue(); },
        "bandwidth_bytes": n => { app_metrics_bandwidth_usage_details.bandwidthBytes = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_metrics_bandwidth_usage_request(app_metrics_bandwidth_usage_request: Partial<App_metrics_bandwidth_usage_request> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "app_ids": n => { app_metrics_bandwidth_usage_request.appIds = n.getCollectionOfPrimitiveValues<string>(); },
        "date": n => { app_metrics_bandwidth_usage_request.date = n.getDateValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_propose(app_propose: Partial<App_propose> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "app_id": n => { app_propose.appId = n.getStringValue(); },
        "spec": n => { app_propose.spec = n.getObjectValue<App_spec>(createApp_specFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_propose_response(app_propose_response: Partial<App_propose_response> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "app_cost": n => { app_propose_response.appCost = n.getNumberValue(); },
        "app_is_static": n => { app_propose_response.appIsStatic = n.getBooleanValue(); },
        "app_name_available": n => { app_propose_response.appNameAvailable = n.getBooleanValue(); },
        "app_name_suggestion": n => { app_propose_response.appNameSuggestion = n.getStringValue(); },
        "app_tier_downgrade_cost": n => { app_propose_response.appTierDowngradeCost = n.getNumberValue(); },
        "existing_static_apps": n => { app_propose_response.existingStaticApps = n.getStringValue(); },
        "spec": n => { app_propose_response.spec = n.getObjectValue<App_spec>(createApp_specFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_response(app_response: Partial<App_response> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "app": n => { app_response.app = n.getObjectValue<App>(createAppFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_rollback_validation_condition(app_rollback_validation_condition: Partial<App_rollback_validation_condition> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "code": n => { app_rollback_validation_condition.code = n.getEnumValue<App_rollback_validation_condition_code>(App_rollback_validation_condition_codeObject); },
        "components": n => { app_rollback_validation_condition.components = n.getCollectionOfPrimitiveValues<string>(); },
        "message": n => { app_rollback_validation_condition.message = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_route_spec(app_route_spec: Partial<App_route_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "path": n => { app_route_spec.path = n.getStringValue(); },
        "preserve_path_prefix": n => { app_route_spec.preservePathPrefix = n.getBooleanValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_service_spec(app_service_spec: Partial<App_service_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "autoscaling": n => { app_service_spec.autoscaling = n.getObjectValue<App_service_spec_autoscaling>(createApp_service_spec_autoscalingFromDiscriminatorValue); },
        "bitbucket": n => { app_service_spec.bitbucket = n.getObjectValue<Apps_bitbucket_source_spec>(createApps_bitbucket_source_specFromDiscriminatorValue); },
        "build_command": n => { app_service_spec.buildCommand = n.getStringValue(); },
        "cors": n => { app_service_spec.cors = n.getObjectValue<Apps_cors_policy>(createApps_cors_policyFromDiscriminatorValue); },
        "dockerfile_path": n => { app_service_spec.dockerfilePath = n.getStringValue(); },
        "environment_slug": n => { app_service_spec.environmentSlug = n.getStringValue(); },
        "envs": n => { app_service_spec.envs = n.getCollectionOfObjectValues<App_variable_definition>(createApp_variable_definitionFromDiscriminatorValue); },
        "git": n => { app_service_spec.git = n.getObjectValue<Apps_git_source_spec>(createApps_git_source_specFromDiscriminatorValue); },
        "github": n => { app_service_spec.github = n.getObjectValue<Apps_github_source_spec>(createApps_github_source_specFromDiscriminatorValue); },
        "gitlab": n => { app_service_spec.gitlab = n.getObjectValue<Apps_gitlab_source_spec>(createApps_gitlab_source_specFromDiscriminatorValue); },
        "health_check": n => { app_service_spec.healthCheck = n.getObjectValue<App_service_spec_health_check>(createApp_service_spec_health_checkFromDiscriminatorValue); },
        "http_port": n => { app_service_spec.httpPort = n.getNumberValue(); },
        "image": n => { app_service_spec.image = n.getObjectValue<Apps_image_source_spec>(createApps_image_source_specFromDiscriminatorValue); },
        "instance_count": n => { app_service_spec.instanceCount = n.getNumberValue(); },
        "instance_size_slug": n => { app_service_spec.instanceSizeSlug = n.getStringValue(); },
        "internal_ports": n => { app_service_spec.internalPorts = n.getCollectionOfPrimitiveValues<number>(); },
        "log_destinations": n => { app_service_spec.logDestinations = n.getCollectionOfObjectValues<App_log_destination_definition>(createApp_log_destination_definitionFromDiscriminatorValue); },
        "name": n => { app_service_spec.name = n.getStringValue(); },
        "protocol": n => { app_service_spec.protocol = n.getEnumValue<App_service_spec_protocol>(App_service_spec_protocolObject); },
        "routes": n => { app_service_spec.routes = n.getCollectionOfObjectValues<App_route_spec>(createApp_route_specFromDiscriminatorValue); },
        "run_command": n => { app_service_spec.runCommand = n.getStringValue(); },
        "source_dir": n => { app_service_spec.sourceDir = n.getStringValue(); },
        "termination": n => { app_service_spec.termination = n.getObjectValue<App_service_spec_termination>(createApp_service_spec_terminationFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_service_spec_autoscaling(app_service_spec_autoscaling: Partial<App_service_spec_autoscaling> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "max_instance_count": n => { app_service_spec_autoscaling.maxInstanceCount = n.getNumberValue(); },
        "metrics": n => { app_service_spec_autoscaling.metrics = n.getObjectValue<App_service_spec_autoscaling_metrics>(createApp_service_spec_autoscaling_metricsFromDiscriminatorValue); },
        "min_instance_count": n => { app_service_spec_autoscaling.minInstanceCount = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_service_spec_autoscaling_metrics(app_service_spec_autoscaling_metrics: Partial<App_service_spec_autoscaling_metrics> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "cpu": n => { app_service_spec_autoscaling_metrics.cpu = n.getObjectValue<App_service_spec_autoscaling_metrics_cpu>(createApp_service_spec_autoscaling_metrics_cpuFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_service_spec_autoscaling_metrics_cpu(app_service_spec_autoscaling_metrics_cpu: Partial<App_service_spec_autoscaling_metrics_cpu> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "percent": n => { app_service_spec_autoscaling_metrics_cpu.percent = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_service_spec_health_check(app_service_spec_health_check: Partial<App_service_spec_health_check> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "failure_threshold": n => { app_service_spec_health_check.failureThreshold = n.getNumberValue(); },
        "http_path": n => { app_service_spec_health_check.httpPath = n.getStringValue(); },
        "initial_delay_seconds": n => { app_service_spec_health_check.initialDelaySeconds = n.getNumberValue(); },
        "period_seconds": n => { app_service_spec_health_check.periodSeconds = n.getNumberValue(); },
        "port": n => { app_service_spec_health_check.port = n.getNumberValue(); },
        "success_threshold": n => { app_service_spec_health_check.successThreshold = n.getNumberValue(); },
        "timeout_seconds": n => { app_service_spec_health_check.timeoutSeconds = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_service_spec_termination(app_service_spec_termination: Partial<App_service_spec_termination> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "drain_seconds": n => { app_service_spec_termination.drainSeconds = n.getNumberValue(); },
        "grace_period_seconds": n => { app_service_spec_termination.gracePeriodSeconds = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_spec(app_spec: Partial<App_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "databases": n => { app_spec.databases = n.getCollectionOfObjectValues<App_database_spec>(createApp_database_specFromDiscriminatorValue); },
        "domains": n => { app_spec.domains = n.getCollectionOfObjectValues<App_domain_spec>(createApp_domain_specFromDiscriminatorValue); },
        "egress": n => { app_spec.egress = n.getObjectValue<App_egress_spec>(createApp_egress_specFromDiscriminatorValue); },
        "functions": n => { app_spec.functions = n.getCollectionOfObjectValues<App_functions_spec>(createApp_functions_specFromDiscriminatorValue); },
        "ingress": n => { app_spec.ingress = n.getObjectValue<App_ingress_spec>(createApp_ingress_specFromDiscriminatorValue); },
        "jobs": n => { app_spec.jobs = n.getCollectionOfObjectValues<App_job_spec>(createApp_job_specFromDiscriminatorValue); },
        "maintenance": n => { app_spec.maintenance = n.getObjectValue<App_maintenance_spec>(createApp_maintenance_specFromDiscriminatorValue); },
        "name": n => { app_spec.name = n.getStringValue(); },
        "region": n => { app_spec.region = n.getEnumValue<App_spec_region>(App_spec_regionObject); },
        "services": n => { app_spec.services = n.getCollectionOfObjectValues<App_service_spec>(createApp_service_specFromDiscriminatorValue); },
        "static_sites": n => { app_spec.staticSites = n.getCollectionOfObjectValues<App_static_site_spec>(createApp_static_site_specFromDiscriminatorValue); },
        "workers": n => { app_spec.workers = n.getCollectionOfObjectValues<App_worker_spec>(createApp_worker_specFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_static_site_spec(app_static_site_spec: Partial<App_static_site_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoApp_component_base(app_static_site_spec),
        "catchall_document": n => { app_static_site_spec.catchallDocument = n.getStringValue(); },
        "cors": n => { app_static_site_spec.cors = n.getObjectValue<Apps_cors_policy>(createApps_cors_policyFromDiscriminatorValue); },
        "error_document": n => { app_static_site_spec.errorDocument = n.getStringValue() ?? "404.html"; },
        "index_document": n => { app_static_site_spec.indexDocument = n.getStringValue() ?? "index.html"; },
        "output_dir": n => { app_static_site_spec.outputDir = n.getStringValue(); },
        "routes": n => { app_static_site_spec.routes = n.getCollectionOfObjectValues<App_route_spec>(createApp_route_specFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_variable_definition(app_variable_definition: Partial<App_variable_definition> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "key": n => { app_variable_definition.key = n.getStringValue(); },
        "scope": n => { app_variable_definition.scope = n.getEnumValue<App_variable_definition_scope>(App_variable_definition_scopeObject) ?? App_variable_definition_scopeObject.RUN_AND_BUILD_TIME; },
        "type": n => { app_variable_definition.type = n.getEnumValue<App_variable_definition_type>(App_variable_definition_typeObject) ?? App_variable_definition_typeObject.GENERAL; },
        "value": n => { app_variable_definition.value = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_worker_spec(app_worker_spec: Partial<App_worker_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "autoscaling": n => { app_worker_spec.autoscaling = n.getObjectValue<App_worker_spec_autoscaling>(createApp_worker_spec_autoscalingFromDiscriminatorValue); },
        "bitbucket": n => { app_worker_spec.bitbucket = n.getObjectValue<Apps_bitbucket_source_spec>(createApps_bitbucket_source_specFromDiscriminatorValue); },
        "build_command": n => { app_worker_spec.buildCommand = n.getStringValue(); },
        "dockerfile_path": n => { app_worker_spec.dockerfilePath = n.getStringValue(); },
        "environment_slug": n => { app_worker_spec.environmentSlug = n.getStringValue(); },
        "envs": n => { app_worker_spec.envs = n.getCollectionOfObjectValues<App_variable_definition>(createApp_variable_definitionFromDiscriminatorValue); },
        "git": n => { app_worker_spec.git = n.getObjectValue<Apps_git_source_spec>(createApps_git_source_specFromDiscriminatorValue); },
        "github": n => { app_worker_spec.github = n.getObjectValue<Apps_github_source_spec>(createApps_github_source_specFromDiscriminatorValue); },
        "gitlab": n => { app_worker_spec.gitlab = n.getObjectValue<Apps_gitlab_source_spec>(createApps_gitlab_source_specFromDiscriminatorValue); },
        "image": n => { app_worker_spec.image = n.getObjectValue<Apps_image_source_spec>(createApps_image_source_specFromDiscriminatorValue); },
        "instance_count": n => { app_worker_spec.instanceCount = n.getNumberValue(); },
        "instance_size_slug": n => { app_worker_spec.instanceSizeSlug = n.getStringValue(); },
        "log_destinations": n => { app_worker_spec.logDestinations = n.getCollectionOfObjectValues<App_log_destination_definition>(createApp_log_destination_definitionFromDiscriminatorValue); },
        "name": n => { app_worker_spec.name = n.getStringValue(); },
        "run_command": n => { app_worker_spec.runCommand = n.getStringValue(); },
        "source_dir": n => { app_worker_spec.sourceDir = n.getStringValue(); },
        "termination": n => { app_worker_spec.termination = n.getObjectValue<App_worker_spec_termination>(createApp_worker_spec_terminationFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_worker_spec_autoscaling(app_worker_spec_autoscaling: Partial<App_worker_spec_autoscaling> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "max_instance_count": n => { app_worker_spec_autoscaling.maxInstanceCount = n.getNumberValue(); },
        "metrics": n => { app_worker_spec_autoscaling.metrics = n.getObjectValue<App_worker_spec_autoscaling_metrics>(createApp_worker_spec_autoscaling_metricsFromDiscriminatorValue); },
        "min_instance_count": n => { app_worker_spec_autoscaling.minInstanceCount = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_worker_spec_autoscaling_metrics(app_worker_spec_autoscaling_metrics: Partial<App_worker_spec_autoscaling_metrics> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "cpu": n => { app_worker_spec_autoscaling_metrics.cpu = n.getObjectValue<App_worker_spec_autoscaling_metrics_cpu>(createApp_worker_spec_autoscaling_metrics_cpuFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_worker_spec_autoscaling_metrics_cpu(app_worker_spec_autoscaling_metrics_cpu: Partial<App_worker_spec_autoscaling_metrics_cpu> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "percent": n => { app_worker_spec_autoscaling_metrics_cpu.percent = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApp_worker_spec_termination(app_worker_spec_termination: Partial<App_worker_spec_termination> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "grace_period_seconds": n => { app_worker_spec_termination.gracePeriodSeconds = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_alert_response(apps_alert_response: Partial<Apps_alert_response> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "alert": n => { apps_alert_response.alert = n.getObjectValue<App_alert>(createApp_alertFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_assign_app_alert_destinations_request(apps_assign_app_alert_destinations_request: Partial<Apps_assign_app_alert_destinations_request> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "emails": n => { apps_assign_app_alert_destinations_request.emails = n.getCollectionOfPrimitiveValues<string>(); },
        "slack_webhooks": n => { apps_assign_app_alert_destinations_request.slackWebhooks = n.getCollectionOfObjectValues<App_alert_slack_webhook>(createApp_alert_slack_webhookFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_bitbucket_source_spec(apps_bitbucket_source_spec: Partial<Apps_bitbucket_source_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "branch": n => { apps_bitbucket_source_spec.branch = n.getStringValue(); },
        "deploy_on_push": n => { apps_bitbucket_source_spec.deployOnPush = n.getBooleanValue(); },
        "repo": n => { apps_bitbucket_source_spec.repo = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_cors_policy(apps_cors_policy: Partial<Apps_cors_policy> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "allow_credentials": n => { apps_cors_policy.allowCredentials = n.getBooleanValue(); },
        "allow_headers": n => { apps_cors_policy.allowHeaders = n.getCollectionOfPrimitiveValues<string>(); },
        "allow_methods": n => { apps_cors_policy.allowMethods = n.getCollectionOfPrimitiveValues<string>(); },
        "allow_origins": n => { apps_cors_policy.allowOrigins = n.getCollectionOfObjectValues<Apps_string_match>(createApps_string_matchFromDiscriminatorValue); },
        "expose_headers": n => { apps_cors_policy.exposeHeaders = n.getCollectionOfPrimitiveValues<string>(); },
        "max_age": n => { apps_cors_policy.maxAge = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_create_app_request(apps_create_app_request: Partial<Apps_create_app_request> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "project_id": n => { apps_create_app_request.projectId = n.getStringValue(); },
        "spec": n => { apps_create_app_request.spec = n.getObjectValue<App_spec>(createApp_specFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_create_deployment_request(apps_create_deployment_request: Partial<Apps_create_deployment_request> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "force_build": n => { apps_create_deployment_request.forceBuild = n.getBooleanValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_dedicated_egress_ip(apps_dedicated_egress_ip: Partial<Apps_dedicated_egress_ip> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "id": n => { apps_dedicated_egress_ip.id = n.getStringValue(); },
        "ip": n => { apps_dedicated_egress_ip.ip = n.getStringValue(); },
        "status": n => { apps_dedicated_egress_ip.status = n.getEnumValue<Apps_dedicated_egress_ip_status>(Apps_dedicated_egress_ip_statusObject) ?? Apps_dedicated_egress_ip_statusObject.UNKNOWN; },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_delete_app_response(apps_delete_app_response: Partial<Apps_delete_app_response> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "id": n => { apps_delete_app_response.id = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_deployment(apps_deployment: Partial<Apps_deployment> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "cause": n => { apps_deployment.cause = n.getStringValue(); },
        "cloned_from": n => { apps_deployment.clonedFrom = n.getStringValue(); },
        "created_at": n => { apps_deployment.createdAt = n.getDateValue(); },
        "functions": n => { apps_deployment.functions = n.getCollectionOfObjectValues<Apps_deployment_functions>(createApps_deployment_functionsFromDiscriminatorValue); },
        "id": n => { apps_deployment.id = n.getStringValue(); },
        "jobs": n => { apps_deployment.jobs = n.getCollectionOfObjectValues<Apps_deployment_job>(createApps_deployment_jobFromDiscriminatorValue); },
        "phase": n => { apps_deployment.phase = n.getEnumValue<Apps_deployment_phase>(Apps_deployment_phaseObject) ?? Apps_deployment_phaseObject.UNKNOWN; },
        "phase_last_updated_at": n => { apps_deployment.phaseLastUpdatedAt = n.getDateValue(); },
        "progress": n => { apps_deployment.progress = n.getObjectValue<Apps_deployment_progress>(createApps_deployment_progressFromDiscriminatorValue); },
        "services": n => { apps_deployment.services = n.getCollectionOfObjectValues<Apps_deployment_service>(createApps_deployment_serviceFromDiscriminatorValue); },
        "spec": n => { apps_deployment.spec = n.getObjectValue<App_spec>(createApp_specFromDiscriminatorValue); },
        "static_sites": n => { apps_deployment.staticSites = n.getCollectionOfObjectValues<Apps_deployment_static_site>(createApps_deployment_static_siteFromDiscriminatorValue); },
        "tier_slug": n => { apps_deployment.tierSlug = n.getStringValue(); },
        "updated_at": n => { apps_deployment.updatedAt = n.getDateValue(); },
        "workers": n => { apps_deployment.workers = n.getCollectionOfObjectValues<Apps_deployment_worker>(createApps_deployment_workerFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_deployment_functions(apps_deployment_functions: Partial<Apps_deployment_functions> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "name": n => { apps_deployment_functions.name = n.getStringValue(); },
        "namespace": n => { apps_deployment_functions.namespace = n.getStringValue(); },
        "source_commit_hash": n => { apps_deployment_functions.sourceCommitHash = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_deployment_job(apps_deployment_job: Partial<Apps_deployment_job> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "name": n => { apps_deployment_job.name = n.getStringValue(); },
        "source_commit_hash": n => { apps_deployment_job.sourceCommitHash = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_deployment_progress(apps_deployment_progress: Partial<Apps_deployment_progress> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "error_steps": n => { apps_deployment_progress.errorSteps = n.getNumberValue(); },
        "pending_steps": n => { apps_deployment_progress.pendingSteps = n.getNumberValue(); },
        "running_steps": n => { apps_deployment_progress.runningSteps = n.getNumberValue(); },
        "steps": n => { apps_deployment_progress.steps = n.getCollectionOfObjectValues<Apps_deployment_progress_step>(createApps_deployment_progress_stepFromDiscriminatorValue); },
        "success_steps": n => { apps_deployment_progress.successSteps = n.getNumberValue(); },
        "summary_steps": n => { apps_deployment_progress.summarySteps = n.getCollectionOfObjectValues<Apps_deployment_progress_step>(createApps_deployment_progress_stepFromDiscriminatorValue); },
        "total_steps": n => { apps_deployment_progress.totalSteps = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_deployment_progress_step(apps_deployment_progress_step: Partial<Apps_deployment_progress_step> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "component_name": n => { apps_deployment_progress_step.componentName = n.getStringValue(); },
        "ended_at": n => { apps_deployment_progress_step.endedAt = n.getDateValue(); },
        "message_base": n => { apps_deployment_progress_step.messageBase = n.getStringValue(); },
        "name": n => { apps_deployment_progress_step.name = n.getStringValue(); },
        "reason": n => { apps_deployment_progress_step.reason = n.getObjectValue<Apps_deployment_progress_step_reason>(createApps_deployment_progress_step_reasonFromDiscriminatorValue); },
        "started_at": n => { apps_deployment_progress_step.startedAt = n.getDateValue(); },
        "status": n => { apps_deployment_progress_step.status = n.getEnumValue<Apps_deployment_progress_step_status>(Apps_deployment_progress_step_statusObject) ?? Apps_deployment_progress_step_statusObject.UNKNOWN; },
        "steps": n => { apps_deployment_progress_step.steps = n.getCollectionOfObjectValues<Apps_deployment_progress_step_steps>(createApps_deployment_progress_step_stepsFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_deployment_progress_step_reason(apps_deployment_progress_step_reason: Partial<Apps_deployment_progress_step_reason> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "code": n => { apps_deployment_progress_step_reason.code = n.getStringValue(); },
        "message": n => { apps_deployment_progress_step_reason.message = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_deployment_progress_step_steps(apps_deployment_progress_step_steps: Partial<Apps_deployment_progress_step_steps> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_deployment_response(apps_deployment_response: Partial<Apps_deployment_response> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "deployment": n => { apps_deployment_response.deployment = n.getObjectValue<Apps_deployment>(createApps_deploymentFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_deployment_service(apps_deployment_service: Partial<Apps_deployment_service> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "name": n => { apps_deployment_service.name = n.getStringValue(); },
        "source_commit_hash": n => { apps_deployment_service.sourceCommitHash = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_deployment_static_site(apps_deployment_static_site: Partial<Apps_deployment_static_site> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "name": n => { apps_deployment_static_site.name = n.getStringValue(); },
        "source_commit_hash": n => { apps_deployment_static_site.sourceCommitHash = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_deployment_worker(apps_deployment_worker: Partial<Apps_deployment_worker> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "name": n => { apps_deployment_worker.name = n.getStringValue(); },
        "source_commit_hash": n => { apps_deployment_worker.sourceCommitHash = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_deployments_response(apps_deployments_response: Partial<Apps_deployments_response> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "deployments": n => { apps_deployments_response.deployments = n.getCollectionOfObjectValues<Apps_deployment>(createApps_deploymentFromDiscriminatorValue); },
        "links": n => { apps_deployments_response.links = n.getObjectValue<Page_links>(createPage_linksFromDiscriminatorValue); },
        "meta": n => { apps_deployments_response.meta = n.getObjectValue<Meta_properties>(createMeta_propertiesFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_domain(apps_domain: Partial<Apps_domain> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "certificate_expires_at": n => { apps_domain.certificateExpiresAt = n.getDateValue(); },
        "id": n => { apps_domain.id = n.getStringValue(); },
        "phase": n => { apps_domain.phase = n.getEnumValue<Apps_domain_phase>(Apps_domain_phaseObject) ?? Apps_domain_phaseObject.UNKNOWN; },
        "progress": n => { apps_domain.progress = n.getObjectValue<Apps_domain_progress>(createApps_domain_progressFromDiscriminatorValue); },
        "rotate_validation_records": n => { apps_domain.rotateValidationRecords = n.getBooleanValue(); },
        "spec": n => { apps_domain.spec = n.getObjectValue<App_domain_spec>(createApp_domain_specFromDiscriminatorValue); },
        "validations": n => { apps_domain.validations = n.getCollectionOfObjectValues<App_domain_validation>(createApp_domain_validationFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_domain_progress(apps_domain_progress: Partial<Apps_domain_progress> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "steps": n => { apps_domain_progress.steps = n.getCollectionOfObjectValues<Apps_domain_progress_steps>(createApps_domain_progress_stepsFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_domain_progress_steps(apps_domain_progress_steps: Partial<Apps_domain_progress_steps> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_get_exec_response(apps_get_exec_response: Partial<Apps_get_exec_response> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "url": n => { apps_get_exec_response.url = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_get_instance_size_response(apps_get_instance_size_response: Partial<Apps_get_instance_size_response> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "instance_size": n => { apps_get_instance_size_response.instanceSize = n.getObjectValue<Apps_instance_size>(createApps_instance_sizeFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_get_logs_response(apps_get_logs_response: Partial<Apps_get_logs_response> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "historic_urls": n => { apps_get_logs_response.historicUrls = n.getCollectionOfPrimitiveValues<string>(); },
        "live_url": n => { apps_get_logs_response.liveUrl = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_git_source_spec(apps_git_source_spec: Partial<Apps_git_source_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "branch": n => { apps_git_source_spec.branch = n.getStringValue(); },
        "repo_clone_url": n => { apps_git_source_spec.repoCloneUrl = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_github_source_spec(apps_github_source_spec: Partial<Apps_github_source_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "branch": n => { apps_github_source_spec.branch = n.getStringValue(); },
        "deploy_on_push": n => { apps_github_source_spec.deployOnPush = n.getBooleanValue(); },
        "repo": n => { apps_github_source_spec.repo = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_gitlab_source_spec(apps_gitlab_source_spec: Partial<Apps_gitlab_source_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "branch": n => { apps_gitlab_source_spec.branch = n.getStringValue(); },
        "deploy_on_push": n => { apps_gitlab_source_spec.deployOnPush = n.getBooleanValue(); },
        "repo": n => { apps_gitlab_source_spec.repo = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_image_source_spec(apps_image_source_spec: Partial<Apps_image_source_spec> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "deploy_on_push": n => { apps_image_source_spec.deployOnPush = n.getObjectValue<Apps_image_source_spec_deploy_on_push>(createApps_image_source_spec_deploy_on_pushFromDiscriminatorValue); },
        "digest": n => { apps_image_source_spec.digest = n.getStringValue(); },
        "registry": n => { apps_image_source_spec.registry = n.getStringValue(); },
        "registry_credentials": n => { apps_image_source_spec.registryCredentials = n.getStringValue(); },
        "registry_type": n => { apps_image_source_spec.registryType = n.getEnumValue<Apps_image_source_spec_registry_type>(Apps_image_source_spec_registry_typeObject); },
        "repository": n => { apps_image_source_spec.repository = n.getStringValue(); },
        "tag": n => { apps_image_source_spec.tag = n.getStringValue() ?? "latest"; },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_image_source_spec_deploy_on_push(apps_image_source_spec_deploy_on_push: Partial<Apps_image_source_spec_deploy_on_push> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "enabled": n => { apps_image_source_spec_deploy_on_push.enabled = n.getBooleanValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_instance_size(apps_instance_size: Partial<Apps_instance_size> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "bandwidth_allowance_gib": n => { apps_instance_size.bandwidthAllowanceGib = n.getStringValue(); },
        "cpus": n => { apps_instance_size.cpus = n.getStringValue(); },
        "cpu_type": n => { apps_instance_size.cpuType = n.getEnumValue<Instance_size_cpu_type>(Instance_size_cpu_typeObject) ?? Instance_size_cpu_typeObject.UNSPECIFIED; },
        "deprecation_intent": n => { apps_instance_size.deprecationIntent = n.getBooleanValue(); },
        "memory_bytes": n => { apps_instance_size.memoryBytes = n.getStringValue(); },
        "name": n => { apps_instance_size.name = n.getStringValue(); },
        "scalable": n => { apps_instance_size.scalable = n.getBooleanValue(); },
        "single_instance_only": n => { apps_instance_size.singleInstanceOnly = n.getBooleanValue(); },
        "slug": n => { apps_instance_size.slug = n.getStringValue(); },
        "tier_downgrade_to": n => { apps_instance_size.tierDowngradeTo = n.getStringValue(); },
        "tier_slug": n => { apps_instance_size.tierSlug = n.getStringValue(); },
        "tier_upgrade_to": n => { apps_instance_size.tierUpgradeTo = n.getStringValue(); },
        "usd_per_month": n => { apps_instance_size.usdPerMonth = n.getStringValue(); },
        "usd_per_second": n => { apps_instance_size.usdPerSecond = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_list_alerts_response(apps_list_alerts_response: Partial<Apps_list_alerts_response> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "alerts": n => { apps_list_alerts_response.alerts = n.getCollectionOfObjectValues<App_alert>(createApp_alertFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_list_instance_sizes_response(apps_list_instance_sizes_response: Partial<Apps_list_instance_sizes_response> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "discount_percent": n => { apps_list_instance_sizes_response.discountPercent = n.getNumberValue(); },
        "instance_sizes": n => { apps_list_instance_sizes_response.instanceSizes = n.getCollectionOfObjectValues<Apps_instance_size>(createApps_instance_sizeFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_list_regions_response(apps_list_regions_response: Partial<Apps_list_regions_response> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "regions": n => { apps_list_regions_response.regions = n.getCollectionOfObjectValues<Apps_region>(createApps_regionFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_region(apps_region: Partial<Apps_region> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "continent": n => { apps_region.continent = n.getStringValue(); },
        "data_centers": n => { apps_region.dataCenters = n.getCollectionOfPrimitiveValues<string>(); },
        "default": n => { apps_region.defaultEscaped = n.getBooleanValue(); },
        "disabled": n => { apps_region.disabled = n.getBooleanValue(); },
        "flag": n => { apps_region.flag = n.getStringValue(); },
        "label": n => { apps_region.label = n.getStringValue(); },
        "reason": n => { apps_region.reason = n.getStringValue(); },
        "slug": n => { apps_region.slug = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_response(apps_response: Partial<Apps_response> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "apps": n => { apps_response.apps = n.getCollectionOfObjectValues<App>(createAppFromDiscriminatorValue); },
        "links": n => { apps_response.links = n.getObjectValue<Page_links>(createPage_linksFromDiscriminatorValue); },
        "meta": n => { apps_response.meta = n.getObjectValue<Meta_properties>(createMeta_propertiesFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_restart_request(apps_restart_request: Partial<Apps_restart_request> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "components": n => { apps_restart_request.components = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_rollback_app_request(apps_rollback_app_request: Partial<Apps_rollback_app_request> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "deployment_id": n => { apps_rollback_app_request.deploymentId = n.getStringValue(); },
        "skip_pin": n => { apps_rollback_app_request.skipPin = n.getBooleanValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_string_match(apps_string_match: Partial<Apps_string_match> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "exact": n => { apps_string_match.exact = n.getStringValue(); },
        "prefix": n => { apps_string_match.prefix = n.getStringValue(); },
        "regex": n => { apps_string_match.regex = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoApps_update_app_request(apps_update_app_request: Partial<Apps_update_app_request> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "spec": n => { apps_update_app_request.spec = n.getObjectValue<App_spec>(createApp_specFromDiscriminatorValue); },
        "update_all_source_versions": n => { apps_update_app_request.updateAllSourceVersions = n.getBooleanValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAssociated_kubernetes_resource(associated_kubernetes_resource: Partial<Associated_kubernetes_resource> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "id": n => { associated_kubernetes_resource.id = n.getStringValue(); },
        "name": n => { associated_kubernetes_resource.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAssociated_kubernetes_resources(associated_kubernetes_resources: Partial<Associated_kubernetes_resources> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "load_balancers": n => { associated_kubernetes_resources.loadBalancers = n.getCollectionOfObjectValues<Associated_kubernetes_resource>(createAssociated_kubernetes_resourceFromDiscriminatorValue); },
        "volumes": n => { associated_kubernetes_resources.volumes = n.getCollectionOfObjectValues<Associated_kubernetes_resource>(createAssociated_kubernetes_resourceFromDiscriminatorValue); },
        "volume_snapshots": n => { associated_kubernetes_resources.volumeSnapshots = n.getCollectionOfObjectValues<Associated_kubernetes_resource>(createAssociated_kubernetes_resourceFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAssociated_resource(associated_resource: Partial<Associated_resource> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "cost": n => { associated_resource.cost = n.getStringValue(); },
        "id": n => { associated_resource.id = n.getStringValue(); },
        "name": n => { associated_resource.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAssociated_resource_status(associated_resource_status: Partial<Associated_resource_status> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "completed_at": n => { associated_resource_status.completedAt = n.getDateValue(); },
        "droplet": n => { associated_resource_status.droplet = n.getObjectValue<Destroyed_associated_resource>(createDestroyed_associated_resourceFromDiscriminatorValue); },
        "failures": n => { associated_resource_status.failures = n.getNumberValue(); },
        "resources": n => { associated_resource_status.resources = n.getObjectValue<Associated_resource_status_resources>(createAssociated_resource_status_resourcesFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAssociated_resource_status_resources(associated_resource_status_resources: Partial<Associated_resource_status_resources> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "floating_ips": n => { associated_resource_status_resources.floatingIps = n.getCollectionOfObjectValues<Destroyed_associated_resource>(createDestroyed_associated_resourceFromDiscriminatorValue); },
        "reserved_ips": n => { associated_resource_status_resources.reservedIps = n.getCollectionOfObjectValues<Destroyed_associated_resource>(createDestroyed_associated_resourceFromDiscriminatorValue); },
        "snapshots": n => { associated_resource_status_resources.snapshots = n.getCollectionOfObjectValues<Destroyed_associated_resource>(createDestroyed_associated_resourceFromDiscriminatorValue); },
        "volumes": n => { associated_resource_status_resources.volumes = n.getCollectionOfObjectValues<Destroyed_associated_resource>(createDestroyed_associated_resourceFromDiscriminatorValue); },
        "volume_snapshots": n => { associated_resource_status_resources.volumeSnapshots = n.getCollectionOfObjectValues<Destroyed_associated_resource>(createDestroyed_associated_resourceFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAutoscale_pool(autoscale_pool: Partial<Autoscale_pool> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "active_resources_count": n => { autoscale_pool.activeResourcesCount = n.getNumberValue(); },
        "config": n => { autoscale_pool.config = n.getObjectValue<Autoscale_pool_dynamic_config>(createAutoscale_pool_dynamic_configFromDiscriminatorValue) ?? n.getObjectValue<Autoscale_pool_static_config>(createAutoscale_pool_static_configFromDiscriminatorValue); },
        "created_at": n => { autoscale_pool.createdAt = n.getDateValue(); },
        "current_utilization": n => { autoscale_pool.currentUtilization = n.getObjectValue<Current_utilization>(createCurrent_utilizationFromDiscriminatorValue); },
        "droplet_template": n => { autoscale_pool.dropletTemplate = n.getObjectValue<Autoscale_pool_droplet_template>(createAutoscale_pool_droplet_templateFromDiscriminatorValue); },
        "id": n => { autoscale_pool.id = n.getStringValue(); },
        "name": n => { autoscale_pool.name = n.getStringValue(); },
        "status": n => { autoscale_pool.status = n.getEnumValue<Autoscale_pool_status>(Autoscale_pool_statusObject); },
        "updated_at": n => { autoscale_pool.updatedAt = n.getDateValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAutoscale_pool_config(autoscale_pool_config: Partial<Autoscale_pool_dynamic_config | Autoscale_pool_static_config> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoAutoscale_pool_dynamic_config(autoscale_pool_config as Autoscale_pool_dynamic_config),
        ...deserializeIntoAutoscale_pool_static_config(autoscale_pool_config as Autoscale_pool_static_config),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAutoscale_pool_create(autoscale_pool_create: Partial<Autoscale_pool_create> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "config": n => { autoscale_pool_create.config = n.getObjectValue<Autoscale_pool_dynamic_config>(createAutoscale_pool_dynamic_configFromDiscriminatorValue) ?? n.getObjectValue<Autoscale_pool_static_config>(createAutoscale_pool_static_configFromDiscriminatorValue); },
        "droplet_template": n => { autoscale_pool_create.dropletTemplate = n.getObjectValue<Autoscale_pool_droplet_template>(createAutoscale_pool_droplet_templateFromDiscriminatorValue); },
        "name": n => { autoscale_pool_create.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAutoscale_pool_create_config(autoscale_pool_create_config: Partial<Autoscale_pool_dynamic_config | Autoscale_pool_static_config> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoAutoscale_pool_dynamic_config(autoscale_pool_create_config as Autoscale_pool_dynamic_config),
        ...deserializeIntoAutoscale_pool_static_config(autoscale_pool_create_config as Autoscale_pool_static_config),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAutoscale_pool_droplet_template(autoscale_pool_droplet_template: Partial<Autoscale_pool_droplet_template> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "image": n => { autoscale_pool_droplet_template.image = n.getStringValue(); },
        "ipv6": n => { autoscale_pool_droplet_template.ipv6 = n.getBooleanValue(); },
        "name": n => { autoscale_pool_droplet_template.name = n.getStringValue(); },
        "project_id": n => { autoscale_pool_droplet_template.projectId = n.getStringValue(); },
        "region": n => { autoscale_pool_droplet_template.region = n.getEnumValue<Autoscale_pool_droplet_template_region>(Autoscale_pool_droplet_template_regionObject); },
        "size": n => { autoscale_pool_droplet_template.size = n.getStringValue(); },
        "ssh_keys": n => { autoscale_pool_droplet_template.sshKeys = n.getCollectionOfPrimitiveValues<string>(); },
        "tags": n => { autoscale_pool_droplet_template.tags = n.getCollectionOfPrimitiveValues<string>(); },
        "user_data": n => { autoscale_pool_droplet_template.userData = n.getStringValue(); },
        "vpc_uuid": n => { autoscale_pool_droplet_template.vpcUuid = n.getStringValue(); },
        "with_droplet_agent": n => { autoscale_pool_droplet_template.withDropletAgent = n.getBooleanValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAutoscale_pool_dynamic_config(autoscale_pool_dynamic_config: Partial<Autoscale_pool_dynamic_config> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "cooldown_minutes": n => { autoscale_pool_dynamic_config.cooldownMinutes = n.getNumberValue(); },
        "max_instances": n => { autoscale_pool_dynamic_config.maxInstances = n.getNumberValue(); },
        "min_instances": n => { autoscale_pool_dynamic_config.minInstances = n.getNumberValue(); },
        "target_cpu_utilization": n => { autoscale_pool_dynamic_config.targetCpuUtilization = n.getNumberValue(); },
        "target_memory_utilization": n => { autoscale_pool_dynamic_config.targetMemoryUtilization = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoAutoscale_pool_static_config(autoscale_pool_static_config: Partial<Autoscale_pool_static_config> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "target_number_instances": n => { autoscale_pool_static_config.targetNumberInstances = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoBackup(backup: Partial<Backup> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { backup.createdAt = n.getDateValue(); },
        "size_gigabytes": n => { backup.sizeGigabytes = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoBackward_links(backward_links: Partial<Backward_links> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "first": n => { backward_links.first = n.getStringValue(); },
        "prev": n => { backward_links.prev = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoBalance(balance: Partial<Balance> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "account_balance": n => { balance.accountBalance = n.getStringValue(); },
        "generated_at": n => { balance.generatedAt = n.getDateValue(); },
        "month_to_date_balance": n => { balance.monthToDateBalance = n.getStringValue(); },
        "month_to_date_usage": n => { balance.monthToDateUsage = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoBilling_address(billing_address: Partial<Billing_address> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "address_line1": n => { billing_address.addressLine1 = n.getStringValue(); },
        "address_line2": n => { billing_address.addressLine2 = n.getStringValue(); },
        "city": n => { billing_address.city = n.getStringValue(); },
        "country_iso2_code": n => { billing_address.countryIso2Code = n.getStringValue(); },
        "created_at": n => { billing_address.createdAt = n.getStringValue(); },
        "postal_code": n => { billing_address.postalCode = n.getStringValue(); },
        "region": n => { billing_address.region = n.getStringValue(); },
        "updated_at": n => { billing_address.updatedAt = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoBilling_history(billing_history: Partial<Billing_history> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "amount": n => { billing_history.amount = n.getStringValue(); },
        "date": n => { billing_history.date = n.getDateValue(); },
        "description": n => { billing_history.description = n.getStringValue(); },
        "invoice_id": n => { billing_history.invoiceId = n.getStringValue(); },
        "invoice_uuid": n => { billing_history.invoiceUuid = n.getStringValue(); },
        "type": n => { billing_history.type = n.getEnumValue<Billing_history_type>(Billing_history_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoCa(ca: Partial<Ca> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "certificate": n => { ca.certificate = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoCdn_endpoint(cdn_endpoint: Partial<Cdn_endpoint> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "certificate_id": n => { cdn_endpoint.certificateId = n.getGuidValue(); },
        "created_at": n => { cdn_endpoint.createdAt = n.getDateValue(); },
        "custom_domain": n => { cdn_endpoint.customDomain = n.getStringValue(); },
        "endpoint": n => { cdn_endpoint.endpoint = n.getStringValue(); },
        "id": n => { cdn_endpoint.id = n.getGuidValue(); },
        "origin": n => { cdn_endpoint.origin = n.getStringValue(); },
        "ttl": n => { cdn_endpoint.ttl = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoCertificate(certificate: Partial<Certificate> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { certificate.createdAt = n.getDateValue(); },
        "dns_names": n => { certificate.dnsNames = n.getCollectionOfPrimitiveValues<string>(); },
        "id": n => { certificate.id = n.getGuidValue(); },
        "name": n => { certificate.name = n.getStringValue(); },
        "not_after": n => { certificate.notAfter = n.getDateValue(); },
        "sha1_fingerprint": n => { certificate.sha1Fingerprint = n.getStringValue(); },
        "state": n => { certificate.state = n.getEnumValue<Certificate_state>(Certificate_stateObject); },
        "type": n => { certificate.type = n.getEnumValue<Certificate_type>(Certificate_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoCertificate_create_base(certificate_create_base: Partial<Certificate_create_base> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "name": n => { certificate_create_base.name = n.getStringValue(); },
        "type": n => { certificate_create_base.type = n.getEnumValue<Certificate_create_base_type>(Certificate_create_base_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoCertificate_request_custom(certificate_request_custom: Partial<Certificate_request_custom> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoCertificate_create_base(certificate_request_custom),
        "certificate_chain": n => { certificate_request_custom.certificateChain = n.getStringValue(); },
        "leaf_certificate": n => { certificate_request_custom.leafCertificate = n.getStringValue(); },
        "private_key": n => { certificate_request_custom.privateKey = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoCertificate_request_lets_encrypt(certificate_request_lets_encrypt: Partial<Certificate_request_lets_encrypt> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoCertificate_create_base(certificate_request_lets_encrypt),
        "dns_names": n => { certificate_request_lets_encrypt.dnsNames = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoCheck(check: Partial<Check> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "enabled": n => { check.enabled = n.getBooleanValue(); },
        "id": n => { check.id = n.getGuidValue(); },
        "name": n => { check.name = n.getStringValue(); },
        "regions": n => { check.regions = n.getCollectionOfEnumValues<Check_regions>(Check_regionsObject); },
        "target": n => { check.target = n.getStringValue(); },
        "type": n => { check.type = n.getEnumValue<Check_type>(Check_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoCheck_updatable(check_updatable: Partial<Check_updatable> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "enabled": n => { check_updatable.enabled = n.getBooleanValue(); },
        "name": n => { check_updatable.name = n.getStringValue(); },
        "regions": n => { check_updatable.regions = n.getCollectionOfEnumValues<Check_updatable_regions>(Check_updatable_regionsObject); },
        "target": n => { check_updatable.target = n.getStringValue(); },
        "type": n => { check_updatable.type = n.getEnumValue<Check_updatable_type>(Check_updatable_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoCluster(cluster: Partial<Cluster> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "auto_upgrade": n => { cluster.autoUpgrade = n.getBooleanValue(); },
        "cluster_autoscaler_configuration": n => { cluster.clusterAutoscalerConfiguration = n.getObjectValue<Cluster_autoscaler_configuration>(createCluster_autoscaler_configurationFromDiscriminatorValue); },
        "cluster_subnet": n => { cluster.clusterSubnet = n.getStringValue(); },
        "control_plane_firewall": n => { cluster.controlPlaneFirewall = n.getObjectValue<Control_plane_firewall>(createControl_plane_firewallFromDiscriminatorValue); },
        "created_at": n => { cluster.createdAt = n.getDateValue(); },
        "endpoint": n => { cluster.endpoint = n.getStringValue(); },
        "ha": n => { cluster.ha = n.getBooleanValue(); },
        "id": n => { cluster.id = n.getGuidValue(); },
        "ipv4": n => { cluster.ipv4 = n.getStringValue(); },
        "maintenance_policy": n => { cluster.maintenancePolicy = n.getObjectValue<Maintenance_policy>(createMaintenance_policyFromDiscriminatorValue); },
        "name": n => { cluster.name = n.getStringValue(); },
        "node_pools": n => { cluster.nodePools = n.getCollectionOfObjectValues<Kubernetes_node_pool>(createKubernetes_node_poolFromDiscriminatorValue); },
        "region": n => { cluster.region = n.getStringValue(); },
        "registry_enabled": n => { cluster.registryEnabled = n.getBooleanValue(); },
        "routing_agent": n => { cluster.routingAgent = n.getObjectValue<Routing_agent>(createRouting_agentFromDiscriminatorValue); },
        "service_subnet": n => { cluster.serviceSubnet = n.getStringValue(); },
        "status": n => { cluster.status = n.getObjectValue<Cluster_status>(createCluster_statusFromDiscriminatorValue); },
        "surge_upgrade": n => { cluster.surgeUpgrade = n.getBooleanValue(); },
        "tags": n => { cluster.tags = n.getCollectionOfPrimitiveValues<string>(); },
        "updated_at": n => { cluster.updatedAt = n.getDateValue(); },
        "version": n => { cluster.version = n.getStringValue(); },
        "vpc_uuid": n => { cluster.vpcUuid = n.getGuidValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoCluster_autoscaler_configuration(cluster_autoscaler_configuration: Partial<Cluster_autoscaler_configuration> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "scale_down_unneeded_time": n => { cluster_autoscaler_configuration.scaleDownUnneededTime = n.getStringValue(); },
        "scale_down_utilization_threshold": n => { cluster_autoscaler_configuration.scaleDownUtilizationThreshold = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoCluster_registries(cluster_registries: Partial<Cluster_registries> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "cluster_uuids": n => { cluster_registries.clusterUuids = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoCluster_status(cluster_status: Partial<Cluster_status> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "message": n => { cluster_status.message = n.getStringValue(); },
        "state": n => { cluster_status.state = n.getEnumValue<Cluster_status_state>(Cluster_status_stateObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoCluster_update(cluster_update: Partial<Cluster_update> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "auto_upgrade": n => { cluster_update.autoUpgrade = n.getBooleanValue(); },
        "cluster_autoscaler_configuration": n => { cluster_update.clusterAutoscalerConfiguration = n.getObjectValue<Cluster_autoscaler_configuration>(createCluster_autoscaler_configurationFromDiscriminatorValue); },
        "control_plane_firewall": n => { cluster_update.controlPlaneFirewall = n.getObjectValue<Control_plane_firewall>(createControl_plane_firewallFromDiscriminatorValue); },
        "ha": n => { cluster_update.ha = n.getBooleanValue(); },
        "maintenance_policy": n => { cluster_update.maintenancePolicy = n.getObjectValue<Maintenance_policy>(createMaintenance_policyFromDiscriminatorValue); },
        "name": n => { cluster_update.name = n.getStringValue(); },
        "routing_agent": n => { cluster_update.routingAgent = n.getObjectValue<Routing_agent>(createRouting_agentFromDiscriminatorValue); },
        "surge_upgrade": n => { cluster_update.surgeUpgrade = n.getBooleanValue(); },
        "tags": n => { cluster_update.tags = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoClusterlint_request(clusterlint_request: Partial<Clusterlint_request> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "exclude_checks": n => { clusterlint_request.excludeChecks = n.getCollectionOfPrimitiveValues<string>(); },
        "exclude_groups": n => { clusterlint_request.excludeGroups = n.getCollectionOfPrimitiveValues<string>(); },
        "include_checks": n => { clusterlint_request.includeChecks = n.getCollectionOfPrimitiveValues<string>(); },
        "include_groups": n => { clusterlint_request.includeGroups = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoClusterlint_results(clusterlint_results: Partial<Clusterlint_results> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "completed_at": n => { clusterlint_results.completedAt = n.getDateValue(); },
        "diagnostics": n => { clusterlint_results.diagnostics = n.getCollectionOfObjectValues<Clusterlint_results_diagnostics>(createClusterlint_results_diagnosticsFromDiscriminatorValue); },
        "requested_at": n => { clusterlint_results.requestedAt = n.getDateValue(); },
        "run_id": n => { clusterlint_results.runId = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoClusterlint_results_diagnostics(clusterlint_results_diagnostics: Partial<Clusterlint_results_diagnostics> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "check_name": n => { clusterlint_results_diagnostics.checkName = n.getStringValue(); },
        "message": n => { clusterlint_results_diagnostics.message = n.getStringValue(); },
        "object": n => { clusterlint_results_diagnostics.object = n.getObjectValue<Clusterlint_results_diagnostics_object>(createClusterlint_results_diagnostics_objectFromDiscriminatorValue); },
        "severity": n => { clusterlint_results_diagnostics.severity = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoClusterlint_results_diagnostics_object(clusterlint_results_diagnostics_object: Partial<Clusterlint_results_diagnostics_object> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "kind": n => { clusterlint_results_diagnostics_object.kind = n.getStringValue(); },
        "name": n => { clusterlint_results_diagnostics_object.name = n.getStringValue(); },
        "namespace": n => { clusterlint_results_diagnostics_object.namespace = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoConnection_pool(connection_pool: Partial<Connection_pool> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "connection": n => { connection_pool.connection = n.getObjectValue<Database_connection>(createDatabase_connectionFromDiscriminatorValue); },
        "db": n => { connection_pool.db = n.getStringValue(); },
        "mode": n => { connection_pool.mode = n.getStringValue(); },
        "name": n => { connection_pool.name = n.getStringValue(); },
        "private_connection": n => { connection_pool.privateConnection = n.getObjectValue<Database_connection>(createDatabase_connectionFromDiscriminatorValue); },
        "size": n => { connection_pool.size = n.getNumberValue(); },
        "standby_connection": n => { connection_pool.standbyConnection = n.getObjectValue<Database_connection>(createDatabase_connectionFromDiscriminatorValue); },
        "standby_private_connection": n => { connection_pool.standbyPrivateConnection = n.getObjectValue<Database_connection>(createDatabase_connectionFromDiscriminatorValue); },
        "user": n => { connection_pool.user = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoConnection_pool_update(connection_pool_update: Partial<Connection_pool_update> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "db": n => { connection_pool_update.db = n.getStringValue(); },
        "mode": n => { connection_pool_update.mode = n.getStringValue(); },
        "size": n => { connection_pool_update.size = n.getNumberValue(); },
        "user": n => { connection_pool_update.user = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoConnection_pools(connection_pools: Partial<Connection_pools> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "pools": n => { connection_pools.pools = n.getCollectionOfObjectValues<Connection_pool>(createConnection_poolFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoControl_plane_firewall(control_plane_firewall: Partial<Control_plane_firewall> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "allowed_addresses": n => { control_plane_firewall.allowedAddresses = n.getCollectionOfPrimitiveValues<string>(); },
        "enabled": n => { control_plane_firewall.enabled = n.getBooleanValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoCreate_namespace(create_namespace: Partial<Create_namespace> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "label": n => { create_namespace.label = n.getStringValue(); },
        "region": n => { create_namespace.region = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoCreate_trigger(create_trigger: Partial<Create_trigger> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "function": n => { create_trigger.functionEscaped = n.getStringValue(); },
        "is_enabled": n => { create_trigger.isEnabled = n.getBooleanValue(); },
        "name": n => { create_trigger.name = n.getStringValue(); },
        "scheduled_details": n => { create_trigger.scheduledDetails = n.getObjectValue<Scheduled_details>(createScheduled_detailsFromDiscriminatorValue); },
        "type": n => { create_trigger.type = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoCredentials(credentials: Partial<Credentials> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "certificate_authority_data": n => { credentials.certificateAuthorityData = n.getByteArrayValue(); },
        "client_certificate_data": n => { credentials.clientCertificateData = n.getByteArrayValue(); },
        "client_key_data": n => { credentials.clientKeyData = n.getByteArrayValue(); },
        "expires_at": n => { credentials.expiresAt = n.getDateValue(); },
        "server": n => { credentials.server = n.getStringValue(); },
        "token": n => { credentials.token = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoCurrent_utilization(current_utilization: Partial<Current_utilization> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "cpu": n => { current_utilization.cpu = n.getNumberValue(); },
        "memory": n => { current_utilization.memory = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDatabase(database: Partial<Database> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "name": n => { database.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDatabase_backup(database_backup: Partial<Database_backup> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "backup_created_at": n => { database_backup.backupCreatedAt = n.getDateValue(); },
        "database_name": n => { database_backup.databaseName = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDatabase_cluster(database_cluster: Partial<Database_cluster> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "connection": n => { database_cluster.connection = n.getObjectValue<Database_connection>(createDatabase_connectionFromDiscriminatorValue); },
        "created_at": n => { database_cluster.createdAt = n.getDateValue(); },
        "db_names": n => { database_cluster.dbNames = n.getCollectionOfPrimitiveValues<string>(); },
        "engine": n => { database_cluster.engine = n.getEnumValue<Database_cluster_engine>(Database_cluster_engineObject); },
        "id": n => { database_cluster.id = n.getGuidValue(); },
        "maintenance_window": n => { database_cluster.maintenanceWindow = n.getObjectValue<Database_maintenance_window>(createDatabase_maintenance_windowFromDiscriminatorValue); },
        "metrics_endpoints": n => { database_cluster.metricsEndpoints = n.getCollectionOfObjectValues<Database_service_endpoint>(createDatabase_service_endpointFromDiscriminatorValue); },
        "name": n => { database_cluster.name = n.getStringValue(); },
        "num_nodes": n => { database_cluster.numNodes = n.getNumberValue(); },
        "private_connection": n => { database_cluster.privateConnection = n.getObjectValue<Database_connection>(createDatabase_connectionFromDiscriminatorValue); },
        "private_network_uuid": n => { database_cluster.privateNetworkUuid = n.getStringValue(); },
        "project_id": n => { database_cluster.projectId = n.getGuidValue(); },
        "region": n => { database_cluster.region = n.getStringValue(); },
        "rules": n => { database_cluster.rules = n.getCollectionOfObjectValues<Firewall_rule>(createFirewall_ruleFromDiscriminatorValue); },
        "semantic_version": n => { database_cluster.semanticVersion = n.getStringValue(); },
        "size": n => { database_cluster.size = n.getStringValue(); },
        "standby_connection": n => { database_cluster.standbyConnection = n.getObjectValue<Database_connection>(createDatabase_connectionFromDiscriminatorValue); },
        "standby_private_connection": n => { database_cluster.standbyPrivateConnection = n.getObjectValue<Database_connection>(createDatabase_connectionFromDiscriminatorValue); },
        "status": n => { database_cluster.status = n.getEnumValue<Database_cluster_status>(Database_cluster_statusObject); },
        "storage_size_mib": n => { database_cluster.storageSizeMib = n.getNumberValue(); },
        "tags": n => { database_cluster.tags = n.getCollectionOfPrimitiveValues<string>(); },
        "ui_connection": n => { database_cluster.uiConnection = n.getObjectValue<Opensearch_connection>(createOpensearch_connectionFromDiscriminatorValue); },
        "users": n => { database_cluster.users = n.getCollectionOfObjectValues<Database_user>(createDatabase_userFromDiscriminatorValue); },
        "version": n => { database_cluster.version = n.getStringValue(); },
        "version_end_of_availability": n => { database_cluster.versionEndOfAvailability = n.getStringValue(); },
        "version_end_of_life": n => { database_cluster.versionEndOfLife = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDatabase_cluster_resize(database_cluster_resize: Partial<Database_cluster_resize> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "num_nodes": n => { database_cluster_resize.numNodes = n.getNumberValue(); },
        "size": n => { database_cluster_resize.size = n.getStringValue(); },
        "storage_size_mib": n => { database_cluster_resize.storageSizeMib = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDatabase_config(database_config: Partial<Database_config> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "config": n => { database_config.config = n.getObjectValue<Kafka_advanced_config>(createKafka_advanced_configFromDiscriminatorValue) ?? n.getObjectValue<Mongo_advanced_config>(createMongo_advanced_configFromDiscriminatorValue) ?? n.getObjectValue<Mysql_advanced_config>(createMysql_advanced_configFromDiscriminatorValue) ?? n.getObjectValue<Opensearch_advanced_config>(createOpensearch_advanced_configFromDiscriminatorValue) ?? n.getObjectValue<Postgres_advanced_config>(createPostgres_advanced_configFromDiscriminatorValue) ?? n.getObjectValue<Redis_advanced_config>(createRedis_advanced_configFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDatabase_config_config(database_config_config: Partial<Kafka_advanced_config | Mongo_advanced_config | Mysql_advanced_config | Opensearch_advanced_config | Postgres_advanced_config | Redis_advanced_config> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoKafka_advanced_config(database_config_config as Kafka_advanced_config),
        ...deserializeIntoMongo_advanced_config(database_config_config as Mongo_advanced_config),
        ...deserializeIntoMysql_advanced_config(database_config_config as Mysql_advanced_config),
        ...deserializeIntoOpensearch_advanced_config(database_config_config as Opensearch_advanced_config),
        ...deserializeIntoPostgres_advanced_config(database_config_config as Postgres_advanced_config),
        ...deserializeIntoRedis_advanced_config(database_config_config as Redis_advanced_config),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDatabase_connection(database_connection: Partial<Database_connection> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "database": n => { database_connection.database = n.getStringValue(); },
        "host": n => { database_connection.host = n.getStringValue(); },
        "password": n => { database_connection.password = n.getStringValue(); },
        "port": n => { database_connection.port = n.getNumberValue(); },
        "ssl": n => { database_connection.ssl = n.getBooleanValue(); },
        "uri": n => { database_connection.uri = n.getStringValue(); },
        "user": n => { database_connection.user = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDatabase_layout_option(database_layout_option: Partial<Database_layout_option> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "num_nodes": n => { database_layout_option.numNodes = n.getNumberValue(); },
        "sizes": n => { database_layout_option.sizes = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDatabase_maintenance_window(database_maintenance_window: Partial<Database_maintenance_window> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "day": n => { database_maintenance_window.day = n.getStringValue(); },
        "description": n => { database_maintenance_window.description = n.getCollectionOfPrimitiveValues<string>(); },
        "hour": n => { database_maintenance_window.hour = n.getStringValue(); },
        "pending": n => { database_maintenance_window.pending = n.getBooleanValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDatabase_metrics_credentials(database_metrics_credentials: Partial<Database_metrics_credentials> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "credentials": n => { database_metrics_credentials.credentials = n.getObjectValue<Databases_basic_auth_credentials>(createDatabases_basic_auth_credentialsFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDatabase_replica(database_replica: Partial<Database_replica> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "connection": n => { database_replica.connection = n.getObjectValue<Database_connection>(createDatabase_connectionFromDiscriminatorValue); },
        "created_at": n => { database_replica.createdAt = n.getDateValue(); },
        "id": n => { database_replica.id = n.getGuidValue(); },
        "name": n => { database_replica.name = n.getStringValue(); },
        "private_connection": n => { database_replica.privateConnection = n.getObjectValue<Database_connection>(createDatabase_connectionFromDiscriminatorValue); },
        "private_network_uuid": n => { database_replica.privateNetworkUuid = n.getStringValue(); },
        "region": n => { database_replica.region = n.getStringValue(); },
        "size": n => { database_replica.size = n.getStringValue(); },
        "status": n => { database_replica.status = n.getEnumValue<Database_replica_status>(Database_replica_statusObject); },
        "storage_size_mib": n => { database_replica.storageSizeMib = n.getNumberValue(); },
        "tags": n => { database_replica.tags = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDatabase_service_endpoint(database_service_endpoint: Partial<Database_service_endpoint> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "host": n => { database_service_endpoint.host = n.getStringValue(); },
        "port": n => { database_service_endpoint.port = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDatabase_user(database_user: Partial<Database_user> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "access_cert": n => { database_user.accessCert = n.getStringValue(); },
        "access_key": n => { database_user.accessKey = n.getStringValue(); },
        "mysql_settings": n => { database_user.mysqlSettings = n.getObjectValue<Mysql_settings>(createMysql_settingsFromDiscriminatorValue); },
        "name": n => { database_user.name = n.getStringValue(); },
        "password": n => { database_user.password = n.getStringValue(); },
        "role": n => { database_user.role = n.getEnumValue<Database_user_role>(Database_user_roleObject); },
        "settings": n => { database_user.settings = n.getObjectValue<User_settings>(createUser_settingsFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDatabase_version_availability(database_version_availability: Partial<Database_version_availability> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "end_of_availability": n => { database_version_availability.endOfAvailability = n.getStringValue(); },
        "end_of_life": n => { database_version_availability.endOfLife = n.getStringValue(); },
        "version": n => { database_version_availability.version = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDatabases_basic_auth_credentials(databases_basic_auth_credentials: Partial<Databases_basic_auth_credentials> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "basic_auth_password": n => { databases_basic_auth_credentials.basicAuthPassword = n.getStringValue(); },
        "basic_auth_username": n => { databases_basic_auth_credentials.basicAuthUsername = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDestination(destination: Partial<Destination> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "config": n => { destination.config = n.getObjectValue<Opensearch_config>(createOpensearch_configFromDiscriminatorValue); },
        "id": n => { destination.id = n.getStringValue(); },
        "name": n => { destination.name = n.getStringValue(); },
        "type": n => { destination.type = n.getEnumValue<Destination_type>(Destination_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDestination_omit_credentials(destination_omit_credentials: Partial<Destination_omit_credentials> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "config": n => { destination_omit_credentials.config = n.getObjectValue<Opensearch_config_omit_credentials>(createOpensearch_config_omit_credentialsFromDiscriminatorValue); },
        "id": n => { destination_omit_credentials.id = n.getStringValue(); },
        "name": n => { destination_omit_credentials.name = n.getStringValue(); },
        "type": n => { destination_omit_credentials.type = n.getEnumValue<Destination_omit_credentials_type>(Destination_omit_credentials_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDestination_request(destination_request: Partial<Destination_request> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "config": n => { destination_request.config = n.getObjectValue<Opensearch_config_request>(createOpensearch_config_requestFromDiscriminatorValue); },
        "name": n => { destination_request.name = n.getStringValue(); },
        "type": n => { destination_request.type = n.getEnumValue<Destination_request_type>(Destination_request_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDestroy_associated_kubernetes_resources(destroy_associated_kubernetes_resources: Partial<Destroy_associated_kubernetes_resources> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "load_balancers": n => { destroy_associated_kubernetes_resources.loadBalancers = n.getCollectionOfPrimitiveValues<string>(); },
        "volumes": n => { destroy_associated_kubernetes_resources.volumes = n.getCollectionOfPrimitiveValues<string>(); },
        "volume_snapshots": n => { destroy_associated_kubernetes_resources.volumeSnapshots = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDestroyed_associated_resource(destroyed_associated_resource: Partial<Destroyed_associated_resource> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "destroyed_at": n => { destroyed_associated_resource.destroyedAt = n.getDateValue(); },
        "error_message": n => { destroyed_associated_resource.errorMessage = n.getStringValue(); },
        "id": n => { destroyed_associated_resource.id = n.getStringValue(); },
        "name": n => { destroyed_associated_resource.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDisk_info(disk_info: Partial<Disk_info> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "size": n => { disk_info.size = n.getObjectValue<Disk_info_size>(createDisk_info_sizeFromDiscriminatorValue); },
        "type": n => { disk_info.type = n.getEnumValue<Disk_info_type>(Disk_info_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDisk_info_size(disk_info_size: Partial<Disk_info_size> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "amount": n => { disk_info_size.amount = n.getNumberValue(); },
        "unit": n => { disk_info_size.unit = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDocker_credentials(docker_credentials: Partial<Docker_credentials> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "auths": n => { docker_credentials.auths = n.getObjectValue<Docker_credentials_auths>(createDocker_credentials_authsFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDocker_credentials_auths(docker_credentials_auths: Partial<Docker_credentials_auths> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "registry.digitalocean.com": n => { docker_credentials_auths.registryDigitaloceanCom = n.getObjectValue<Docker_credentials_auths_registryDigitaloceanCom>(createDocker_credentials_auths_registryDigitaloceanComFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDocker_credentials_auths_registryDigitaloceanCom(docker_credentials_auths_registryDigitaloceanCom: Partial<Docker_credentials_auths_registryDigitaloceanCom> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "auth": n => { docker_credentials_auths_registryDigitaloceanCom.auth = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDomain(domain: Partial<Domain> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "ip_address": n => { domain.ipAddress = n.getStringValue(); },
        "name": n => { domain.name = n.getStringValue(); },
        "ttl": n => { domain.ttl = n.getNumberValue(); },
        "zone_file": n => { domain.zoneFile = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDomain_record(domain_record: Partial<Domain_record> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "data": n => { domain_record.data = n.getStringValue(); },
        "flags": n => { domain_record.flags = n.getNumberValue(); },
        "id": n => { domain_record.id = n.getNumberValue(); },
        "name": n => { domain_record.name = n.getStringValue(); },
        "port": n => { domain_record.port = n.getNumberValue(); },
        "priority": n => { domain_record.priority = n.getNumberValue(); },
        "tag": n => { domain_record.tag = n.getStringValue(); },
        "ttl": n => { domain_record.ttl = n.getNumberValue(); },
        "type": n => { domain_record.type = n.getStringValue(); },
        "weight": n => { domain_record.weight = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDomain_record_a(domain_record_a: Partial<Domain_record_a> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoDomain_record(domain_record_a),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDomain_record_aaaa(domain_record_aaaa: Partial<Domain_record_aaaa> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoDomain_record(domain_record_aaaa),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDomain_record_caa(domain_record_caa: Partial<Domain_record_caa> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoDomain_record(domain_record_caa),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDomain_record_cname(domain_record_cname: Partial<Domain_record_cname> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoDomain_record(domain_record_cname),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDomain_record_mx(domain_record_mx: Partial<Domain_record_mx> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoDomain_record(domain_record_mx),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDomain_record_ns(domain_record_ns: Partial<Domain_record_ns> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoDomain_record(domain_record_ns),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDomain_record_soa(domain_record_soa: Partial<Domain_record_soa> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoDomain_record(domain_record_soa),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDomain_record_srv(domain_record_srv: Partial<Domain_record_srv> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoDomain_record(domain_record_srv),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDomain_record_txt(domain_record_txt: Partial<Domain_record_txt> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoDomain_record(domain_record_txt),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDomains(domains: Partial<Domains> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "certificate_id": n => { domains.certificateId = n.getStringValue(); },
        "is_managed": n => { domains.isManaged = n.getBooleanValue(); },
        "name": n => { domains.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDroplet(droplet: Partial<Droplet> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "backup_ids": n => { droplet.backupIds = n.getCollectionOfPrimitiveValues<number>(); },
        "created_at": n => { droplet.createdAt = n.getDateValue(); },
        "disk": n => { droplet.disk = n.getNumberValue(); },
        "disk_info": n => { droplet.diskInfo = n.getCollectionOfObjectValues<Disk_info>(createDisk_infoFromDiscriminatorValue); },
        "features": n => { droplet.features = n.getCollectionOfPrimitiveValues<string>(); },
        "gpu_info": n => { droplet.gpuInfo = n.getObjectValue<Gpu_info>(createGpu_infoFromDiscriminatorValue); },
        "id": n => { droplet.id = n.getNumberValue(); },
        "image": n => { droplet.image = n.getObjectValue<Image>(createImageFromDiscriminatorValue); },
        "kernel": n => { droplet.kernel = n.getObjectValue<Kernel>(createKernelFromDiscriminatorValue); },
        "locked": n => { droplet.locked = n.getBooleanValue(); },
        "memory": n => { droplet.memory = n.getNumberValue(); },
        "name": n => { droplet.name = n.getStringValue(); },
        "networks": n => { droplet.networks = n.getObjectValue<Droplet_networks>(createDroplet_networksFromDiscriminatorValue); },
        "next_backup_window": n => { droplet.nextBackupWindow = n.getObjectValue<Droplet_next_backup_window>(createDroplet_next_backup_windowFromDiscriminatorValue); },
        "region": n => { droplet.region = n.getObjectValue<Region>(createRegionFromDiscriminatorValue); },
        "size": n => { droplet.size = n.getObjectValue<Size>(createSizeFromDiscriminatorValue); },
        "size_slug": n => { droplet.sizeSlug = n.getStringValue(); },
        "snapshot_ids": n => { droplet.snapshotIds = n.getCollectionOfPrimitiveValues<number>(); },
        "status": n => { droplet.status = n.getEnumValue<Droplet_status>(Droplet_statusObject); },
        "tags": n => { droplet.tags = n.getCollectionOfPrimitiveValues<string>(); },
        "vcpus": n => { droplet.vcpus = n.getNumberValue(); },
        "volume_ids": n => { droplet.volumeIds = n.getCollectionOfPrimitiveValues<string>(); },
        "vpc_uuid": n => { droplet.vpcUuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDroplet_action(droplet_action: Partial<Droplet_action> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "type": n => { droplet_action.type = n.getEnumValue<Droplet_action_type>(Droplet_action_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDroplet_action_change_backup_policy(droplet_action_change_backup_policy: Partial<Droplet_action_change_backup_policy> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoDroplet_action(droplet_action_change_backup_policy),
        "backup_policy": n => { droplet_action_change_backup_policy.backupPolicy = n.getObjectValue<Droplet_backup_policy>(createDroplet_backup_policyFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDroplet_action_change_kernel(droplet_action_change_kernel: Partial<Droplet_action_change_kernel> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoDroplet_action(droplet_action_change_kernel),
        "kernel": n => { droplet_action_change_kernel.kernel = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDroplet_action_enable_backups(droplet_action_enable_backups: Partial<Droplet_action_enable_backups> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoDroplet_action(droplet_action_enable_backups),
        "backup_policy": n => { droplet_action_enable_backups.backupPolicy = n.getObjectValue<Droplet_backup_policy>(createDroplet_backup_policyFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDroplet_action_rebuild(droplet_action_rebuild: Partial<Droplet_action_rebuild> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoDroplet_action(droplet_action_rebuild),
        "image": n => { droplet_action_rebuild.image = n.getNumberValue() ?? n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDroplet_action_rename(droplet_action_rename: Partial<Droplet_action_rename> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoDroplet_action(droplet_action_rename),
        "name": n => { droplet_action_rename.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDroplet_action_resize(droplet_action_resize: Partial<Droplet_action_resize> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoDroplet_action(droplet_action_resize),
        "disk": n => { droplet_action_resize.disk = n.getBooleanValue(); },
        "size": n => { droplet_action_resize.size = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDroplet_action_restore(droplet_action_restore: Partial<Droplet_action_restore> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoDroplet_action(droplet_action_restore),
        "image": n => { droplet_action_restore.image = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDroplet_action_snapshot(droplet_action_snapshot: Partial<Droplet_action_snapshot> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoDroplet_action(droplet_action_snapshot),
        "name": n => { droplet_action_snapshot.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDroplet_backup_policy(droplet_backup_policy: Partial<Droplet_backup_policy> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "hour": n => { droplet_backup_policy.hour = n.getNumberValue(); },
        "plan": n => { droplet_backup_policy.plan = n.getEnumValue<Droplet_backup_policy_plan>(Droplet_backup_policy_planObject); },
        "retention_period_days": n => { droplet_backup_policy.retentionPeriodDays = n.getNumberValue(); },
        "weekday": n => { droplet_backup_policy.weekday = n.getEnumValue<Droplet_backup_policy_weekday>(Droplet_backup_policy_weekdayObject); },
        "window_length_hours": n => { droplet_backup_policy.windowLengthHours = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDroplet_backup_policy_record(droplet_backup_policy_record: Partial<Droplet_backup_policy_record> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "backup_enabled": n => { droplet_backup_policy_record.backupEnabled = n.getBooleanValue(); },
        "backup_policy": n => { droplet_backup_policy_record.backupPolicy = n.getObjectValue<Droplet_backup_policy>(createDroplet_backup_policyFromDiscriminatorValue); },
        "droplet_id": n => { droplet_backup_policy_record.dropletId = n.getNumberValue(); },
        "next_backup_window": n => { droplet_backup_policy_record.nextBackupWindow = n.getObjectValue<Droplet_next_backup_window>(createDroplet_next_backup_windowFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDroplet_create(droplet_create: Partial<Droplet_create> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "backup_policy": n => { droplet_create.backupPolicy = n.getObjectValue<Droplet_backup_policy>(createDroplet_backup_policyFromDiscriminatorValue); },
        "backups": n => { droplet_create.backups = n.getBooleanValue(); },
        "image": n => { droplet_create.image = n.getNumberValue() ?? n.getStringValue(); },
        "ipv6": n => { droplet_create.ipv6 = n.getBooleanValue(); },
        "monitoring": n => { droplet_create.monitoring = n.getBooleanValue(); },
        "private_networking": n => { droplet_create.privateNetworking = n.getBooleanValue(); },
        "region": n => { droplet_create.region = n.getStringValue(); },
        "size": n => { droplet_create.size = n.getStringValue(); },
        "ssh_keys": n => { droplet_create.sshKeys = n.getCollectionOfPrimitiveValues<string>(); },
        "tags": n => { droplet_create.tags = n.getCollectionOfPrimitiveValues<string>(); },
        "user_data": n => { droplet_create.userData = n.getStringValue(); },
        "volumes": n => { droplet_create.volumes = n.getCollectionOfPrimitiveValues<string>(); },
        "vpc_uuid": n => { droplet_create.vpcUuid = n.getStringValue(); },
        "with_droplet_agent": n => { droplet_create.withDropletAgent = n.getBooleanValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDroplet_multi_create(droplet_multi_create: Partial<Droplet_multi_create> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoDroplet_create(droplet_multi_create),
        "names": n => { droplet_multi_create.names = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDroplet_networks(droplet_networks: Partial<Droplet_networks> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "v4": n => { droplet_networks.v4 = n.getCollectionOfObjectValues<Network_v4>(createNetwork_v4FromDiscriminatorValue); },
        "v6": n => { droplet_networks.v6 = n.getCollectionOfObjectValues<Network_v6>(createNetwork_v6FromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDroplet_next_backup_window(droplet_next_backup_window: Partial<Droplet_next_backup_window> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "end": n => { droplet_next_backup_window.end = n.getDateValue(); },
        "start": n => { droplet_next_backup_window.start = n.getDateValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDroplet_single_create(droplet_single_create: Partial<Droplet_single_create> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoDroplet_create(droplet_single_create),
        "name": n => { droplet_single_create.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoDroplet_snapshot(droplet_snapshot: Partial<Droplet_snapshot> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoSnapshots_base(droplet_snapshot),
        "id": n => { droplet_snapshot.id = n.getNumberValue(); },
        "type": n => { droplet_snapshot.type = n.getEnumValue<Droplet_snapshot_type>(Droplet_snapshot_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoElasticsearch_logsink(elasticsearch_logsink: Partial<Elasticsearch_logsink> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "ca": n => { elasticsearch_logsink.ca = n.getStringValue(); },
        "index_days_max": n => { elasticsearch_logsink.indexDaysMax = n.getNumberValue(); },
        "index_prefix": n => { elasticsearch_logsink.indexPrefix = n.getStringValue(); },
        "timeout": n => { elasticsearch_logsink.timeout = n.getNumberValue(); },
        "url": n => { elasticsearch_logsink.url = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoError_with_root_causes(error_with_root_causes: Partial<Error_with_root_causes> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "error": n => { error_with_root_causes.errorEscaped = n.getStringValue(); },
        "messages": n => { error_with_root_causes.messages = n.getCollectionOfPrimitiveValues<string>(); },
        "root_causes": n => { error_with_root_causes.rootCauses = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoErrorEscaped(errorEscaped: Partial<ErrorEscaped> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "id": n => { errorEscaped.id = n.getStringValue(); },
        "message": n => { errorEscaped.messageEscaped = n.getStringValue(); },
        "request_id": n => { errorEscaped.requestId = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoEvents_logs(events_logs: Partial<Events_logs> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "cluster_name": n => { events_logs.clusterName = n.getStringValue(); },
        "create_time": n => { events_logs.createTime = n.getStringValue(); },
        "event_type": n => { events_logs.eventType = n.getEnumValue<Events_logs_event_type>(Events_logs_event_typeObject); },
        "id": n => { events_logs.id = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoFirewall(firewall: Partial<Firewall> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoFirewall_rules(firewall),
        "created_at": n => { firewall.createdAt = n.getDateValue(); },
        "droplet_ids": n => { firewall.dropletIds = n.getCollectionOfPrimitiveValues<number>(); },
        "id": n => { firewall.id = n.getStringValue(); },
        "name": n => { firewall.name = n.getStringValue(); },
        "pending_changes": n => { firewall.pendingChanges = n.getCollectionOfObjectValues<Firewall_pending_changes>(createFirewall_pending_changesFromDiscriminatorValue); },
        "status": n => { firewall.status = n.getEnumValue<Firewall_status>(Firewall_statusObject); },
        "tags": n => { firewall.tags = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoFirewall_pending_changes(firewall_pending_changes: Partial<Firewall_pending_changes> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "droplet_id": n => { firewall_pending_changes.dropletId = n.getNumberValue(); },
        "removing": n => { firewall_pending_changes.removing = n.getBooleanValue(); },
        "status": n => { firewall_pending_changes.status = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoFirewall_rule(firewall_rule: Partial<Firewall_rule> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "cluster_uuid": n => { firewall_rule.clusterUuid = n.getStringValue(); },
        "created_at": n => { firewall_rule.createdAt = n.getDateValue(); },
        "type": n => { firewall_rule.type = n.getEnumValue<Firewall_rule_type>(Firewall_rule_typeObject); },
        "uuid": n => { firewall_rule.uuid = n.getStringValue(); },
        "value": n => { firewall_rule.value = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoFirewall_rule_base(firewall_rule_base: Partial<Firewall_rule_base> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "ports": n => { firewall_rule_base.ports = n.getStringValue(); },
        "protocol": n => { firewall_rule_base.protocol = n.getEnumValue<Firewall_rule_base_protocol>(Firewall_rule_base_protocolObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoFirewall_rule_target(firewall_rule_target: Partial<Firewall_rule_target> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "addresses": n => { firewall_rule_target.addresses = n.getCollectionOfPrimitiveValues<string>(); },
        "droplet_ids": n => { firewall_rule_target.dropletIds = n.getCollectionOfPrimitiveValues<number>(); },
        "kubernetes_ids": n => { firewall_rule_target.kubernetesIds = n.getCollectionOfPrimitiveValues<string>(); },
        "load_balancer_uids": n => { firewall_rule_target.loadBalancerUids = n.getCollectionOfPrimitiveValues<string>(); },
        "tags": n => { firewall_rule_target.tags = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoFirewall_rules(firewall_rules: Partial<Firewall_rules> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "inbound_rules": n => { firewall_rules.inboundRules = n.getCollectionOfObjectValues<Firewall_rules_inbound_rules>(createFirewall_rules_inbound_rulesFromDiscriminatorValue); },
        "outbound_rules": n => { firewall_rules.outboundRules = n.getCollectionOfObjectValues<Firewall_rules_outbound_rules>(createFirewall_rules_outbound_rulesFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoFirewall_rules_inbound_rules(firewall_rules_inbound_rules: Partial<Firewall_rules_inbound_rules> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoFirewall_rule_base(firewall_rules_inbound_rules),
        "sources": n => { firewall_rules_inbound_rules.sources = n.getObjectValue<Firewall_rule_target>(createFirewall_rule_targetFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoFirewall_rules_outbound_rules(firewall_rules_outbound_rules: Partial<Firewall_rules_outbound_rules> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoFirewall_rule_base(firewall_rules_outbound_rules),
        "destinations": n => { firewall_rules_outbound_rules.destinations = n.getObjectValue<Firewall_rule_target>(createFirewall_rule_targetFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoFloating_ip(floating_ip: Partial<Floating_ip> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "droplet": n => { floating_ip.droplet = n.getObjectValue<Droplet>(createDropletFromDiscriminatorValue); },
        "ip": n => { floating_ip.ip = n.getStringValue(); },
        "locked": n => { floating_ip.locked = n.getBooleanValue(); },
        "project_id": n => { floating_ip.projectId = n.getGuidValue(); },
        "region": n => { floating_ip.region = n.getObjectValue<Region>(createRegionFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoFloating_ip_action_assign(floating_ip_action_assign: Partial<Floating_ip_action_assign> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoFloatingIPsAction(floating_ip_action_assign),
        "droplet_id": n => { floating_ip_action_assign.dropletId = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoFloating_ip_action_unassign(floating_ip_action_unassign: Partial<Floating_ip_action_unassign> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoFloatingIPsAction(floating_ip_action_unassign),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoFloating_ip_createMember1(floating_ip_createMember1: Partial<Floating_ip_createMember1> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "droplet_id": n => { floating_ip_createMember1.dropletId = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoFloating_ip_createMember2(floating_ip_createMember2: Partial<Floating_ip_createMember2> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "project_id": n => { floating_ip_createMember2.projectId = n.getGuidValue(); },
        "region": n => { floating_ip_createMember2.region = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoFloatingIPsAction(floatingIPsAction: Partial<FloatingIPsAction> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "type": n => { floatingIPsAction.type = n.getEnumValue<FloatingIPsAction_type>(FloatingIPsAction_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoForward_links(forward_links: Partial<Forward_links> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "last": n => { forward_links.last = n.getStringValue(); },
        "next": n => { forward_links.next = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoForwarding_rule(forwarding_rule: Partial<Forwarding_rule> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "certificate_id": n => { forwarding_rule.certificateId = n.getStringValue(); },
        "entry_port": n => { forwarding_rule.entryPort = n.getNumberValue(); },
        "entry_protocol": n => { forwarding_rule.entryProtocol = n.getEnumValue<Forwarding_rule_entry_protocol>(Forwarding_rule_entry_protocolObject); },
        "target_port": n => { forwarding_rule.targetPort = n.getNumberValue(); },
        "target_protocol": n => { forwarding_rule.targetProtocol = n.getEnumValue<Forwarding_rule_target_protocol>(Forwarding_rule_target_protocolObject); },
        "tls_passthrough": n => { forwarding_rule.tlsPassthrough = n.getBooleanValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoGarbage_collection(garbage_collection: Partial<Garbage_collection> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "blobs_deleted": n => { garbage_collection.blobsDeleted = n.getNumberValue(); },
        "created_at": n => { garbage_collection.createdAt = n.getDateValue(); },
        "freed_bytes": n => { garbage_collection.freedBytes = n.getNumberValue(); },
        "registry_name": n => { garbage_collection.registryName = n.getStringValue(); },
        "status": n => { garbage_collection.status = n.getEnumValue<Garbage_collection_status>(Garbage_collection_statusObject); },
        "updated_at": n => { garbage_collection.updatedAt = n.getDateValue(); },
        "uuid": n => { garbage_collection.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoGenaiapiRegion(genaiapiRegion: Partial<GenaiapiRegion> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "inference_url": n => { genaiapiRegion.inferenceUrl = n.getStringValue(); },
        "region": n => { genaiapiRegion.region = n.getStringValue(); },
        "serves_batch": n => { genaiapiRegion.servesBatch = n.getBooleanValue(); },
        "serves_inference": n => { genaiapiRegion.servesInference = n.getBooleanValue(); },
        "stream_inference_url": n => { genaiapiRegion.streamInferenceUrl = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoGlb_settings(glb_settings: Partial<Glb_settings> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "cdn": n => { glb_settings.cdn = n.getObjectValue<Glb_settings_cdn>(createGlb_settings_cdnFromDiscriminatorValue); },
        "failover_threshold": n => { glb_settings.failoverThreshold = n.getNumberValue(); },
        "region_priorities": n => { glb_settings.regionPriorities = n.getObjectValue<Glb_settings_region_priorities>(createGlb_settings_region_prioritiesFromDiscriminatorValue); },
        "target_port": n => { glb_settings.targetPort = n.getNumberValue(); },
        "target_protocol": n => { glb_settings.targetProtocol = n.getEnumValue<Glb_settings_target_protocol>(Glb_settings_target_protocolObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoGlb_settings_cdn(glb_settings_cdn: Partial<Glb_settings_cdn> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "is_enabled": n => { glb_settings_cdn.isEnabled = n.getBooleanValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoGlb_settings_region_priorities(glb_settings_region_priorities: Partial<Glb_settings_region_priorities> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoGpu_info(gpu_info: Partial<Gpu_info> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "count": n => { gpu_info.count = n.getNumberValue(); },
        "model": n => { gpu_info.model = n.getStringValue(); },
        "vram": n => { gpu_info.vram = n.getObjectValue<Gpu_info_vram>(createGpu_info_vramFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoGpu_info_vram(gpu_info_vram: Partial<Gpu_info_vram> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "amount": n => { gpu_info_vram.amount = n.getNumberValue(); },
        "unit": n => { gpu_info_vram.unit = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoGrant(grant: Partial<Grant> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "bucket": n => { grant.bucket = n.getStringValue(); },
        "permission": n => { grant.permission = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoHealth_check(health_check: Partial<Health_check> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "check_interval_seconds": n => { health_check.checkIntervalSeconds = n.getNumberValue(); },
        "healthy_threshold": n => { health_check.healthyThreshold = n.getNumberValue(); },
        "path": n => { health_check.path = n.getStringValue() ?? "/"; },
        "port": n => { health_check.port = n.getNumberValue(); },
        "protocol": n => { health_check.protocol = n.getEnumValue<Health_check_protocol>(Health_check_protocolObject) ?? Health_check_protocolObject.Http; },
        "response_timeout_seconds": n => { health_check.responseTimeoutSeconds = n.getNumberValue(); },
        "unhealthy_threshold": n => { health_check.unhealthyThreshold = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoHistory(history: Partial<History> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { history.createdAt = n.getDateValue(); },
        "current_instance_count": n => { history.currentInstanceCount = n.getNumberValue(); },
        "desired_instance_count": n => { history.desiredInstanceCount = n.getNumberValue(); },
        "history_event_id": n => { history.historyEventId = n.getStringValue(); },
        "reason": n => { history.reason = n.getEnumValue<History_reason>(History_reasonObject); },
        "status": n => { history.status = n.getEnumValue<History_status>(History_statusObject); },
        "updated_at": n => { history.updatedAt = n.getDateValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoImage(image: Partial<Image> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { image.createdAt = n.getDateValue(); },
        "description": n => { image.description = n.getStringValue(); },
        "distribution": n => { image.distribution = n.getEnumValue<Distribution>(DistributionObject); },
        "error_message": n => { image.errorMessage = n.getStringValue(); },
        "id": n => { image.id = n.getNumberValue(); },
        "min_disk_size": n => { image.minDiskSize = n.getNumberValue(); },
        "name": n => { image.name = n.getStringValue(); },
        "public": n => { image.public = n.getBooleanValue(); },
        "regions": n => { image.regions = n.getCollectionOfEnumValues<Region_slug>(Region_slugObject); },
        "size_gigabytes": n => { image.sizeGigabytes = n.getNumberValue(); },
        "slug": n => { image.slug = n.getStringValue(); },
        "status": n => { image.status = n.getEnumValue<Image_status>(Image_statusObject); },
        "tags": n => { image.tags = n.getCollectionOfPrimitiveValues<string>(); },
        "type": n => { image.type = n.getEnumValue<Image_type>(Image_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoImage_action_base(image_action_base: Partial<Image_action_base> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "type": n => { image_action_base.type = n.getEnumValue<Image_action_base_type>(Image_action_base_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoImage_action_transfer(image_action_transfer: Partial<Image_action_transfer> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoImage_action_base(image_action_transfer),
        "region": n => { image_action_transfer.region = n.getEnumValue<Region_slug>(Region_slugObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoImage_new_custom(image_new_custom: Partial<Image_new_custom> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoImage_update(image_new_custom),
        "region": n => { image_new_custom.region = n.getEnumValue<Region_slug>(Region_slugObject); },
        "tags": n => { image_new_custom.tags = n.getCollectionOfPrimitiveValues<string>(); },
        "url": n => { image_new_custom.url = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoImage_update(image_update: Partial<Image_update> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "description": n => { image_update.description = n.getStringValue(); },
        "distribution": n => { image_update.distribution = n.getEnumValue<Distribution>(DistributionObject); },
        "name": n => { image_update.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoInvoice_item(invoice_item: Partial<Invoice_item> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "amount": n => { invoice_item.amount = n.getStringValue(); },
        "description": n => { invoice_item.description = n.getStringValue(); },
        "duration": n => { invoice_item.duration = n.getStringValue(); },
        "duration_unit": n => { invoice_item.durationUnit = n.getStringValue(); },
        "end_time": n => { invoice_item.endTime = n.getStringValue(); },
        "group_description": n => { invoice_item.groupDescription = n.getStringValue(); },
        "product": n => { invoice_item.product = n.getStringValue(); },
        "project_name": n => { invoice_item.projectName = n.getStringValue(); },
        "resource_id": n => { invoice_item.resourceId = n.getStringValue(); },
        "resource_uuid": n => { invoice_item.resourceUuid = n.getStringValue(); },
        "start_time": n => { invoice_item.startTime = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoInvoice_preview(invoice_preview: Partial<Invoice_preview> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "amount": n => { invoice_preview.amount = n.getStringValue(); },
        "invoice_id": n => { invoice_preview.invoiceId = n.getStringValue(); },
        "invoice_period": n => { invoice_preview.invoicePeriod = n.getStringValue(); },
        "invoice_uuid": n => { invoice_preview.invoiceUuid = n.getStringValue(); },
        "updated_at": n => { invoice_preview.updatedAt = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoInvoice_summary(invoice_summary: Partial<Invoice_summary> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "amount": n => { invoice_summary.amount = n.getStringValue(); },
        "billing_period": n => { invoice_summary.billingPeriod = n.getStringValue(); },
        "credits_and_adjustments": n => { invoice_summary.creditsAndAdjustments = n.getObjectValue<Simple_charge>(createSimple_chargeFromDiscriminatorValue); },
        "invoice_id": n => { invoice_summary.invoiceId = n.getStringValue(); },
        "invoice_uuid": n => { invoice_summary.invoiceUuid = n.getStringValue(); },
        "overages": n => { invoice_summary.overages = n.getObjectValue<Simple_charge>(createSimple_chargeFromDiscriminatorValue); },
        "product_charges": n => { invoice_summary.productCharges = n.getObjectValue<Product_usage_charges>(createProduct_usage_chargesFromDiscriminatorValue); },
        "taxes": n => { invoice_summary.taxes = n.getObjectValue<Simple_charge>(createSimple_chargeFromDiscriminatorValue); },
        "user_billing_address": n => { invoice_summary.userBillingAddress = n.getObjectValue<Billing_address>(createBilling_addressFromDiscriminatorValue); },
        "user_company": n => { invoice_summary.userCompany = n.getStringValue(); },
        "user_email": n => { invoice_summary.userEmail = n.getStringValue(); },
        "user_name": n => { invoice_summary.userName = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKafka_advanced_config(kafka_advanced_config: Partial<Kafka_advanced_config> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "auto_create_topics_enable": n => { kafka_advanced_config.autoCreateTopicsEnable = n.getBooleanValue(); },
        "compression_type": n => { kafka_advanced_config.compressionType = n.getEnumValue<Kafka_advanced_config_compression_type>(Kafka_advanced_config_compression_typeObject); },
        "connections_max_idle_ms": n => { kafka_advanced_config.connectionsMaxIdleMs = n.getNumberValue(); },
        "default_replication_factor": n => { kafka_advanced_config.defaultReplicationFactor = n.getNumberValue(); },
        "group_initial_rebalance_delay_ms": n => { kafka_advanced_config.groupInitialRebalanceDelayMs = n.getNumberValue(); },
        "group_max_session_timeout_ms": n => { kafka_advanced_config.groupMaxSessionTimeoutMs = n.getNumberValue(); },
        "group_min_session_timeout_ms": n => { kafka_advanced_config.groupMinSessionTimeoutMs = n.getNumberValue(); },
        "log_cleaner_delete_retention_ms": n => { kafka_advanced_config.logCleanerDeleteRetentionMs = n.getNumberValue(); },
        "log_cleaner_max_compaction_lag_ms": n => { kafka_advanced_config.logCleanerMaxCompactionLagMs = n.getNumberValue(); },
        "log_cleaner_min_cleanable_ratio": n => { kafka_advanced_config.logCleanerMinCleanableRatio = n.getNumberValue(); },
        "log_cleaner_min_compaction_lag_ms": n => { kafka_advanced_config.logCleanerMinCompactionLagMs = n.getNumberValue(); },
        "log_cleanup_policy": n => { kafka_advanced_config.logCleanupPolicy = n.getEnumValue<Kafka_advanced_config_log_cleanup_policy>(Kafka_advanced_config_log_cleanup_policyObject); },
        "log_flush_interval_messages": n => { kafka_advanced_config.logFlushIntervalMessages = n.getNumberValue(); },
        "log_flush_interval_ms": n => { kafka_advanced_config.logFlushIntervalMs = n.getNumberValue(); },
        "log_index_interval_bytes": n => { kafka_advanced_config.logIndexIntervalBytes = n.getNumberValue(); },
        "log_index_size_max_bytes": n => { kafka_advanced_config.logIndexSizeMaxBytes = n.getNumberValue(); },
        "log_message_downconversion_enable": n => { kafka_advanced_config.logMessageDownconversionEnable = n.getBooleanValue(); },
        "log_message_timestamp_difference_max_ms": n => { kafka_advanced_config.logMessageTimestampDifferenceMaxMs = n.getNumberValue(); },
        "log_message_timestamp_type": n => { kafka_advanced_config.logMessageTimestampType = n.getEnumValue<Kafka_advanced_config_log_message_timestamp_type>(Kafka_advanced_config_log_message_timestamp_typeObject); },
        "log_preallocate": n => { kafka_advanced_config.logPreallocate = n.getBooleanValue(); },
        "log_retention_bytes": n => { kafka_advanced_config.logRetentionBytes = n.getNumberValue(); },
        "log_retention_hours": n => { kafka_advanced_config.logRetentionHours = n.getNumberValue(); },
        "log_retention_ms": n => { kafka_advanced_config.logRetentionMs = n.getNumberValue(); },
        "log_roll_jitter_ms": n => { kafka_advanced_config.logRollJitterMs = n.getNumberValue(); },
        "log_roll_ms": n => { kafka_advanced_config.logRollMs = n.getNumberValue(); },
        "log_segment_bytes": n => { kafka_advanced_config.logSegmentBytes = n.getNumberValue(); },
        "log_segment_delete_delay_ms": n => { kafka_advanced_config.logSegmentDeleteDelayMs = n.getNumberValue(); },
        "max_connections_per_ip": n => { kafka_advanced_config.maxConnectionsPerIp = n.getNumberValue(); },
        "max_incremental_fetch_session_cache_slots": n => { kafka_advanced_config.maxIncrementalFetchSessionCacheSlots = n.getNumberValue(); },
        "message_max_bytes": n => { kafka_advanced_config.messageMaxBytes = n.getNumberValue(); },
        "min_insync_replicas": n => { kafka_advanced_config.minInsyncReplicas = n.getNumberValue(); },
        "num_partitions": n => { kafka_advanced_config.numPartitions = n.getNumberValue(); },
        "offsets_retention_minutes": n => { kafka_advanced_config.offsetsRetentionMinutes = n.getNumberValue(); },
        "producer_purgatory_purge_interval_requests": n => { kafka_advanced_config.producerPurgatoryPurgeIntervalRequests = n.getNumberValue(); },
        "replica_fetch_max_bytes": n => { kafka_advanced_config.replicaFetchMaxBytes = n.getNumberValue(); },
        "replica_fetch_response_max_bytes": n => { kafka_advanced_config.replicaFetchResponseMaxBytes = n.getNumberValue(); },
        "socket_request_max_bytes": n => { kafka_advanced_config.socketRequestMaxBytes = n.getNumberValue(); },
        "transaction_remove_expired_transaction_cleanup_interval_ms": n => { kafka_advanced_config.transactionRemoveExpiredTransactionCleanupIntervalMs = n.getNumberValue(); },
        "transaction_state_log_segment_bytes": n => { kafka_advanced_config.transactionStateLogSegmentBytes = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKafka_topic(kafka_topic: Partial<Kafka_topic> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoKafka_topic_base(kafka_topic),
        "state": n => { kafka_topic.state = n.getEnumValue<Kafka_topic_state>(Kafka_topic_stateObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKafka_topic_base(kafka_topic_base: Partial<Kafka_topic_base> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "name": n => { kafka_topic_base.name = n.getStringValue(); },
        "partition_count": n => { kafka_topic_base.partitionCount = n.getNumberValue(); },
        "replication_factor": n => { kafka_topic_base.replicationFactor = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKafka_topic_config(kafka_topic_config: Partial<Kafka_topic_config> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "cleanup_policy": n => { kafka_topic_config.cleanupPolicy = n.getEnumValue<Kafka_topic_config_cleanup_policy>(Kafka_topic_config_cleanup_policyObject) ?? Kafka_topic_config_cleanup_policyObject.Delete; },
        "compression_type": n => { kafka_topic_config.compressionType = n.getEnumValue<Kafka_topic_config_compression_type>(Kafka_topic_config_compression_typeObject) ?? Kafka_topic_config_compression_typeObject.Producer; },
        "delete_retention_ms": n => { kafka_topic_config.deleteRetentionMs = n.getNumberValue(); },
        "file_delete_delay_ms": n => { kafka_topic_config.fileDeleteDelayMs = n.getNumberValue(); },
        "flush_messages": n => { kafka_topic_config.flushMessages = n.getNumberValue(); },
        "flush_ms": n => { kafka_topic_config.flushMs = n.getNumberValue(); },
        "index_interval_bytes": n => { kafka_topic_config.indexIntervalBytes = n.getNumberValue(); },
        "max_compaction_lag_ms": n => { kafka_topic_config.maxCompactionLagMs = n.getNumberValue(); },
        "max_message_bytes": n => { kafka_topic_config.maxMessageBytes = n.getNumberValue(); },
        "message_down_conversion_enable": n => { kafka_topic_config.messageDownConversionEnable = n.getBooleanValue(); },
        "message_format_version": n => { kafka_topic_config.messageFormatVersion = n.getEnumValue<Kafka_topic_config_message_format_version>(Kafka_topic_config_message_format_versionObject) ?? Kafka_topic_config_message_format_versionObject.ThreeZeroIV1; },
        "message_timestamp_type": n => { kafka_topic_config.messageTimestampType = n.getEnumValue<Kafka_topic_config_message_timestamp_type>(Kafka_topic_config_message_timestamp_typeObject) ?? Kafka_topic_config_message_timestamp_typeObject.Create_time; },
        "min_cleanable_dirty_ratio": n => { kafka_topic_config.minCleanableDirtyRatio = n.getNumberValue(); },
        "min_compaction_lag_ms": n => { kafka_topic_config.minCompactionLagMs = n.getNumberValue(); },
        "min_insync_replicas": n => { kafka_topic_config.minInsyncReplicas = n.getNumberValue(); },
        "preallocate": n => { kafka_topic_config.preallocate = n.getBooleanValue(); },
        "retention_bytes": n => { kafka_topic_config.retentionBytes = n.getNumberValue(); },
        "retention_ms": n => { kafka_topic_config.retentionMs = n.getNumberValue(); },
        "segment_bytes": n => { kafka_topic_config.segmentBytes = n.getNumberValue(); },
        "segment_jitter_ms": n => { kafka_topic_config.segmentJitterMs = n.getNumberValue(); },
        "segment_ms": n => { kafka_topic_config.segmentMs = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKafka_topic_create(kafka_topic_create: Partial<Kafka_topic_create> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoKafka_topic_base(kafka_topic_create),
        "config": n => { kafka_topic_create.config = n.getObjectValue<Kafka_topic_config>(createKafka_topic_configFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKafka_topic_partition(kafka_topic_partition: Partial<Kafka_topic_partition> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "consumer_groups": n => { kafka_topic_partition.consumerGroups = n.getCollectionOfObjectValues<Kafka_topic_partition_consumer_groups>(createKafka_topic_partition_consumer_groupsFromDiscriminatorValue); },
        "earliest_offset": n => { kafka_topic_partition.earliestOffset = n.getNumberValue(); },
        "id": n => { kafka_topic_partition.id = n.getNumberValue(); },
        "in_sync_replicas": n => { kafka_topic_partition.inSyncReplicas = n.getNumberValue(); },
        "size": n => { kafka_topic_partition.size = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKafka_topic_partition_consumer_groups(kafka_topic_partition_consumer_groups: Partial<Kafka_topic_partition_consumer_groups> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "group_name": n => { kafka_topic_partition_consumer_groups.groupName = n.getStringValue(); },
        "offset": n => { kafka_topic_partition_consumer_groups.offset = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKafka_topic_update(kafka_topic_update: Partial<Kafka_topic_update> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "config": n => { kafka_topic_update.config = n.getObjectValue<Kafka_topic_config>(createKafka_topic_configFromDiscriminatorValue); },
        "partition_count": n => { kafka_topic_update.partitionCount = n.getNumberValue(); },
        "replication_factor": n => { kafka_topic_update.replicationFactor = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKafka_topic_verbose(kafka_topic_verbose: Partial<Kafka_topic_verbose> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "config": n => { kafka_topic_verbose.config = n.getObjectValue<Kafka_topic_config>(createKafka_topic_configFromDiscriminatorValue); },
        "name": n => { kafka_topic_verbose.name = n.getStringValue(); },
        "partitions": n => { kafka_topic_verbose.partitions = n.getCollectionOfObjectValues<Kafka_topic_partition>(createKafka_topic_partitionFromDiscriminatorValue); },
        "replication_factor": n => { kafka_topic_verbose.replicationFactor = n.getNumberValue(); },
        "state": n => { kafka_topic_verbose.state = n.getEnumValue<Kafka_topic_verbose_state>(Kafka_topic_verbose_stateObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKernel(kernel: Partial<Kernel> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "id": n => { kernel.id = n.getNumberValue(); },
        "name": n => { kernel.name = n.getStringValue(); },
        "version": n => { kernel.version = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKey(key: Partial<Key> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "access_key": n => { key.accessKey = n.getStringValue(); },
        "created_at": n => { key.createdAt = n.getDateValue(); },
        "grants": n => { key.grants = n.getCollectionOfObjectValues<Grant>(createGrantFromDiscriminatorValue); },
        "name": n => { key.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKey_create_response(key_create_response: Partial<Key_create_response> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoKey(key_create_response),
        "secret_key": n => { key_create_response.secretKey = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKubernetes_node_pool(kubernetes_node_pool: Partial<Kubernetes_node_pool> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "auto_scale": n => { kubernetes_node_pool.autoScale = n.getBooleanValue(); },
        "count": n => { kubernetes_node_pool.count = n.getNumberValue(); },
        "id": n => { kubernetes_node_pool.id = n.getGuidValue(); },
        "labels": n => { kubernetes_node_pool.labels = n.getObjectValue<Kubernetes_node_pool_labels>(createKubernetes_node_pool_labelsFromDiscriminatorValue); },
        "max_nodes": n => { kubernetes_node_pool.maxNodes = n.getNumberValue(); },
        "min_nodes": n => { kubernetes_node_pool.minNodes = n.getNumberValue(); },
        "name": n => { kubernetes_node_pool.name = n.getStringValue(); },
        "nodes": n => { kubernetes_node_pool.nodes = n.getCollectionOfObjectValues<Node>(createNodeFromDiscriminatorValue); },
        "size": n => { kubernetes_node_pool.size = n.getStringValue(); },
        "tags": n => { kubernetes_node_pool.tags = n.getCollectionOfPrimitiveValues<string>(); },
        "taints": n => { kubernetes_node_pool.taints = n.getCollectionOfObjectValues<Kubernetes_node_pool_taint>(createKubernetes_node_pool_taintFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKubernetes_node_pool_labels(kubernetes_node_pool_labels: Partial<Kubernetes_node_pool_labels> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKubernetes_node_pool_taint(kubernetes_node_pool_taint: Partial<Kubernetes_node_pool_taint> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "effect": n => { kubernetes_node_pool_taint.effect = n.getEnumValue<Kubernetes_node_pool_taint_effect>(Kubernetes_node_pool_taint_effectObject); },
        "key": n => { kubernetes_node_pool_taint.key = n.getStringValue(); },
        "value": n => { kubernetes_node_pool_taint.value = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKubernetes_node_pool_update(kubernetes_node_pool_update: Partial<Kubernetes_node_pool_update> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "auto_scale": n => { kubernetes_node_pool_update.autoScale = n.getBooleanValue(); },
        "count": n => { kubernetes_node_pool_update.count = n.getNumberValue(); },
        "id": n => { kubernetes_node_pool_update.id = n.getGuidValue(); },
        "labels": n => { kubernetes_node_pool_update.labels = n.getObjectValue<Kubernetes_node_pool_update_labels>(createKubernetes_node_pool_update_labelsFromDiscriminatorValue); },
        "max_nodes": n => { kubernetes_node_pool_update.maxNodes = n.getNumberValue(); },
        "min_nodes": n => { kubernetes_node_pool_update.minNodes = n.getNumberValue(); },
        "name": n => { kubernetes_node_pool_update.name = n.getStringValue(); },
        "nodes": n => { kubernetes_node_pool_update.nodes = n.getCollectionOfObjectValues<Node>(createNodeFromDiscriminatorValue); },
        "tags": n => { kubernetes_node_pool_update.tags = n.getCollectionOfPrimitiveValues<string>(); },
        "taints": n => { kubernetes_node_pool_update.taints = n.getCollectionOfObjectValues<Kubernetes_node_pool_taint>(createKubernetes_node_pool_taintFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKubernetes_node_pool_update_labels(kubernetes_node_pool_update_labels: Partial<Kubernetes_node_pool_update_labels> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKubernetes_options(kubernetes_options: Partial<Kubernetes_options> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "options": n => { kubernetes_options.options = n.getObjectValue<Kubernetes_options_options>(createKubernetes_options_optionsFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKubernetes_options_options(kubernetes_options_options: Partial<Kubernetes_options_options> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "regions": n => { kubernetes_options_options.regions = n.getCollectionOfObjectValues<Kubernetes_region>(createKubernetes_regionFromDiscriminatorValue); },
        "sizes": n => { kubernetes_options_options.sizes = n.getCollectionOfObjectValues<Kubernetes_size>(createKubernetes_sizeFromDiscriminatorValue); },
        "versions": n => { kubernetes_options_options.versions = n.getCollectionOfObjectValues<Kubernetes_version>(createKubernetes_versionFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKubernetes_region(kubernetes_region: Partial<Kubernetes_region> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "name": n => { kubernetes_region.name = n.getStringValue(); },
        "slug": n => { kubernetes_region.slug = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKubernetes_size(kubernetes_size: Partial<Kubernetes_size> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "name": n => { kubernetes_size.name = n.getStringValue(); },
        "slug": n => { kubernetes_size.slug = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoKubernetes_version(kubernetes_version: Partial<Kubernetes_version> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "kubernetes_version": n => { kubernetes_version.kubernetesVersion = n.getStringValue(); },
        "slug": n => { kubernetes_version.slug = n.getStringValue(); },
        "supported_features": n => { kubernetes_version.supportedFeatures = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoLb_firewall(lb_firewall: Partial<Lb_firewall> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "allow": n => { lb_firewall.allow = n.getCollectionOfPrimitiveValues<string>(); },
        "deny": n => { lb_firewall.deny = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoLoad_balancer(load_balancer: Partial<Load_balancer> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoLoad_balancer_base(load_balancer),
        "droplet_ids": n => { load_balancer.dropletIds = n.getCollectionOfPrimitiveValues<number>(); },
        "region": n => { load_balancer.region = n.getObjectValue<Load_balancer_region>(createLoad_balancer_regionFromDiscriminatorValue); },
        "tag": n => { load_balancer.tag = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoLoad_balancer_base(load_balancer_base: Partial<Load_balancer_base> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "algorithm": n => { load_balancer_base.algorithm = n.getEnumValue<Load_balancer_base_algorithm>(Load_balancer_base_algorithmObject) ?? Load_balancer_base_algorithmObject.Round_robin; },
        "created_at": n => { load_balancer_base.createdAt = n.getDateValue(); },
        "disable_lets_encrypt_dns_records": n => { load_balancer_base.disableLetsEncryptDnsRecords = n.getBooleanValue(); },
        "domains": n => { load_balancer_base.domains = n.getCollectionOfObjectValues<Domains>(createDomainsFromDiscriminatorValue); },
        "enable_backend_keepalive": n => { load_balancer_base.enableBackendKeepalive = n.getBooleanValue(); },
        "enable_proxy_protocol": n => { load_balancer_base.enableProxyProtocol = n.getBooleanValue(); },
        "firewall": n => { load_balancer_base.firewall = n.getObjectValue<Lb_firewall>(createLb_firewallFromDiscriminatorValue); },
        "forwarding_rules": n => { load_balancer_base.forwardingRules = n.getCollectionOfObjectValues<Forwarding_rule>(createForwarding_ruleFromDiscriminatorValue); },
        "glb_settings": n => { load_balancer_base.glbSettings = n.getObjectValue<Glb_settings>(createGlb_settingsFromDiscriminatorValue); },
        "health_check": n => { load_balancer_base.healthCheck = n.getObjectValue<Health_check>(createHealth_checkFromDiscriminatorValue); },
        "http_idle_timeout_seconds": n => { load_balancer_base.httpIdleTimeoutSeconds = n.getNumberValue(); },
        "id": n => { load_balancer_base.id = n.getGuidValue(); },
        "ip": n => { load_balancer_base.ip = n.getStringValue(); },
        "ipv6": n => { load_balancer_base.ipv6 = n.getStringValue(); },
        "name": n => { load_balancer_base.name = n.getStringValue(); },
        "network": n => { load_balancer_base.network = n.getEnumValue<Load_balancer_base_network>(Load_balancer_base_networkObject) ?? Load_balancer_base_networkObject.EXTERNAL; },
        "network_stack": n => { load_balancer_base.networkStack = n.getEnumValue<Load_balancer_base_network_stack>(Load_balancer_base_network_stackObject) ?? Load_balancer_base_network_stackObject.IPV4; },
        "project_id": n => { load_balancer_base.projectId = n.getStringValue(); },
        "redirect_http_to_https": n => { load_balancer_base.redirectHttpToHttps = n.getBooleanValue(); },
        "size": n => { load_balancer_base.size = n.getEnumValue<Load_balancer_base_size>(Load_balancer_base_sizeObject) ?? Load_balancer_base_sizeObject.LbSmall; },
        "size_unit": n => { load_balancer_base.sizeUnit = n.getNumberValue(); },
        "status": n => { load_balancer_base.status = n.getEnumValue<Load_balancer_base_status>(Load_balancer_base_statusObject); },
        "sticky_sessions": n => { load_balancer_base.stickySessions = n.getObjectValue<Sticky_sessions>(createSticky_sessionsFromDiscriminatorValue); },
        "target_load_balancer_ids": n => { load_balancer_base.targetLoadBalancerIds = n.getCollectionOfPrimitiveValues<string>(); },
        "type": n => { load_balancer_base.type = n.getEnumValue<Load_balancer_base_type>(Load_balancer_base_typeObject) ?? Load_balancer_base_typeObject.REGIONAL; },
        "vpc_uuid": n => { load_balancer_base.vpcUuid = n.getGuidValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoLoad_balancer_region(load_balancer_region: Partial<Load_balancer_region> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoRegion(load_balancer_region),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoLogsink_base(logsink_base: Partial<Logsink_base> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "sink_name": n => { logsink_base.sinkName = n.getStringValue(); },
        "sink_type": n => { logsink_base.sinkType = n.getEnumValue<Logsink_base_sink_type>(Logsink_base_sink_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoLogsink_base_verbose(logsink_base_verbose: Partial<Logsink_base_verbose> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "sink_id": n => { logsink_base_verbose.sinkId = n.getStringValue(); },
        "sink_name": n => { logsink_base_verbose.sinkName = n.getStringValue(); },
        "sink_type": n => { logsink_base_verbose.sinkType = n.getEnumValue<Logsink_base_verbose_sink_type>(Logsink_base_verbose_sink_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoLogsink_create(logsink_create: Partial<Logsink_create> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoLogsink_base(logsink_create),
        "config": n => { logsink_create.config = n.getObjectValue<Elasticsearch_logsink>(createElasticsearch_logsinkFromDiscriminatorValue) ?? n.getObjectValue<Opensearch_logsink>(createOpensearch_logsinkFromDiscriminatorValue) ?? n.getObjectValue<Rsyslog_logsink>(createRsyslog_logsinkFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoLogsink_create_config(logsink_create_config: Partial<Elasticsearch_logsink | Opensearch_logsink | Rsyslog_logsink> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoElasticsearch_logsink(logsink_create_config as Elasticsearch_logsink),
        ...deserializeIntoOpensearch_logsink(logsink_create_config as Opensearch_logsink),
        ...deserializeIntoRsyslog_logsink(logsink_create_config as Rsyslog_logsink),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoLogsink_update(logsink_update: Partial<Logsink_update> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "config": n => { logsink_update.config = n.getObjectValue<Elasticsearch_logsink>(createElasticsearch_logsinkFromDiscriminatorValue) ?? n.getObjectValue<Opensearch_logsink>(createOpensearch_logsinkFromDiscriminatorValue) ?? n.getObjectValue<Rsyslog_logsink>(createRsyslog_logsinkFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoLogsink_update_config(logsink_update_config: Partial<Elasticsearch_logsink | Opensearch_logsink | Rsyslog_logsink> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoElasticsearch_logsink(logsink_update_config as Elasticsearch_logsink),
        ...deserializeIntoOpensearch_logsink(logsink_update_config as Opensearch_logsink),
        ...deserializeIntoRsyslog_logsink(logsink_update_config as Rsyslog_logsink),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoLogsink_verbose(logsink_verbose: Partial<Logsink_verbose> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoLogsink_base_verbose(logsink_verbose),
        "config": n => { logsink_verbose.config = n.getObjectValue<Elasticsearch_logsink>(createElasticsearch_logsinkFromDiscriminatorValue) ?? n.getObjectValue<Opensearch_logsink>(createOpensearch_logsinkFromDiscriminatorValue) ?? n.getObjectValue<Rsyslog_logsink>(createRsyslog_logsinkFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoLogsink_verbose_config(logsink_verbose_config: Partial<Elasticsearch_logsink | Opensearch_logsink | Rsyslog_logsink> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoElasticsearch_logsink(logsink_verbose_config as Elasticsearch_logsink),
        ...deserializeIntoOpensearch_logsink(logsink_verbose_config as Opensearch_logsink),
        ...deserializeIntoRsyslog_logsink(logsink_verbose_config as Rsyslog_logsink),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoMaintenance_policy(maintenance_policy: Partial<Maintenance_policy> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "day": n => { maintenance_policy.day = n.getEnumValue<Maintenance_policy_day>(Maintenance_policy_dayObject); },
        "duration": n => { maintenance_policy.duration = n.getStringValue(); },
        "start_time": n => { maintenance_policy.startTime = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoMember(member: Partial<Member> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { member.createdAt = n.getDateValue(); },
        "current_utilization": n => { member.currentUtilization = n.getObjectValue<Member_current_utilization>(createMember_current_utilizationFromDiscriminatorValue); },
        "droplet_id": n => { member.dropletId = n.getNumberValue(); },
        "health_status": n => { member.healthStatus = n.getStringValue(); },
        "status": n => { member.status = n.getEnumValue<Member_status>(Member_statusObject); },
        "updated_at": n => { member.updatedAt = n.getDateValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoMember_current_utilization(member_current_utilization: Partial<Member_current_utilization> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "cpu": n => { member_current_utilization.cpu = n.getNumberValue(); },
        "memory": n => { member_current_utilization.memory = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoMeta_properties(meta_properties: Partial<Meta_properties> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "total": n => { meta_properties.total = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoMetrics(metrics: Partial<Metrics> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "data": n => { metrics.data = n.getObjectValue<Metrics_data>(createMetrics_dataFromDiscriminatorValue); },
        "status": n => { metrics.status = n.getEnumValue<Metrics_status>(Metrics_statusObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoMetrics_data(metrics_data: Partial<Metrics_data> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "result": n => { metrics_data.result = n.getCollectionOfObjectValues<Metrics_result>(createMetrics_resultFromDiscriminatorValue); },
        "resultType": n => { metrics_data.resultType = n.getEnumValue<Metrics_data_resultType>(Metrics_data_resultTypeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoMetrics_result(metrics_result: Partial<Metrics_result> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "metric": n => { metrics_result.metric = n.getObjectValue<Metrics_result_metric>(createMetrics_result_metricFromDiscriminatorValue); },
        "values": n => { metrics_result.values = n.getObjectValue<UntypedNode>(createUntypedNodeFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoMetrics_result_metric(metrics_result_metric: Partial<Metrics_result_metric> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoMongo_advanced_config(mongo_advanced_config: Partial<Mongo_advanced_config> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "default_read_concern": n => { mongo_advanced_config.defaultReadConcern = n.getEnumValue<Mongo_advanced_config_default_read_concern>(Mongo_advanced_config_default_read_concernObject) ?? Mongo_advanced_config_default_read_concernObject.Local; },
        "default_write_concern": n => { mongo_advanced_config.defaultWriteConcern = n.getStringValue() ?? "majority"; },
        "slow_op_threshold_ms": n => { mongo_advanced_config.slowOpThresholdMs = n.getNumberValue(); },
        "transaction_lifetime_limit_seconds": n => { mongo_advanced_config.transactionLifetimeLimitSeconds = n.getNumberValue(); },
        "verbosity": n => { mongo_advanced_config.verbosity = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoMysql_advanced_config(mysql_advanced_config: Partial<Mysql_advanced_config> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "backup_hour": n => { mysql_advanced_config.backupHour = n.getNumberValue(); },
        "backup_minute": n => { mysql_advanced_config.backupMinute = n.getNumberValue(); },
        "binlog_retention_period": n => { mysql_advanced_config.binlogRetentionPeriod = n.getNumberValue(); },
        "connect_timeout": n => { mysql_advanced_config.connectTimeout = n.getNumberValue(); },
        "default_time_zone": n => { mysql_advanced_config.defaultTimeZone = n.getStringValue(); },
        "group_concat_max_len": n => { mysql_advanced_config.groupConcatMaxLen = n.getNumberValue(); },
        "information_schema_stats_expiry": n => { mysql_advanced_config.informationSchemaStatsExpiry = n.getNumberValue(); },
        "innodb_change_buffer_max_size": n => { mysql_advanced_config.innodbChangeBufferMaxSize = n.getNumberValue(); },
        "innodb_flush_neighbors": n => { mysql_advanced_config.innodbFlushNeighbors = n.getNumberValue(); },
        "innodb_ft_min_token_size": n => { mysql_advanced_config.innodbFtMinTokenSize = n.getNumberValue(); },
        "innodb_ft_server_stopword_table": n => { mysql_advanced_config.innodbFtServerStopwordTable = n.getStringValue(); },
        "innodb_lock_wait_timeout": n => { mysql_advanced_config.innodbLockWaitTimeout = n.getNumberValue(); },
        "innodb_log_buffer_size": n => { mysql_advanced_config.innodbLogBufferSize = n.getNumberValue(); },
        "innodb_online_alter_log_max_size": n => { mysql_advanced_config.innodbOnlineAlterLogMaxSize = n.getNumberValue(); },
        "innodb_print_all_deadlocks": n => { mysql_advanced_config.innodbPrintAllDeadlocks = n.getBooleanValue(); },
        "innodb_read_io_threads": n => { mysql_advanced_config.innodbReadIoThreads = n.getNumberValue(); },
        "innodb_rollback_on_timeout": n => { mysql_advanced_config.innodbRollbackOnTimeout = n.getBooleanValue(); },
        "innodb_thread_concurrency": n => { mysql_advanced_config.innodbThreadConcurrency = n.getNumberValue(); },
        "innodb_write_io_threads": n => { mysql_advanced_config.innodbWriteIoThreads = n.getNumberValue(); },
        "interactive_timeout": n => { mysql_advanced_config.interactiveTimeout = n.getNumberValue(); },
        "internal_tmp_mem_storage_engine": n => { mysql_advanced_config.internalTmpMemStorageEngine = n.getEnumValue<Mysql_advanced_config_internal_tmp_mem_storage_engine>(Mysql_advanced_config_internal_tmp_mem_storage_engineObject); },
        "log_output": n => { mysql_advanced_config.logOutput = n.getEnumValue<Mysql_advanced_config_log_output>(Mysql_advanced_config_log_outputObject) ?? Mysql_advanced_config_log_outputObject.NONE; },
        "long_query_time": n => { mysql_advanced_config.longQueryTime = n.getNumberValue(); },
        "max_allowed_packet": n => { mysql_advanced_config.maxAllowedPacket = n.getNumberValue(); },
        "max_heap_table_size": n => { mysql_advanced_config.maxHeapTableSize = n.getNumberValue(); },
        "net_buffer_length": n => { mysql_advanced_config.netBufferLength = n.getNumberValue(); },
        "net_read_timeout": n => { mysql_advanced_config.netReadTimeout = n.getNumberValue(); },
        "net_write_timeout": n => { mysql_advanced_config.netWriteTimeout = n.getNumberValue(); },
        "slow_query_log": n => { mysql_advanced_config.slowQueryLog = n.getBooleanValue(); },
        "sort_buffer_size": n => { mysql_advanced_config.sortBufferSize = n.getNumberValue(); },
        "sql_mode": n => { mysql_advanced_config.sqlMode = n.getStringValue(); },
        "sql_require_primary_key": n => { mysql_advanced_config.sqlRequirePrimaryKey = n.getBooleanValue(); },
        "tmp_table_size": n => { mysql_advanced_config.tmpTableSize = n.getNumberValue(); },
        "wait_timeout": n => { mysql_advanced_config.waitTimeout = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoMysql_settings(mysql_settings: Partial<Mysql_settings> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "auth_plugin": n => { mysql_settings.authPlugin = n.getEnumValue<Mysql_settings_auth_plugin>(Mysql_settings_auth_pluginObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoNamespace_info(namespace_info: Partial<Namespace_info> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "api_host": n => { namespace_info.apiHost = n.getStringValue(); },
        "created_at": n => { namespace_info.createdAt = n.getStringValue(); },
        "key": n => { namespace_info.key = n.getStringValue(); },
        "label": n => { namespace_info.label = n.getStringValue(); },
        "namespace": n => { namespace_info.namespace = n.getStringValue(); },
        "region": n => { namespace_info.region = n.getStringValue(); },
        "updated_at": n => { namespace_info.updatedAt = n.getStringValue(); },
        "uuid": n => { namespace_info.uuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoNeighbor_ids(neighbor_ids: Partial<Neighbor_ids> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "neighbor_ids": n => { neighbor_ids.neighborIds = n.getObjectValue<UntypedNode>(createUntypedNodeFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoNetwork_v4(network_v4: Partial<Network_v4> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "gateway": n => { network_v4.gateway = n.getStringValue(); },
        "ip_address": n => { network_v4.ipAddress = n.getStringValue(); },
        "netmask": n => { network_v4.netmask = n.getStringValue(); },
        "type": n => { network_v4.type = n.getEnumValue<Network_v4_type>(Network_v4_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoNetwork_v6(network_v6: Partial<Network_v6> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "gateway": n => { network_v6.gateway = n.getStringValue(); },
        "ip_address": n => { network_v6.ipAddress = n.getStringValue(); },
        "netmask": n => { network_v6.netmask = n.getNumberValue(); },
        "type": n => { network_v6.type = n.getEnumValue<Network_v6_type>(Network_v6_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoNode(node: Partial<Node> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { node.createdAt = n.getDateValue(); },
        "droplet_id": n => { node.dropletId = n.getStringValue(); },
        "id": n => { node.id = n.getGuidValue(); },
        "name": n => { node.name = n.getStringValue(); },
        "status": n => { node.status = n.getObjectValue<Node_status>(createNode_statusFromDiscriminatorValue); },
        "updated_at": n => { node.updatedAt = n.getDateValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoNode_status(node_status: Partial<Node_status> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "state": n => { node_status.state = n.getEnumValue<Node_status_state>(Node_status_stateObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoNotification(notification: Partial<Notification> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "email": n => { notification.email = n.getCollectionOfPrimitiveValues<string>(); },
        "slack": n => { notification.slack = n.getCollectionOfObjectValues<Notification_slack>(createNotification_slackFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoNotification_slack(notification_slack: Partial<Notification_slack> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "channel": n => { notification_slack.channel = n.getStringValue(); },
        "url": n => { notification_slack.url = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOneClicks(oneClicks: Partial<OneClicks> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "slug": n => { oneClicks.slug = n.getStringValue(); },
        "type": n => { oneClicks.type = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOneClicks_create(oneClicks_create: Partial<OneClicks_create> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "addon_slugs": n => { oneClicks_create.addonSlugs = n.getCollectionOfPrimitiveValues<string>(); },
        "cluster_uuid": n => { oneClicks_create.clusterUuid = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOnline_migration(online_migration: Partial<Online_migration> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { online_migration.createdAt = n.getStringValue(); },
        "id": n => { online_migration.id = n.getStringValue(); },
        "status": n => { online_migration.status = n.getEnumValue<Online_migration_status>(Online_migration_statusObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOpensearch_advanced_config(opensearch_advanced_config: Partial<Opensearch_advanced_config> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "action_auto_create_index_enabled": n => { opensearch_advanced_config.actionAutoCreateIndexEnabled = n.getBooleanValue(); },
        "action_destructive_requires_name": n => { opensearch_advanced_config.actionDestructiveRequiresName = n.getBooleanValue(); },
        "cluster_max_shards_per_node": n => { opensearch_advanced_config.clusterMaxShardsPerNode = n.getNumberValue(); },
        "cluster_routing_allocation_node_concurrent_recoveries": n => { opensearch_advanced_config.clusterRoutingAllocationNodeConcurrentRecoveries = n.getNumberValue(); },
        "enable_security_audit": n => { opensearch_advanced_config.enableSecurityAudit = n.getBooleanValue(); },
        "http_max_content_length_bytes": n => { opensearch_advanced_config.httpMaxContentLengthBytes = n.getNumberValue(); },
        "http_max_header_size_bytes": n => { opensearch_advanced_config.httpMaxHeaderSizeBytes = n.getNumberValue(); },
        "http_max_initial_line_length_bytes": n => { opensearch_advanced_config.httpMaxInitialLineLengthBytes = n.getNumberValue(); },
        "indices_fielddata_cache_size_percentage": n => { opensearch_advanced_config.indicesFielddataCacheSizePercentage = n.getNumberValue(); },
        "indices_memory_index_buffer_size_percentage": n => { opensearch_advanced_config.indicesMemoryIndexBufferSizePercentage = n.getNumberValue(); },
        "indices_memory_max_index_buffer_size_mb": n => { opensearch_advanced_config.indicesMemoryMaxIndexBufferSizeMb = n.getNumberValue(); },
        "indices_memory_min_index_buffer_size_mb": n => { opensearch_advanced_config.indicesMemoryMinIndexBufferSizeMb = n.getNumberValue(); },
        "indices_queries_cache_size_percentage": n => { opensearch_advanced_config.indicesQueriesCacheSizePercentage = n.getNumberValue(); },
        "indices_query_bool_max_clause_count": n => { opensearch_advanced_config.indicesQueryBoolMaxClauseCount = n.getNumberValue(); },
        "indices_recovery_max_concurrent_file_chunks": n => { opensearch_advanced_config.indicesRecoveryMaxConcurrentFileChunks = n.getNumberValue(); },
        "indices_recovery_max_mb_per_sec": n => { opensearch_advanced_config.indicesRecoveryMaxMbPerSec = n.getNumberValue(); },
        "ism_enabled": n => { opensearch_advanced_config.ismEnabled = n.getBooleanValue(); },
        "ism_history_enabled": n => { opensearch_advanced_config.ismHistoryEnabled = n.getBooleanValue(); },
        "ism_history_max_age_hours": n => { opensearch_advanced_config.ismHistoryMaxAgeHours = n.getNumberValue(); },
        "ism_history_max_docs": n => { opensearch_advanced_config.ismHistoryMaxDocs = n.getNumberValue(); },
        "ism_history_rollover_check_period_hours": n => { opensearch_advanced_config.ismHistoryRolloverCheckPeriodHours = n.getNumberValue(); },
        "ism_history_rollover_retention_period_days": n => { opensearch_advanced_config.ismHistoryRolloverRetentionPeriodDays = n.getNumberValue(); },
        "override_main_response_version": n => { opensearch_advanced_config.overrideMainResponseVersion = n.getBooleanValue(); },
        "plugins_alerting_filter_by_backend_roles_enabled": n => { opensearch_advanced_config.pluginsAlertingFilterByBackendRolesEnabled = n.getBooleanValue(); },
        "reindex_remote_whitelist": n => { opensearch_advanced_config.reindexRemoteWhitelist = n.getCollectionOfPrimitiveValues<string>(); },
        "script_max_compilations_rate": n => { opensearch_advanced_config.scriptMaxCompilationsRate = n.getStringValue() ?? "use-context"; },
        "search_max_buckets": n => { opensearch_advanced_config.searchMaxBuckets = n.getNumberValue(); },
        "thread_pool_analyze_queue_size": n => { opensearch_advanced_config.threadPoolAnalyzeQueueSize = n.getNumberValue(); },
        "thread_pool_analyze_size": n => { opensearch_advanced_config.threadPoolAnalyzeSize = n.getNumberValue(); },
        "thread_pool_force_merge_size": n => { opensearch_advanced_config.threadPoolForceMergeSize = n.getNumberValue(); },
        "thread_pool_get_queue_size": n => { opensearch_advanced_config.threadPoolGetQueueSize = n.getNumberValue(); },
        "thread_pool_get_size": n => { opensearch_advanced_config.threadPoolGetSize = n.getNumberValue(); },
        "thread_pool_search_queue_size": n => { opensearch_advanced_config.threadPoolSearchQueueSize = n.getNumberValue(); },
        "thread_pool_search_size": n => { opensearch_advanced_config.threadPoolSearchSize = n.getNumberValue(); },
        "thread_pool_search_throttled_queue_size": n => { opensearch_advanced_config.threadPoolSearchThrottledQueueSize = n.getNumberValue(); },
        "thread_pool_search_throttled_size": n => { opensearch_advanced_config.threadPoolSearchThrottledSize = n.getNumberValue(); },
        "thread_pool_write_queue_size": n => { opensearch_advanced_config.threadPoolWriteQueueSize = n.getNumberValue(); },
        "thread_pool_write_size": n => { opensearch_advanced_config.threadPoolWriteSize = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOpensearch_config(opensearch_config: Partial<Opensearch_config> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "cluster_name": n => { opensearch_config.clusterName = n.getStringValue(); },
        "cluster_uuid": n => { opensearch_config.clusterUuid = n.getStringValue(); },
        "credentials": n => { opensearch_config.credentials = n.getObjectValue<Opensearch_config_credentials>(createOpensearch_config_credentialsFromDiscriminatorValue); },
        "endpoint": n => { opensearch_config.endpoint = n.getStringValue(); },
        "id": n => { opensearch_config.id = n.getStringValue(); },
        "index_name": n => { opensearch_config.indexName = n.getStringValue(); },
        "retention_days": n => { opensearch_config.retentionDays = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOpensearch_config_credentials(opensearch_config_credentials: Partial<Opensearch_config_credentials> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "password": n => { opensearch_config_credentials.password = n.getStringValue(); },
        "username": n => { opensearch_config_credentials.username = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOpensearch_config_omit_credentials(opensearch_config_omit_credentials: Partial<Opensearch_config_omit_credentials> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "cluster_name": n => { opensearch_config_omit_credentials.clusterName = n.getStringValue(); },
        "cluster_uuid": n => { opensearch_config_omit_credentials.clusterUuid = n.getStringValue(); },
        "endpoint": n => { opensearch_config_omit_credentials.endpoint = n.getStringValue(); },
        "id": n => { opensearch_config_omit_credentials.id = n.getStringValue(); },
        "index_name": n => { opensearch_config_omit_credentials.indexName = n.getStringValue(); },
        "retention_days": n => { opensearch_config_omit_credentials.retentionDays = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOpensearch_config_request(opensearch_config_request: Partial<Opensearch_config_request> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "cluster_name": n => { opensearch_config_request.clusterName = n.getStringValue(); },
        "cluster_uuid": n => { opensearch_config_request.clusterUuid = n.getStringValue(); },
        "credentials": n => { opensearch_config_request.credentials = n.getObjectValue<Opensearch_config_request_credentials>(createOpensearch_config_request_credentialsFromDiscriminatorValue); },
        "endpoint": n => { opensearch_config_request.endpoint = n.getStringValue(); },
        "index_name": n => { opensearch_config_request.indexName = n.getStringValue(); },
        "retention_days": n => { opensearch_config_request.retentionDays = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOpensearch_config_request_credentials(opensearch_config_request_credentials: Partial<Opensearch_config_request_credentials> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "password": n => { opensearch_config_request_credentials.password = n.getStringValue(); },
        "username": n => { opensearch_config_request_credentials.username = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOpensearch_connection(opensearch_connection: Partial<Opensearch_connection> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "host": n => { opensearch_connection.host = n.getStringValue(); },
        "password": n => { opensearch_connection.password = n.getStringValue(); },
        "port": n => { opensearch_connection.port = n.getNumberValue(); },
        "ssl": n => { opensearch_connection.ssl = n.getBooleanValue(); },
        "uri": n => { opensearch_connection.uri = n.getStringValue(); },
        "user": n => { opensearch_connection.user = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOpensearch_index(opensearch_index: Partial<Opensearch_index> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoOpensearch_index_base(opensearch_index),
        "health": n => { opensearch_index.health = n.getEnumValue<Opensearch_index_health>(Opensearch_index_healthObject); },
        "status": n => { opensearch_index.status = n.getEnumValue<Opensearch_index_status>(Opensearch_index_statusObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOpensearch_index_base(opensearch_index_base: Partial<Opensearch_index_base> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_time": n => { opensearch_index_base.createdTime = n.getDateValue(); },
        "index_name": n => { opensearch_index_base.indexName = n.getStringValue(); },
        "number_of_replicas": n => { opensearch_index_base.numberOfReplicas = n.getNumberValue(); },
        "number_of_shards": n => { opensearch_index_base.numberOfShards = n.getNumberValue(); },
        "size": n => { opensearch_index_base.size = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOpensearch_logsink(opensearch_logsink: Partial<Opensearch_logsink> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "ca": n => { opensearch_logsink.ca = n.getStringValue(); },
        "index_days_max": n => { opensearch_logsink.indexDaysMax = n.getNumberValue(); },
        "index_prefix": n => { opensearch_logsink.indexPrefix = n.getStringValue(); },
        "timeout": n => { opensearch_logsink.timeout = n.getNumberValue(); },
        "url": n => { opensearch_logsink.url = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOptions(options: Partial<Options> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "options": n => { options.options = n.getObjectValue<Options_options>(createOptions_optionsFromDiscriminatorValue); },
        "version_availability": n => { options.versionAvailability = n.getObjectValue<Options_version_availability>(createOptions_version_availabilityFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOptions_options(options_options: Partial<Options_options> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "kafka": n => { options_options.kafka = n.getObjectValue<Options_options_kafka>(createOptions_options_kafkaFromDiscriminatorValue); },
        "mongodb": n => { options_options.mongodb = n.getObjectValue<Options_options_mongodb>(createOptions_options_mongodbFromDiscriminatorValue); },
        "mysql": n => { options_options.mysql = n.getObjectValue<Options_options_mysql>(createOptions_options_mysqlFromDiscriminatorValue); },
        "opensearch": n => { options_options.opensearch = n.getObjectValue<Options_options_opensearch>(createOptions_options_opensearchFromDiscriminatorValue); },
        "pg": n => { options_options.pg = n.getObjectValue<Options_options_pg>(createOptions_options_pgFromDiscriminatorValue); },
        "redis": n => { options_options.redis = n.getObjectValue<Options_options_redis>(createOptions_options_redisFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOptions_options_kafka(options_options_kafka: Partial<Options_options_kafka> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "layouts": n => { options_options_kafka.layouts = n.getCollectionOfObjectValues<Database_layout_option>(createDatabase_layout_optionFromDiscriminatorValue); },
        "regions": n => { options_options_kafka.regions = n.getCollectionOfPrimitiveValues<string>(); },
        "versions": n => { options_options_kafka.versions = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOptions_options_mongodb(options_options_mongodb: Partial<Options_options_mongodb> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "layouts": n => { options_options_mongodb.layouts = n.getCollectionOfObjectValues<Database_layout_option>(createDatabase_layout_optionFromDiscriminatorValue); },
        "regions": n => { options_options_mongodb.regions = n.getCollectionOfPrimitiveValues<string>(); },
        "versions": n => { options_options_mongodb.versions = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOptions_options_mysql(options_options_mysql: Partial<Options_options_mysql> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "layouts": n => { options_options_mysql.layouts = n.getCollectionOfObjectValues<Database_layout_option>(createDatabase_layout_optionFromDiscriminatorValue); },
        "regions": n => { options_options_mysql.regions = n.getCollectionOfPrimitiveValues<string>(); },
        "versions": n => { options_options_mysql.versions = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOptions_options_opensearch(options_options_opensearch: Partial<Options_options_opensearch> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "layouts": n => { options_options_opensearch.layouts = n.getCollectionOfObjectValues<Database_layout_option>(createDatabase_layout_optionFromDiscriminatorValue); },
        "regions": n => { options_options_opensearch.regions = n.getCollectionOfPrimitiveValues<string>(); },
        "versions": n => { options_options_opensearch.versions = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOptions_options_pg(options_options_pg: Partial<Options_options_pg> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "layouts": n => { options_options_pg.layouts = n.getCollectionOfObjectValues<Database_layout_option>(createDatabase_layout_optionFromDiscriminatorValue); },
        "regions": n => { options_options_pg.regions = n.getCollectionOfPrimitiveValues<string>(); },
        "versions": n => { options_options_pg.versions = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOptions_options_redis(options_options_redis: Partial<Options_options_redis> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "layouts": n => { options_options_redis.layouts = n.getCollectionOfObjectValues<Database_layout_option>(createDatabase_layout_optionFromDiscriminatorValue); },
        "regions": n => { options_options_redis.regions = n.getCollectionOfPrimitiveValues<string>(); },
        "versions": n => { options_options_redis.versions = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoOptions_version_availability(options_version_availability: Partial<Options_version_availability> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "kafka": n => { options_version_availability.kafka = n.getCollectionOfObjectValues<Database_version_availability>(createDatabase_version_availabilityFromDiscriminatorValue); },
        "mongodb": n => { options_version_availability.mongodb = n.getCollectionOfObjectValues<Database_version_availability>(createDatabase_version_availabilityFromDiscriminatorValue); },
        "mysql": n => { options_version_availability.mysql = n.getCollectionOfObjectValues<Database_version_availability>(createDatabase_version_availabilityFromDiscriminatorValue); },
        "opensearch": n => { options_version_availability.opensearch = n.getCollectionOfObjectValues<Database_version_availability>(createDatabase_version_availabilityFromDiscriminatorValue); },
        "pg": n => { options_version_availability.pg = n.getCollectionOfObjectValues<Database_version_availability>(createDatabase_version_availabilityFromDiscriminatorValue); },
        "redis": n => { options_version_availability.redis = n.getCollectionOfObjectValues<Database_version_availability>(createDatabase_version_availabilityFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoPage_links(page_links: Partial<Page_links> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "pages": n => { page_links.pages = n.getObjectValue<Backward_links>(createBackward_linksFromDiscriminatorValue) ?? n.getObjectValue<Forward_links>(createForward_linksFromDiscriminatorValue) ?? n.getObjectValue<Page_links_pagesMember1>(createPage_links_pagesMember1FromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoPage_links_pages(page_links_pages: Partial<Backward_links | Forward_links | Page_links_pagesMember1> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoBackward_links(page_links_pages as Backward_links),
        ...deserializeIntoForward_links(page_links_pages as Forward_links),
        ...deserializeIntoPage_links_pagesMember1(page_links_pages as Page_links_pagesMember1),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoPage_links_pagesMember1(page_links_pagesMember1: Partial<Page_links_pagesMember1> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoPgbouncer_advanced_config(pgbouncer_advanced_config: Partial<Pgbouncer_advanced_config> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "autodb_idle_timeout": n => { pgbouncer_advanced_config.autodbIdleTimeout = n.getNumberValue(); },
        "autodb_max_db_connections": n => { pgbouncer_advanced_config.autodbMaxDbConnections = n.getNumberValue(); },
        "autodb_pool_mode": n => { pgbouncer_advanced_config.autodbPoolMode = n.getEnumValue<Pgbouncer_advanced_config_autodb_pool_mode>(Pgbouncer_advanced_config_autodb_pool_modeObject); },
        "autodb_pool_size": n => { pgbouncer_advanced_config.autodbPoolSize = n.getNumberValue(); },
        "ignore_startup_parameters": n => { pgbouncer_advanced_config.ignoreStartupParameters = n.getCollectionOfEnumValues<Pgbouncer_advanced_config_ignore_startup_parameters>(Pgbouncer_advanced_config_ignore_startup_parametersObject); },
        "min_pool_size": n => { pgbouncer_advanced_config.minPoolSize = n.getNumberValue(); },
        "server_idle_timeout": n => { pgbouncer_advanced_config.serverIdleTimeout = n.getNumberValue(); },
        "server_lifetime": n => { pgbouncer_advanced_config.serverLifetime = n.getNumberValue(); },
        "server_reset_query_always": n => { pgbouncer_advanced_config.serverResetQueryAlways = n.getBooleanValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoPostgres_advanced_config(postgres_advanced_config: Partial<Postgres_advanced_config> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "autovacuum_analyze_scale_factor": n => { postgres_advanced_config.autovacuumAnalyzeScaleFactor = n.getNumberValue(); },
        "autovacuum_analyze_threshold": n => { postgres_advanced_config.autovacuumAnalyzeThreshold = n.getNumberValue(); },
        "autovacuum_freeze_max_age": n => { postgres_advanced_config.autovacuumFreezeMaxAge = n.getNumberValue(); },
        "autovacuum_max_workers": n => { postgres_advanced_config.autovacuumMaxWorkers = n.getNumberValue(); },
        "autovacuum_naptime": n => { postgres_advanced_config.autovacuumNaptime = n.getNumberValue(); },
        "autovacuum_vacuum_cost_delay": n => { postgres_advanced_config.autovacuumVacuumCostDelay = n.getNumberValue(); },
        "autovacuum_vacuum_cost_limit": n => { postgres_advanced_config.autovacuumVacuumCostLimit = n.getNumberValue(); },
        "autovacuum_vacuum_scale_factor": n => { postgres_advanced_config.autovacuumVacuumScaleFactor = n.getNumberValue(); },
        "autovacuum_vacuum_threshold": n => { postgres_advanced_config.autovacuumVacuumThreshold = n.getNumberValue(); },
        "backup_hour": n => { postgres_advanced_config.backupHour = n.getNumberValue(); },
        "backup_minute": n => { postgres_advanced_config.backupMinute = n.getNumberValue(); },
        "bgwriter_delay": n => { postgres_advanced_config.bgwriterDelay = n.getNumberValue(); },
        "bgwriter_flush_after": n => { postgres_advanced_config.bgwriterFlushAfter = n.getNumberValue(); },
        "bgwriter_lru_maxpages": n => { postgres_advanced_config.bgwriterLruMaxpages = n.getNumberValue(); },
        "bgwriter_lru_multiplier": n => { postgres_advanced_config.bgwriterLruMultiplier = n.getNumberValue(); },
        "deadlock_timeout": n => { postgres_advanced_config.deadlockTimeout = n.getNumberValue(); },
        "default_toast_compression": n => { postgres_advanced_config.defaultToastCompression = n.getEnumValue<Postgres_advanced_config_default_toast_compression>(Postgres_advanced_config_default_toast_compressionObject); },
        "idle_in_transaction_session_timeout": n => { postgres_advanced_config.idleInTransactionSessionTimeout = n.getNumberValue(); },
        "jit": n => { postgres_advanced_config.jit = n.getBooleanValue(); },
        "log_autovacuum_min_duration": n => { postgres_advanced_config.logAutovacuumMinDuration = n.getNumberValue(); },
        "log_error_verbosity": n => { postgres_advanced_config.logErrorVerbosity = n.getEnumValue<Postgres_advanced_config_log_error_verbosity>(Postgres_advanced_config_log_error_verbosityObject); },
        "log_line_prefix": n => { postgres_advanced_config.logLinePrefix = n.getEnumValue<Postgres_advanced_config_log_line_prefix>(Postgres_advanced_config_log_line_prefixObject); },
        "log_min_duration_statement": n => { postgres_advanced_config.logMinDurationStatement = n.getNumberValue(); },
        "max_failover_replication_time_lag": n => { postgres_advanced_config.maxFailoverReplicationTimeLag = n.getNumberValue(); },
        "max_files_per_process": n => { postgres_advanced_config.maxFilesPerProcess = n.getNumberValue(); },
        "max_locks_per_transaction": n => { postgres_advanced_config.maxLocksPerTransaction = n.getNumberValue(); },
        "max_logical_replication_workers": n => { postgres_advanced_config.maxLogicalReplicationWorkers = n.getNumberValue(); },
        "max_parallel_workers": n => { postgres_advanced_config.maxParallelWorkers = n.getNumberValue(); },
        "max_parallel_workers_per_gather": n => { postgres_advanced_config.maxParallelWorkersPerGather = n.getNumberValue(); },
        "max_pred_locks_per_transaction": n => { postgres_advanced_config.maxPredLocksPerTransaction = n.getNumberValue(); },
        "max_prepared_transactions": n => { postgres_advanced_config.maxPreparedTransactions = n.getNumberValue(); },
        "max_replication_slots": n => { postgres_advanced_config.maxReplicationSlots = n.getNumberValue(); },
        "max_stack_depth": n => { postgres_advanced_config.maxStackDepth = n.getNumberValue(); },
        "max_standby_archive_delay": n => { postgres_advanced_config.maxStandbyArchiveDelay = n.getNumberValue(); },
        "max_standby_streaming_delay": n => { postgres_advanced_config.maxStandbyStreamingDelay = n.getNumberValue(); },
        "max_wal_senders": n => { postgres_advanced_config.maxWalSenders = n.getNumberValue(); },
        "max_worker_processes": n => { postgres_advanced_config.maxWorkerProcesses = n.getNumberValue(); },
        "pgbouncer": n => { postgres_advanced_config.pgbouncer = n.getObjectValue<Pgbouncer_advanced_config>(createPgbouncer_advanced_configFromDiscriminatorValue); },
        "pg_partman_bgw.interval": n => { postgres_advanced_config.pgPartmanBgwInterval = n.getNumberValue(); },
        "pg_partman_bgw.role": n => { postgres_advanced_config.pgPartmanBgwRole = n.getStringValue(); },
        "pg_stat_statements.track": n => { postgres_advanced_config.pgStatStatementsTrack = n.getEnumValue<Postgres_advanced_config_pg_stat_statementsTrack>(Postgres_advanced_config_pg_stat_statementsTrackObject); },
        "shared_buffers_percentage": n => { postgres_advanced_config.sharedBuffersPercentage = n.getNumberValue(); },
        "stat_monitor_enable": n => { postgres_advanced_config.statMonitorEnable = n.getBooleanValue(); },
        "synchronous_replication": n => { postgres_advanced_config.synchronousReplication = n.getEnumValue<Postgres_advanced_config_synchronous_replication>(Postgres_advanced_config_synchronous_replicationObject); },
        "temp_file_limit": n => { postgres_advanced_config.tempFileLimit = n.getNumberValue(); },
        "timescaledb": n => { postgres_advanced_config.timescaledb = n.getObjectValue<Timescaledb_advanced_config>(createTimescaledb_advanced_configFromDiscriminatorValue); },
        "timezone": n => { postgres_advanced_config.timezone = n.getStringValue(); },
        "track_activity_query_size": n => { postgres_advanced_config.trackActivityQuerySize = n.getNumberValue(); },
        "track_commit_timestamp": n => { postgres_advanced_config.trackCommitTimestamp = n.getEnumValue<Postgres_advanced_config_track_commit_timestamp>(Postgres_advanced_config_track_commit_timestampObject); },
        "track_functions": n => { postgres_advanced_config.trackFunctions = n.getEnumValue<Postgres_advanced_config_track_functions>(Postgres_advanced_config_track_functionsObject); },
        "track_io_timing": n => { postgres_advanced_config.trackIoTiming = n.getEnumValue<Postgres_advanced_config_track_io_timing>(Postgres_advanced_config_track_io_timingObject); },
        "wal_sender_timeout": n => { postgres_advanced_config.walSenderTimeout = n.getNumberValue(); },
        "wal_writer_delay": n => { postgres_advanced_config.walWriterDelay = n.getNumberValue(); },
        "work_mem": n => { postgres_advanced_config.workMem = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoPrevious_outage(previous_outage: Partial<Previous_outage> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "duration_seconds": n => { previous_outage.durationSeconds = n.getNumberValue(); },
        "ended_at": n => { previous_outage.endedAt = n.getStringValue(); },
        "region": n => { previous_outage.region = n.getStringValue(); },
        "started_at": n => { previous_outage.startedAt = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoProduct_charge_item(product_charge_item: Partial<Product_charge_item> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "amount": n => { product_charge_item.amount = n.getStringValue(); },
        "count": n => { product_charge_item.count = n.getStringValue(); },
        "name": n => { product_charge_item.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoProduct_usage_charges(product_usage_charges: Partial<Product_usage_charges> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "amount": n => { product_usage_charges.amount = n.getStringValue(); },
        "items": n => { product_usage_charges.items = n.getCollectionOfObjectValues<Product_charge_item>(createProduct_charge_itemFromDiscriminatorValue); },
        "name": n => { product_usage_charges.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoProject(project: Partial<Project> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoProject_base(project),
        "is_default": n => { project.isDefault = n.getBooleanValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoProject_assignment(project_assignment: Partial<Project_assignment> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "resources": n => { project_assignment.resources = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoProject_base(project_base: Partial<Project_base> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { project_base.createdAt = n.getDateValue(); },
        "description": n => { project_base.description = n.getStringValue(); },
        "environment": n => { project_base.environment = n.getEnumValue<Project_base_environment>(Project_base_environmentObject); },
        "id": n => { project_base.id = n.getGuidValue(); },
        "name": n => { project_base.name = n.getStringValue(); },
        "owner_id": n => { project_base.ownerId = n.getNumberValue(); },
        "owner_uuid": n => { project_base.ownerUuid = n.getStringValue(); },
        "purpose": n => { project_base.purpose = n.getStringValue(); },
        "updated_at": n => { project_base.updatedAt = n.getDateValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoPurge_cache(purge_cache: Partial<Purge_cache> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "files": n => { purge_cache.files = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoRedis_advanced_config(redis_advanced_config: Partial<Redis_advanced_config> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "redis_acl_channels_default": n => { redis_advanced_config.redisAclChannelsDefault = n.getEnumValue<Redis_advanced_config_redis_acl_channels_default>(Redis_advanced_config_redis_acl_channels_defaultObject); },
        "redis_io_threads": n => { redis_advanced_config.redisIoThreads = n.getNumberValue(); },
        "redis_lfu_decay_time": n => { redis_advanced_config.redisLfuDecayTime = n.getNumberValue(); },
        "redis_lfu_log_factor": n => { redis_advanced_config.redisLfuLogFactor = n.getNumberValue(); },
        "redis_maxmemory_policy": n => { redis_advanced_config.redisMaxmemoryPolicy = n.getEnumValue<Redis_advanced_config_redis_maxmemory_policy>(Redis_advanced_config_redis_maxmemory_policyObject); },
        "redis_notify_keyspace_events": n => { redis_advanced_config.redisNotifyKeyspaceEvents = n.getStringValue(); },
        "redis_number_of_databases": n => { redis_advanced_config.redisNumberOfDatabases = n.getNumberValue(); },
        "redis_persistence": n => { redis_advanced_config.redisPersistence = n.getEnumValue<Redis_advanced_config_redis_persistence>(Redis_advanced_config_redis_persistenceObject); },
        "redis_pubsub_client_output_buffer_limit": n => { redis_advanced_config.redisPubsubClientOutputBufferLimit = n.getNumberValue(); },
        "redis_ssl": n => { redis_advanced_config.redisSsl = n.getBooleanValue(); },
        "redis_timeout": n => { redis_advanced_config.redisTimeout = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoRegion(region: Partial<Region> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "available": n => { region.available = n.getBooleanValue(); },
        "features": n => { region.features = n.getObjectValue<UntypedNode>(createUntypedNodeFromDiscriminatorValue); },
        "name": n => { region.name = n.getStringValue(); },
        "sizes": n => { region.sizes = n.getObjectValue<UntypedNode>(createUntypedNodeFromDiscriminatorValue); },
        "slug": n => { region.slug = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoRegion_state(region_state: Partial<Region_state> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "status": n => { region_state.status = n.getEnumValue<Region_state_status>(Region_state_statusObject); },
        "status_changed_at": n => { region_state.statusChangedAt = n.getStringValue(); },
        "thirty_day_uptime_percentage": n => { region_state.thirtyDayUptimePercentage = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoRegional_state(regional_state: Partial<Regional_state> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "eu_west": n => { regional_state.euWest = n.getObjectValue<Region_state>(createRegion_stateFromDiscriminatorValue); },
        "us_east": n => { regional_state.usEast = n.getObjectValue<Region_state>(createRegion_stateFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoRegistry(registry: Partial<Registry> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { registry.createdAt = n.getDateValue(); },
        "name": n => { registry.name = n.getStringValue(); },
        "region": n => { registry.region = n.getStringValue(); },
        "storage_usage_bytes": n => { registry.storageUsageBytes = n.getNumberValue(); },
        "storage_usage_bytes_updated_at": n => { registry.storageUsageBytesUpdatedAt = n.getDateValue(); },
        "subscription": n => { registry.subscription = n.getObjectValue<Subscription>(createSubscriptionFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoRegistry_create(registry_create: Partial<Registry_create> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "name": n => { registry_create.name = n.getStringValue(); },
        "region": n => { registry_create.region = n.getEnumValue<Registry_create_region>(Registry_create_regionObject); },
        "subscription_tier_slug": n => { registry_create.subscriptionTierSlug = n.getEnumValue<Registry_create_subscription_tier_slug>(Registry_create_subscription_tier_slugObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoRepository(repository: Partial<Repository> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "latest_tag": n => { repository.latestTag = n.getObjectValue<Repository_tag>(createRepository_tagFromDiscriminatorValue); },
        "name": n => { repository.name = n.getStringValue(); },
        "registry_name": n => { repository.registryName = n.getStringValue(); },
        "tag_count": n => { repository.tagCount = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoRepository_blob(repository_blob: Partial<Repository_blob> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "compressed_size_bytes": n => { repository_blob.compressedSizeBytes = n.getNumberValue(); },
        "digest": n => { repository_blob.digest = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoRepository_manifest(repository_manifest: Partial<Repository_manifest> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "blobs": n => { repository_manifest.blobs = n.getCollectionOfObjectValues<Repository_blob>(createRepository_blobFromDiscriminatorValue); },
        "compressed_size_bytes": n => { repository_manifest.compressedSizeBytes = n.getNumberValue(); },
        "digest": n => { repository_manifest.digest = n.getStringValue(); },
        "registry_name": n => { repository_manifest.registryName = n.getStringValue(); },
        "repository": n => { repository_manifest.repository = n.getStringValue(); },
        "size_bytes": n => { repository_manifest.sizeBytes = n.getNumberValue(); },
        "tags": n => { repository_manifest.tags = n.getCollectionOfPrimitiveValues<string>(); },
        "updated_at": n => { repository_manifest.updatedAt = n.getDateValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoRepository_tag(repository_tag: Partial<Repository_tag> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "compressed_size_bytes": n => { repository_tag.compressedSizeBytes = n.getNumberValue(); },
        "manifest_digest": n => { repository_tag.manifestDigest = n.getStringValue(); },
        "registry_name": n => { repository_tag.registryName = n.getStringValue(); },
        "repository": n => { repository_tag.repository = n.getStringValue(); },
        "size_bytes": n => { repository_tag.sizeBytes = n.getNumberValue(); },
        "tag": n => { repository_tag.tag = n.getStringValue(); },
        "updated_at": n => { repository_tag.updatedAt = n.getDateValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoRepository_v2(repository_v2: Partial<Repository_v2> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "latest_manifest": n => { repository_v2.latestManifest = n.getObjectValue<Repository_manifest>(createRepository_manifestFromDiscriminatorValue); },
        "manifest_count": n => { repository_v2.manifestCount = n.getNumberValue(); },
        "name": n => { repository_v2.name = n.getStringValue(); },
        "registry_name": n => { repository_v2.registryName = n.getStringValue(); },
        "tag_count": n => { repository_v2.tagCount = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoReserved_ip(reserved_ip: Partial<Reserved_ip> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "droplet": n => { reserved_ip.droplet = n.getObjectValue<Droplet>(createDropletFromDiscriminatorValue); },
        "ip": n => { reserved_ip.ip = n.getStringValue(); },
        "locked": n => { reserved_ip.locked = n.getBooleanValue(); },
        "project_id": n => { reserved_ip.projectId = n.getGuidValue(); },
        "region": n => { reserved_ip.region = n.getObjectValue<Region>(createRegionFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoReserved_ip_action_assign(reserved_ip_action_assign: Partial<Reserved_ip_action_assign> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoReserved_ip_action_type(reserved_ip_action_assign),
        "droplet_id": n => { reserved_ip_action_assign.dropletId = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoReserved_ip_action_type(reserved_ip_action_type: Partial<Reserved_ip_action_type> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "type": n => { reserved_ip_action_type.type = n.getEnumValue<Reserved_ip_action_type_type>(Reserved_ip_action_type_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoReserved_ip_action_unassign(reserved_ip_action_unassign: Partial<Reserved_ip_action_unassign> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoReserved_ip_action_type(reserved_ip_action_unassign),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoReserved_ip_createMember1(reserved_ip_createMember1: Partial<Reserved_ip_createMember1> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "droplet_id": n => { reserved_ip_createMember1.dropletId = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoReserved_ip_createMember2(reserved_ip_createMember2: Partial<Reserved_ip_createMember2> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "project_id": n => { reserved_ip_createMember2.projectId = n.getGuidValue(); },
        "region": n => { reserved_ip_createMember2.region = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoReserved_ipv6(reserved_ipv6: Partial<Reserved_ipv6> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "droplet": n => { reserved_ipv6.droplet = n.getObjectValue<Droplet>(createDropletFromDiscriminatorValue); },
        "ip": n => { reserved_ipv6.ip = n.getStringValue(); },
        "region_slug": n => { reserved_ipv6.regionSlug = n.getStringValue(); },
        "reserved_at": n => { reserved_ipv6.reservedAt = n.getDateValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoReserved_ipv6_action_assign(reserved_ipv6_action_assign: Partial<Reserved_ipv6_action_assign> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoReserved_ipv6_action_type(reserved_ipv6_action_assign),
        "droplet_id": n => { reserved_ipv6_action_assign.dropletId = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoReserved_ipv6_action_type(reserved_ipv6_action_type: Partial<Reserved_ipv6_action_type> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "type": n => { reserved_ipv6_action_type.type = n.getEnumValue<Reserved_ipv6_action_type_type>(Reserved_ipv6_action_type_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoReserved_ipv6_action_unassign(reserved_ipv6_action_unassign: Partial<Reserved_ipv6_action_unassign> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoReserved_ipv6_action_type(reserved_ipv6_action_unassign),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoReserved_ipv6_create(reserved_ipv6_create: Partial<Reserved_ipv6_create> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "region_slug": n => { reserved_ipv6_create.regionSlug = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoResource(resource: Partial<Resource> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "assigned_at": n => { resource.assignedAt = n.getDateValue(); },
        "links": n => { resource.links = n.getObjectValue<Resource_links>(createResource_linksFromDiscriminatorValue); },
        "status": n => { resource.status = n.getEnumValue<Resource_status>(Resource_statusObject); },
        "urn": n => { resource.urn = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoResource_links(resource_links: Partial<Resource_links> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "self": n => { resource_links.self = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoRouting_agent(routing_agent: Partial<Routing_agent> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "enabled": n => { routing_agent.enabled = n.getBooleanValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoRsyslog_logsink(rsyslog_logsink: Partial<Rsyslog_logsink> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "ca": n => { rsyslog_logsink.ca = n.getStringValue(); },
        "cert": n => { rsyslog_logsink.cert = n.getStringValue(); },
        "format": n => { rsyslog_logsink.format = n.getEnumValue<Rsyslog_logsink_format>(Rsyslog_logsink_formatObject); },
        "key": n => { rsyslog_logsink.key = n.getStringValue(); },
        "logline": n => { rsyslog_logsink.logline = n.getStringValue(); },
        "port": n => { rsyslog_logsink.port = n.getNumberValue(); },
        "sd": n => { rsyslog_logsink.sd = n.getStringValue(); },
        "server": n => { rsyslog_logsink.server = n.getStringValue(); },
        "tls": n => { rsyslog_logsink.tls = n.getBooleanValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoScheduled_details(scheduled_details: Partial<Scheduled_details> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "body": n => { scheduled_details.body = n.getObjectValue<Scheduled_details_body>(createScheduled_details_bodyFromDiscriminatorValue); },
        "cron": n => { scheduled_details.cron = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoScheduled_details_body(scheduled_details_body: Partial<Scheduled_details_body> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "name": n => { scheduled_details_body.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoSelective_destroy_associated_resource(selective_destroy_associated_resource: Partial<Selective_destroy_associated_resource> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "floating_ips": n => { selective_destroy_associated_resource.floatingIps = n.getCollectionOfPrimitiveValues<string>(); },
        "reserved_ips": n => { selective_destroy_associated_resource.reservedIps = n.getCollectionOfPrimitiveValues<string>(); },
        "snapshots": n => { selective_destroy_associated_resource.snapshots = n.getCollectionOfPrimitiveValues<string>(); },
        "volumes": n => { selective_destroy_associated_resource.volumes = n.getCollectionOfPrimitiveValues<string>(); },
        "volume_snapshots": n => { selective_destroy_associated_resource.volumeSnapshots = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoSimple_charge(simple_charge: Partial<Simple_charge> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "amount": n => { simple_charge.amount = n.getStringValue(); },
        "name": n => { simple_charge.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoSink_resource(sink_resource: Partial<Sink_resource> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "name": n => { sink_resource.name = n.getStringValue(); },
        "urn": n => { sink_resource.urn = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoSinks_response(sinks_response: Partial<Sinks_response> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "destination": n => { sinks_response.destination = n.getObjectValue<Destination>(createDestinationFromDiscriminatorValue); },
        "resources": n => { sinks_response.resources = n.getCollectionOfObjectValues<Sink_resource>(createSink_resourceFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoSize(size: Partial<Size> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "available": n => { size.available = n.getBooleanValue(); },
        "description": n => { size.description = n.getStringValue(); },
        "disk": n => { size.disk = n.getNumberValue(); },
        "disk_info": n => { size.diskInfo = n.getCollectionOfObjectValues<Disk_info>(createDisk_infoFromDiscriminatorValue); },
        "gpu_info": n => { size.gpuInfo = n.getObjectValue<Gpu_info>(createGpu_infoFromDiscriminatorValue); },
        "memory": n => { size.memory = n.getNumberValue(); },
        "price_hourly": n => { size.priceHourly = n.getNumberValue(); },
        "price_monthly": n => { size.priceMonthly = n.getNumberValue(); },
        "regions": n => { size.regions = n.getCollectionOfPrimitiveValues<string>(); },
        "slug": n => { size.slug = n.getStringValue(); },
        "transfer": n => { size.transfer = n.getNumberValue(); },
        "vcpus": n => { size.vcpus = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoSlack_details(slack_details: Partial<Slack_details> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "channel": n => { slack_details.channel = n.getStringValue(); },
        "url": n => { slack_details.url = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoSnapshots(snapshots: Partial<Snapshots> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoSnapshots_base(snapshots),
        "id": n => { snapshots.id = n.getStringValue(); },
        "resource_id": n => { snapshots.resourceId = n.getStringValue(); },
        "resource_type": n => { snapshots.resourceType = n.getEnumValue<Snapshots_resource_type>(Snapshots_resource_typeObject); },
        "tags": n => { snapshots.tags = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoSnapshots_base(snapshots_base: Partial<Snapshots_base> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { snapshots_base.createdAt = n.getDateValue(); },
        "min_disk_size": n => { snapshots_base.minDiskSize = n.getNumberValue(); },
        "name": n => { snapshots_base.name = n.getStringValue(); },
        "regions": n => { snapshots_base.regions = n.getCollectionOfPrimitiveValues<string>(); },
        "size_gigabytes": n => { snapshots_base.sizeGigabytes = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoSource_database(source_database: Partial<Source_database> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "disable_ssl": n => { source_database.disableSsl = n.getBooleanValue(); },
        "ignore_dbs": n => { source_database.ignoreDbs = n.getCollectionOfPrimitiveValues<string>(); },
        "source": n => { source_database.source = n.getObjectValue<Source_database_source>(createSource_database_sourceFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoSource_database_source(source_database_source: Partial<Source_database_source> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "dbname": n => { source_database_source.dbname = n.getStringValue(); },
        "host": n => { source_database_source.host = n.getStringValue(); },
        "password": n => { source_database_source.password = n.getStringValue(); },
        "port": n => { source_database_source.port = n.getNumberValue(); },
        "username": n => { source_database_source.username = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoSql_mode(sql_mode: Partial<Sql_mode> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "sql_mode": n => { sql_mode.sqlMode = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoSshKeys(sshKeys: Partial<SshKeys> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "fingerprint": n => { sshKeys.fingerprint = n.getStringValue(); },
        "id": n => { sshKeys.id = n.getNumberValue(); },
        "name": n => { sshKeys.name = n.getStringValue(); },
        "public_key": n => { sshKeys.publicKey = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoState(state: Partial<State> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "previous_outage": n => { state.previousOutage = n.getObjectValue<Previous_outage>(createPrevious_outageFromDiscriminatorValue); },
        "regions": n => { state.regions = n.getObjectValue<Regional_state>(createRegional_stateFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoSticky_sessions(sticky_sessions: Partial<Sticky_sessions> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "cookie_name": n => { sticky_sessions.cookieName = n.getStringValue(); },
        "cookie_ttl_seconds": n => { sticky_sessions.cookieTtlSeconds = n.getNumberValue(); },
        "type": n => { sticky_sessions.type = n.getEnumValue<Sticky_sessions_type>(Sticky_sessions_typeObject) ?? Sticky_sessions_typeObject.None; },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoSubscription(subscription: Partial<Subscription> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { subscription.createdAt = n.getDateValue(); },
        "tier": n => { subscription.tier = n.getObjectValue<Subscription_tier_base>(createSubscription_tier_baseFromDiscriminatorValue); },
        "updated_at": n => { subscription.updatedAt = n.getDateValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoSubscription_tier_base(subscription_tier_base: Partial<Subscription_tier_base> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "allow_storage_overage": n => { subscription_tier_base.allowStorageOverage = n.getBooleanValue(); },
        "included_bandwidth_bytes": n => { subscription_tier_base.includedBandwidthBytes = n.getNumberValue(); },
        "included_repositories": n => { subscription_tier_base.includedRepositories = n.getNumberValue(); },
        "included_storage_bytes": n => { subscription_tier_base.includedStorageBytes = n.getNumberValue(); },
        "monthly_price_in_cents": n => { subscription_tier_base.monthlyPriceInCents = n.getNumberValue(); },
        "name": n => { subscription_tier_base.name = n.getStringValue(); },
        "slug": n => { subscription_tier_base.slug = n.getStringValue(); },
        "storage_overage_price_in_cents": n => { subscription_tier_base.storageOveragePriceInCents = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoSupported_droplet_backup_policy(supported_droplet_backup_policy: Partial<Supported_droplet_backup_policy> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "name": n => { supported_droplet_backup_policy.name = n.getStringValue(); },
        "possible_days": n => { supported_droplet_backup_policy.possibleDays = n.getCollectionOfPrimitiveValues<string>(); },
        "possible_window_starts": n => { supported_droplet_backup_policy.possibleWindowStarts = n.getCollectionOfPrimitiveValues<number>(); },
        "retention_period_days": n => { supported_droplet_backup_policy.retentionPeriodDays = n.getNumberValue(); },
        "window_length_hours": n => { supported_droplet_backup_policy.windowLengthHours = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoTags(tags: Partial<Tags> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "name": n => { tags.name = n.getStringValue(); },
        "resources": n => { tags.resources = n.getObjectValue<Tags_resources>(createTags_resourcesFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoTags_metadata(tags_metadata: Partial<Tags_metadata> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "count": n => { tags_metadata.count = n.getNumberValue(); },
        "last_tagged_uri": n => { tags_metadata.lastTaggedUri = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoTags_resource(tags_resource: Partial<Tags_resource> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "resources": n => { tags_resource.resources = n.getCollectionOfObjectValues<Tags_resource_resources>(createTags_resource_resourcesFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoTags_resource_resources(tags_resource_resources: Partial<Tags_resource_resources> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "resource_id": n => { tags_resource_resources.resourceId = n.getStringValue(); },
        "resource_type": n => { tags_resource_resources.resourceType = n.getEnumValue<Tags_resource_resources_resource_type>(Tags_resource_resources_resource_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoTags_resources(tags_resources: Partial<Tags_resources> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoTags_metadata(tags_resources),
        "databases": n => { tags_resources.databases = n.getObjectValue<Tags_metadata>(createTags_metadataFromDiscriminatorValue); },
        "droplets": n => { tags_resources.droplets = n.getObjectValue<Tags_metadata>(createTags_metadataFromDiscriminatorValue); },
        "imgages": n => { tags_resources.imgages = n.getObjectValue<Tags_metadata>(createTags_metadataFromDiscriminatorValue); },
        "volumes": n => { tags_resources.volumes = n.getObjectValue<Tags_metadata>(createTags_metadataFromDiscriminatorValue); },
        "volume_snapshots": n => { tags_resources.volumeSnapshots = n.getObjectValue<Tags_metadata>(createTags_metadataFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoTimescaledb_advanced_config(timescaledb_advanced_config: Partial<Timescaledb_advanced_config> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "max_background_workers": n => { timescaledb_advanced_config.maxBackgroundWorkers = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoTrigger_info(trigger_info: Partial<Trigger_info> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { trigger_info.createdAt = n.getStringValue(); },
        "function": n => { trigger_info.functionEscaped = n.getStringValue(); },
        "is_enabled": n => { trigger_info.isEnabled = n.getBooleanValue(); },
        "name": n => { trigger_info.name = n.getStringValue(); },
        "namespace": n => { trigger_info.namespace = n.getStringValue(); },
        "scheduled_details": n => { trigger_info.scheduledDetails = n.getObjectValue<Scheduled_details>(createScheduled_detailsFromDiscriminatorValue); },
        "scheduled_runs": n => { trigger_info.scheduledRuns = n.getObjectValue<Trigger_info_scheduled_runs>(createTrigger_info_scheduled_runsFromDiscriminatorValue); },
        "type": n => { trigger_info.type = n.getStringValue(); },
        "updated_at": n => { trigger_info.updatedAt = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoTrigger_info_scheduled_runs(trigger_info_scheduled_runs: Partial<Trigger_info_scheduled_runs> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "last_run_at": n => { trigger_info_scheduled_runs.lastRunAt = n.getStringValue(); },
        "next_run_at": n => { trigger_info_scheduled_runs.nextRunAt = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoUpdate_endpoint(update_endpoint: Partial<Update_endpoint> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "certificate_id": n => { update_endpoint.certificateId = n.getGuidValue(); },
        "custom_domain": n => { update_endpoint.customDomain = n.getStringValue(); },
        "ttl": n => { update_endpoint.ttl = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoUpdate_registry(update_registry: Partial<Update_registry> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "cancel": n => { update_registry.cancel = n.getBooleanValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoUpdate_trigger(update_trigger: Partial<Update_trigger> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "is_enabled": n => { update_trigger.isEnabled = n.getBooleanValue(); },
        "scheduled_details": n => { update_trigger.scheduledDetails = n.getObjectValue<Scheduled_details>(createScheduled_detailsFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoUser(user: Partial<User> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "kubernetes_cluster_user": n => { user.kubernetesClusterUser = n.getObjectValue<User_kubernetes_cluster_user>(createUser_kubernetes_cluster_userFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoUser_kubernetes_cluster_user(user_kubernetes_cluster_user: Partial<User_kubernetes_cluster_user> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "groups": n => { user_kubernetes_cluster_user.groups = n.getCollectionOfPrimitiveValues<string>(); },
        "username": n => { user_kubernetes_cluster_user.username = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoUser_settings(user_settings: Partial<User_settings> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "acl": n => { user_settings.acl = n.getCollectionOfObjectValues<User_settings_acl>(createUser_settings_aclFromDiscriminatorValue); },
        "opensearch_acl": n => { user_settings.opensearchAcl = n.getCollectionOfObjectValues<User_settings_opensearch_acl>(createUser_settings_opensearch_aclFromDiscriminatorValue); },
        "pg_allow_replication": n => { user_settings.pgAllowReplication = n.getBooleanValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoUser_settings_acl(user_settings_acl: Partial<User_settings_acl> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "id": n => { user_settings_acl.id = n.getStringValue(); },
        "permission": n => { user_settings_acl.permission = n.getEnumValue<User_settings_acl_permission>(User_settings_acl_permissionObject); },
        "topic": n => { user_settings_acl.topic = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoUser_settings_opensearch_acl(user_settings_opensearch_acl: Partial<User_settings_opensearch_acl> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "index": n => { user_settings_opensearch_acl.index = n.getStringValue(); },
        "permission": n => { user_settings_opensearch_acl.permission = n.getEnumValue<User_settings_opensearch_acl_permission>(User_settings_opensearch_acl_permissionObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoValidate_registry(validate_registry: Partial<Validate_registry> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "name": n => { validate_registry.name = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoVersion2(version2: Partial<Version2> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "version": n => { version2.version = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoVolume_action_post_attach(volume_action_post_attach: Partial<Volume_action_post_attach> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoVolume_action_post_base(volume_action_post_attach),
        "droplet_id": n => { volume_action_post_attach.dropletId = n.getNumberValue(); },
        "tags": n => { volume_action_post_attach.tags = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoVolume_action_post_base(volume_action_post_base: Partial<Volume_action_post_base> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "region": n => { volume_action_post_base.region = n.getEnumValue<Region_slug>(Region_slugObject); },
        "type": n => { volume_action_post_base.type = n.getEnumValue<Volume_action_post_base_type>(Volume_action_post_base_typeObject); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoVolume_action_post_detach(volume_action_post_detach: Partial<Volume_action_post_detach> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoVolume_action_post_base(volume_action_post_detach),
        "droplet_id": n => { volume_action_post_detach.dropletId = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoVolume_action_post_resize(volume_action_post_resize: Partial<Volume_action_post_resize> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoVolume_action_post_base(volume_action_post_resize),
        "size_gigabytes": n => { volume_action_post_resize.sizeGigabytes = n.getNumberValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoVolume_base(volume_base: Partial<Volume_base> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { volume_base.createdAt = n.getStringValue(); },
        "description": n => { volume_base.description = n.getStringValue(); },
        "droplet_ids": n => { volume_base.dropletIds = n.getCollectionOfPrimitiveValues<number>(); },
        "id": n => { volume_base.id = n.getStringValue(); },
        "name": n => { volume_base.name = n.getStringValue(); },
        "size_gigabytes": n => { volume_base.sizeGigabytes = n.getNumberValue(); },
        "tags": n => { volume_base.tags = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoVolume_full(volume_full: Partial<Volume_full> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoVolume_base(volume_full),
        "filesystem_label": n => { volume_full.filesystemLabel = n.getStringValue(); },
        "filesystem_type": n => { volume_full.filesystemType = n.getStringValue(); },
        "region": n => { volume_full.region = n.getObjectValue<Region>(createRegionFromDiscriminatorValue); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoVolumeAction(volumeAction: Partial<VolumeAction> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        ...deserializeIntoAction(volumeAction),
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoVolumes_ext4(volumes_ext4: Partial<Volumes_ext4> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { volumes_ext4.createdAt = n.getStringValue(); },
        "description": n => { volumes_ext4.description = n.getStringValue(); },
        "droplet_ids": n => { volumes_ext4.dropletIds = n.getCollectionOfPrimitiveValues<number>(); },
        "filesystem_label": n => { volumes_ext4.filesystemLabel = n.getStringValue(); },
        "filesystem_type": n => { volumes_ext4.filesystemType = n.getStringValue(); },
        "id": n => { volumes_ext4.id = n.getStringValue(); },
        "name": n => { volumes_ext4.name = n.getStringValue(); },
        "region": n => { volumes_ext4.region = n.getEnumValue<Region_slug>(Region_slugObject); },
        "size_gigabytes": n => { volumes_ext4.sizeGigabytes = n.getNumberValue(); },
        "snapshot_id": n => { volumes_ext4.snapshotId = n.getStringValue(); },
        "tags": n => { volumes_ext4.tags = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoVolumes_xfs(volumes_xfs: Partial<Volumes_xfs> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { volumes_xfs.createdAt = n.getStringValue(); },
        "description": n => { volumes_xfs.description = n.getStringValue(); },
        "droplet_ids": n => { volumes_xfs.dropletIds = n.getCollectionOfPrimitiveValues<number>(); },
        "filesystem_label": n => { volumes_xfs.filesystemLabel = n.getStringValue(); },
        "filesystem_type": n => { volumes_xfs.filesystemType = n.getStringValue(); },
        "id": n => { volumes_xfs.id = n.getStringValue(); },
        "name": n => { volumes_xfs.name = n.getStringValue(); },
        "region": n => { volumes_xfs.region = n.getEnumValue<Region_slug>(Region_slugObject); },
        "size_gigabytes": n => { volumes_xfs.sizeGigabytes = n.getNumberValue(); },
        "snapshot_id": n => { volumes_xfs.snapshotId = n.getStringValue(); },
        "tags": n => { volumes_xfs.tags = n.getCollectionOfPrimitiveValues<string>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoVpc(vpc: Partial<Vpc> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { vpc.createdAt = n.getDateValue(); },
        "default": n => { vpc.defaultEscaped = n.getBooleanValue(); },
        "description": n => { vpc.description = n.getStringValue(); },
        "id": n => { vpc.id = n.getGuidValue(); },
        "ip_range": n => { vpc.ipRange = n.getStringValue(); },
        "name": n => { vpc.name = n.getStringValue(); },
        "region": n => { vpc.region = n.getStringValue(); },
        "urn": n => { vpc.urn = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoVpc_member(vpc_member: Partial<Vpc_member> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { vpc_member.createdAt = n.getStringValue(); },
        "name": n => { vpc_member.name = n.getStringValue(); },
        "urn": n => { vpc_member.urn = n.getStringValue(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoVpc_peering(vpc_peering: Partial<Vpc_peering> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "created_at": n => { vpc_peering.createdAt = n.getDateValue(); },
        "id": n => { vpc_peering.id = n.getGuidValue(); },
        "name": n => { vpc_peering.name = n.getStringValue(); },
        "status": n => { vpc_peering.status = n.getEnumValue<Vpc_peering_status>(Vpc_peering_statusObject); },
        "vpc_ids": n => { vpc_peering.vpcIds = n.getCollectionOfPrimitiveValues<Guid>(); },
    }
}
/**
 * The deserialization information for the current model
 * @returns {Record<string, (node: ParseNode) => void>}
 */
// @ts-ignore
export function deserializeIntoVpc_peering_updatable(vpc_peering_updatable: Partial<Vpc_peering_updatable> | undefined = {}) : Record<string, (node: ParseNode) => void> {
    return {
        "name": n => { vpc_peering_updatable.name = n.getStringValue(); },
    }
}
export interface Destination extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The config property
     */
    config?: Opensearch_config | null;
    /**
     * A unique identifier for a destination.
     */
    id?: string | null;
    /**
     * destination name
     */
    name?: string | null;
    /**
     * The destination type. `opensearch_dbaas` for a DigitalOcean managed OpenSearchcluster or `opensearch_ext` for an externally managed one.
     */
    type?: Destination_type | null;
}
export interface Destination_omit_credentials extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * OpenSearch destination configuration with `credentials` omitted.
     */
    config?: Opensearch_config_omit_credentials | null;
    /**
     * A unique identifier for a destination.
     */
    id?: string | null;
    /**
     * destination name
     */
    name?: string | null;
    /**
     * The destination type. `opensearch_dbaas` for a DigitalOcean managed OpenSearchcluster or `opensearch_ext` for an externally managed one.
     */
    type?: Destination_omit_credentials_type | null;
}
export type Destination_omit_credentials_type = (typeof Destination_omit_credentials_typeObject)[keyof typeof Destination_omit_credentials_typeObject];
export interface Destination_request extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The config property
     */
    config?: Opensearch_config_request | null;
    /**
     * destination name
     */
    name?: string | null;
    /**
     * The destination type. `opensearch_dbaas` for a DigitalOcean managed OpenSearchcluster or `opensearch_ext` for an externally managed one.
     */
    type?: Destination_request_type | null;
}
export type Destination_request_type = (typeof Destination_request_typeObject)[keyof typeof Destination_request_typeObject];
export type Destination_type = (typeof Destination_typeObject)[keyof typeof Destination_typeObject];
/**
 * An object containing the IDs of resources to be destroyed along with their associated with a Kubernetes cluster.
 */
export interface Destroy_associated_kubernetes_resources extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A list of IDs for associated load balancers to destroy along with the cluster.
     */
    loadBalancers?: string[] | null;
    /**
     * A list of IDs for associated volumes to destroy along with the cluster.
     */
    volumes?: string[] | null;
    /**
     * A list of IDs for associated volume snapshots to destroy along with the cluster.
     */
    volumeSnapshots?: string[] | null;
}
/**
 * An object containing information about a resource scheduled for deletion.
 */
export interface Destroyed_associated_resource extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A time value given in ISO8601 combined date and time format indicating when the resource was destroyed if the request was successful.
     */
    destroyedAt?: Date | null;
    /**
     * A string indicating that the resource was not successfully destroyed and providing additional information.
     */
    errorMessage?: string | null;
    /**
     * The unique identifier for the resource scheduled for deletion.
     */
    id?: string | null;
    /**
     * The name of the resource scheduled for deletion.
     */
    name?: string | null;
}
export interface Disk_info extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The size property
     */
    size?: Disk_info_size | null;
    /**
     * The type of disk. All Droplets contain a `local` disk. Additionally, GPU Droplets can also have a `scratch` disk for non-persistent data.
     */
    type?: Disk_info_type | null;
}
export interface Disk_info_size extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The amount of space allocated to the disk.
     */
    amount?: number | null;
    /**
     * The unit of measure for the disk size.
     */
    unit?: string | null;
}
export type Disk_info_type = (typeof Disk_info_typeObject)[keyof typeof Disk_info_typeObject];
export type Distribution = (typeof DistributionObject)[keyof typeof DistributionObject];
export interface Docker_credentials extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The auths property
     */
    auths?: Docker_credentials_auths | null;
}
export interface Docker_credentials_auths extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The registryDigitaloceanCom property
     */
    registryDigitaloceanCom?: Docker_credentials_auths_registryDigitaloceanCom | null;
}
export interface Docker_credentials_auths_registryDigitaloceanCom extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A base64 encoded string containing credentials for the container registry.
     */
    auth?: string | null;
}
export interface Domain extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * This optional attribute may contain an IP address. When provided, an A record will be automatically created pointing to the apex domain.
     */
    ipAddress?: string | null;
    /**
     * The name of the domain itself. This should follow the standard domain format of domain.TLD. For instance, `example.com` is a valid domain name.
     */
    name?: string | null;
    /**
     * This value is the time to live for the records on this domain, in seconds. This defines the time frame that clients can cache queried information before a refresh should be requested.
     */
    ttl?: number | null;
    /**
     * This attribute contains the complete contents of the zone file for the selected domain. Individual domain record resources should be used to get more granular control over records. However, this attribute can also be used to get information about the SOA record, which is created automatically and is not accessible as an individual record resource.
     */
    zoneFile?: string | null;
}
export interface Domain_record extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Variable data depending on record type. For example, the "data" value for an A record would be the IPv4 address to which the domain will be mapped. For a CAA record, it would contain the domain name of the CA being granted permission to issue certificates.
     */
    data?: string | null;
    /**
     * An unsigned integer between 0-255 used for CAA records.
     */
    flags?: number | null;
    /**
     * A unique identifier for each domain record.
     */
    id?: number | null;
    /**
     * The host name, alias, or service being defined by the record.
     */
    name?: string | null;
    /**
     * The port for SRV records.
     */
    port?: number | null;
    /**
     * The priority for SRV and MX records.
     */
    priority?: number | null;
    /**
     * The parameter tag for CAA records. Valid values are "issue", "issuewild", or "iodef"
     */
    tag?: string | null;
    /**
     * This value is the time to live for the record, in seconds. This defines the time frame that clients can cache queried information before a refresh should be requested.
     */
    ttl?: number | null;
    /**
     * The type of the DNS record. For example: A, CNAME, TXT, ...
     */
    type?: string | null;
    /**
     * The weight for SRV records.
     */
    weight?: number | null;
}
export interface Domain_record_a extends Domain_record, Parsable {
}
export interface Domain_record_aaaa extends Domain_record, Parsable {
}
export interface Domain_record_caa extends Domain_record, Parsable {
}
export interface Domain_record_cname extends Domain_record, Parsable {
}
export interface Domain_record_mx extends Domain_record, Parsable {
}
export interface Domain_record_ns extends Domain_record, Parsable {
}
export interface Domain_record_soa extends Domain_record, Parsable {
}
export interface Domain_record_srv extends Domain_record, Parsable {
}
export interface Domain_record_txt extends Domain_record, Parsable {
}
/**
 * An object specifying domain configurations for a Global load balancer.
 */
export interface Domains extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The ID of the TLS certificate used for SSL termination.
     */
    certificateId?: string | null;
    /**
     * A boolean value indicating if the domain is already managed by DigitalOcean. If true, all A and AAAA records required to enable Global load balancers will be automatically added.
     */
    isManaged?: boolean | null;
    /**
     * FQDN to associate with a Global load balancer.
     */
    name?: string | null;
}
export interface Droplet extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An array of backup IDs of any backups that have been taken of the Droplet instance.  Droplet backups are enabled at the time of the instance creation.
     */
    backupIds?: number[] | null;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the Droplet was created.
     */
    createdAt?: Date | null;
    /**
     * The size of the Droplet's disk in gigabytes.
     */
    disk?: number | null;
    /**
     * An array of objects containing information about the disks available to the Droplet.
     */
    diskInfo?: Disk_info[] | null;
    /**
     * An array of features enabled on this Droplet.
     */
    features?: string[] | null;
    /**
     * An object containing information about the GPU capabilities of Droplets created with this size.
     */
    gpuInfo?: Gpu_info | null;
    /**
     * A unique identifier for each Droplet instance. This is automatically generated upon Droplet creation.
     */
    id?: number | null;
    /**
     * The image property
     */
    image?: Image | null;
    /**
     * **Note**: All Droplets created after March 2017 use internal kernels by default.These Droplets will have this attribute set to `null`.The current [kernel](https://docs.digitalocean.com/products/droplets/how-to/kernel/)for Droplets with externally managed kernels. This will initially be set tothe kernel of the base image when the Droplet is created.
     * @deprecated 
     */
    kernel?: Kernel | null;
    /**
     * A boolean value indicating whether the Droplet has been locked, preventing actions by users.
     */
    locked?: boolean | null;
    /**
     * Memory of the Droplet in megabytes.
     */
    memory?: number | null;
    /**
     * The human-readable name set for the Droplet instance.
     */
    name?: string | null;
    /**
     * The details of the network that are configured for the Droplet instance.  This is an object that contains keys for IPv4 and IPv6.  The value of each of these is an array that contains objects describing an individual IP resource allocated to the Droplet.  These will define attributes like the IP address, netmask, and gateway of the specific network depending on the type of network it is.
     */
    networks?: Droplet_networks | null;
    /**
     * The next_backup_window property
     */
    nextBackupWindow?: Droplet_next_backup_window | null;
    /**
     * The region property
     */
    region?: Region | null;
    /**
     * The size property
     */
    size?: Size | null;
    /**
     * The unique slug identifier for the size of this Droplet.
     */
    sizeSlug?: string | null;
    /**
     * An array of snapshot IDs of any snapshots created from the Droplet instance.
     */
    snapshotIds?: number[] | null;
    /**
     * A status string indicating the state of the Droplet instance. This may be "new", "active", "off", or "archive".
     */
    status?: Droplet_status | null;
    /**
     * An array of Tags the Droplet has been tagged with.
     */
    tags?: string[] | null;
    /**
     * The number of virtual CPUs.
     */
    vcpus?: number | null;
    /**
     * A flat array including the unique identifier for each Block Storage volume attached to the Droplet.
     */
    volumeIds?: string[] | null;
    /**
     * A string specifying the UUID of the VPC to which the Droplet is assigned.
     */
    vpcUuid?: string | null;
}
/**
 * Specifies the action that will be taken on the Droplet.
 */
export interface Droplet_action extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The type of action to initiate for the Droplet.
     */
    type?: Droplet_action_type | null;
}
export interface Droplet_action_change_backup_policy extends Droplet_action, Parsable {
    /**
     * The backup_policy property
     */
    backupPolicy?: Droplet_backup_policy | null;
}
export interface Droplet_action_change_kernel extends Droplet_action, Parsable {
    /**
     * A unique number used to identify and reference a specific kernel.
     */
    kernel?: number | null;
}
export interface Droplet_action_enable_backups extends Droplet_action, Parsable {
    /**
     * The backup_policy property
     */
    backupPolicy?: Droplet_backup_policy | null;
}
export interface Droplet_action_rebuild extends Droplet_action, Parsable {
    /**
     * The image ID of a public or private image or the slug identifier for a public image. The Droplet will be rebuilt using this image as its base.
     */
    image?: number | string | null;
}
export type Droplet_action_rebuild_image = number | string;
export interface Droplet_action_rename extends Droplet_action, Parsable {
    /**
     * The new name for the Droplet.
     */
    name?: string | null;
}
export interface Droplet_action_resize extends Droplet_action, Parsable {
    /**
     * When `true`, the Droplet's disk will be resized in addition to its RAM and CPU. This is a permanent change and cannot be reversed as a Droplet's disk size cannot be decreased.
     */
    disk?: boolean | null;
    /**
     * The slug identifier for the size to which you wish to resize the Droplet.
     */
    size?: string | null;
}
export interface Droplet_action_restore extends Droplet_action, Parsable {
    /**
     * The ID of a backup of the current Droplet instance to restore from.
     */
    image?: number | null;
}
export interface Droplet_action_snapshot extends Droplet_action, Parsable {
    /**
     * The name to give the new snapshot of the Droplet.
     */
    name?: string | null;
}
export type Droplet_action_type = (typeof Droplet_action_typeObject)[keyof typeof Droplet_action_typeObject];
export interface Droplet_backup_policy extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The hour of the day that the backup window will start.
     */
    hour?: number | null;
    /**
     * The backup plan used for the Droplet. The plan can be either `daily` or `weekly`.
     */
    plan?: Droplet_backup_policy_plan | null;
    /**
     * The number of days the backup will be retained.
     */
    retentionPeriodDays?: number | null;
    /**
     * The day of the week on which the backup will occur.
     */
    weekday?: Droplet_backup_policy_weekday | null;
    /**
     * The length of the backup window starting from `hour`.
     */
    windowLengthHours?: number | null;
}
export type Droplet_backup_policy_plan = (typeof Droplet_backup_policy_planObject)[keyof typeof Droplet_backup_policy_planObject];
export interface Droplet_backup_policy_record extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A boolean value indicating whether backups are enabled for the Droplet.
     */
    backupEnabled?: boolean | null;
    /**
     * The backup_policy property
     */
    backupPolicy?: Droplet_backup_policy | null;
    /**
     * The unique identifier for the Droplet.
     */
    dropletId?: number | null;
    /**
     * The next_backup_window property
     */
    nextBackupWindow?: Droplet_next_backup_window | null;
}
export type Droplet_backup_policy_weekday = (typeof Droplet_backup_policy_weekdayObject)[keyof typeof Droplet_backup_policy_weekdayObject];
export interface Droplet_create extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The backup_policy property
     */
    backupPolicy?: Droplet_backup_policy | null;
    /**
     * A boolean indicating whether automated backups should be enabled for the Droplet.
     */
    backups?: boolean | null;
    /**
     * The image ID of a public or private image or the slug identifier for a public image. This image will be the base image for your Droplet.
     */
    image?: number | string | null;
    /**
     * A boolean indicating whether to enable IPv6 on the Droplet.
     */
    ipv6?: boolean | null;
    /**
     * A boolean indicating whether to install the DigitalOcean agent for monitoring.
     */
    monitoring?: boolean | null;
    /**
     * This parameter has been deprecated. Use `vpc_uuid` instead to specify a VPC network for the Droplet. If no `vpc_uuid` is provided, the Droplet will be placed in your account's default VPC for the region.
     * @deprecated 
     */
    privateNetworking?: boolean | null;
    /**
     * The slug identifier for the region that you wish to deploy the Droplet in. If the specific datacenter is not not important, a slug prefix (e.g. `nyc`) can be used to deploy the Droplet in any of the that region's locations (`nyc1`, `nyc2`, or `nyc3`). If the region is omitted from the create request completely, the Droplet may deploy in any region.
     */
    region?: string | null;
    /**
     * The slug identifier for the size that you wish to select for this Droplet.
     */
    size?: string | null;
    /**
     * An array containing the IDs or fingerprints of the SSH keys that you wish to embed in the Droplet's root account upon creation.
     */
    sshKeys?: string[] | null;
    /**
     * A flat array of tag names as strings to apply to the Droplet after it is created. Tag names can either be existing or new tags.
     */
    tags?: string[] | null;
    /**
     * A string containing 'user data' which may be used to configure the Droplet on first boot, often a 'cloud-config' file or Bash script. It must be plain text and may not exceed 64 KiB in size.
     */
    userData?: string | null;
    /**
     * An array of IDs for block storage volumes that will be attached to the Droplet once created. The volumes must not already be attached to an existing Droplet.
     */
    volumes?: string[] | null;
    /**
     * A string specifying the UUID of the VPC to which the Droplet will be assigned. If excluded, the Droplet will be assigned to your account's default VPC for the region.
     */
    vpcUuid?: string | null;
    /**
     * A boolean indicating whether to install the DigitalOcean agent used for providing access to the Droplet web console in the control panel. By default, the agent is installed on new Droplets but installation errors (i.e. OS not supported) are ignored. To prevent it from being installed, set to `false`. To make installation errors fatal, explicitly set it to `true`.
     */
    withDropletAgent?: boolean | null;
}
export type Droplet_create_image = number | string;
export interface Droplet_multi_create extends Droplet_create, Parsable {
    /**
     * An array of human human-readable strings you wish to use when displaying the Droplet name. Each name, if set to a domain name managed in the DigitalOcean DNS management system, will configure a PTR record for the Droplet. Each name set during creation will also determine the hostname for the Droplet in its internal configuration.
     */
    names?: string[] | null;
}
/**
 * The details of the network that are configured for the Droplet instance.  This is an object that contains keys for IPv4 and IPv6.  The value of each of these is an array that contains objects describing an individual IP resource allocated to the Droplet.  These will define attributes like the IP address, netmask, and gateway of the specific network depending on the type of network it is.
 */
export interface Droplet_networks extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The v4 property
     */
    v4?: Network_v4[] | null;
    /**
     * The v6 property
     */
    v6?: Network_v6[] | null;
}
export interface Droplet_next_backup_window extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A time value given in ISO8601 combined date and time format specifying the end of the Droplet's backup window.
     */
    end?: Date | null;
    /**
     * A time value given in ISO8601 combined date and time format specifying the start of the Droplet's backup window.
     */
    start?: Date | null;
}
export interface Droplet_single_create extends Droplet_create, Parsable {
    /**
     * The human-readable string you wish to use when displaying the Droplet name. The name, if set to a domain name managed in the DigitalOcean DNS management system, will configure a PTR record for the Droplet. The name set during creation will also determine the hostname for the Droplet in its internal configuration.
     */
    name?: string | null;
}
export interface Droplet_snapshot extends Parsable, Snapshots_base {
    /**
     * The unique identifier for the snapshot or backup.
     */
    id?: number | null;
    /**
     * Describes the kind of image. It may be one of `snapshot` or `backup`. This specifies whether an image is a user-generated Droplet snapshot or automatically created Droplet backup.
     */
    type?: Droplet_snapshot_type | null;
}
export type Droplet_snapshot_type = (typeof Droplet_snapshot_typeObject)[keyof typeof Droplet_snapshot_typeObject];
export type Droplet_status = (typeof Droplet_statusObject)[keyof typeof Droplet_statusObject];
export interface Elasticsearch_logsink extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * PEM encoded CA certificate
     */
    ca?: string | null;
    /**
     * Maximum number of days of logs to keep
     */
    indexDaysMax?: number | null;
    /**
     * Elasticsearch index prefix
     */
    indexPrefix?: string | null;
    /**
     * Elasticsearch request timeout limit
     */
    timeout?: number | null;
    /**
     * Elasticsearch connection URL
     */
    url?: string | null;
}
export interface Error_with_root_causes extends AdditionalDataHolder, ApiError, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A message providing information about the error.
     */
    errorEscaped?: string | null;
    /**
     * A list of error messages.
     */
    messages?: string[] | null;
    /**
     * A list of underlying causes for the error, including details to help  resolve it when possible.
     */
    rootCauses?: string[] | null;
}
export interface ErrorEscaped extends AdditionalDataHolder, ApiError, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A short identifier corresponding to the HTTP status code returned. For  example, the ID for a response returning a 404 status code would be "not_found."
     */
    id?: string | null;
    /**
     * A message providing additional information about the error, including  details to help resolve it when possible.
     */
    messageEscaped?: string | null;
    /**
     * Optionally, some endpoints may include a request ID that should be  provided when reporting bugs or opening support tickets to help  identify the issue.
     */
    requestId?: string | null;
}
export interface Events_logs extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name of cluster.
     */
    clusterName?: string | null;
    /**
     * The time of the generation of a event.
     */
    createTime?: string | null;
    /**
     * Type of the event.
     */
    eventType?: Events_logs_event_type | null;
    /**
     * ID of the particular event.
     */
    id?: string | null;
}
export type Events_logs_event_type = (typeof Events_logs_event_typeObject)[keyof typeof Events_logs_event_typeObject];
export type Eviction_policy_model = (typeof Eviction_policy_modelObject)[keyof typeof Eviction_policy_modelObject];
export interface Firewall extends Firewall_rules, Parsable {
    /**
     * A time value given in ISO8601 combined date and time format that represents when the firewall was created.
     */
    createdAt?: Date | null;
    /**
     * An array containing the IDs of the Droplets assigned to the firewall.
     */
    dropletIds?: number[] | null;
    /**
     * A unique ID that can be used to identify and reference a firewall.
     */
    id?: string | null;
    /**
     * A human-readable name for a firewall. The name must begin with an alphanumeric character. Subsequent characters must either be alphanumeric characters, a period (.), or a dash (-).
     */
    name?: string | null;
    /**
     * An array of objects each containing the fields "droplet_id", "removing", and "status". It is provided to detail exactly which Droplets are having their security policies updated. When empty, all changes have been successfully applied.
     */
    pendingChanges?: Firewall_pending_changes[] | null;
    /**
     * A status string indicating the current state of the firewall. This can be "waiting", "succeeded", or "failed".
     */
    status?: Firewall_status | null;
    /**
     * The tags property
     */
    tags?: string[] | null;
}
export interface Firewall_pending_changes extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The droplet_id property
     */
    dropletId?: number | null;
    /**
     * The removing property
     */
    removing?: boolean | null;
    /**
     * The status property
     */
    status?: string | null;
}
export interface Firewall_rule extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A unique ID for the database cluster to which the rule is applied.
     */
    clusterUuid?: string | null;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the firewall rule was created.
     */
    createdAt?: Date | null;
    /**
     * The type of resource that the firewall rule allows to access the database cluster.
     */
    type?: Firewall_rule_type | null;
    /**
     * A unique ID for the firewall rule itself.
     */
    uuid?: string | null;
    /**
     * The ID of the specific resource, the name of a tag applied to a group of resources, or the IP address that the firewall rule allows to access the database cluster.
     */
    value?: string | null;
}
export interface Firewall_rule_base extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The ports on which traffic will be allowed specified as a string containing a single port, a range (e.g. "8000-9000"), or "0" when all ports are open for a protocol. For ICMP rules this parameter will always return "0".
     */
    ports?: string | null;
    /**
     * The type of traffic to be allowed. This may be one of `tcp`, `udp`, or `icmp`.
     */
    protocol?: Firewall_rule_base_protocol | null;
}
export type Firewall_rule_base_protocol = (typeof Firewall_rule_base_protocolObject)[keyof typeof Firewall_rule_base_protocolObject];
export interface Firewall_rule_target extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An array of strings containing the IPv4 addresses, IPv6 addresses, IPv4 CIDRs, and/or IPv6 CIDRs to which the firewall will allow traffic.
     */
    addresses?: string[] | null;
    /**
     * An array containing the IDs of the Droplets to which the firewall will allow traffic.
     */
    dropletIds?: number[] | null;
    /**
     * An array containing the IDs of the Kubernetes clusters to which the firewall will allow traffic.
     */
    kubernetesIds?: string[] | null;
    /**
     * An array containing the IDs of the load balancers to which the firewall will allow traffic.
     */
    loadBalancerUids?: string[] | null;
    /**
     * The tags property
     */
    tags?: string[] | null;
}
export type Firewall_rule_type = (typeof Firewall_rule_typeObject)[keyof typeof Firewall_rule_typeObject];
export interface Firewall_rules extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The inbound_rules property
     */
    inboundRules?: Firewall_rules_inbound_rules[] | null;
    /**
     * The outbound_rules property
     */
    outboundRules?: Firewall_rules_outbound_rules[] | null;
}
export interface Firewall_rules_inbound_rules extends Firewall_rule_base, Parsable {
    /**
     * The sources property
     */
    sources?: Firewall_rule_target | null;
}
export interface Firewall_rules_outbound_rules extends Firewall_rule_base, Parsable {
    /**
     * The destinations property
     */
    destinations?: Firewall_rule_target | null;
}
export type Firewall_status = (typeof Firewall_statusObject)[keyof typeof Firewall_statusObject];
export interface Floating_ip extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The Droplet that the floating IP has been assigned to. When you query a floating IP, if it is assigned to a Droplet, the entire Droplet object will be returned. If it is not assigned, the value will be null.
     */
    droplet?: Droplet | null;
    /**
     * The public IP address of the floating IP. It also serves as its identifier.
     */
    ip?: string | null;
    /**
     * A boolean value indicating whether or not the floating IP has pending actions preventing new ones from being submitted.
     */
    locked?: boolean | null;
    /**
     * The UUID of the project to which the reserved IP currently belongs.
     */
    projectId?: Guid | null;
    /**
     * The region property
     */
    region?: Region | null;
}
export interface Floating_ip_action_assign extends FloatingIPsAction, Parsable {
    /**
     * The ID of the Droplet that the floating IP will be assigned to.
     */
    dropletId?: number | null;
}
export interface Floating_ip_action_unassign extends FloatingIPsAction, Parsable {
}
export interface Floating_ip_createMember1 extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The ID of the Droplet that the floating IP will be assigned to.
     */
    dropletId?: number | null;
}
export interface Floating_ip_createMember2 extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The UUID of the project to which the floating IP will be assigned.
     */
    projectId?: Guid | null;
    /**
     * The slug identifier for the region the floating IP will be reserved to.
     */
    region?: string | null;
}
export interface FloatingIPsAction extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The type of action to initiate for the floating IP.
     */
    type?: FloatingIPsAction_type | null;
}
export type FloatingIPsAction_type = (typeof FloatingIPsAction_typeObject)[keyof typeof FloatingIPsAction_typeObject];
export interface Forward_links extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * URI of the last page of the results.
     */
    last?: string | null;
    /**
     * URI of the next page of the results.
     */
    next?: string | null;
}
/**
 * An object specifying a forwarding rule for a load balancer.
 */
export interface Forwarding_rule extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The ID of the TLS certificate used for SSL termination if enabled.
     */
    certificateId?: string | null;
    /**
     * An integer representing the port on which the load balancer instance will listen.
     */
    entryPort?: number | null;
    /**
     * The protocol used for traffic to the load balancer. The possible values are: `http`, `https`, `http2`, `http3`, `tcp`, or `udp`. If you set the  `entry_protocol` to `udp`, the `target_protocol` must be set to `udp`.  When using UDP, the load balancer requires that you set up a health  check with a port that uses TCP, HTTP, or HTTPS to work properly.
     */
    entryProtocol?: Forwarding_rule_entry_protocol | null;
    /**
     * An integer representing the port on the backend Droplets to which the load balancer will send traffic.
     */
    targetPort?: number | null;
    /**
     * The protocol used for traffic from the load balancer to the backend Droplets. The possible values are: `http`, `https`, `http2`, `tcp`, or `udp`. If you set the `target_protocol` to `udp`, the `entry_protocol` must be set to  `udp`. When using UDP, the load balancer requires that you set up a health  check with a port that uses TCP, HTTP, or HTTPS to work properly.
     */
    targetProtocol?: Forwarding_rule_target_protocol | null;
    /**
     * A boolean value indicating whether SSL encrypted traffic will be passed through to the backend Droplets.
     */
    tlsPassthrough?: boolean | null;
}
export type Forwarding_rule_entry_protocol = (typeof Forwarding_rule_entry_protocolObject)[keyof typeof Forwarding_rule_entry_protocolObject];
export type Forwarding_rule_target_protocol = (typeof Forwarding_rule_target_protocolObject)[keyof typeof Forwarding_rule_target_protocolObject];
export interface Garbage_collection extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The number of blobs deleted as a result of this garbage collection.
     */
    blobsDeleted?: number | null;
    /**
     * The time the garbage collection was created.
     */
    createdAt?: Date | null;
    /**
     * The number of bytes freed as a result of this garbage collection.
     */
    freedBytes?: number | null;
    /**
     * The name of the container registry.
     */
    registryName?: string | null;
    /**
     * The current status of this garbage collection.
     */
    status?: Garbage_collection_status | null;
    /**
     * The time the garbage collection was last updated.
     */
    updatedAt?: Date | null;
    /**
     * A string specifying the UUID of the garbage collection.
     */
    uuid?: string | null;
}
export type Garbage_collection_status = (typeof Garbage_collection_statusObject)[keyof typeof Garbage_collection_statusObject];
/**
 * Description for a specific Region
 */
export interface GenaiapiRegion extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Url for inference server
     */
    inferenceUrl?: string | null;
    /**
     * Region code
     */
    region?: string | null;
    /**
     * This datacenter is capable of running batch jobs
     */
    servesBatch?: boolean | null;
    /**
     * This datacenter is capable of serving inference
     */
    servesInference?: boolean | null;
    /**
     * The url for the inference streaming server
     */
    streamInferenceUrl?: string | null;
}
/**
 * An object specifying forwarding configurations for a Global load balancer.
 */
export interface Glb_settings extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An object specifying CDN configurations for a Global load balancer.
     */
    cdn?: Glb_settings_cdn | null;
    /**
     * An integer value as a percentage to indicate failure threshold to decide how the regional priorities will take effect. A value of `50` would indicate that the Global load balancer will choose a lower priority region to forward traffic to once this failure threshold has been reached for the higher priority region.
     */
    failoverThreshold?: number | null;
    /**
     * A map of region string to an integer priority value indicating preference for which regional target a Global load balancer will forward traffic to. A lower value indicates a higher priority.
     */
    regionPriorities?: Glb_settings_region_priorities | null;
    /**
     * An integer representing the port on the target backends which the load balancer will forward traffic to.
     */
    targetPort?: number | null;
    /**
     * The protocol used for forwarding traffic from the load balancer to the target backends. The possible values are `http`, `https` and `http2`.
     */
    targetProtocol?: Glb_settings_target_protocol | null;
}
/**
 * An object specifying CDN configurations for a Global load balancer.
 */
export interface Glb_settings_cdn extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A boolean flag to enable CDN caching.
     */
    isEnabled?: boolean | null;
}
/**
 * A map of region string to an integer priority value indicating preference for which regional target a Global load balancer will forward traffic to. A lower value indicates a higher priority.
 */
export interface Glb_settings_region_priorities extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
}
export type Glb_settings_target_protocol = (typeof Glb_settings_target_protocolObject)[keyof typeof Glb_settings_target_protocolObject];
/**
 * An object containing information about the GPU capabilities of Droplets created with this size.
 */
export interface Gpu_info extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The number of GPUs allocated to the Droplet.
     */
    count?: number | null;
    /**
     * The model of the GPU.
     */
    model?: string | null;
    /**
     * The vram property
     */
    vram?: Gpu_info_vram | null;
}
export interface Gpu_info_vram extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The amount of VRAM allocated to the GPU.
     */
    amount?: number | null;
    /**
     * The unit of measure for the VRAM.
     */
    unit?: string | null;
}
export interface Grant extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name of the bucket.
     */
    bucket?: string | null;
    /**
     * The permission to grant to the user. Possible values are `read`, `readwrite`, `fullaccess`, or an empty string.
     */
    permission?: string | null;
}
/**
 * An object specifying health check settings for the load balancer.
 */
export interface Health_check extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The number of seconds between between two consecutive health checks.
     */
    checkIntervalSeconds?: number | null;
    /**
     * The number of times a health check must pass for a backend Droplet to be marked "healthy" and be re-added to the pool.
     */
    healthyThreshold?: number | null;
    /**
     * The path on the backend Droplets to which the load balancer instance will send a request.
     */
    path?: string | null;
    /**
     * An integer representing the port on the backend Droplets on which the health check will attempt a connection.
     */
    port?: number | null;
    /**
     * The protocol used for health checks sent to the backend Droplets. The possible values are `http`, `https`, or `tcp`.
     */
    protocol?: Health_check_protocol | null;
    /**
     * The number of seconds the load balancer instance will wait for a response until marking a health check as failed.
     */
    responseTimeoutSeconds?: number | null;
    /**
     * The number of times a health check must fail for a backend Droplet to be marked "unhealthy" and be removed from the pool.
     */
    unhealthyThreshold?: number | null;
}
export type Health_check_protocol = (typeof Health_check_protocolObject)[keyof typeof Health_check_protocolObject];
export interface History extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The creation time of the history event in ISO8601 combined date and time format.
     */
    createdAt?: Date | null;
    /**
     * The current number of Droplets in the autoscale pool.
     */
    currentInstanceCount?: number | null;
    /**
     * The target number of Droplets for the autoscale pool after the scaling event.
     */
    desiredInstanceCount?: number | null;
    /**
     * The unique identifier of the history event.
     */
    historyEventId?: string | null;
    /**
     * The reason for the scaling event.
     */
    reason?: History_reason | null;
    /**
     * The status of the scaling event.
     */
    status?: History_status | null;
    /**
     * The last updated time of the history event in ISO8601 combined date and time format.
     */
    updatedAt?: Date | null;
}
export type History_reason = (typeof History_reasonObject)[keyof typeof History_reasonObject];
export type History_status = (typeof History_statusObject)[keyof typeof History_statusObject];
export interface Image extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the image was created.
     */
    createdAt?: Date | null;
    /**
     * An optional free-form text field to describe an image.
     */
    description?: string | null;
    /**
     * The name of a custom image's distribution. Currently, the valid values are  `Arch Linux`, `CentOS`, `CoreOS`, `Debian`, `Fedora`, `Fedora Atomic`,  `FreeBSD`, `Gentoo`, `openSUSE`, `RancherOS`, `Rocky Linux`, `Ubuntu`, and `Unknown`.  Any other value will be accepted but ignored, and `Unknown` will be used in its place.
     */
    distribution?: Distribution | null;
    /**
     * A string containing information about errors that may occur when importing a custom image.
     */
    errorMessage?: string | null;
    /**
     * A unique number that can be used to identify and reference a specific image.
     */
    id?: number | null;
    /**
     * The minimum disk size in GB required for a Droplet to use this image.
     */
    minDiskSize?: number | null;
    /**
     * The display name that has been given to an image.  This is what is shown in the control panel and is generally a descriptive title for the image in question.
     */
    name?: string | null;
    /**
     * This is a boolean value that indicates whether the image in question is public or not. An image that is public is available to all accounts. A non-public image is only accessible from your account.
     */
    public?: boolean | null;
    /**
     * This attribute is an array of the regions that the image is available in. The regions are represented by their identifying slug values.
     */
    regions?: Region_slug[] | null;
    /**
     * The size of the image in gigabytes.
     */
    sizeGigabytes?: number | null;
    /**
     * A uniquely identifying string that is associated with each of the DigitalOcean-provided public images. These can be used to reference a public image as an alternative to the numeric id.
     */
    slug?: string | null;
    /**
     * A status string indicating the state of a custom image. This may be `NEW`, `available`, `pending`, `deleted`, or `retired`.
     */
    status?: Image_status | null;
    /**
     * A flat array of tag names as strings to be applied to the resource. Tag names may be for either existing or new tags.
     */
    tags?: string[] | null;
    /**
     * Describes the kind of image. It may be one of `base`, `snapshot`, `backup`, `custom`, or `admin`. Respectively, this specifies whether an image is a DigitalOcean base OS image, user-generated Droplet snapshot, automatically created Droplet backup, user-provided virtual machine image, or an image used for DigitalOcean managed resources (e.g. DOKS worker nodes).
     */
    type?: Image_type | null;
}
export interface Image_action_base extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The action to be taken on the image. Can be either `convert` or `transfer`.
     */
    type?: Image_action_base_type | null;
}
export type Image_action_base_type = (typeof Image_action_base_typeObject)[keyof typeof Image_action_base_typeObject];
export interface Image_action_transfer extends Image_action_base, Parsable {
    /**
     * The slug identifier for the region where the resource will initially be  available.
     */
    region?: Region_slug | null;
}
export interface Image_new_custom extends Image_update, Parsable {
    /**
     * The slug identifier for the region where the resource will initially be  available.
     */
    region?: Region_slug | null;
    /**
     * A flat array of tag names as strings to be applied to the resource. Tag names may be for either existing or new tags.
     */
    tags?: string[] | null;
    /**
     * A URL from which the custom Linux virtual machine image may be retrieved.  The image it points to must be in the raw, qcow2, vhdx, vdi, or vmdk format.  It may be compressed using gzip or bzip2 and must be smaller than 100 GB after being decompressed.
     */
    url?: string | null;
}
export type Image_status = (typeof Image_statusObject)[keyof typeof Image_statusObject];
export type Image_type = (typeof Image_typeObject)[keyof typeof Image_typeObject];
export interface Image_update extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An optional free-form text field to describe an image.
     */
    description?: string | null;
    /**
     * The name of a custom image's distribution. Currently, the valid values are  `Arch Linux`, `CentOS`, `CoreOS`, `Debian`, `Fedora`, `Fedora Atomic`,  `FreeBSD`, `Gentoo`, `openSUSE`, `RancherOS`, `Rocky Linux`, `Ubuntu`, and `Unknown`.  Any other value will be accepted but ignored, and `Unknown` will be used in its place.
     */
    distribution?: Distribution | null;
    /**
     * The display name that has been given to an image.  This is what is shown in the control panel and is generally a descriptive title for the image in question.
     */
    name?: string | null;
}
export type Instance_size_cpu_type = (typeof Instance_size_cpu_typeObject)[keyof typeof Instance_size_cpu_typeObject];
export interface Invoice_item extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Billed amount of this invoice item. Billed in USD.
     */
    amount?: string | null;
    /**
     * Description of the invoice item.
     */
    description?: string | null;
    /**
     * Duration of time this invoice item was used and subsequently billed.
     */
    duration?: string | null;
    /**
     * Unit of time for duration.
     */
    durationUnit?: string | null;
    /**
     * Time the invoice item stopped being billed for usage.
     */
    endTime?: string | null;
    /**
     * Description of the invoice item when it is a grouped set of usage, such  as DOKS or databases.
     */
    groupDescription?: string | null;
    /**
     * Name of the product being billed in the invoice item.
     */
    product?: string | null;
    /**
     * Name of the DigitalOcean Project this resource belongs to.
     */
    projectName?: string | null;
    /**
     * ID of the resource billing in the invoice item if available.
     */
    resourceId?: string | null;
    /**
     * UUID of the resource billing in the invoice item if available.
     */
    resourceUuid?: string | null;
    /**
     * Time the invoice item began to be billed for usage.
     */
    startTime?: string | null;
}
/**
 * The invoice preview.
 */
export interface Invoice_preview extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Total amount of the invoice, in USD.  This will reflect month-to-date usage in the invoice preview.
     */
    amount?: string | null;
    /**
     * ID of the invoice. Listed on the face of the invoice PDF as the "Invoice number".
     */
    invoiceId?: string | null;
    /**
     * Billing period of usage for which the invoice is issued, in `YYYY-MM`  format.
     */
    invoicePeriod?: string | null;
    /**
     * The UUID of the invoice. The canonical reference for the invoice.
     */
    invoiceUuid?: string | null;
    /**
     * Time the invoice was last updated.  This is only included with the invoice preview.
     */
    updatedAt?: string | null;
}
export interface Invoice_summary extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Total amount of the invoice, in USD.  This will reflect month-to-date usage in the invoice preview.
     */
    amount?: string | null;
    /**
     * Billing period of usage for which the invoice is issued, in `YYYY-MM`  format.
     */
    billingPeriod?: string | null;
    /**
     * The credits_and_adjustments property
     */
    creditsAndAdjustments?: Simple_charge | null;
    /**
     * ID of the invoice
     */
    invoiceId?: string | null;
    /**
     * UUID of the invoice
     */
    invoiceUuid?: string | null;
    /**
     * The overages property
     */
    overages?: Simple_charge | null;
    /**
     * The product_charges property
     */
    productCharges?: Product_usage_charges | null;
    /**
     * The taxes property
     */
    taxes?: Simple_charge | null;
    /**
     * The user_billing_address property
     */
    userBillingAddress?: Billing_address | null;
    /**
     * Company of the DigitalOcean customer being invoiced, if set.
     */
    userCompany?: string | null;
    /**
     * Email of the DigitalOcean customer being invoiced.
     */
    userEmail?: string | null;
    /**
     * Name of the DigitalOcean customer being invoiced.
     */
    userName?: string | null;
}
export interface Kafka_advanced_config extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Enable auto creation of topics
     */
    autoCreateTopicsEnable?: boolean | null;
    /**
     * Specify the final compression type for a given topic. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'uncompressed' which is equivalent to no compression; and 'producer' which means retain the original compression codec set by the producer.
     */
    compressionType?: Kafka_advanced_config_compression_type | null;
    /**
     * Idle connections timeout: the server socket processor threads close the connections that idle for longer than this.
     */
    connectionsMaxIdleMs?: number | null;
    /**
     * Replication factor for autocreated topics
     */
    defaultReplicationFactor?: number | null;
    /**
     * The amount of time, in milliseconds, the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins. The default value for this is 3 seconds. During development and testing it might be desirable to set this to 0 in order to not delay test execution time.
     */
    groupInitialRebalanceDelayMs?: number | null;
    /**
     * The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
     */
    groupMaxSessionTimeoutMs?: number | null;
    /**
     * The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
     */
    groupMinSessionTimeoutMs?: number | null;
    /**
     * How long are delete records retained?
     */
    logCleanerDeleteRetentionMs?: number | null;
    /**
     * The maximum amount of time message will remain uncompacted. Only applicable for logs that are being compacted
     */
    logCleanerMaxCompactionLagMs?: number | null;
    /**
     * Controls log compactor frequency. Larger value means more frequent compactions but also more space wasted for logs. Consider setting log_cleaner_max_compaction_lag_ms to enforce compactions sooner, instead of setting a very high value for this option.
     */
    logCleanerMinCleanableRatio?: number | null;
    /**
     * The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted.
     */
    logCleanerMinCompactionLagMs?: number | null;
    /**
     * The default cleanup policy for segments beyond the retention window
     */
    logCleanupPolicy?: Kafka_advanced_config_log_cleanup_policy | null;
    /**
     * The number of messages accumulated on a log partition before messages are flushed to disk
     */
    logFlushIntervalMessages?: number | null;
    /**
     * The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used
     */
    logFlushIntervalMs?: number | null;
    /**
     * The interval with which Kafka adds an entry to the offset index
     */
    logIndexIntervalBytes?: number | null;
    /**
     * The maximum size in bytes of the offset index
     */
    logIndexSizeMaxBytes?: number | null;
    /**
     * This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests.
     */
    logMessageDownconversionEnable?: boolean | null;
    /**
     * The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message
     */
    logMessageTimestampDifferenceMaxMs?: number | null;
    /**
     * Define whether the timestamp in the message is message create time or log append time.
     */
    logMessageTimestampType?: Kafka_advanced_config_log_message_timestamp_type | null;
    /**
     * Controls whether to preallocate a file when creating a new segment
     */
    logPreallocate?: boolean | null;
    /**
     * The maximum size of the log before deleting messages
     */
    logRetentionBytes?: number | null;
    /**
     * The number of hours to keep a log file before deleting it
     */
    logRetentionHours?: number | null;
    /**
     * The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
     */
    logRetentionMs?: number | null;
    /**
     * The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used
     */
    logRollJitterMs?: number | null;
    /**
     * The maximum time before a new log segment is rolled out (in milliseconds).
     */
    logRollMs?: number | null;
    /**
     * The maximum size of a single log file
     */
    logSegmentBytes?: number | null;
    /**
     * The amount of time to wait before deleting a file from the filesystem
     */
    logSegmentDeleteDelayMs?: number | null;
    /**
     * The maximum number of connections allowed from each ip address (defaults to 2147483647).
     */
    maxConnectionsPerIp?: number | null;
    /**
     * The maximum number of incremental fetch sessions that the broker will maintain.
     */
    maxIncrementalFetchSessionCacheSlots?: number | null;
    /**
     * The maximum size of message that the server can receive.
     */
    messageMaxBytes?: number | null;
    /**
     * When a producer sets acks to 'all' (or '-1'), min_insync_replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful.
     */
    minInsyncReplicas?: number | null;
    /**
     * Number of partitions for autocreated topics
     */
    numPartitions?: number | null;
    /**
     * Log retention window in minutes for offsets topic
     */
    offsetsRetentionMinutes?: number | null;
    /**
     * The purge interval (in number of requests) of the producer request purgatory (defaults to 1000).
     */
    producerPurgatoryPurgeIntervalRequests?: number | null;
    /**
     * The number of bytes of messages to attempt to fetch for each partition (defaults to 1048576). This is not an absolute maximum, if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made.
     */
    replicaFetchMaxBytes?: number | null;
    /**
     * Maximum bytes expected for the entire fetch response (defaults to 10485760). Records are fetched in batches, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made. As such, this is not an absolute maximum.
     */
    replicaFetchResponseMaxBytes?: number | null;
    /**
     * The maximum number of bytes in a socket request (defaults to 104857600).
     */
    socketRequestMaxBytes?: number | null;
    /**
     * The interval at which to remove transactions that have expired due to transactional.id.expiration.ms passing (defaults to 3600000 (1 hour)).
     */
    transactionRemoveExpiredTransactionCleanupIntervalMs?: number | null;
    /**
     * The transaction topic segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads (defaults to 104857600 (100 mebibytes)).
     */
    transactionStateLogSegmentBytes?: number | null;
}
export type Kafka_advanced_config_compression_type = (typeof Kafka_advanced_config_compression_typeObject)[keyof typeof Kafka_advanced_config_compression_typeObject];
export type Kafka_advanced_config_log_cleanup_policy = (typeof Kafka_advanced_config_log_cleanup_policyObject)[keyof typeof Kafka_advanced_config_log_cleanup_policyObject];
export type Kafka_advanced_config_log_message_timestamp_type = (typeof Kafka_advanced_config_log_message_timestamp_typeObject)[keyof typeof Kafka_advanced_config_log_message_timestamp_typeObject];
export interface Kafka_topic extends Kafka_topic_base, Parsable {
    /**
     * The state of the Kafka topic.
     */
    state?: Kafka_topic_state | null;
}
export interface Kafka_topic_base extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name of the Kafka topic.
     */
    name?: string | null;
    /**
     * The number of partitions available for the topic. On update, this value can only be increased.
     */
    partitionCount?: number | null;
    /**
     * The number of nodes to replicate data across the cluster.
     */
    replicationFactor?: number | null;
}
export interface Kafka_topic_config extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The cleanup_policy sets the retention policy to use on log segments. 'delete' will discard old segments when retention time/size limits are reached. 'compact' will enable log compaction, resulting in retention of the latest value for each key.
     */
    cleanupPolicy?: Kafka_topic_config_cleanup_policy | null;
    /**
     * The compression_type specifies the compression type of the topic.
     */
    compressionType?: Kafka_topic_config_compression_type | null;
    /**
     * The delete_retention_ms specifies how long (in ms) to retain delete tombstone markers for topics.
     */
    deleteRetentionMs?: number | null;
    /**
     * The file_delete_delay_ms specifies the time (in ms) to wait before deleting a file from the filesystem.
     */
    fileDeleteDelayMs?: number | null;
    /**
     * The flush_messages specifies the number of messages to accumulate on a log partition before messages are flushed to disk.
     */
    flushMessages?: number | null;
    /**
     * The flush_ms specifies the maximum time (in ms) that a message is kept in memory before being flushed to disk.
     */
    flushMs?: number | null;
    /**
     * The index_interval_bytes specifies the number of bytes between entries being added into te offset index.
     */
    indexIntervalBytes?: number | null;
    /**
     * The max_compaction_lag_ms specifies the maximum amount of time (in ms) that a message will remain uncompacted. This is only applicable if the logs are have compaction enabled.
     */
    maxCompactionLagMs?: number | null;
    /**
     * The max_messages_bytes specifies the largest record batch size (in bytes) that can be sent to the server.  This is calculated after compression if compression is enabled.
     */
    maxMessageBytes?: number | null;
    /**
     * The message_down_conversion_enable specifies whether down-conversion of message formats is enabled to satisfy consumer requests. When 'false', the broker will not perform conversion for consumers expecting older message formats. The broker will respond with an `UNSUPPORTED_VERSION` error for consume requests from these older clients.
     */
    messageDownConversionEnable?: boolean | null;
    /**
     * The message_format_version specifies the message format version used by the broker to append messages to the logs. The value of this setting is assumed to be 3.0-IV1 if the broker protocol version is 3.0 or higher. By setting a  particular message format version, all existing messages on disk must be smaller or equal to the specified version.
     */
    messageFormatVersion?: Kafka_topic_config_message_format_version | null;
    /**
     * The message_timestamp_type specifies whether to use the message create time or log append time as the timestamp on a message.
     */
    messageTimestampType?: Kafka_topic_config_message_timestamp_type | null;
    /**
     * The min_cleanable_dirty_ratio specifies the frequency of log compaction (if enabled) in relation to duplicates present in the logs. For example, at 0.5, at most 50% of the log could be duplicates before compaction would begin.
     */
    minCleanableDirtyRatio?: number | null;
    /**
     * The min_compaction_lag_ms specifies the minimum time (in ms) that a message will remain uncompacted in the log. Only relevant if log compaction is enabled.
     */
    minCompactionLagMs?: number | null;
    /**
     * The min_insync_replicas specifies the number of replicas that must ACK a write for the write to be considered successful.
     */
    minInsyncReplicas?: number | null;
    /**
     * The preallocate specifies whether a file should be preallocated on disk when creating a new log segment.
     */
    preallocate?: boolean | null;
    /**
     * The retention_bytes specifies the maximum size of the log (in bytes) before deleting messages. -1 indicates that there is no limit.
     */
    retentionBytes?: number | null;
    /**
     * The retention_ms specifies the maximum amount of time (in ms) to keep a message before deleting it.
     */
    retentionMs?: number | null;
    /**
     * The segment_bytes specifies the maximum size of a single log file (in bytes).
     */
    segmentBytes?: number | null;
    /**
     * The segment_jitter_ms specifies the maximum random jitter subtracted from the scheduled segment roll time to avoid thundering herds of segment rolling.
     */
    segmentJitterMs?: number | null;
    /**
     * The segment_ms specifies the period of time after which the log will be forced to roll if the segment file isn't full. This ensures that retention can delete or compact old data.
     */
    segmentMs?: number | null;
}
export type Kafka_topic_config_cleanup_policy = (typeof Kafka_topic_config_cleanup_policyObject)[keyof typeof Kafka_topic_config_cleanup_policyObject];
export type Kafka_topic_config_compression_type = (typeof Kafka_topic_config_compression_typeObject)[keyof typeof Kafka_topic_config_compression_typeObject];
export type Kafka_topic_config_message_format_version = (typeof Kafka_topic_config_message_format_versionObject)[keyof typeof Kafka_topic_config_message_format_versionObject];
export type Kafka_topic_config_message_timestamp_type = (typeof Kafka_topic_config_message_timestamp_typeObject)[keyof typeof Kafka_topic_config_message_timestamp_typeObject];
export interface Kafka_topic_create extends Kafka_topic_base, Parsable {
    /**
     * The config property
     */
    config?: Kafka_topic_config | null;
}
export interface Kafka_topic_partition extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The consumer_groups property
     */
    consumerGroups?: Kafka_topic_partition_consumer_groups[] | null;
    /**
     * The earliest consumer offset amongst consumer groups.
     */
    earliestOffset?: number | null;
    /**
     * An identifier for the partition.
     */
    id?: number | null;
    /**
     * The number of nodes that are in-sync (have the latest data) for the given partition
     */
    inSyncReplicas?: number | null;
    /**
     * Size of the topic partition in bytes.
     */
    size?: number | null;
}
export interface Kafka_topic_partition_consumer_groups extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Name of the consumer group.
     */
    groupName?: string | null;
    /**
     * The current offset of the consumer group.
     */
    offset?: number | null;
}
export type Kafka_topic_state = (typeof Kafka_topic_stateObject)[keyof typeof Kafka_topic_stateObject];
export interface Kafka_topic_update extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The config property
     */
    config?: Kafka_topic_config | null;
    /**
     * The number of partitions available for the topic. On update, this value can only be increased.
     */
    partitionCount?: number | null;
    /**
     * The number of nodes to replicate data across the cluster.
     */
    replicationFactor?: number | null;
}
export interface Kafka_topic_verbose extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The config property
     */
    config?: Kafka_topic_config | null;
    /**
     * The name of the Kafka topic.
     */
    name?: string | null;
    /**
     * The partitions property
     */
    partitions?: Kafka_topic_partition[] | null;
    /**
     * The number of nodes to replicate data across the cluster.
     */
    replicationFactor?: number | null;
    /**
     * The state of the Kafka topic.
     */
    state?: Kafka_topic_verbose_state | null;
}
export type Kafka_topic_verbose_state = (typeof Kafka_topic_verbose_stateObject)[keyof typeof Kafka_topic_verbose_stateObject];
/**
 * **Note**: All Droplets created after March 2017 use internal kernels by default.These Droplets will have this attribute set to `null`.The current [kernel](https://docs.digitalocean.com/products/droplets/how-to/kernel/)for Droplets with externally managed kernels. This will initially be set tothe kernel of the base image when the Droplet is created.
 * @deprecated 
 */
export interface Kernel extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A unique number used to identify and reference a specific kernel.
     */
    id?: number | null;
    /**
     * The display name of the kernel. This is shown in the web UI and is generally a descriptive title for the kernel in question.
     */
    name?: string | null;
    /**
     * A standard kernel version string representing the version, patch, and release information.
     */
    version?: string | null;
}
export interface Key extends AdditionalDataHolder, Parsable {
    /**
     * The Access Key ID used to access a bucket.
     */
    accessKey?: string | null;
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The date and time the key was created.
     */
    createdAt?: Date | null;
    /**
     * The list of permissions for the access key.
     */
    grants?: Grant[] | null;
    /**
     * The access key's name.
     */
    name?: string | null;
}
export interface Key_create_response extends Key, Parsable {
    /**
     * The secret key used to access the bucket. We return secret keys only once upon creation. Make sure to copy the key and securely store it.
     */
    secretKey?: string | null;
}
export interface Kubernetes_node_pool extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A boolean value indicating whether auto-scaling is enabled for this node pool.
     */
    autoScale?: boolean | null;
    /**
     * The number of Droplet instances in the node pool.
     */
    count?: number | null;
    /**
     * A unique ID that can be used to identify and reference a specific node pool.
     */
    id?: Guid | null;
    /**
     * An object of key/value mappings specifying labels to apply to all nodes in a pool. Labels will automatically be applied to all existing nodes and any subsequent nodes added to the pool. Note that when a label is removed, it is not deleted from the nodes in the pool.
     */
    labels?: Kubernetes_node_pool_labels | null;
    /**
     * The maximum number of nodes that this node pool can be auto-scaled to. The value will be `0` if `auto_scale` is set to `false`.
     */
    maxNodes?: number | null;
    /**
     * The minimum number of nodes that this node pool can be auto-scaled to. The value will be `0` if `auto_scale` is set to `false`.
     */
    minNodes?: number | null;
    /**
     * A human-readable name for the node pool.
     */
    name?: string | null;
    /**
     * An object specifying the details of a specific worker node in a node pool.
     */
    nodes?: Node[] | null;
    /**
     * The slug identifier for the type of Droplet used as workers in the node pool.
     */
    size?: string | null;
    /**
     * An array containing the tags applied to the node pool. All node pools are automatically tagged `k8s`, `k8s-worker`, and `k8s:$K8S_CLUSTER_ID`.
     */
    tags?: string[] | null;
    /**
     * An array of taints to apply to all nodes in a pool. Taints will automatically be applied to all existing nodes and any subsequent nodes added to the pool. When a taint is removed, it is deleted from all nodes in the pool.
     */
    taints?: Kubernetes_node_pool_taint[] | null;
}
/**
 * An object of key/value mappings specifying labels to apply to all nodes in a pool. Labels will automatically be applied to all existing nodes and any subsequent nodes added to the pool. Note that when a label is removed, it is not deleted from the nodes in the pool.
 */
export interface Kubernetes_node_pool_labels extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
}
export interface Kubernetes_node_pool_taint extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * How the node reacts to pods that it won't tolerate. Available effect values are `NoSchedule`, `PreferNoSchedule`, and `NoExecute`.
     */
    effect?: Kubernetes_node_pool_taint_effect | null;
    /**
     * An arbitrary string. The `key` and `value` fields of the `taint` object form a key-value pair. For example, if the value of the `key` field is "special" and the value of the `value` field is "gpu", the key value pair would be `special=gpu`.
     */
    key?: string | null;
    /**
     * An arbitrary string. The `key` and `value` fields of the `taint` object form a key-value pair. For example, if the value of the `key` field is "special" and the value of the `value` field is "gpu", the key value pair would be `special=gpu`.
     */
    value?: string | null;
}
export type Kubernetes_node_pool_taint_effect = (typeof Kubernetes_node_pool_taint_effectObject)[keyof typeof Kubernetes_node_pool_taint_effectObject];
export interface Kubernetes_node_pool_update extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A boolean value indicating whether auto-scaling is enabled for this node pool.
     */
    autoScale?: boolean | null;
    /**
     * The number of Droplet instances in the node pool.
     */
    count?: number | null;
    /**
     * A unique ID that can be used to identify and reference a specific node pool.
     */
    id?: Guid | null;
    /**
     * An object of key/value mappings specifying labels to apply to all nodes in a pool. Labels will automatically be applied to all existing nodes and any subsequent nodes added to the pool. Note that when a label is removed, it is not deleted from the nodes in the pool.
     */
    labels?: Kubernetes_node_pool_update_labels | null;
    /**
     * The maximum number of nodes that this node pool can be auto-scaled to. The value will be `0` if `auto_scale` is set to `false`.
     */
    maxNodes?: number | null;
    /**
     * The minimum number of nodes that this node pool can be auto-scaled to. The value will be `0` if `auto_scale` is set to `false`.
     */
    minNodes?: number | null;
    /**
     * A human-readable name for the node pool.
     */
    name?: string | null;
    /**
     * An object specifying the details of a specific worker node in a node pool.
     */
    nodes?: Node[] | null;
    /**
     * An array containing the tags applied to the node pool. All node pools are automatically tagged `k8s`, `k8s-worker`, and `k8s:$K8S_CLUSTER_ID`.
     */
    tags?: string[] | null;
    /**
     * An array of taints to apply to all nodes in a pool. Taints will automatically be applied to all existing nodes and any subsequent nodes added to the pool. When a taint is removed, it is deleted from all nodes in the pool.
     */
    taints?: Kubernetes_node_pool_taint[] | null;
}
/**
 * An object of key/value mappings specifying labels to apply to all nodes in a pool. Labels will automatically be applied to all existing nodes and any subsequent nodes added to the pool. Note that when a label is removed, it is not deleted from the nodes in the pool.
 */
export interface Kubernetes_node_pool_update_labels extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
}
export interface Kubernetes_options extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The options property
     */
    options?: Kubernetes_options_options | null;
}
export interface Kubernetes_options_options extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The regions property
     */
    regions?: Kubernetes_region[] | null;
    /**
     * The sizes property
     */
    sizes?: Kubernetes_size[] | null;
    /**
     * The versions property
     */
    versions?: Kubernetes_version[] | null;
}
export interface Kubernetes_region extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A DigitalOcean region where Kubernetes is available.
     */
    name?: string | null;
    /**
     * The identifier for a region for use when creating a new cluster.
     */
    slug?: string | null;
}
export interface Kubernetes_size extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A Droplet size available for use in a Kubernetes node pool.
     */
    name?: string | null;
    /**
     * The identifier for a size for use when creating a new cluster.
     */
    slug?: string | null;
}
export interface Kubernetes_version extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The upstream version string for the version of Kubernetes provided by a given slug.
     */
    kubernetesVersion?: string | null;
    /**
     * The slug identifier for an available version of Kubernetes for use when creating or updating a cluster. The string contains both the upstream version of Kubernetes as well as the DigitalOcean revision.
     */
    slug?: string | null;
    /**
     * The features available with the version of Kubernetes provided by a given slug.
     */
    supportedFeatures?: string[] | null;
}
/**
 * An object specifying allow and deny rules to control traffic to the load balancer.
 */
export interface Lb_firewall extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * the rules for allowing traffic to the load balancer (in the form 'ip:1.2.3.4' or 'cidr:1.2.0.0/16')
     */
    allow?: string[] | null;
    /**
     * the rules for denying traffic to the load balancer (in the form 'ip:1.2.3.4' or 'cidr:1.2.0.0/16')
     */
    deny?: string[] | null;
}
export interface Load_balancer extends Load_balancer_base, Parsable {
    /**
     * An array containing the IDs of the Droplets assigned to the load balancer.
     */
    dropletIds?: number[] | null;
    /**
     * The region property
     */
    region?: Load_balancer_region | null;
    /**
     * The name of a Droplet tag corresponding to Droplets assigned to the load balancer.
     */
    tag?: string | null;
}
export interface Load_balancer_base extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * This field has been deprecated. You can no longer specify an algorithm for load balancers.
     * @deprecated 
     */
    algorithm?: Load_balancer_base_algorithm | null;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the load balancer was created.
     */
    createdAt?: Date | null;
    /**
     * A boolean value indicating whether to disable automatic DNS record creation for Let's Encrypt certificates that are added to the load balancer.
     */
    disableLetsEncryptDnsRecords?: boolean | null;
    /**
     * An array of objects specifying the domain configurations for a Global load balancer.
     */
    domains?: Domains[] | null;
    /**
     * A boolean value indicating whether HTTP keepalive connections are maintained to target Droplets.
     */
    enableBackendKeepalive?: boolean | null;
    /**
     * A boolean value indicating whether PROXY Protocol is in use.
     */
    enableProxyProtocol?: boolean | null;
    /**
     * An object specifying allow and deny rules to control traffic to the load balancer.
     */
    firewall?: Lb_firewall | null;
    /**
     * An array of objects specifying the forwarding rules for a load balancer.
     */
    forwardingRules?: Forwarding_rule[] | null;
    /**
     * An object specifying forwarding configurations for a Global load balancer.
     */
    glbSettings?: Glb_settings | null;
    /**
     * An object specifying health check settings for the load balancer.
     */
    healthCheck?: Health_check | null;
    /**
     * An integer value which configures the idle timeout for HTTP requests to the target droplets.
     */
    httpIdleTimeoutSeconds?: number | null;
    /**
     * A unique ID that can be used to identify and reference a load balancer.
     */
    id?: Guid | null;
    /**
     * An attribute containing the public-facing IP address of the load balancer.
     */
    ip?: string | null;
    /**
     * An attribute containing the public-facing IPv6 address of the load balancer. Note that this feature is currently in private preview.
     */
    ipv6?: string | null;
    /**
     * A human-readable name for a load balancer instance.
     */
    name?: string | null;
    /**
     * A string indicating whether the load balancer should be external or internal. Internal load balancers have no public IPs and are only accessible to resources on the same VPC network. This property cannot be updated after creating the load balancer.
     */
    network?: Load_balancer_base_network | null;
    /**
     * A string indicating whether the load balancer will support IPv4 or both IPv4 and IPv6 networking. This property cannot be updated after creating the load balancer. Note that this feature is in private preview.
     */
    networkStack?: Load_balancer_base_network_stack | null;
    /**
     * The ID of the project that the load balancer is associated with. If no ID is provided at creation, the load balancer associates with the user's default project. If an invalid project ID is provided, the load balancer will not be created.
     */
    projectId?: string | null;
    /**
     * A boolean value indicating whether HTTP requests to the load balancer on port 80 will be redirected to HTTPS on port 443.
     */
    redirectHttpToHttps?: boolean | null;
    /**
     * This field has been replaced by the `size_unit` field for all regions except in AMS2, NYC2, and SFO1. Each available load balancer size now equates to the load balancer having a set number of nodes.* `lb-small` = 1 node* `lb-medium` = 3 nodes* `lb-large` = 6 nodesYou can resize load balancers after creation up to once per hour. You cannot resize a load balancer within the first hour of its creation.
     * @deprecated 
     */
    size?: Load_balancer_base_size | null;
    /**
     * How many nodes the load balancer contains. Each additional node increases the load balancer's ability to manage more connections. Load balancers can be scaled up or down, and you can change the number of nodes after creation up to once per hour. This field is currently not available in the AMS2, NYC2, or SFO1 regions. Use the `size` field to scale load balancers that reside in these regions.
     */
    sizeUnit?: number | null;
    /**
     * A status string indicating the current state of the load balancer. This can be `new`, `active`, or `errored`.
     */
    status?: Load_balancer_base_status | null;
    /**
     * An object specifying sticky sessions settings for the load balancer.
     */
    stickySessions?: Sticky_sessions | null;
    /**
     * An array containing the UUIDs of the Regional load balancers to be used as target backends for a Global load balancer.
     */
    targetLoadBalancerIds?: string[] | null;
    /**
     * A string indicating whether the load balancer should be a standard regional HTTP load balancer, a regional network load balancer that routes traffic at the TCP/UDP transport layer, or a global load balancer.
     */
    type?: Load_balancer_base_type | null;
    /**
     * A string specifying the UUID of the VPC to which the load balancer is assigned.
     */
    vpcUuid?: Guid | null;
}
export type Load_balancer_base_algorithm = (typeof Load_balancer_base_algorithmObject)[keyof typeof Load_balancer_base_algorithmObject];
export type Load_balancer_base_network = (typeof Load_balancer_base_networkObject)[keyof typeof Load_balancer_base_networkObject];
export type Load_balancer_base_network_stack = (typeof Load_balancer_base_network_stackObject)[keyof typeof Load_balancer_base_network_stackObject];
export type Load_balancer_base_size = (typeof Load_balancer_base_sizeObject)[keyof typeof Load_balancer_base_sizeObject];
export type Load_balancer_base_status = (typeof Load_balancer_base_statusObject)[keyof typeof Load_balancer_base_statusObject];
export type Load_balancer_base_type = (typeof Load_balancer_base_typeObject)[keyof typeof Load_balancer_base_typeObject];
/**
 * The region where the load balancer instance is located. When setting a region, the value should be the slug identifier for the region. When you query a load balancer, an entire region object will be returned.
 */
export interface Load_balancer_region extends Parsable, Region {
}
export interface Logsink_base extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name of the Logsink
     */
    sinkName?: string | null;
    /**
     * The sink_type property
     */
    sinkType?: Logsink_base_sink_type | null;
}
export type Logsink_base_sink_type = (typeof Logsink_base_sink_typeObject)[keyof typeof Logsink_base_sink_typeObject];
export interface Logsink_base_verbose extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A unique identifier for Logsink
     */
    sinkId?: string | null;
    /**
     * The name of the Logsink
     */
    sinkName?: string | null;
    /**
     * The sink_type property
     */
    sinkType?: Logsink_base_verbose_sink_type | null;
}
export type Logsink_base_verbose_sink_type = (typeof Logsink_base_verbose_sink_typeObject)[keyof typeof Logsink_base_verbose_sink_typeObject];
export interface Logsink_create extends Logsink_base, Parsable {
    /**
     * The config property
     */
    config?: Elasticsearch_logsink | Opensearch_logsink | Rsyslog_logsink | null;
}
export type Logsink_create_config = Elasticsearch_logsink | Opensearch_logsink | Rsyslog_logsink;
export interface Logsink_update extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The config property
     */
    config?: Elasticsearch_logsink | Opensearch_logsink | Rsyslog_logsink | null;
}
export type Logsink_update_config = Elasticsearch_logsink | Opensearch_logsink | Rsyslog_logsink;
export interface Logsink_verbose extends Logsink_base_verbose, Parsable {
    /**
     * The config property
     */
    config?: Elasticsearch_logsink | Opensearch_logsink | Rsyslog_logsink | null;
}
export type Logsink_verbose_config = Elasticsearch_logsink | Opensearch_logsink | Rsyslog_logsink;
/**
 * An object specifying the maintenance window policy for the Kubernetes cluster.
 */
export interface Maintenance_policy extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The day of the maintenance window policy. May be one of `monday` through `sunday`, or `any` to indicate an arbitrary week day.
     */
    day?: Maintenance_policy_day | null;
    /**
     * The duration of the maintenance window policy in human-readable format.
     */
    duration?: string | null;
    /**
     * The start time in UTC of the maintenance window policy in 24-hour clock format / HH:MM notation (e.g., `15:00`).
     */
    startTime?: string | null;
}
export type Maintenance_policy_day = (typeof Maintenance_policy_dayObject)[keyof typeof Maintenance_policy_dayObject];
export interface Member extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The creation time of the Droplet in ISO8601 combined date and time format.
     */
    createdAt?: Date | null;
    /**
     * The current_utilization property
     */
    currentUtilization?: Member_current_utilization | null;
    /**
     * The unique identifier of the Droplet.
     */
    dropletId?: number | null;
    /**
     * The health status of the Droplet.
     */
    healthStatus?: string | null;
    /**
     * The power status of the Droplet.
     */
    status?: Member_status | null;
    /**
     * The last updated time of the Droplet in ISO8601 combined date and time format.
     */
    updatedAt?: Date | null;
}
export interface Member_current_utilization extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The CPU utilization average of the individual Droplet.
     */
    cpu?: number | null;
    /**
     * The memory utilization average of the individual Droplet.
     */
    memory?: number | null;
}
export type Member_status = (typeof Member_statusObject)[keyof typeof Member_statusObject];
/**
 * Information about the response itself.
 */
export interface Meta_properties extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Number of objects returned by the request.
     */
    total?: number | null;
}
export interface Metrics extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The data property
     */
    data?: Metrics_data | null;
    /**
     * The status property
     */
    status?: Metrics_status | null;
}
export interface Metrics_data extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Result of query.
     */
    result?: Metrics_result[] | null;
    /**
     * The resultType property
     */
    resultType?: Metrics_data_resultType | null;
}
export type Metrics_data_resultType = (typeof Metrics_data_resultTypeObject)[keyof typeof Metrics_data_resultTypeObject];
export interface Metrics_result extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An object containing the metric's labels. These labels are key/value pairs that vary depending on the metric being queried. For example, load balancer metrics contain a `lb_id` label, while Droplet metrics contain a `host_id` label, and App Platform metrics contain a `app_component` label.
     */
    metric?: Metrics_result_metric | null;
    /**
     * An array of values for the metric.
     */
    values?: UntypedNode | null;
}
/**
 * An object containing the metric's labels. These labels are key/value pairs that vary depending on the metric being queried. For example, load balancer metrics contain a `lb_id` label, while Droplet metrics contain a `host_id` label, and App Platform metrics contain a `app_component` label.
 */
export interface Metrics_result_metric extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
}
export type Metrics_status = (typeof Metrics_statusObject)[keyof typeof Metrics_statusObject];
export interface Mongo_advanced_config extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Specifies the default consistency behavior of reads from the database. Data that is returned from the query with may or may not have been acknowledged by all nodes in the replicaset depending on this value.  Learn more [here](https://www.mongodb.com/docs/manual/reference/read-concern/).
     */
    defaultReadConcern?: Mongo_advanced_config_default_read_concern | null;
    /**
     * Describes the level of acknowledgment requested from MongoDB for write operations clusters. This field can set to either `majority` or a number `0...n` which will describe the number of nodes that must acknowledge the write operation before it is fully accepted. Setting to `0` will request no acknowledgement of the write operation.  Learn more [here](https://www.mongodb.com/docs/manual/reference/write-concern/).
     */
    defaultWriteConcern?: string | null;
    /**
     * Operations that run for longer than this threshold are considered slow which are then recorded to the diagnostic logs.  Higher log levels (verbosity) will record all operations regardless of this threshold on the primary node.  *Changing this parameter will lead to a restart of the MongoDB service.* Learn more [here](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-operationProfiling.slowOpThresholdMs).
     */
    slowOpThresholdMs?: number | null;
    /**
     * Specifies the lifetime of multi-document transactions. Transactions that exceed this limit are considered expired and will be  aborted by a periodic cleanup process. The cleanup process runs every `transactionLifetimeLimitSeconds/2 seconds` or at least  once every 60 seconds. *Changing this parameter will lead to a restart of the MongoDB service.* Learn more [here](https://www.mongodb.com/docs/manual/reference/parameters/#mongodb-parameter-param.transactionLifetimeLimitSeconds).
     */
    transactionLifetimeLimitSeconds?: number | null;
    /**
     * The log message verbosity level. The verbosity level determines the amount of Informational and Debug messages MongoDB outputs. 0 includes informational messages while 1...5 increases the level to include debug messages. *Changing this parameter will lead to a restart of the MongoDB service.* Learn more [here](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-systemLog.verbosity).
     */
    verbosity?: number | null;
}
export type Mongo_advanced_config_default_read_concern = (typeof Mongo_advanced_config_default_read_concernObject)[keyof typeof Mongo_advanced_config_default_read_concernObject];
export interface Mysql_advanced_config extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The hour of day (in UTC) when backup for the service starts. New backup only starts if previous backup has already completed.
     */
    backupHour?: number | null;
    /**
     * The minute of the backup hour when backup for the service starts. New backup  only starts if previous backup has already completed.
     */
    backupMinute?: number | null;
    /**
     * The minimum amount of time, in seconds, to keep binlog entries before deletion.  This may be extended for services that require binlog entries for longer than the default, for example if using the MySQL Debezium Kafka connector.
     */
    binlogRetentionPeriod?: number | null;
    /**
     * The number of seconds that the mysqld server waits for a connect packet before responding with bad handshake.
     */
    connectTimeout?: number | null;
    /**
     * Default server time zone, in the form of an offset from UTC (from -12:00 to +12:00), a time zone name (EST), or 'SYSTEM' to use the MySQL server default.
     */
    defaultTimeZone?: string | null;
    /**
     * The maximum permitted result length, in bytes, for the GROUP_CONCAT() function.
     */
    groupConcatMaxLen?: number | null;
    /**
     * The time, in seconds, before cached statistics expire.
     */
    informationSchemaStatsExpiry?: number | null;
    /**
     * Specifies the maximum size of the InnoDB change buffer as a percentage of the buffer pool.
     */
    innodbChangeBufferMaxSize?: number | null;
    /**
     * Specifies whether flushing a page from the InnoDB buffer pool also flushes other dirty pages in the same extent.  - 0 &mdash; disables this functionality, dirty pages in the same extent are not flushed.  - 1 &mdash; flushes contiguous dirty pages in the same extent.  - 2 &mdash; flushes dirty pages in the same extent.
     */
    innodbFlushNeighbors?: number | null;
    /**
     * The minimum length of words that an InnoDB FULLTEXT index stores.
     */
    innodbFtMinTokenSize?: number | null;
    /**
     * The InnoDB FULLTEXT index stopword list for all InnoDB tables.
     */
    innodbFtServerStopwordTable?: string | null;
    /**
     * The time, in seconds, that an InnoDB transaction waits for a row lock. before giving up.
     */
    innodbLockWaitTimeout?: number | null;
    /**
     * The size of the buffer, in bytes, that InnoDB uses to write to the log files. on disk.
     */
    innodbLogBufferSize?: number | null;
    /**
     * The upper limit, in bytes, of the size of the temporary log files used during online DDL operations for InnoDB tables.
     */
    innodbOnlineAlterLogMaxSize?: number | null;
    /**
     * When enabled, records information about all deadlocks in InnoDB user transactions  in the error log. Disabled by default.
     */
    innodbPrintAllDeadlocks?: boolean | null;
    /**
     * The number of I/O threads for read operations in InnoDB. Changing this parameter will lead to a restart of the MySQL service.
     */
    innodbReadIoThreads?: number | null;
    /**
     * When enabled, transaction timeouts cause InnoDB to abort and roll back the entire transaction.
     */
    innodbRollbackOnTimeout?: boolean | null;
    /**
     * Defines the maximum number of threads permitted inside of InnoDB. A value of 0 (the default) is interpreted as infinite concurrency (no limit). This variable is intended for performance  tuning on high concurrency systems.
     */
    innodbThreadConcurrency?: number | null;
    /**
     * The number of I/O threads for write operations in InnoDB. Changing this parameter will lead to a restart of the MySQL service.
     */
    innodbWriteIoThreads?: number | null;
    /**
     * The time, in seconds, the server waits for activity on an interactive. connection before closing it.
     */
    interactiveTimeout?: number | null;
    /**
     * The storage engine for in-memory internal temporary tables.
     */
    internalTmpMemStorageEngine?: Mysql_advanced_config_internal_tmp_mem_storage_engine | null;
    /**
     * Defines the destination for logs. Can be `INSIGHTS`, `TABLE`, or both (`INSIGHTS,TABLE`), or `NONE` to disable logs. To specify both destinations, use `INSIGHTS,TABLE` (order matters). Default is NONE.
     */
    logOutput?: Mysql_advanced_config_log_output | null;
    /**
     * The time, in seconds, for a query to take to execute before  being captured by slow_query_logs. Default is 10 seconds.
     */
    longQueryTime?: number | null;
    /**
     * The size of the largest message, in bytes, that can be received by the server. Default is 67108864 (64M).
     */
    maxAllowedPacket?: number | null;
    /**
     * The maximum size, in bytes, of internal in-memory tables. Also set tmp_table_size. Default is 16777216 (16M)
     */
    maxHeapTableSize?: number | null;
    /**
     * Start sizes of connection buffer and result buffer, must be multiple of 1024. Changing this parameter will lead to a restart of the MySQL service.
     */
    netBufferLength?: number | null;
    /**
     * The time, in seconds, to wait for more data from an existing connection. aborting the read.
     */
    netReadTimeout?: number | null;
    /**
     * The number of seconds to wait for a block to be written to a connection before aborting the write.
     */
    netWriteTimeout?: number | null;
    /**
     * When enabled, captures slow queries. When disabled, also truncates the mysql.slow_log table. Default is false.
     */
    slowQueryLog?: boolean | null;
    /**
     * The sort buffer size, in bytes, for ORDER BY optimization. Default is 262144. (256K).
     */
    sortBufferSize?: number | null;
    /**
     * Global SQL mode. If empty, uses MySQL server defaults. Must only include uppercase alphabetic characters, underscores, and commas.
     */
    sqlMode?: string | null;
    /**
     * Require primary key to be defined for new tables or old tables modified with ALTER TABLE and fail if missing. It is recommended to always have primary keys because various functionality may break if any large table is missing them.
     */
    sqlRequirePrimaryKey?: boolean | null;
    /**
     * The maximum size, in bytes, of internal in-memory tables. Also set max_heap_table_size. Default is 16777216 (16M).
     */
    tmpTableSize?: number | null;
    /**
     * The number of seconds the server waits for activity on a noninteractive connection before closing it.
     */
    waitTimeout?: number | null;
}
export type Mysql_advanced_config_internal_tmp_mem_storage_engine = (typeof Mysql_advanced_config_internal_tmp_mem_storage_engineObject)[keyof typeof Mysql_advanced_config_internal_tmp_mem_storage_engineObject];
export type Mysql_advanced_config_log_output = (typeof Mysql_advanced_config_log_outputObject)[keyof typeof Mysql_advanced_config_log_outputObject];
export interface Mysql_settings extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A string specifying the authentication method to be used for connectionsto the MySQL user account. The valid values are `mysql_native_password`or `caching_sha2_password`. If excluded when creating a new user, thedefault for the version of MySQL in use will be used. As of MySQL 8.0, thedefault is `caching_sha2_password`.
     */
    authPlugin?: Mysql_settings_auth_plugin | null;
}
export type Mysql_settings_auth_plugin = (typeof Mysql_settings_auth_pluginObject)[keyof typeof Mysql_settings_auth_pluginObject];
export interface Namespace_info extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The namespace's API hostname. Each function in a namespace is provided an endpoint at the namespace's hostname.
     */
    apiHost?: string | null;
    /**
     * UTC time string.
     */
    createdAt?: string | null;
    /**
     * A random alpha numeric string. This key is used in conjunction with the namespace's UUID to authenticate a user to use the namespace via `doctl`, DigitalOcean's official CLI.
     */
    key?: string | null;
    /**
     * The namespace's unique name.
     */
    label?: string | null;
    /**
     * A unique string format of UUID with a prefix fn-.
     */
    namespace?: string | null;
    /**
     * The namespace's datacenter region.
     */
    region?: string | null;
    /**
     * UTC time string.
     */
    updatedAt?: string | null;
    /**
     * The namespace's Universally Unique Identifier.
     */
    uuid?: string | null;
}
export interface Neighbor_ids extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An array of arrays. Each array will contain a set of Droplet IDs for Droplets that share a physical server.
     */
    neighborIds?: UntypedNode | null;
}
export interface Network_v4 extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The gateway of the specified IPv4 network interface.For private interfaces, a gateway is not provided. This is denoted byreturning `nil` as its value.
     */
    gateway?: string | null;
    /**
     * The IP address of the IPv4 network interface.
     */
    ipAddress?: string | null;
    /**
     * The netmask of the IPv4 network interface.
     */
    netmask?: string | null;
    /**
     * The type of the IPv4 network interface.
     */
    type?: Network_v4_type | null;
}
export type Network_v4_type = (typeof Network_v4_typeObject)[keyof typeof Network_v4_typeObject];
export interface Network_v6 extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The gateway of the specified IPv6 network interface.
     */
    gateway?: string | null;
    /**
     * The IP address of the IPv6 network interface.
     */
    ipAddress?: string | null;
    /**
     * The netmask of the IPv6 network interface.
     */
    netmask?: number | null;
    /**
     * The type of the IPv6 network interface.**Note**: IPv6 private  networking is not currently supported.
     */
    type?: Network_v6_type | null;
}
export type Network_v6_type = (typeof Network_v6_typeObject)[keyof typeof Network_v6_typeObject];
export interface Node extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the node was created.
     */
    createdAt?: Date | null;
    /**
     * The ID of the Droplet used for the worker node.
     */
    dropletId?: string | null;
    /**
     * A unique ID that can be used to identify and reference the node.
     */
    id?: Guid | null;
    /**
     * An automatically generated, human-readable name for the node.
     */
    name?: string | null;
    /**
     * An object containing a `state` attribute whose value is set to a string indicating the current status of the node.
     */
    status?: Node_status | null;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the node was last updated.
     */
    updatedAt?: Date | null;
}
/**
 * An object containing a `state` attribute whose value is set to a string indicating the current status of the node.
 */
export interface Node_status extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A string indicating the current status of the node.
     */
    state?: Node_status_state | null;
}
export type Node_status_state = (typeof Node_status_stateObject)[keyof typeof Node_status_stateObject];
/**
 * The notification settings for a trigger alert.
 */
export interface Notification extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An email to notify on an alert trigger. The Email has to be one that is verified on that DigitalOcean account.
     */
    email?: string[] | null;
    /**
     * Slack integration details.
     */
    slack?: Notification_slack[] | null;
}
export interface Notification_slack extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Slack channel to notify of an alert trigger.
     */
    channel?: string | null;
    /**
     * Slack Webhook URL.
     */
    url?: string | null;
}
export interface OneClicks extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The slug identifier for the 1-Click application.
     */
    slug?: string | null;
    /**
     * The type of the 1-Click application.
     */
    type?: string | null;
}
export interface OneClicks_create extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An array of 1-Click Application slugs to be installed to the Kubernetes cluster.
     */
    addonSlugs?: string[] | null;
    /**
     * A unique ID for the Kubernetes cluster to which the 1-Click Applications will be installed.
     */
    clusterUuid?: string | null;
}
export interface Online_migration extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The time the migration was initiated, in ISO 8601 format.
     */
    createdAt?: string | null;
    /**
     * The ID of the most recent migration.
     */
    id?: string | null;
    /**
     * The current status of the migration.
     */
    status?: Online_migration_status | null;
}
export type Online_migration_status = (typeof Online_migration_statusObject)[keyof typeof Online_migration_statusObject];
export interface Opensearch_advanced_config extends AdditionalDataHolder, Parsable {
    /**
     * Specifices whether to allow automatic creation of indices.
     */
    actionAutoCreateIndexEnabled?: boolean | null;
    /**
     * Specifies whether to require explicit index names when deleting indices.
     */
    actionDestructiveRequiresName?: boolean | null;
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Maximum number of shards allowed per data node.
     */
    clusterMaxShardsPerNode?: number | null;
    /**
     * Maximum concurrent incoming/outgoing shard recoveries (normally replicas) are allowed to happen per node .
     */
    clusterRoutingAllocationNodeConcurrentRecoveries?: number | null;
    /**
     * Specifies whether to allow security audit logging.
     */
    enableSecurityAudit?: boolean | null;
    /**
     * Maximum content length for HTTP requests to the OpenSearch HTTP API, in bytes.
     */
    httpMaxContentLengthBytes?: number | null;
    /**
     * Maximum size of allowed headers, in bytes.
     */
    httpMaxHeaderSizeBytes?: number | null;
    /**
     * Maximum length of an HTTP URL, in bytes.
     */
    httpMaxInitialLineLengthBytes?: number | null;
    /**
     * Maximum amount of heap memory used for field data cache, expressed as a percentage. Decreasing the value too much will increase overhead of loading field data. Increasing the value too much will decrease amount of heap available for other operations.
     */
    indicesFielddataCacheSizePercentage?: number | null;
    /**
     * Total amount of heap used for indexing buffer before writing segments to disk, expressed as a percentage. Too low value will slow down indexing; too high value will increase indexing performance but causes performance issues for query performance.
     */
    indicesMemoryIndexBufferSizePercentage?: number | null;
    /**
     * Maximum amount of heap used for indexing buffer before writing segments to disk, in mb. Works in conjunction with indices_memory_index_buffer_size_percentage, each being enforced. The default is unbounded.
     */
    indicesMemoryMaxIndexBufferSizeMb?: number | null;
    /**
     * Minimum amount of heap used for indexing buffer before writing segments to disk, in mb. Works in conjunction with indices_memory_index_buffer_size_percentage, each being enforced.
     */
    indicesMemoryMinIndexBufferSizeMb?: number | null;
    /**
     * Maximum amount of heap used for query cache.  Too low value will decrease query performance and increase performance for other operations; too high value will cause issues with other functionality.
     */
    indicesQueriesCacheSizePercentage?: number | null;
    /**
     * Maximum number of clauses Lucene BooleanQuery can have.  Only increase it if necessary, as it may cause performance issues.
     */
    indicesQueryBoolMaxClauseCount?: number | null;
    /**
     * Maximum number of file chunks sent in parallel for each recovery.
     */
    indicesRecoveryMaxConcurrentFileChunks?: number | null;
    /**
     * Limits total inbound and outbound recovery traffic for each node, expressed in mb per second. Applies to both peer recoveries as well as snapshot recoveries (i.e., restores from a snapshot).
     */
    indicesRecoveryMaxMbPerSec?: number | null;
    /**
     * Specifies whether ISM is enabled or not.
     */
    ismEnabled?: boolean | null;
    /**
     * Specifies whether audit history is enabled or not. The logs from ISM are automatically indexed to a logs document.
     */
    ismHistoryEnabled?: boolean | null;
    /**
     * Maximum age before rolling over the audit history index, in hours.
     */
    ismHistoryMaxAgeHours?: number | null;
    /**
     * Maximum number of documents before rolling over the audit history index.
     */
    ismHistoryMaxDocs?: number | null;
    /**
     * The time between rollover checks for the audit history index, in hours.
     */
    ismHistoryRolloverCheckPeriodHours?: number | null;
    /**
     * Length of time long audit history indices are kept, in days.
     */
    ismHistoryRolloverRetentionPeriodDays?: number | null;
    /**
     * Compatibility mode sets OpenSearch to report its version as 7.10 so clients continue to work.
     */
    overrideMainResponseVersion?: boolean | null;
    /**
     * Enable or disable filtering of alerting by backend roles.
     */
    pluginsAlertingFilterByBackendRolesEnabled?: boolean | null;
    /**
     * Allowlist of remote IP addresses for reindexing. Changing this value will cause all OpenSearch instances to restart.
     */
    reindexRemoteWhitelist?: string[] | null;
    /**
     * Limits the number of inline script compilations within a period of time. Default is use-context
     */
    scriptMaxCompilationsRate?: string | null;
    /**
     * Maximum number of aggregation buckets allowed in a single response.
     */
    searchMaxBuckets?: number | null;
    /**
     * Size of queue for operations in the analyze thread pool.
     */
    threadPoolAnalyzeQueueSize?: number | null;
    /**
     * Number of workers in the analyze operation thread pool.  Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.
     */
    threadPoolAnalyzeSize?: number | null;
    /**
     * Number of workers in the force merge operation thread pool. This pool is used for forcing a merge between shards of one or more indices. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.
     */
    threadPoolForceMergeSize?: number | null;
    /**
     * Size of queue for operations in the get thread pool.
     */
    threadPoolGetQueueSize?: number | null;
    /**
     * Number of workers in the get operation thread pool.  Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.
     */
    threadPoolGetSize?: number | null;
    /**
     * Size of queue for operations in the search thread pool.
     */
    threadPoolSearchQueueSize?: number | null;
    /**
     * Number of workers in the search operation thread pool.  Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.
     */
    threadPoolSearchSize?: number | null;
    /**
     * Size of queue for operations in the search throttled thread pool.
     */
    threadPoolSearchThrottledQueueSize?: number | null;
    /**
     * Number of workers in the search throttled operation thread pool. This pool is used for searching frozen indices. Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.
     */
    threadPoolSearchThrottledSize?: number | null;
    /**
     * Size of queue for operations in the write thread pool.
     */
    threadPoolWriteQueueSize?: number | null;
    /**
     * Number of workers in the write operation thread pool.  Do note this may have maximum value depending on CPU count - value is automatically lowered if set to higher than maximum value.
     */
    threadPoolWriteSize?: number | null;
}
export interface Opensearch_config extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Name of a managed OpenSearch cluster.
     */
    clusterName?: string | null;
    /**
     * A unique identifier for a managed OpenSearch cluster.
     */
    clusterUuid?: string | null;
    /**
     * Credentials for an OpenSearch cluster user. Optional if `cluster_uuid` is passed.
     */
    credentials?: Opensearch_config_credentials | null;
    /**
     * host of the OpenSearch cluster
     */
    endpoint?: string | null;
    /**
     * A unique identifier for a configuration.
     */
    id?: string | null;
    /**
     * OpenSearch index to send logs to.
     */
    indexName?: string | null;
    /**
     * Number of days to retain logs in OpenSearch (default: 14)
     */
    retentionDays?: number | null;
}
/**
 * Credentials for an OpenSearch cluster user. Optional if `cluster_uuid` is passed.
 */
export interface Opensearch_config_credentials extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The password property
     */
    password?: string | null;
    /**
     * The username property
     */
    username?: string | null;
}
/**
 * OpenSearch destination configuration with `credentials` omitted.
 */
export interface Opensearch_config_omit_credentials extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Name of a managed OpenSearch cluster.
     */
    clusterName?: string | null;
    /**
     * A unique identifier for a managed OpenSearch cluster.
     */
    clusterUuid?: string | null;
    /**
     * host of the OpenSearch cluster
     */
    endpoint?: string | null;
    /**
     * A unique identifier for a configuration.
     */
    id?: string | null;
    /**
     * OpenSearch index to send logs to.
     */
    indexName?: string | null;
    /**
     * Number of days to retain logs in OpenSearch.
     */
    retentionDays?: number | null;
}
export interface Opensearch_config_request extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Name of a managed OpenSearch cluster.
     */
    clusterName?: string | null;
    /**
     * A unique identifier for a managed OpenSearch cluster.
     */
    clusterUuid?: string | null;
    /**
     * Credentials for an OpenSearch cluster user. Optional if `cluster_uuid` is passed.
     */
    credentials?: Opensearch_config_request_credentials | null;
    /**
     * host of the OpenSearch cluster
     */
    endpoint?: string | null;
    /**
     * OpenSearch index to send logs to.
     */
    indexName?: string | null;
    /**
     * Number of days to retain logs in an OpenSearch cluster.
     */
    retentionDays?: number | null;
}
/**
 * Credentials for an OpenSearch cluster user. Optional if `cluster_uuid` is passed.
 */
export interface Opensearch_config_request_credentials extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The password property
     */
    password?: string | null;
    /**
     * The username property
     */
    username?: string | null;
}
export interface Opensearch_connection extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The FQDN pointing to the opensearch cluster's current primary node.
     */
    host?: string | null;
    /**
     * The randomly generated password for the default user.
     */
    password?: string | null;
    /**
     * The port on which the opensearch dashboard is listening.
     */
    port?: number | null;
    /**
     * A boolean value indicating if the connection should be made over SSL.
     */
    ssl?: boolean | null;
    /**
     * This is provided as a convenience and should be able to be constructed by the other attributes.
     */
    uri?: string | null;
    /**
     * The default user for the opensearch dashboard.
     */
    user?: string | null;
}
export interface Opensearch_index extends Opensearch_index_base, Parsable {
    /**
     * The health of the OpenSearch index.
     */
    health?: Opensearch_index_health | null;
    /**
     * The status of the OpenSearch index.
     */
    status?: Opensearch_index_status | null;
}
export interface Opensearch_index_base extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The date and time the index was created.
     */
    createdTime?: Date | null;
    /**
     * The name of the opensearch index.
     */
    indexName?: string | null;
    /**
     * The number of replicas for the index.
     */
    numberOfReplicas?: number | null;
    /**
     * The number of shards for the index.
     */
    numberOfShards?: number | null;
    /**
     * The size of the index.
     */
    size?: number | null;
}
export type Opensearch_index_health = (typeof Opensearch_index_healthObject)[keyof typeof Opensearch_index_healthObject];
export type Opensearch_index_status = (typeof Opensearch_index_statusObject)[keyof typeof Opensearch_index_statusObject];
export interface Opensearch_logsink extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * PEM encoded CA certificate
     */
    ca?: string | null;
    /**
     * Maximum number of days of logs to keep
     */
    indexDaysMax?: number | null;
    /**
     * Opensearch index prefix
     */
    indexPrefix?: string | null;
    /**
     * Opensearch request timeout limit
     */
    timeout?: number | null;
    /**
     * Opensearch connection URL
     */
    url?: string | null;
}
export interface Options extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The options property
     */
    options?: Options_options | null;
    /**
     * The version_availability property
     */
    versionAvailability?: Options_version_availability | null;
}
export interface Options_options extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The kafka property
     */
    kafka?: Options_options_kafka | null;
    /**
     * The mongodb property
     */
    mongodb?: Options_options_mongodb | null;
    /**
     * The mysql property
     */
    mysql?: Options_options_mysql | null;
    /**
     * The opensearch property
     */
    opensearch?: Options_options_opensearch | null;
    /**
     * The pg property
     */
    pg?: Options_options_pg | null;
    /**
     * The redis property
     */
    redis?: Options_options_redis | null;
}
export interface Options_options_kafka extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An array of objects, each indicating the node sizes (otherwise referred to as slugs) that are available with various numbers of nodes in the database cluster. Each slugs denotes the node's identifier, CPU, and RAM (in that order).
     */
    layouts?: Database_layout_option[] | null;
    /**
     * An array of strings containing the names of available regions
     */
    regions?: string[] | null;
    /**
     * An array of strings containing the names of available regions
     */
    versions?: string[] | null;
}
export interface Options_options_mongodb extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An array of objects, each indicating the node sizes (otherwise referred to as slugs) that are available with various numbers of nodes in the database cluster. Each slugs denotes the node's identifier, CPU, and RAM (in that order).
     */
    layouts?: Database_layout_option[] | null;
    /**
     * An array of strings containing the names of available regions
     */
    regions?: string[] | null;
    /**
     * An array of strings containing the names of available regions
     */
    versions?: string[] | null;
}
export interface Options_options_mysql extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An array of objects, each indicating the node sizes (otherwise referred to as slugs) that are available with various numbers of nodes in the database cluster. Each slugs denotes the node's identifier, CPU, and RAM (in that order).
     */
    layouts?: Database_layout_option[] | null;
    /**
     * An array of strings containing the names of available regions
     */
    regions?: string[] | null;
    /**
     * An array of strings containing the names of available regions
     */
    versions?: string[] | null;
}
export interface Options_options_opensearch extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An array of objects, each indicating the node sizes (otherwise referred to as slugs) that are available with various numbers of nodes in the database cluster. Each slugs denotes the node's identifier, CPU, and RAM (in that order).
     */
    layouts?: Database_layout_option[] | null;
    /**
     * An array of strings containing the names of available regions
     */
    regions?: string[] | null;
    /**
     * An array of strings containing the names of available regions
     */
    versions?: string[] | null;
}
export interface Options_options_pg extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An array of objects, each indicating the node sizes (otherwise referred to as slugs) that are available with various numbers of nodes in the database cluster. Each slugs denotes the node's identifier, CPU, and RAM (in that order).
     */
    layouts?: Database_layout_option[] | null;
    /**
     * An array of strings containing the names of available regions
     */
    regions?: string[] | null;
    /**
     * An array of strings containing the names of available regions
     */
    versions?: string[] | null;
}
export interface Options_options_redis extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An array of objects, each indicating the node sizes (otherwise referred to as slugs) that are available with various numbers of nodes in the database cluster. Each slugs denotes the node's identifier, CPU, and RAM (in that order).
     */
    layouts?: Database_layout_option[] | null;
    /**
     * An array of strings containing the names of available regions
     */
    regions?: string[] | null;
    /**
     * An array of strings containing the names of available regions
     */
    versions?: string[] | null;
}
export interface Options_version_availability extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An array of objects, each indicating the version end-of-life, end-of-availability for various database engines
     */
    kafka?: Database_version_availability[] | null;
    /**
     * An array of objects, each indicating the version end-of-life, end-of-availability for various database engines
     */
    mongodb?: Database_version_availability[] | null;
    /**
     * An array of objects, each indicating the version end-of-life, end-of-availability for various database engines
     */
    mysql?: Database_version_availability[] | null;
    /**
     * An array of objects, each indicating the version end-of-life, end-of-availability for various database engines
     */
    opensearch?: Database_version_availability[] | null;
    /**
     * An array of objects, each indicating the version end-of-life, end-of-availability for various database engines
     */
    pg?: Database_version_availability[] | null;
    /**
     * An array of objects, each indicating the version end-of-life, end-of-availability for various database engines
     */
    redis?: Database_version_availability[] | null;
}
export interface Page_links extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The pages property
     */
    pages?: Backward_links | Forward_links | Page_links_pagesMember1 | null;
}
export type Page_links_pages = Backward_links | Forward_links | Page_links_pagesMember1;
export interface Page_links_pagesMember1 extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
}
/**
 * PGBouncer connection pooling settings
 */
export interface Pgbouncer_advanced_config extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * If the automatically-created database pools have been unused this many seconds, they are freed. If 0, timeout is disabled.
     */
    autodbIdleTimeout?: number | null;
    /**
     * Only allows a maximum this many server connections per database (regardless of user). If 0, allows unlimited connections.
     */
    autodbMaxDbConnections?: number | null;
    /**
     * PGBouncer pool mode
     */
    autodbPoolMode?: Pgbouncer_advanced_config_autodb_pool_mode | null;
    /**
     * If non-zero, automatically creates a pool of that size per user when a pool doesn't exist.
     */
    autodbPoolSize?: number | null;
    /**
     * List of parameters to ignore when given in startup packet.
     */
    ignoreStartupParameters?: Pgbouncer_advanced_config_ignore_startup_parameters[] | null;
    /**
     * If current server connections are below this number, adds more. Improves behavior when usual load comes suddenly back after period of total inactivity. The value is effectively capped at the pool size.
     */
    minPoolSize?: number | null;
    /**
     * Drops server connections if they have been idle more than this many seconds.  If 0, timeout is disabled. 
     */
    serverIdleTimeout?: number | null;
    /**
     * The pooler closes any unused server connection that has been connected longer than this amount of seconds.
     */
    serverLifetime?: number | null;
    /**
     * Run server_reset_query (DISCARD ALL) in all pooling modes.
     */
    serverResetQueryAlways?: boolean | null;
}
export type Pgbouncer_advanced_config_autodb_pool_mode = (typeof Pgbouncer_advanced_config_autodb_pool_modeObject)[keyof typeof Pgbouncer_advanced_config_autodb_pool_modeObject];
export type Pgbouncer_advanced_config_ignore_startup_parameters = (typeof Pgbouncer_advanced_config_ignore_startup_parametersObject)[keyof typeof Pgbouncer_advanced_config_ignore_startup_parametersObject];
export interface Postgres_advanced_config extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Specifies a fraction, in a decimal value, of the table size to add to autovacuum_analyze_threshold when deciding whether to trigger an ANALYZE. The default is 0.2 (20% of table size).
     */
    autovacuumAnalyzeScaleFactor?: number | null;
    /**
     * Specifies the minimum number of inserted, updated, or deleted tuples needed to trigger an ANALYZE in any one table. The default is 50 tuples.
     */
    autovacuumAnalyzeThreshold?: number | null;
    /**
     * Specifies the maximum age (in transactions) that a table's pg_class.relfrozenxid field can attain before a VACUUM operation is forced to prevent transaction ID wraparound within the table. Note that the system will launch autovacuum processes to prevent wraparound even when autovacuum is otherwise disabled. This parameter will cause the server to be restarted.
     */
    autovacuumFreezeMaxAge?: number | null;
    /**
     * Specifies the maximum number of autovacuum processes (other than the autovacuum launcher) that may be running at any one time. The default is three. This parameter can only be set at server start.
     */
    autovacuumMaxWorkers?: number | null;
    /**
     * Specifies the minimum delay, in seconds, between autovacuum runs on any given database. The default is one minute.
     */
    autovacuumNaptime?: number | null;
    /**
     * Specifies the cost delay value, in milliseconds, that will be used in automatic VACUUM operations. If -1, uses the regular vacuum_cost_delay value, which is 20 milliseconds.
     */
    autovacuumVacuumCostDelay?: number | null;
    /**
     * Specifies the cost limit value that will be used in automatic VACUUM operations. If -1 is specified (which is the default), the regular vacuum_cost_limit value will be used.
     */
    autovacuumVacuumCostLimit?: number | null;
    /**
     * Specifies a fraction, in a decimal value, of the table size to add to autovacuum_vacuum_threshold when deciding whether to trigger a VACUUM. The default is 0.2 (20% of table size).
     */
    autovacuumVacuumScaleFactor?: number | null;
    /**
     * Specifies the minimum number of updated or deleted tuples needed to trigger a VACUUM in any one table. The default is 50 tuples.
     */
    autovacuumVacuumThreshold?: number | null;
    /**
     * The hour of day (in UTC) when backup for the service starts. New backup only starts if previous backup has already completed.
     */
    backupHour?: number | null;
    /**
     * The minute of the backup hour when backup for the service starts. New backup is only started if previous backup has already completed.
     */
    backupMinute?: number | null;
    /**
     * Specifies the delay, in milliseconds, between activity rounds for the background writer. Default is 200 ms.
     */
    bgwriterDelay?: number | null;
    /**
     * The amount of kilobytes that need to be written by the background writer before attempting to force the OS to issue these writes to underlying storage. Specified in kilobytes, default is 512.  Setting of 0 disables forced writeback.
     */
    bgwriterFlushAfter?: number | null;
    /**
     * The maximum number of buffers that the background writer can write. Setting this to zero disables background writing. Default is 100.
     */
    bgwriterLruMaxpages?: number | null;
    /**
     * The average recent need for new buffers is multiplied by bgwriter_lru_multiplier to arrive at an estimate of the number that will be needed during the next round, (up to bgwriter_lru_maxpages). 1.0 represents a â€œjust in timeâ€ policy of writing exactly the number of buffers predicted to be needed. Larger values provide some cushion against spikes in demand, while smaller values intentionally leave writes to be done by server processes. The default is 2.0.
     */
    bgwriterLruMultiplier?: number | null;
    /**
     * The amount of time, in milliseconds, to wait on a lock before checking to see if there is a deadlock condition.
     */
    deadlockTimeout?: number | null;
    /**
     * Specifies the default TOAST compression method for values of compressible columns (the default is lz4).
     */
    defaultToastCompression?: Postgres_advanced_config_default_toast_compression | null;
    /**
     * Time out sessions with open transactions after this number of milliseconds
     */
    idleInTransactionSessionTimeout?: number | null;
    /**
     * Activates, in a boolean, the system-wide use of Just-in-Time Compilation (JIT).
     */
    jit?: boolean | null;
    /**
     * Causes each action executed by autovacuum to be logged if it ran for at least the specified number of milliseconds. Setting this to zero logs all autovacuum actions. Minus-one (the default) disables logging autovacuum actions.
     */
    logAutovacuumMinDuration?: number | null;
    /**
     * Controls the amount of detail written in the server log for each message that is logged.
     */
    logErrorVerbosity?: Postgres_advanced_config_log_error_verbosity | null;
    /**
     * Selects one of the available log-formats. These can support popular log analyzers like pgbadger, pganalyze, etc.
     */
    logLinePrefix?: Postgres_advanced_config_log_line_prefix | null;
    /**
     * Log statements that take more than this number of milliseconds to run. If -1, disables.
     */
    logMinDurationStatement?: number | null;
    /**
     * Number of seconds of master unavailability before triggering database failover to standby. The default value is 60.
     */
    maxFailoverReplicationTimeLag?: number | null;
    /**
     * PostgreSQL maximum number of files that can be open per process.
     */
    maxFilesPerProcess?: number | null;
    /**
     * PostgreSQL maximum locks per transaction. Once increased, this parameter cannot be lowered from its set value.
     */
    maxLocksPerTransaction?: number | null;
    /**
     * PostgreSQL maximum logical replication workers (taken from the pool of max_parallel_workers).
     */
    maxLogicalReplicationWorkers?: number | null;
    /**
     * Sets the maximum number of workers that the system can support for parallel queries.
     */
    maxParallelWorkers?: number | null;
    /**
     * Sets the maximum number of workers that can be started by a single Gather or Gather Merge node.
     */
    maxParallelWorkersPerGather?: number | null;
    /**
     * PostgreSQL maximum predicate locks per transaction.
     */
    maxPredLocksPerTransaction?: number | null;
    /**
     * PostgreSQL maximum prepared transactions. Once increased, this parameter cannot be lowered from its set value.
     */
    maxPreparedTransactions?: number | null;
    /**
     * PostgreSQL maximum replication slots.
     */
    maxReplicationSlots?: number | null;
    /**
     * Maximum depth of the stack in bytes.
     */
    maxStackDepth?: number | null;
    /**
     * Max standby archive delay in milliseconds.
     */
    maxStandbyArchiveDelay?: number | null;
    /**
     * Max standby streaming delay in milliseconds.
     */
    maxStandbyStreamingDelay?: number | null;
    /**
     * PostgreSQL maximum WAL senders. Once increased, this parameter cannot be lowered from its set value.
     */
    maxWalSenders?: number | null;
    /**
     * Sets the maximum number of background processes that the system can support. Once increased, this parameter cannot be lowered from its set value.
     */
    maxWorkerProcesses?: number | null;
    /**
     * PGBouncer connection pooling settings
     */
    pgbouncer?: Pgbouncer_advanced_config | null;
    /**
     * Sets the time interval to run pg_partman's scheduled tasks.
     */
    pgPartmanBgwInterval?: number | null;
    /**
     * Controls which role to use for pg_partman's scheduled background tasks. Must consist of alpha-numeric characters, dots, underscores, or dashes. May not start with dash or dot. Maximum of 64 characters.
     */
    pgPartmanBgwRole?: string | null;
    /**
     * Controls which statements are counted. Specify 'top' to track top-level statements (those issued directly by clients), 'all' to also track nested statements (such as statements invoked within functions), or 'none' to disable statement statistics collection. The default value is top.
     */
    pgStatStatementsTrack?: Postgres_advanced_config_pg_stat_statementsTrack | null;
    /**
     * Percentage of total RAM that the database server uses for shared memory buffers.  Valid range is 20-60 (float), which corresponds to 20% - 60%.  This setting adjusts the shared_buffers configuration value.
     */
    sharedBuffersPercentage?: number | null;
    /**
     * Enable the pg_stat_monitor extension. <b>Enabling this extension will cause the cluster to be restarted.</b> When this extension is enabled, pg_stat_statements results for utility commands are unreliable.
     */
    statMonitorEnable?: boolean | null;
    /**
     * Synchronous replication type. Note that the service plan also needs to support synchronous replication.
     */
    synchronousReplication?: Postgres_advanced_config_synchronous_replication | null;
    /**
     * PostgreSQL temporary file limit in KiB. If -1, sets to unlimited.
     */
    tempFileLimit?: number | null;
    /**
     * TimescaleDB extension configuration values
     */
    timescaledb?: Timescaledb_advanced_config | null;
    /**
     * PostgreSQL service timezone
     */
    timezone?: string | null;
    /**
     * Specifies the number of bytes reserved to track the currently executing command for each active session.
     */
    trackActivityQuerySize?: number | null;
    /**
     * Record commit time of transactions.
     */
    trackCommitTimestamp?: Postgres_advanced_config_track_commit_timestamp | null;
    /**
     * Enables tracking of function call counts and time used.
     */
    trackFunctions?: Postgres_advanced_config_track_functions | null;
    /**
     * Enables timing of database I/O calls. This parameter is off by default, because it will repeatedly query the operating system for the current time, which may cause significant overhead on some platforms.
     */
    trackIoTiming?: Postgres_advanced_config_track_io_timing | null;
    /**
     * Terminate replication connections that are inactive for longer than this amount of time, in milliseconds. Setting this value to zero disables the timeout. Must be either 0 or between 5000 and 10800000.
     */
    walSenderTimeout?: number | null;
    /**
     * WAL flush interval in milliseconds. Note that setting this value to lower than the default 200ms may negatively impact performance
     */
    walWriterDelay?: number | null;
    /**
     * The maximum amount of memory, in MB, used by a query operation (such as a sort or hash table) before writing to temporary disk files. Default is 1MB + 0.075% of total RAM (up to 32MB).
     */
    workMem?: number | null;
}
export type Postgres_advanced_config_default_toast_compression = (typeof Postgres_advanced_config_default_toast_compressionObject)[keyof typeof Postgres_advanced_config_default_toast_compressionObject];
export type Postgres_advanced_config_log_error_verbosity = (typeof Postgres_advanced_config_log_error_verbosityObject)[keyof typeof Postgres_advanced_config_log_error_verbosityObject];
export type Postgres_advanced_config_log_line_prefix = (typeof Postgres_advanced_config_log_line_prefixObject)[keyof typeof Postgres_advanced_config_log_line_prefixObject];
export type Postgres_advanced_config_pg_stat_statementsTrack = (typeof Postgres_advanced_config_pg_stat_statementsTrackObject)[keyof typeof Postgres_advanced_config_pg_stat_statementsTrackObject];
export type Postgres_advanced_config_synchronous_replication = (typeof Postgres_advanced_config_synchronous_replicationObject)[keyof typeof Postgres_advanced_config_synchronous_replicationObject];
export type Postgres_advanced_config_track_commit_timestamp = (typeof Postgres_advanced_config_track_commit_timestampObject)[keyof typeof Postgres_advanced_config_track_commit_timestampObject];
export type Postgres_advanced_config_track_functions = (typeof Postgres_advanced_config_track_functionsObject)[keyof typeof Postgres_advanced_config_track_functionsObject];
export type Postgres_advanced_config_track_io_timing = (typeof Postgres_advanced_config_track_io_timingObject)[keyof typeof Postgres_advanced_config_track_io_timingObject];
export interface Previous_outage extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The duration_seconds property
     */
    durationSeconds?: number | null;
    /**
     * The ended_at property
     */
    endedAt?: string | null;
    /**
     * The region property
     */
    region?: string | null;
    /**
     * The started_at property
     */
    startedAt?: string | null;
}
export interface Product_charge_item extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Amount of the charge
     */
    amount?: string | null;
    /**
     * Number of times the charge was applied
     */
    count?: string | null;
    /**
     * Description of the charge
     */
    name?: string | null;
}
export interface Product_usage_charges extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Total amount charged
     */
    amount?: string | null;
    /**
     * List of amount, and grouped aggregates by resource type.
     */
    items?: Product_charge_item[] | null;
    /**
     * Description of usage charges
     */
    name?: string | null;
}
export interface Project extends Parsable, Project_base {
    /**
     * If true, all resources will be added to this project if no project is specified.
     */
    isDefault?: boolean | null;
}
export interface Project_assignment extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A list of uniform resource names (URNs) to be added to a project.
     */
    resources?: string[] | null;
}
export interface Project_base extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the project was created.
     */
    createdAt?: Date | null;
    /**
     * The description of the project. The maximum length is 255 characters.
     */
    description?: string | null;
    /**
     * The environment of the project's resources.
     */
    environment?: Project_base_environment | null;
    /**
     * The unique universal identifier of this project.
     */
    id?: Guid | null;
    /**
     * The human-readable name for the project. The maximum length is 175 characters and the name must be unique.
     */
    name?: string | null;
    /**
     * The integer id of the project owner.
     */
    ownerId?: number | null;
    /**
     * The unique universal identifier of the project owner.
     */
    ownerUuid?: string | null;
    /**
     * The purpose of the project. The maximum length is 255 characters. It canhave one of the following values:- Just trying out DigitalOcean- Class project / Educational purposes- Website or blog- Web Application- Service or API- Mobile Application- Machine learning / AI / Data processing- IoT- Operational / Developer toolingIf another value for purpose is specified, for example, "your custom purpose",your purpose will be stored as `Other: your custom purpose`.
     */
    purpose?: string | null;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the project was updated.
     */
    updatedAt?: Date | null;
}
export type Project_base_environment = (typeof Project_base_environmentObject)[keyof typeof Project_base_environmentObject];
export interface Purge_cache extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An array of strings containing the path to the content to be purged from the CDN cache.
     */
    files?: string[] | null;
}
export interface Redis_advanced_config extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Determines default pub/sub channels' ACL for new users if ACL is not supplied. When this option is not defined, all_channels is assumed to keep backward compatibility. This option doesn't affect Redis configuration acl-pubsub-default.
     */
    redisAclChannelsDefault?: Redis_advanced_config_redis_acl_channels_default | null;
    /**
     * Redis IO thread count
     */
    redisIoThreads?: number | null;
    /**
     * LFU maxmemory-policy counter decay time in minutes
     */
    redisLfuDecayTime?: number | null;
    /**
     * Counter logarithm factor for volatile-lfu and allkeys-lfu maxmemory-policies
     */
    redisLfuLogFactor?: number | null;
    /**
     * A string specifying the desired eviction policy for the Redis cluster.- `noeviction`: Don't evict any data, returns error when memory limit is reached.- `allkeys-lru:` Evict any key, least recently used (LRU) first.- `allkeys-random`: Evict keys in a random order.- `volatile-lru`: Evict keys with expiration only, least recently used (LRU) first.- `volatile-random`: Evict keys with expiration only in a random order.- `volatile-ttl`: Evict keys with expiration only, shortest time-to-live (TTL) first.
     */
    redisMaxmemoryPolicy?: Redis_advanced_config_redis_maxmemory_policy | null;
    /**
     * Set notify-keyspace-events option. Requires at least `K` or `E` and accepts any combination of the following options. Setting the parameter to `""` disables notifications.- `K` &mdash; Keyspace events- `E` &mdash; Keyevent events- `g` &mdash; Generic commands (e.g. `DEL`, `EXPIRE`, `RENAME`, ...)- `$` &mdash; String commands- `l` &mdash; List commands- `s` &mdash; Set commands- `h` &mdash; Hash commands- `z` &mdash; Sorted set commands- `t` &mdash; Stream commands- `d` &mdash; Module key type events- `x` &mdash; Expired events- `e` &mdash; Evicted events- `m` &mdash; Key miss events- `n` &mdash; New key events- `A` &mdash; Alias for `"g$lshztxed"`
     */
    redisNotifyKeyspaceEvents?: string | null;
    /**
     * Set number of redis databases. Changing this will cause a restart of redis service.
     */
    redisNumberOfDatabases?: number | null;
    /**
     * Creates an RDB dump of the database every 10 minutes that can be used  to recover data after a node crash. The database does not create the  dump if no keys have changed since the last dump. When set to `off`,  the database cannot fork services, and data can be lost if a service  is restarted or powered off. DigitalOcean Managed Caching databases  do not support the Append Only File (AOF) persistence method.
     */
    redisPersistence?: Redis_advanced_config_redis_persistence | null;
    /**
     * Set output buffer limit for pub / sub clients in MB. The value is the hard limit, the soft limit is 1/4 of the hard limit. When setting the limit, be mindful of the available memory in the selected service plan.
     */
    redisPubsubClientOutputBufferLimit?: number | null;
    /**
     * Require SSL to access Redis.- When enabled, Redis accepts only SSL connections on port `25061`.- When disabled, port `25060` is opened for non-SSL connections, while port `25061` remains available for SSL connections.
     */
    redisSsl?: boolean | null;
    /**
     * Redis idle connection timeout in seconds
     */
    redisTimeout?: number | null;
}
export type Redis_advanced_config_redis_acl_channels_default = (typeof Redis_advanced_config_redis_acl_channels_defaultObject)[keyof typeof Redis_advanced_config_redis_acl_channels_defaultObject];
export type Redis_advanced_config_redis_maxmemory_policy = (typeof Redis_advanced_config_redis_maxmemory_policyObject)[keyof typeof Redis_advanced_config_redis_maxmemory_policyObject];
export type Redis_advanced_config_redis_persistence = (typeof Redis_advanced_config_redis_persistenceObject)[keyof typeof Redis_advanced_config_redis_persistenceObject];
export interface Region extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * This is a boolean value that represents whether new Droplets can be created in this region.
     */
    available?: boolean | null;
    /**
     * This attribute is set to an array which contains features available in this region
     */
    features?: UntypedNode | null;
    /**
     * The display name of the region.  This will be a full name that is used in the control panel and other interfaces.
     */
    name?: string | null;
    /**
     * This attribute is set to an array which contains the identifying slugs for the sizes available in this region.
     */
    sizes?: UntypedNode | null;
    /**
     * A human-readable string that is used as a unique identifier for each region.
     */
    slug?: string | null;
}
export type Region_slug = (typeof Region_slugObject)[keyof typeof Region_slugObject];
export interface Region_state extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The status property
     */
    status?: Region_state_status | null;
    /**
     * The status_changed_at property
     */
    statusChangedAt?: string | null;
    /**
     * The thirty_day_uptime_percentage property
     */
    thirtyDayUptimePercentage?: number | null;
}
export type Region_state_status = (typeof Region_state_statusObject)[keyof typeof Region_state_statusObject];
/**
 * A map of region to regional state
 */
export interface Regional_state extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The eu_west property
     */
    euWest?: Region_state | null;
    /**
     * The us_east property
     */
    usEast?: Region_state | null;
}
export interface Registry extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the registry was created.
     */
    createdAt?: Date | null;
    /**
     * A globally unique name for the container registry. Must be lowercase and be composed only of numbers, letters and `-`, up to a limit of 63 characters.
     */
    name?: string | null;
    /**
     * Slug of the region where registry data is stored
     */
    region?: string | null;
    /**
     * The amount of storage used in the registry in bytes.
     */
    storageUsageBytes?: number | null;
    /**
     * The time at which the storage usage was updated. Storage usage is calculated asynchronously, and may not immediately reflect pushes to the registry.
     */
    storageUsageBytesUpdatedAt?: Date | null;
    /**
     * The subscription property
     */
    subscription?: Subscription | null;
}
export interface Registry_create extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A globally unique name for the container registry. Must be lowercase and be composed only of numbers, letters and `-`, up to a limit of 63 characters.
     */
    name?: string | null;
    /**
     * Slug of the region where registry data is stored. When not provided, a region will be selected.
     */
    region?: Registry_create_region | null;
    /**
     * The slug of the subscription tier to sign up for. Valid values can be retrieved using the options endpoint.
     */
    subscriptionTierSlug?: Registry_create_subscription_tier_slug | null;
}
export type Registry_create_region = (typeof Registry_create_regionObject)[keyof typeof Registry_create_regionObject];
export type Registry_create_subscription_tier_slug = (typeof Registry_create_subscription_tier_slugObject)[keyof typeof Registry_create_subscription_tier_slugObject];
export interface Repository extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The latest_tag property
     */
    latestTag?: Repository_tag | null;
    /**
     * The name of the repository.
     */
    name?: string | null;
    /**
     * The name of the container registry.
     */
    registryName?: string | null;
    /**
     * The number of tags in the repository.
     */
    tagCount?: number | null;
}
export interface Repository_blob extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The compressed size of the blob in bytes.
     */
    compressedSizeBytes?: number | null;
    /**
     * The digest of the blob
     */
    digest?: string | null;
}
export interface Repository_manifest extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * All blobs associated with this manifest
     */
    blobs?: Repository_blob[] | null;
    /**
     * The compressed size of the manifest in bytes.
     */
    compressedSizeBytes?: number | null;
    /**
     * The manifest digest
     */
    digest?: string | null;
    /**
     * The name of the container registry.
     */
    registryName?: string | null;
    /**
     * The name of the repository.
     */
    repository?: string | null;
    /**
     * The uncompressed size of the manifest in bytes (this size is calculated asynchronously so it may not be immediately available).
     */
    sizeBytes?: number | null;
    /**
     * All tags associated with this manifest
     */
    tags?: string[] | null;
    /**
     * The time the manifest was last updated.
     */
    updatedAt?: Date | null;
}
export interface Repository_tag extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The compressed size of the tag in bytes.
     */
    compressedSizeBytes?: number | null;
    /**
     * The digest of the manifest associated with the tag.
     */
    manifestDigest?: string | null;
    /**
     * The name of the container registry.
     */
    registryName?: string | null;
    /**
     * The name of the repository.
     */
    repository?: string | null;
    /**
     * The uncompressed size of the tag in bytes (this size is calculated asynchronously so it may not be immediately available).
     */
    sizeBytes?: number | null;
    /**
     * The name of the tag.
     */
    tag?: string | null;
    /**
     * The time the tag was last updated.
     */
    updatedAt?: Date | null;
}
export interface Repository_v2 extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The latest_manifest property
     */
    latestManifest?: Repository_manifest | null;
    /**
     * The number of manifests in the repository.
     */
    manifestCount?: number | null;
    /**
     * The name of the repository.
     */
    name?: string | null;
    /**
     * The name of the container registry.
     */
    registryName?: string | null;
    /**
     * The number of tags in the repository.
     */
    tagCount?: number | null;
}
export interface Reserved_ip extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The Droplet that the reserved IP has been assigned to. When you query a reserved IP, if it is assigned to a Droplet, the entire Droplet object will be returned. If it is not assigned, the value will be null.
     */
    droplet?: Droplet | null;
    /**
     * The public IP address of the reserved IP. It also serves as its identifier.
     */
    ip?: string | null;
    /**
     * A boolean value indicating whether or not the reserved IP has pending actions preventing new ones from being submitted.
     */
    locked?: boolean | null;
    /**
     * The UUID of the project to which the reserved IP currently belongs.
     */
    projectId?: Guid | null;
    /**
     * The region property
     */
    region?: Region | null;
}
export interface Reserved_ip_action_assign extends Parsable, Reserved_ip_action_type {
    /**
     * The ID of the Droplet that the reserved IP will be assigned to.
     */
    dropletId?: number | null;
}
export interface Reserved_ip_action_type extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The type of action to initiate for the reserved IP.
     */
    type?: Reserved_ip_action_type_type | null;
}
export type Reserved_ip_action_type_type = (typeof Reserved_ip_action_type_typeObject)[keyof typeof Reserved_ip_action_type_typeObject];
export interface Reserved_ip_action_unassign extends Parsable, Reserved_ip_action_type {
}
export interface Reserved_ip_createMember1 extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The ID of the Droplet that the reserved IP will be assigned to.
     */
    dropletId?: number | null;
}
export interface Reserved_ip_createMember2 extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The UUID of the project to which the reserved IP will be assigned.
     */
    projectId?: Guid | null;
    /**
     * The slug identifier for the region the reserved IP will be reserved to.
     */
    region?: string | null;
}
export interface Reserved_ipv6 extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The droplet property
     */
    droplet?: Droplet | null;
    /**
     * The public IP address of the reserved IPv6. It also serves as its identifier.
     */
    ip?: string | null;
    /**
     * The region that the reserved IPv6 is reserved to. When you query a reserved IPv6,the region_slug will be returned.
     */
    regionSlug?: string | null;
    /**
     * The date and time when the reserved IPv6 was reserved.
     */
    reservedAt?: Date | null;
}
export interface Reserved_ipv6_action_assign extends Parsable, Reserved_ipv6_action_type {
    /**
     * The ID of the Droplet that the reserved IPv6 will be assigned to.
     */
    dropletId?: number | null;
}
export interface Reserved_ipv6_action_type extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The type of action to initiate for the reserved IPv6.
     */
    type?: Reserved_ipv6_action_type_type | null;
}
export type Reserved_ipv6_action_type_type = (typeof Reserved_ipv6_action_type_typeObject)[keyof typeof Reserved_ipv6_action_type_typeObject];
export interface Reserved_ipv6_action_unassign extends Parsable, Reserved_ipv6_action_type {
}
export interface Reserved_ipv6_create extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The slug identifier for the region the reserved IPv6 will be reserved to.
     */
    regionSlug?: string | null;
}
export interface Resource extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the project was created.
     */
    assignedAt?: Date | null;
    /**
     * The links object contains the `self` object, which contains the resource relationship.
     */
    links?: Resource_links | null;
    /**
     * The status of assigning and fetching the resources.
     */
    status?: Resource_status | null;
    /**
     * The uniform resource name (URN) for the resource in the format do:resource_type:resource_id.
     */
    urn?: string | null;
}
/**
 * The links object contains the `self` object, which contains the resource relationship.
 */
export interface Resource_links extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A URI that can be used to retrieve the resource.
     */
    self?: string | null;
}
export type Resource_status = (typeof Resource_statusObject)[keyof typeof Resource_statusObject];
/**
 * An object specifying whether the routing-agent component should be enabled for the Kubernetes cluster.
 */
export interface Routing_agent extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Indicates whether the routing-agent component is enabled.
     */
    enabled?: boolean | null;
}
export interface Rsyslog_logsink extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * PEM encoded CA certificate
     */
    ca?: string | null;
    /**
     * (PEM format) client cert to use
     */
    cert?: string | null;
    /**
     * Message format used by the server, this can be either rfc3164 (the old BSD style message format), `rfc5424` (current syslog message format) or custom
     */
    format?: Rsyslog_logsink_format | null;
    /**
     * (PEM format) client key if the server requires client authentication
     */
    key?: string | null;
    /**
     * Conditional (required if `format` == `custom`).Syslog log line template for a custom format, supporting limited rsyslog style templating (using `%tag%`). Supported tags are: `HOSTNAME`, `app-name`, `msg`, `msgid`, `pri`, `procid`, `structured-data`, `timestamp` and `timestamp:::date-rfc3339`.
     */
    logline?: string | null;
    /**
     * The internal port on which the rsyslog server is listening
     */
    port?: number | null;
    /**
     * content of the structured data block of rfc5424 message
     */
    sd?: string | null;
    /**
     * DNS name or IPv4 address of the rsyslog server
     */
    server?: string | null;
    /**
     * Use TLS (as the messages are not filtered and may contain sensitive information, it is highly recommended to set this to true if the remote server supports it)
     */
    tls?: boolean | null;
}
export type Rsyslog_logsink_format = (typeof Rsyslog_logsink_formatObject)[keyof typeof Rsyslog_logsink_formatObject];
/**
 * Trigger details for SCHEDULED type, where body is optional.
 */
export interface Scheduled_details extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Optional data to be sent to function while triggering the function.
     */
    body?: Scheduled_details_body | null;
    /**
     * valid cron expression string which is required for SCHEDULED type triggers.
     */
    cron?: string | null;
}
/**
 * Optional data to be sent to function while triggering the function.
 */
export interface Scheduled_details_body extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name property
     */
    name?: string | null;
}
/**
 * An object containing information about a resource to be scheduled for deletion.
 */
export interface Selective_destroy_associated_resource extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An array of unique identifiers for the floating IPs to be scheduled for deletion.
     * @deprecated 
     */
    floatingIps?: string[] | null;
    /**
     * An array of unique identifiers for the reserved IPs to be scheduled for deletion.
     */
    reservedIps?: string[] | null;
    /**
     * An array of unique identifiers for the snapshots to be scheduled for deletion.
     */
    snapshots?: string[] | null;
    /**
     * An array of unique identifiers for the volumes to be scheduled for deletion.
     */
    volumes?: string[] | null;
    /**
     * An array of unique identifiers for the volume snapshots to be scheduled for deletion.
     */
    volumeSnapshots?: string[] | null;
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAccount(writer: SerializationWriter, account: Partial<Account> | undefined | null = {}) : void {
    if (account) {
        writer.writeNumberValue("droplet_limit", account.dropletLimit);
        writer.writeStringValue("email", account.email);
        writer.writeBooleanValue("email_verified", account.emailVerified);
        writer.writeNumberValue("floating_ip_limit", account.floatingIpLimit);
        writer.writeStringValue("name", account.name);
        writer.writeEnumValue<Account_status>("status", account.status ?? Account_statusObject.Active);
        writer.writeStringValue("status_message", account.statusMessage);
        writer.writeObjectValue<Account_team>("team", account.team, serializeAccount_team);
        writer.writeStringValue("uuid", account.uuid);
        writer.writeAdditionalData(account.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAccount_team(writer: SerializationWriter, account_team: Partial<Account_team> | undefined | null = {}) : void {
    if (account_team) {
        writer.writeStringValue("name", account_team.name);
        writer.writeStringValue("uuid", account_team.uuid);
        writer.writeAdditionalData(account_team.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAction(writer: SerializationWriter, action: Partial<Action> | undefined | null = {}) : void {
    if (action) {
        writer.writeDateValue("completed_at", action.completedAt);
        writer.writeNumberValue("id", action.id);
        writer.writeObjectValue<Region>("region", action.region, serializeRegion);
        writer.writeStringValue("region_slug", action.regionSlug);
        writer.writeNumberValue("resource_id", action.resourceId);
        writer.writeStringValue("resource_type", action.resourceType);
        writer.writeDateValue("started_at", action.startedAt);
        writer.writeEnumValue<Action_status>("status", action.status ?? Action_statusObject.InProgress);
        writer.writeStringValue("type", action.type);
        writer.writeAdditionalData(action.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAction_link(writer: SerializationWriter, action_link: Partial<Action_link> | undefined | null = {}) : void {
    if (action_link) {
        writer.writeStringValue("href", action_link.href);
        writer.writeNumberValue("id", action_link.id);
        writer.writeStringValue("rel", action_link.rel);
        writer.writeAdditionalData(action_link.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAlert(writer: SerializationWriter, alert: Partial<Alert> | undefined | null = {}) : void {
    if (alert) {
        writer.writeEnumValue<Alert_comparison>("comparison", alert.comparison);
        writer.writeStringValue("name", alert.name);
        writer.writeObjectValue<Notification>("notifications", alert.notifications, serializeNotification);
        writer.writeEnumValue<Alert_period>("period", alert.period);
        writer.writeNumberValue("threshold", alert.threshold);
        writer.writeEnumValue<Alert_type>("type", alert.type);
        writer.writeAdditionalData(alert.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAlert_policy(writer: SerializationWriter, alert_policy: Partial<Alert_policy> | undefined | null = {}) : void {
    if (alert_policy) {
        writer.writeObjectValue<Alerts>("alerts", alert_policy.alerts, serializeAlerts);
        writer.writeEnumValue<Alert_policy_compare>("compare", alert_policy.compare);
        writer.writeStringValue("description", alert_policy.description);
        writer.writeBooleanValue("enabled", alert_policy.enabled);
        writer.writeCollectionOfPrimitiveValues<string>("entities", alert_policy.entities);
        writer.writeCollectionOfPrimitiveValues<string>("tags", alert_policy.tags);
        writer.writeEnumValue<Alert_policy_type>("type", alert_policy.type);
        writer.writeStringValue("uuid", alert_policy.uuid);
        writer.writeNumberValue("value", alert_policy.value);
        writer.writeEnumValue<Alert_policy_window>("window", alert_policy.window);
        writer.writeAdditionalData(alert_policy.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAlert_policy_request(writer: SerializationWriter, alert_policy_request: Partial<Alert_policy_request> | undefined | null = {}) : void {
    if (alert_policy_request) {
        writer.writeObjectValue<Alerts>("alerts", alert_policy_request.alerts, serializeAlerts);
        writer.writeEnumValue<Alert_policy_request_compare>("compare", alert_policy_request.compare);
        writer.writeStringValue("description", alert_policy_request.description);
        writer.writeBooleanValue("enabled", alert_policy_request.enabled);
        writer.writeCollectionOfPrimitiveValues<string>("entities", alert_policy_request.entities);
        writer.writeCollectionOfPrimitiveValues<string>("tags", alert_policy_request.tags);
        writer.writeEnumValue<Alert_policy_request_type>("type", alert_policy_request.type);
        writer.writeNumberValue("value", alert_policy_request.value);
        writer.writeEnumValue<Alert_policy_request_window>("window", alert_policy_request.window);
        writer.writeAdditionalData(alert_policy_request.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAlert_updatable(writer: SerializationWriter, alert_updatable: Partial<Alert_updatable> | undefined | null = {}) : void {
    if (alert_updatable) {
        writer.writeEnumValue<Alert_updatable_comparison>("comparison", alert_updatable.comparison);
        writer.writeStringValue("name", alert_updatable.name);
        writer.writeObjectValue<Notification>("notifications", alert_updatable.notifications, serializeNotification);
        writer.writeEnumValue<Alert_updatable_period>("period", alert_updatable.period);
        writer.writeNumberValue("threshold", alert_updatable.threshold);
        writer.writeEnumValue<Alert_updatable_type>("type", alert_updatable.type);
        writer.writeAdditionalData(alert_updatable.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAlerts(writer: SerializationWriter, alerts: Partial<Alerts> | undefined | null = {}) : void {
    if (alerts) {
        writer.writeCollectionOfPrimitiveValues<string>("email", alerts.email);
        writer.writeCollectionOfObjectValues<Slack_details>("slack", alerts.slack, serializeSlack_details);
        writer.writeAdditionalData(alerts.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiAgent(writer: SerializationWriter, apiAgent: Partial<ApiAgent> | undefined | null = {}) : void {
    if (apiAgent) {
        writer.writeObjectValue<ApiAnthropicAPIKeyInfo>("anthropic_api_key", apiAgent.anthropicApiKey, serializeApiAnthropicAPIKeyInfo);
        writer.writeCollectionOfObjectValues<ApiAgentAPIKeyInfo>("api_key_infos", apiAgent.apiKeyInfos, serializeApiAgentAPIKeyInfo);
        writer.writeCollectionOfObjectValues<ApiAgentAPIKey>("api_keys", apiAgent.apiKeys, serializeApiAgentAPIKey);
        writer.writeObjectValue<ApiChatbot>("chatbot", apiAgent.chatbot, serializeApiChatbot);
        writer.writeCollectionOfObjectValues<ApiAgentChatbotIdentifier>("chatbot_identifiers", apiAgent.chatbotIdentifiers, serializeApiAgentChatbotIdentifier);
        writer.writeCollectionOfObjectValues<ApiAgent>("child_agents", apiAgent.childAgents, serializeApiAgent);
        writer.writeDateValue("created_at", apiAgent.createdAt);
        writer.writeObjectValue<ApiDeployment>("deployment", apiAgent.deployment, serializeApiDeployment);
        writer.writeStringValue("description", apiAgent.description);
        writer.writeCollectionOfObjectValues<ApiAgentFunction>("functions", apiAgent.functions, serializeApiAgentFunction);
        writer.writeCollectionOfObjectValues<ApiAgentGuardrail>("guardrails", apiAgent.guardrails, serializeApiAgentGuardrail);
        writer.writeStringValue("if_case", apiAgent.ifCase);
        writer.writeStringValue("instruction", apiAgent.instruction);
        writer.writeNumberValue("k", apiAgent.k);
        writer.writeCollectionOfObjectValues<ApiKnowledgeBase>("knowledge_bases", apiAgent.knowledgeBases, serializeApiKnowledgeBase);
        writer.writeNumberValue("max_tokens", apiAgent.maxTokens);
        writer.writeObjectValue<ApiModel>("model", apiAgent.model, serializeApiModel);
        writer.writeStringValue("name", apiAgent.name);
        writer.writeCollectionOfObjectValues<ApiAgent>("parent_agents", apiAgent.parentAgents, serializeApiAgent);
        writer.writeStringValue("project_id", apiAgent.projectId);
        writer.writeStringValue("region", apiAgent.region);
        writer.writeDateValue("route_created_at", apiAgent.routeCreatedAt);
        writer.writeStringValue("route_created_by", apiAgent.routeCreatedBy);
        writer.writeStringValue("route_name", apiAgent.routeName);
        writer.writeStringValue("route_uuid", apiAgent.routeUuid);
        writer.writeCollectionOfPrimitiveValues<string>("tags", apiAgent.tags);
        writer.writeNumberValue("temperature", apiAgent.temperature);
        writer.writeObjectValue<ApiAgentTemplate>("template", apiAgent.template, serializeApiAgentTemplate);
        writer.writeNumberValue("top_p", apiAgent.topP);
        writer.writeDateValue("updated_at", apiAgent.updatedAt);
        writer.writeStringValue("url", apiAgent.url);
        writer.writeStringValue("user_id", apiAgent.userId);
        writer.writeStringValue("uuid", apiAgent.uuid);
        writer.writeAdditionalData(apiAgent.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiAgentAPIKey(writer: SerializationWriter, apiAgentAPIKey: Partial<ApiAgentAPIKey> | undefined | null = {}) : void {
    if (apiAgentAPIKey) {
        writer.writeStringValue("api_key", apiAgentAPIKey.apiKey);
        writer.writeAdditionalData(apiAgentAPIKey.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiAgentAPIKeyInfo(writer: SerializationWriter, apiAgentAPIKeyInfo: Partial<ApiAgentAPIKeyInfo> | undefined | null = {}) : void {
    if (apiAgentAPIKeyInfo) {
        writer.writeDateValue("created_at", apiAgentAPIKeyInfo.createdAt);
        writer.writeStringValue("created_by", apiAgentAPIKeyInfo.createdBy);
        writer.writeDateValue("deleted_at", apiAgentAPIKeyInfo.deletedAt);
        writer.writeStringValue("name", apiAgentAPIKeyInfo.name);
        writer.writeStringValue("secret_key", apiAgentAPIKeyInfo.secretKey);
        writer.writeStringValue("uuid", apiAgentAPIKeyInfo.uuid);
        writer.writeAdditionalData(apiAgentAPIKeyInfo.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiAgentChatbotIdentifier(writer: SerializationWriter, apiAgentChatbotIdentifier: Partial<ApiAgentChatbotIdentifier> | undefined | null = {}) : void {
    if (apiAgentChatbotIdentifier) {
        writer.writeStringValue("agent_chatbot_identifier", apiAgentChatbotIdentifier.agentChatbotIdentifier);
        writer.writeAdditionalData(apiAgentChatbotIdentifier.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiAgentFunction(writer: SerializationWriter, apiAgentFunction: Partial<ApiAgentFunction> | undefined | null = {}) : void {
    if (apiAgentFunction) {
        writer.writeStringValue("api_key", apiAgentFunction.apiKey);
        writer.writeDateValue("created_at", apiAgentFunction.createdAt);
        writer.writeStringValue("description", apiAgentFunction.description);
        writer.writeStringValue("faas_name", apiAgentFunction.faasName);
        writer.writeStringValue("faas_namespace", apiAgentFunction.faasNamespace);
        writer.writeObjectValue<ApiAgentFunction_input_schema>("input_schema", apiAgentFunction.inputSchema, serializeApiAgentFunction_input_schema);
        writer.writeStringValue("name", apiAgentFunction.name);
        writer.writeObjectValue<ApiAgentFunction_output_schema>("output_schema", apiAgentFunction.outputSchema, serializeApiAgentFunction_output_schema);
        writer.writeDateValue("updated_at", apiAgentFunction.updatedAt);
        writer.writeStringValue("url", apiAgentFunction.url);
        writer.writeStringValue("uuid", apiAgentFunction.uuid);
        writer.writeAdditionalData(apiAgentFunction.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiAgentFunction_input_schema(writer: SerializationWriter, apiAgentFunction_input_schema: Partial<ApiAgentFunction_input_schema> | undefined | null = {}) : void {
    if (apiAgentFunction_input_schema) {
        writer.writeAdditionalData(apiAgentFunction_input_schema.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiAgentFunction_output_schema(writer: SerializationWriter, apiAgentFunction_output_schema: Partial<ApiAgentFunction_output_schema> | undefined | null = {}) : void {
    if (apiAgentFunction_output_schema) {
        writer.writeAdditionalData(apiAgentFunction_output_schema.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiAgentGuardrail(writer: SerializationWriter, apiAgentGuardrail: Partial<ApiAgentGuardrail> | undefined | null = {}) : void {
    if (apiAgentGuardrail) {
        writer.writeStringValue("agent_uuid", apiAgentGuardrail.agentUuid);
        writer.writeDateValue("created_at", apiAgentGuardrail.createdAt);
        writer.writeStringValue("default_response", apiAgentGuardrail.defaultResponse);
        writer.writeStringValue("description", apiAgentGuardrail.description);
        writer.writeStringValue("guardrail_uuid", apiAgentGuardrail.guardrailUuid);
        writer.writeBooleanValue("is_attached", apiAgentGuardrail.isAttached);
        writer.writeBooleanValue("is_default", apiAgentGuardrail.isDefault);
        writer.writeObjectValue<ApiAgentGuardrail_metadata>("metadata", apiAgentGuardrail.metadata, serializeApiAgentGuardrail_metadata);
        writer.writeStringValue("name", apiAgentGuardrail.name);
        writer.writeNumberValue("priority", apiAgentGuardrail.priority);
        writer.writeEnumValue<ApiGuardrailType>("type", apiAgentGuardrail.type ?? ApiGuardrailTypeObject.GUARDRAIL_TYPE_UNKNOWN);
        writer.writeDateValue("updated_at", apiAgentGuardrail.updatedAt);
        writer.writeStringValue("uuid", apiAgentGuardrail.uuid);
        writer.writeAdditionalData(apiAgentGuardrail.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiAgentGuardrail_metadata(writer: SerializationWriter, apiAgentGuardrail_metadata: Partial<ApiAgentGuardrail_metadata> | undefined | null = {}) : void {
    if (apiAgentGuardrail_metadata) {
        writer.writeAdditionalData(apiAgentGuardrail_metadata.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiAgentPublic(writer: SerializationWriter, apiAgentPublic: Partial<ApiAgentPublic> | undefined | null = {}) : void {
    if (apiAgentPublic) {
        writer.writeObjectValue<ApiChatbot>("chatbot", apiAgentPublic.chatbot, serializeApiChatbot);
        writer.writeCollectionOfObjectValues<ApiAgentChatbotIdentifier>("chatbot_identifiers", apiAgentPublic.chatbotIdentifiers, serializeApiAgentChatbotIdentifier);
        writer.writeDateValue("created_at", apiAgentPublic.createdAt);
        writer.writeObjectValue<ApiDeployment>("deployment", apiAgentPublic.deployment, serializeApiDeployment);
        writer.writeStringValue("description", apiAgentPublic.description);
        writer.writeStringValue("if_case", apiAgentPublic.ifCase);
        writer.writeStringValue("instruction", apiAgentPublic.instruction);
        writer.writeNumberValue("k", apiAgentPublic.k);
        writer.writeNumberValue("max_tokens", apiAgentPublic.maxTokens);
        writer.writeObjectValue<ApiModel>("model", apiAgentPublic.model, serializeApiModel);
        writer.writeStringValue("name", apiAgentPublic.name);
        writer.writeStringValue("project_id", apiAgentPublic.projectId);
        writer.writeStringValue("region", apiAgentPublic.region);
        writer.writeDateValue("route_created_at", apiAgentPublic.routeCreatedAt);
        writer.writeStringValue("route_created_by", apiAgentPublic.routeCreatedBy);
        writer.writeStringValue("route_name", apiAgentPublic.routeName);
        writer.writeStringValue("route_uuid", apiAgentPublic.routeUuid);
        writer.writeCollectionOfPrimitiveValues<string>("tags", apiAgentPublic.tags);
        writer.writeNumberValue("temperature", apiAgentPublic.temperature);
        writer.writeObjectValue<ApiAgentTemplate>("template", apiAgentPublic.template, serializeApiAgentTemplate);
        writer.writeNumberValue("top_p", apiAgentPublic.topP);
        writer.writeDateValue("updated_at", apiAgentPublic.updatedAt);
        writer.writeStringValue("url", apiAgentPublic.url);
        writer.writeStringValue("user_id", apiAgentPublic.userId);
        writer.writeStringValue("uuid", apiAgentPublic.uuid);
        writer.writeAdditionalData(apiAgentPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiAgentTemplate(writer: SerializationWriter, apiAgentTemplate: Partial<ApiAgentTemplate> | undefined | null = {}) : void {
    if (apiAgentTemplate) {
        writer.writeDateValue("created_at", apiAgentTemplate.createdAt);
        writer.writeStringValue("description", apiAgentTemplate.description);
        writer.writeStringValue("instruction", apiAgentTemplate.instruction);
        writer.writeNumberValue("k", apiAgentTemplate.k);
        writer.writeCollectionOfObjectValues<ApiKnowledgeBase>("knowledge_bases", apiAgentTemplate.knowledgeBases, serializeApiKnowledgeBase);
        writer.writeNumberValue("max_tokens", apiAgentTemplate.maxTokens);
        writer.writeObjectValue<ApiModel>("model", apiAgentTemplate.model, serializeApiModel);
        writer.writeStringValue("name", apiAgentTemplate.name);
        writer.writeNumberValue("temperature", apiAgentTemplate.temperature);
        writer.writeNumberValue("top_p", apiAgentTemplate.topP);
        writer.writeDateValue("updated_at", apiAgentTemplate.updatedAt);
        writer.writeStringValue("uuid", apiAgentTemplate.uuid);
        writer.writeAdditionalData(apiAgentTemplate.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiAgreement(writer: SerializationWriter, apiAgreement: Partial<ApiAgreement> | undefined | null = {}) : void {
    if (apiAgreement) {
        writer.writeStringValue("description", apiAgreement.description);
        writer.writeStringValue("name", apiAgreement.name);
        writer.writeStringValue("url", apiAgreement.url);
        writer.writeStringValue("uuid", apiAgreement.uuid);
        writer.writeAdditionalData(apiAgreement.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiAnthropicAPIKeyInfo(writer: SerializationWriter, apiAnthropicAPIKeyInfo: Partial<ApiAnthropicAPIKeyInfo> | undefined | null = {}) : void {
    if (apiAnthropicAPIKeyInfo) {
        writer.writeDateValue("created_at", apiAnthropicAPIKeyInfo.createdAt);
        writer.writeStringValue("created_by", apiAnthropicAPIKeyInfo.createdBy);
        writer.writeDateValue("deleted_at", apiAnthropicAPIKeyInfo.deletedAt);
        writer.writeStringValue("name", apiAnthropicAPIKeyInfo.name);
        writer.writeDateValue("updated_at", apiAnthropicAPIKeyInfo.updatedAt);
        writer.writeStringValue("uuid", apiAnthropicAPIKeyInfo.uuid);
        writer.writeAdditionalData(apiAnthropicAPIKeyInfo.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiCancelKnowledgeBaseIndexingJobInputPublic(writer: SerializationWriter, apiCancelKnowledgeBaseIndexingJobInputPublic: Partial<ApiCancelKnowledgeBaseIndexingJobInputPublic> | undefined | null = {}) : void {
    if (apiCancelKnowledgeBaseIndexingJobInputPublic) {
        writer.writeStringValue("uuid", apiCancelKnowledgeBaseIndexingJobInputPublic.uuid);
        writer.writeAdditionalData(apiCancelKnowledgeBaseIndexingJobInputPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiCancelKnowledgeBaseIndexingJobOutput(writer: SerializationWriter, apiCancelKnowledgeBaseIndexingJobOutput: Partial<ApiCancelKnowledgeBaseIndexingJobOutput> | undefined | null = {}) : void {
    if (apiCancelKnowledgeBaseIndexingJobOutput) {
        writer.writeObjectValue<ApiIndexingJob>("job", apiCancelKnowledgeBaseIndexingJobOutput.job, serializeApiIndexingJob);
        writer.writeAdditionalData(apiCancelKnowledgeBaseIndexingJobOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiChatbot(writer: SerializationWriter, apiChatbot: Partial<ApiChatbot> | undefined | null = {}) : void {
    if (apiChatbot) {
        writer.writeStringValue("button_background_color", apiChatbot.buttonBackgroundColor);
        writer.writeStringValue("logo", apiChatbot.logo);
        writer.writeStringValue("name", apiChatbot.name);
        writer.writeStringValue("primary_color", apiChatbot.primaryColor);
        writer.writeStringValue("secondary_color", apiChatbot.secondaryColor);
        writer.writeStringValue("starting_message", apiChatbot.startingMessage);
        writer.writeAdditionalData(apiChatbot.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiCreateAgentAPIKeyInputPublic(writer: SerializationWriter, apiCreateAgentAPIKeyInputPublic: Partial<ApiCreateAgentAPIKeyInputPublic> | undefined | null = {}) : void {
    if (apiCreateAgentAPIKeyInputPublic) {
        writer.writeStringValue("agent_uuid", apiCreateAgentAPIKeyInputPublic.agentUuid);
        writer.writeStringValue("name", apiCreateAgentAPIKeyInputPublic.name);
        writer.writeAdditionalData(apiCreateAgentAPIKeyInputPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiCreateAgentAPIKeyOutput(writer: SerializationWriter, apiCreateAgentAPIKeyOutput: Partial<ApiCreateAgentAPIKeyOutput> | undefined | null = {}) : void {
    if (apiCreateAgentAPIKeyOutput) {
        writer.writeObjectValue<ApiAgentAPIKeyInfo>("api_key_info", apiCreateAgentAPIKeyOutput.apiKeyInfo, serializeApiAgentAPIKeyInfo);
        writer.writeAdditionalData(apiCreateAgentAPIKeyOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiCreateAgentInputPublic(writer: SerializationWriter, apiCreateAgentInputPublic: Partial<ApiCreateAgentInputPublic> | undefined | null = {}) : void {
    if (apiCreateAgentInputPublic) {
        writer.writeStringValue("anthropic_key_uuid", apiCreateAgentInputPublic.anthropicKeyUuid);
        writer.writeStringValue("description", apiCreateAgentInputPublic.description);
        writer.writeStringValue("instruction", apiCreateAgentInputPublic.instruction);
        writer.writeCollectionOfPrimitiveValues<string>("knowledge_base_uuid", apiCreateAgentInputPublic.knowledgeBaseUuid);
        writer.writeStringValue("model_uuid", apiCreateAgentInputPublic.modelUuid);
        writer.writeStringValue("name", apiCreateAgentInputPublic.name);
        writer.writeStringValue("project_id", apiCreateAgentInputPublic.projectId);
        writer.writeStringValue("region", apiCreateAgentInputPublic.region);
        writer.writeCollectionOfPrimitiveValues<string>("tags", apiCreateAgentInputPublic.tags);
        writer.writeAdditionalData(apiCreateAgentInputPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiCreateAgentOutput(writer: SerializationWriter, apiCreateAgentOutput: Partial<ApiCreateAgentOutput> | undefined | null = {}) : void {
    if (apiCreateAgentOutput) {
        writer.writeObjectValue<ApiAgent>("agent", apiCreateAgentOutput.agent, serializeApiAgent);
        writer.writeAdditionalData(apiCreateAgentOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiCreateAnthropicAPIKeyInputPublic(writer: SerializationWriter, apiCreateAnthropicAPIKeyInputPublic: Partial<ApiCreateAnthropicAPIKeyInputPublic> | undefined | null = {}) : void {
    if (apiCreateAnthropicAPIKeyInputPublic) {
        writer.writeStringValue("api_key", apiCreateAnthropicAPIKeyInputPublic.apiKey);
        writer.writeStringValue("name", apiCreateAnthropicAPIKeyInputPublic.name);
        writer.writeAdditionalData(apiCreateAnthropicAPIKeyInputPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiCreateAnthropicAPIKeyOutput(writer: SerializationWriter, apiCreateAnthropicAPIKeyOutput: Partial<ApiCreateAnthropicAPIKeyOutput> | undefined | null = {}) : void {
    if (apiCreateAnthropicAPIKeyOutput) {
        writer.writeObjectValue<ApiAnthropicAPIKeyInfo>("api_key_info", apiCreateAnthropicAPIKeyOutput.apiKeyInfo, serializeApiAnthropicAPIKeyInfo);
        writer.writeAdditionalData(apiCreateAnthropicAPIKeyOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiCreateKnowledgeBaseDataSourceInputPublic(writer: SerializationWriter, apiCreateKnowledgeBaseDataSourceInputPublic: Partial<ApiCreateKnowledgeBaseDataSourceInputPublic> | undefined | null = {}) : void {
    if (apiCreateKnowledgeBaseDataSourceInputPublic) {
        writer.writeObjectValue<ApiFileUploadDataSource>("file_upload_data_source", apiCreateKnowledgeBaseDataSourceInputPublic.fileUploadDataSource, serializeApiFileUploadDataSource);
        writer.writeStringValue("knowledge_base_uuid", apiCreateKnowledgeBaseDataSourceInputPublic.knowledgeBaseUuid);
        writer.writeObjectValue<ApiSpacesDataSource>("spaces_data_source", apiCreateKnowledgeBaseDataSourceInputPublic.spacesDataSource, serializeApiSpacesDataSource);
        writer.writeAdditionalData(apiCreateKnowledgeBaseDataSourceInputPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiCreateKnowledgeBaseDataSourceOutput(writer: SerializationWriter, apiCreateKnowledgeBaseDataSourceOutput: Partial<ApiCreateKnowledgeBaseDataSourceOutput> | undefined | null = {}) : void {
    if (apiCreateKnowledgeBaseDataSourceOutput) {
        writer.writeObjectValue<ApiKnowledgeBaseDataSource>("knowledge_base_data_source", apiCreateKnowledgeBaseDataSourceOutput.knowledgeBaseDataSource, serializeApiKnowledgeBaseDataSource);
        writer.writeAdditionalData(apiCreateKnowledgeBaseDataSourceOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiCreateKnowledgeBaseInputPublic(writer: SerializationWriter, apiCreateKnowledgeBaseInputPublic: Partial<ApiCreateKnowledgeBaseInputPublic> | undefined | null = {}) : void {
    if (apiCreateKnowledgeBaseInputPublic) {
        writer.writeStringValue("database_id", apiCreateKnowledgeBaseInputPublic.databaseId);
        writer.writeCollectionOfObjectValues<ApiKBDataSource>("datasources", apiCreateKnowledgeBaseInputPublic.datasources, serializeApiKBDataSource);
        writer.writeStringValue("embedding_model_uuid", apiCreateKnowledgeBaseInputPublic.embeddingModelUuid);
        writer.writeStringValue("name", apiCreateKnowledgeBaseInputPublic.name);
        writer.writeStringValue("project_id", apiCreateKnowledgeBaseInputPublic.projectId);
        writer.writeStringValue("region", apiCreateKnowledgeBaseInputPublic.region);
        writer.writeCollectionOfPrimitiveValues<string>("tags", apiCreateKnowledgeBaseInputPublic.tags);
        writer.writeStringValue("vpc_uuid", apiCreateKnowledgeBaseInputPublic.vpcUuid);
        writer.writeAdditionalData(apiCreateKnowledgeBaseInputPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiCreateKnowledgeBaseOutput(writer: SerializationWriter, apiCreateKnowledgeBaseOutput: Partial<ApiCreateKnowledgeBaseOutput> | undefined | null = {}) : void {
    if (apiCreateKnowledgeBaseOutput) {
        writer.writeObjectValue<ApiKnowledgeBase>("knowledge_base", apiCreateKnowledgeBaseOutput.knowledgeBase, serializeApiKnowledgeBase);
        writer.writeAdditionalData(apiCreateKnowledgeBaseOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiDeleteAgentAPIKeyOutput(writer: SerializationWriter, apiDeleteAgentAPIKeyOutput: Partial<ApiDeleteAgentAPIKeyOutput> | undefined | null = {}) : void {
    if (apiDeleteAgentAPIKeyOutput) {
        writer.writeObjectValue<ApiAgentAPIKeyInfo>("api_key_info", apiDeleteAgentAPIKeyOutput.apiKeyInfo, serializeApiAgentAPIKeyInfo);
        writer.writeAdditionalData(apiDeleteAgentAPIKeyOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiDeleteAgentOutput(writer: SerializationWriter, apiDeleteAgentOutput: Partial<ApiDeleteAgentOutput> | undefined | null = {}) : void {
    if (apiDeleteAgentOutput) {
        writer.writeObjectValue<ApiAgent>("agent", apiDeleteAgentOutput.agent, serializeApiAgent);
        writer.writeAdditionalData(apiDeleteAgentOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiDeleteAnthropicAPIKeyOutput(writer: SerializationWriter, apiDeleteAnthropicAPIKeyOutput: Partial<ApiDeleteAnthropicAPIKeyOutput> | undefined | null = {}) : void {
    if (apiDeleteAnthropicAPIKeyOutput) {
        writer.writeObjectValue<ApiAnthropicAPIKeyInfo>("api_key_info", apiDeleteAnthropicAPIKeyOutput.apiKeyInfo, serializeApiAnthropicAPIKeyInfo);
        writer.writeAdditionalData(apiDeleteAnthropicAPIKeyOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiDeleteKnowledgeBaseDataSourceOutput(writer: SerializationWriter, apiDeleteKnowledgeBaseDataSourceOutput: Partial<ApiDeleteKnowledgeBaseDataSourceOutput> | undefined | null = {}) : void {
    if (apiDeleteKnowledgeBaseDataSourceOutput) {
        writer.writeStringValue("data_source_uuid", apiDeleteKnowledgeBaseDataSourceOutput.dataSourceUuid);
        writer.writeStringValue("knowledge_base_uuid", apiDeleteKnowledgeBaseDataSourceOutput.knowledgeBaseUuid);
        writer.writeAdditionalData(apiDeleteKnowledgeBaseDataSourceOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiDeleteKnowledgeBaseOutput(writer: SerializationWriter, apiDeleteKnowledgeBaseOutput: Partial<ApiDeleteKnowledgeBaseOutput> | undefined | null = {}) : void {
    if (apiDeleteKnowledgeBaseOutput) {
        writer.writeStringValue("uuid", apiDeleteKnowledgeBaseOutput.uuid);
        writer.writeAdditionalData(apiDeleteKnowledgeBaseOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiDeployment(writer: SerializationWriter, apiDeployment: Partial<ApiDeployment> | undefined | null = {}) : void {
    if (apiDeployment) {
        writer.writeDateValue("created_at", apiDeployment.createdAt);
        writer.writeStringValue("name", apiDeployment.name);
        writer.writeEnumValue<ApiDeploymentStatus>("status", apiDeployment.status ?? ApiDeploymentStatusObject.STATUS_UNKNOWN);
        writer.writeDateValue("updated_at", apiDeployment.updatedAt);
        writer.writeStringValue("url", apiDeployment.url);
        writer.writeStringValue("uuid", apiDeployment.uuid);
        writer.writeEnumValue<ApiDeploymentVisibility>("visibility", apiDeployment.visibility ?? ApiDeploymentVisibilityObject.VISIBILITY_UNKNOWN);
        writer.writeAdditionalData(apiDeployment.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiFileUploadDataSource(writer: SerializationWriter, apiFileUploadDataSource: Partial<ApiFileUploadDataSource> | undefined | null = {}) : void {
    if (apiFileUploadDataSource) {
        writer.writeStringValue("original_file_name", apiFileUploadDataSource.originalFileName);
        writer.writeStringValue("size_in_bytes", apiFileUploadDataSource.sizeInBytes);
        writer.writeStringValue("stored_object_key", apiFileUploadDataSource.storedObjectKey);
        writer.writeAdditionalData(apiFileUploadDataSource.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiGetAgentOutput(writer: SerializationWriter, apiGetAgentOutput: Partial<ApiGetAgentOutput> | undefined | null = {}) : void {
    if (apiGetAgentOutput) {
        writer.writeObjectValue<ApiAgent>("agent", apiGetAgentOutput.agent, serializeApiAgent);
        writer.writeAdditionalData(apiGetAgentOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiGetAnthropicAPIKeyOutput(writer: SerializationWriter, apiGetAnthropicAPIKeyOutput: Partial<ApiGetAnthropicAPIKeyOutput> | undefined | null = {}) : void {
    if (apiGetAnthropicAPIKeyOutput) {
        writer.writeObjectValue<ApiAnthropicAPIKeyInfo>("api_key_info", apiGetAnthropicAPIKeyOutput.apiKeyInfo, serializeApiAnthropicAPIKeyInfo);
        writer.writeAdditionalData(apiGetAnthropicAPIKeyOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiGetChildrenOutput(writer: SerializationWriter, apiGetChildrenOutput: Partial<ApiGetChildrenOutput> | undefined | null = {}) : void {
    if (apiGetChildrenOutput) {
        writer.writeCollectionOfObjectValues<ApiAgent>("children", apiGetChildrenOutput.children, serializeApiAgent);
        writer.writeAdditionalData(apiGetChildrenOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiGetKnowledgeBaseIndexingJobOutput(writer: SerializationWriter, apiGetKnowledgeBaseIndexingJobOutput: Partial<ApiGetKnowledgeBaseIndexingJobOutput> | undefined | null = {}) : void {
    if (apiGetKnowledgeBaseIndexingJobOutput) {
        writer.writeObjectValue<ApiIndexingJob>("job", apiGetKnowledgeBaseIndexingJobOutput.job, serializeApiIndexingJob);
        writer.writeAdditionalData(apiGetKnowledgeBaseIndexingJobOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiGetKnowledgeBaseOutput(writer: SerializationWriter, apiGetKnowledgeBaseOutput: Partial<ApiGetKnowledgeBaseOutput> | undefined | null = {}) : void {
    if (apiGetKnowledgeBaseOutput) {
        writer.writeEnumValue<DbaasClusterStatus>("database_status", apiGetKnowledgeBaseOutput.databaseStatus ?? DbaasClusterStatusObject.CREATING);
        writer.writeObjectValue<ApiKnowledgeBase>("knowledge_base", apiGetKnowledgeBaseOutput.knowledgeBase, serializeApiKnowledgeBase);
        writer.writeAdditionalData(apiGetKnowledgeBaseOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiIndexedDataSource(writer: SerializationWriter, apiIndexedDataSource: Partial<ApiIndexedDataSource> | undefined | null = {}) : void {
    if (apiIndexedDataSource) {
        writer.writeDateValue("completed_at", apiIndexedDataSource.completedAt);
        writer.writeStringValue("data_source_uuid", apiIndexedDataSource.dataSourceUuid);
        writer.writeStringValue("indexed_file_count", apiIndexedDataSource.indexedFileCount);
        writer.writeDateValue("started_at", apiIndexedDataSource.startedAt);
        writer.writeStringValue("total_bytes", apiIndexedDataSource.totalBytes);
        writer.writeStringValue("total_bytes_indexed", apiIndexedDataSource.totalBytesIndexed);
        writer.writeStringValue("total_file_count", apiIndexedDataSource.totalFileCount);
        writer.writeAdditionalData(apiIndexedDataSource.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiIndexingJob(writer: SerializationWriter, apiIndexingJob: Partial<ApiIndexingJob> | undefined | null = {}) : void {
    if (apiIndexingJob) {
        writer.writeNumberValue("completed_datasources", apiIndexingJob.completedDatasources);
        writer.writeDateValue("created_at", apiIndexingJob.createdAt);
        writer.writeCollectionOfPrimitiveValues<string>("data_source_uuids", apiIndexingJob.dataSourceUuids);
        writer.writeDateValue("finished_at", apiIndexingJob.finishedAt);
        writer.writeStringValue("knowledge_base_uuid", apiIndexingJob.knowledgeBaseUuid);
        writer.writeEnumValue<ApiBatchJobPhase>("phase", apiIndexingJob.phase ?? ApiBatchJobPhaseObject.BATCH_JOB_PHASE_UNKNOWN);
        writer.writeDateValue("started_at", apiIndexingJob.startedAt);
        writer.writeNumberValue("tokens", apiIndexingJob.tokens);
        writer.writeNumberValue("total_datasources", apiIndexingJob.totalDatasources);
        writer.writeDateValue("updated_at", apiIndexingJob.updatedAt);
        writer.writeStringValue("uuid", apiIndexingJob.uuid);
        writer.writeAdditionalData(apiIndexingJob.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiKBDataSource(writer: SerializationWriter, apiKBDataSource: Partial<ApiKBDataSource> | undefined | null = {}) : void {
    if (apiKBDataSource) {
        writer.writeStringValue("bucket_name", apiKBDataSource.bucketName);
        writer.writeStringValue("bucket_region", apiKBDataSource.bucketRegion);
        writer.writeObjectValue<ApiFileUploadDataSource>("file_upload_data_source", apiKBDataSource.fileUploadDataSource, serializeApiFileUploadDataSource);
        writer.writeStringValue("item_path", apiKBDataSource.itemPath);
        writer.writeObjectValue<ApiSpacesDataSource>("spaces_data_source", apiKBDataSource.spacesDataSource, serializeApiSpacesDataSource);
        writer.writeObjectValue<ApiWebCrawlerDataSource>("web_crawler_data_source", apiKBDataSource.webCrawlerDataSource, serializeApiWebCrawlerDataSource);
        writer.writeAdditionalData(apiKBDataSource.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiKnowledgeBase(writer: SerializationWriter, apiKnowledgeBase: Partial<ApiKnowledgeBase> | undefined | null = {}) : void {
    if (apiKnowledgeBase) {
        writer.writeDateValue("added_to_agent_at", apiKnowledgeBase.addedToAgentAt);
        writer.writeDateValue("created_at", apiKnowledgeBase.createdAt);
        writer.writeStringValue("database_id", apiKnowledgeBase.databaseId);
        writer.writeStringValue("embedding_model_uuid", apiKnowledgeBase.embeddingModelUuid);
        writer.writeBooleanValue("is_public", apiKnowledgeBase.isPublic);
        writer.writeObjectValue<ApiIndexingJob>("last_indexing_job", apiKnowledgeBase.lastIndexingJob, serializeApiIndexingJob);
        writer.writeStringValue("name", apiKnowledgeBase.name);
        writer.writeStringValue("project_id", apiKnowledgeBase.projectId);
        writer.writeStringValue("region", apiKnowledgeBase.region);
        writer.writeCollectionOfPrimitiveValues<string>("tags", apiKnowledgeBase.tags);
        writer.writeDateValue("updated_at", apiKnowledgeBase.updatedAt);
        writer.writeStringValue("user_id", apiKnowledgeBase.userId);
        writer.writeStringValue("uuid", apiKnowledgeBase.uuid);
        writer.writeAdditionalData(apiKnowledgeBase.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiKnowledgeBaseDataSource(writer: SerializationWriter, apiKnowledgeBaseDataSource: Partial<ApiKnowledgeBaseDataSource> | undefined | null = {}) : void {
    if (apiKnowledgeBaseDataSource) {
        writer.writeStringValue("bucket_name", apiKnowledgeBaseDataSource.bucketName);
        writer.writeDateValue("created_at", apiKnowledgeBaseDataSource.createdAt);
        writer.writeObjectValue<ApiFileUploadDataSource>("file_upload_data_source", apiKnowledgeBaseDataSource.fileUploadDataSource, serializeApiFileUploadDataSource);
        writer.writeStringValue("item_path", apiKnowledgeBaseDataSource.itemPath);
        writer.writeObjectValue<ApiIndexingJob>("last_indexing_job", apiKnowledgeBaseDataSource.lastIndexingJob, serializeApiIndexingJob);
        writer.writeStringValue("region", apiKnowledgeBaseDataSource.region);
        writer.writeObjectValue<ApiSpacesDataSource>("spaces_data_source", apiKnowledgeBaseDataSource.spacesDataSource, serializeApiSpacesDataSource);
        writer.writeDateValue("updated_at", apiKnowledgeBaseDataSource.updatedAt);
        writer.writeStringValue("uuid", apiKnowledgeBaseDataSource.uuid);
        writer.writeObjectValue<ApiWebCrawlerDataSource>("web_crawler_data_source", apiKnowledgeBaseDataSource.webCrawlerDataSource, serializeApiWebCrawlerDataSource);
        writer.writeAdditionalData(apiKnowledgeBaseDataSource.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiLinkAgentFunctionInputPublic(writer: SerializationWriter, apiLinkAgentFunctionInputPublic: Partial<ApiLinkAgentFunctionInputPublic> | undefined | null = {}) : void {
    if (apiLinkAgentFunctionInputPublic) {
        writer.writeStringValue("agent_uuid", apiLinkAgentFunctionInputPublic.agentUuid);
        writer.writeStringValue("description", apiLinkAgentFunctionInputPublic.description);
        writer.writeStringValue("faas_name", apiLinkAgentFunctionInputPublic.faasName);
        writer.writeStringValue("faas_namespace", apiLinkAgentFunctionInputPublic.faasNamespace);
        writer.writeStringValue("function_name", apiLinkAgentFunctionInputPublic.functionName);
        writer.writeObjectValue<ApiLinkAgentFunctionInputPublic_input_schema>("input_schema", apiLinkAgentFunctionInputPublic.inputSchema, serializeApiLinkAgentFunctionInputPublic_input_schema);
        writer.writeObjectValue<ApiLinkAgentFunctionInputPublic_output_schema>("output_schema", apiLinkAgentFunctionInputPublic.outputSchema, serializeApiLinkAgentFunctionInputPublic_output_schema);
        writer.writeAdditionalData(apiLinkAgentFunctionInputPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiLinkAgentFunctionInputPublic_input_schema(writer: SerializationWriter, apiLinkAgentFunctionInputPublic_input_schema: Partial<ApiLinkAgentFunctionInputPublic_input_schema> | undefined | null = {}) : void {
    if (apiLinkAgentFunctionInputPublic_input_schema) {
        writer.writeAdditionalData(apiLinkAgentFunctionInputPublic_input_schema.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiLinkAgentFunctionInputPublic_output_schema(writer: SerializationWriter, apiLinkAgentFunctionInputPublic_output_schema: Partial<ApiLinkAgentFunctionInputPublic_output_schema> | undefined | null = {}) : void {
    if (apiLinkAgentFunctionInputPublic_output_schema) {
        writer.writeAdditionalData(apiLinkAgentFunctionInputPublic_output_schema.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiLinkAgentFunctionOutput(writer: SerializationWriter, apiLinkAgentFunctionOutput: Partial<ApiLinkAgentFunctionOutput> | undefined | null = {}) : void {
    if (apiLinkAgentFunctionOutput) {
        writer.writeObjectValue<ApiAgent>("agent", apiLinkAgentFunctionOutput.agent, serializeApiAgent);
        writer.writeAdditionalData(apiLinkAgentFunctionOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiLinkAgentInputPublic(writer: SerializationWriter, apiLinkAgentInputPublic: Partial<ApiLinkAgentInputPublic> | undefined | null = {}) : void {
    if (apiLinkAgentInputPublic) {
        writer.writeStringValue("child_agent_uuid", apiLinkAgentInputPublic.childAgentUuid);
        writer.writeStringValue("if_case", apiLinkAgentInputPublic.ifCase);
        writer.writeStringValue("parent_agent_uuid", apiLinkAgentInputPublic.parentAgentUuid);
        writer.writeStringValue("route_name", apiLinkAgentInputPublic.routeName);
        writer.writeAdditionalData(apiLinkAgentInputPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiLinkAgentOutput(writer: SerializationWriter, apiLinkAgentOutput: Partial<ApiLinkAgentOutput> | undefined | null = {}) : void {
    if (apiLinkAgentOutput) {
        writer.writeStringValue("child_agent_uuid", apiLinkAgentOutput.childAgentUuid);
        writer.writeStringValue("parent_agent_uuid", apiLinkAgentOutput.parentAgentUuid);
        writer.writeAdditionalData(apiLinkAgentOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiLinkKnowledgeBaseOutput(writer: SerializationWriter, apiLinkKnowledgeBaseOutput: Partial<ApiLinkKnowledgeBaseOutput> | undefined | null = {}) : void {
    if (apiLinkKnowledgeBaseOutput) {
        writer.writeObjectValue<ApiAgent>("agent", apiLinkKnowledgeBaseOutput.agent, serializeApiAgent);
        writer.writeAdditionalData(apiLinkKnowledgeBaseOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiLinks(writer: SerializationWriter, apiLinks: Partial<ApiLinks> | undefined | null = {}) : void {
    if (apiLinks) {
        writer.writeObjectValue<ApiPages>("pages", apiLinks.pages, serializeApiPages);
        writer.writeAdditionalData(apiLinks.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiListAgentAPIKeysOutput(writer: SerializationWriter, apiListAgentAPIKeysOutput: Partial<ApiListAgentAPIKeysOutput> | undefined | null = {}) : void {
    if (apiListAgentAPIKeysOutput) {
        writer.writeCollectionOfObjectValues<ApiAgentAPIKeyInfo>("api_key_infos", apiListAgentAPIKeysOutput.apiKeyInfos, serializeApiAgentAPIKeyInfo);
        writer.writeObjectValue<ApiLinks>("links", apiListAgentAPIKeysOutput.links, serializeApiLinks);
        writer.writeObjectValue<ApiMeta>("meta", apiListAgentAPIKeysOutput.meta, serializeApiMeta);
        writer.writeAdditionalData(apiListAgentAPIKeysOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiListAgentsByAnthropicKeyOutput(writer: SerializationWriter, apiListAgentsByAnthropicKeyOutput: Partial<ApiListAgentsByAnthropicKeyOutput> | undefined | null = {}) : void {
    if (apiListAgentsByAnthropicKeyOutput) {
        writer.writeCollectionOfObjectValues<ApiAgent>("agents", apiListAgentsByAnthropicKeyOutput.agents, serializeApiAgent);
        writer.writeObjectValue<ApiLinks>("links", apiListAgentsByAnthropicKeyOutput.links, serializeApiLinks);
        writer.writeObjectValue<ApiMeta>("meta", apiListAgentsByAnthropicKeyOutput.meta, serializeApiMeta);
        writer.writeAdditionalData(apiListAgentsByAnthropicKeyOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiListAgentsOutputPublic(writer: SerializationWriter, apiListAgentsOutputPublic: Partial<ApiListAgentsOutputPublic> | undefined | null = {}) : void {
    if (apiListAgentsOutputPublic) {
        writer.writeCollectionOfObjectValues<ApiAgentPublic>("agents", apiListAgentsOutputPublic.agents, serializeApiAgentPublic);
        writer.writeObjectValue<ApiLinks>("links", apiListAgentsOutputPublic.links, serializeApiLinks);
        writer.writeObjectValue<ApiMeta>("meta", apiListAgentsOutputPublic.meta, serializeApiMeta);
        writer.writeAdditionalData(apiListAgentsOutputPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiListAnthropicAPIKeysOutput(writer: SerializationWriter, apiListAnthropicAPIKeysOutput: Partial<ApiListAnthropicAPIKeysOutput> | undefined | null = {}) : void {
    if (apiListAnthropicAPIKeysOutput) {
        writer.writeCollectionOfObjectValues<ApiAnthropicAPIKeyInfo>("api_key_infos", apiListAnthropicAPIKeysOutput.apiKeyInfos, serializeApiAnthropicAPIKeyInfo);
        writer.writeObjectValue<ApiLinks>("links", apiListAnthropicAPIKeysOutput.links, serializeApiLinks);
        writer.writeObjectValue<ApiMeta>("meta", apiListAnthropicAPIKeysOutput.meta, serializeApiMeta);
        writer.writeAdditionalData(apiListAnthropicAPIKeysOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiListIndexingJobDataSourcesOutput(writer: SerializationWriter, apiListIndexingJobDataSourcesOutput: Partial<ApiListIndexingJobDataSourcesOutput> | undefined | null = {}) : void {
    if (apiListIndexingJobDataSourcesOutput) {
        writer.writeCollectionOfObjectValues<ApiIndexedDataSource>("indexed_data_sources", apiListIndexingJobDataSourcesOutput.indexedDataSources, serializeApiIndexedDataSource);
        writer.writeAdditionalData(apiListIndexingJobDataSourcesOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiListKnowledgeBaseDataSourcesOutput(writer: SerializationWriter, apiListKnowledgeBaseDataSourcesOutput: Partial<ApiListKnowledgeBaseDataSourcesOutput> | undefined | null = {}) : void {
    if (apiListKnowledgeBaseDataSourcesOutput) {
        writer.writeCollectionOfObjectValues<ApiKnowledgeBaseDataSource>("knowledge_base_data_sources", apiListKnowledgeBaseDataSourcesOutput.knowledgeBaseDataSources, serializeApiKnowledgeBaseDataSource);
        writer.writeObjectValue<ApiLinks>("links", apiListKnowledgeBaseDataSourcesOutput.links, serializeApiLinks);
        writer.writeObjectValue<ApiMeta>("meta", apiListKnowledgeBaseDataSourcesOutput.meta, serializeApiMeta);
        writer.writeAdditionalData(apiListKnowledgeBaseDataSourcesOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiListKnowledgeBaseIndexingJobsOutput(writer: SerializationWriter, apiListKnowledgeBaseIndexingJobsOutput: Partial<ApiListKnowledgeBaseIndexingJobsOutput> | undefined | null = {}) : void {
    if (apiListKnowledgeBaseIndexingJobsOutput) {
        writer.writeCollectionOfObjectValues<ApiIndexingJob>("jobs", apiListKnowledgeBaseIndexingJobsOutput.jobs, serializeApiIndexingJob);
        writer.writeObjectValue<ApiLinks>("links", apiListKnowledgeBaseIndexingJobsOutput.links, serializeApiLinks);
        writer.writeObjectValue<ApiMeta>("meta", apiListKnowledgeBaseIndexingJobsOutput.meta, serializeApiMeta);
        writer.writeAdditionalData(apiListKnowledgeBaseIndexingJobsOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiListKnowledgeBasesOutput(writer: SerializationWriter, apiListKnowledgeBasesOutput: Partial<ApiListKnowledgeBasesOutput> | undefined | null = {}) : void {
    if (apiListKnowledgeBasesOutput) {
        writer.writeCollectionOfObjectValues<ApiKnowledgeBase>("knowledge_bases", apiListKnowledgeBasesOutput.knowledgeBases, serializeApiKnowledgeBase);
        writer.writeObjectValue<ApiLinks>("links", apiListKnowledgeBasesOutput.links, serializeApiLinks);
        writer.writeObjectValue<ApiMeta>("meta", apiListKnowledgeBasesOutput.meta, serializeApiMeta);
        writer.writeAdditionalData(apiListKnowledgeBasesOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiListModelsOutputPublic(writer: SerializationWriter, apiListModelsOutputPublic: Partial<ApiListModelsOutputPublic> | undefined | null = {}) : void {
    if (apiListModelsOutputPublic) {
        writer.writeObjectValue<ApiLinks>("links", apiListModelsOutputPublic.links, serializeApiLinks);
        writer.writeObjectValue<ApiMeta>("meta", apiListModelsOutputPublic.meta, serializeApiMeta);
        writer.writeCollectionOfObjectValues<ApiModelPublic>("models", apiListModelsOutputPublic.models, serializeApiModelPublic);
        writer.writeAdditionalData(apiListModelsOutputPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiListRegionsOutput(writer: SerializationWriter, apiListRegionsOutput: Partial<ApiListRegionsOutput> | undefined | null = {}) : void {
    if (apiListRegionsOutput) {
        writer.writeCollectionOfObjectValues<GenaiapiRegion>("regions", apiListRegionsOutput.regions, serializeGenaiapiRegion);
        writer.writeAdditionalData(apiListRegionsOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiMeta(writer: SerializationWriter, apiMeta: Partial<ApiMeta> | undefined | null = {}) : void {
    if (apiMeta) {
        writer.writeNumberValue("page", apiMeta.page);
        writer.writeNumberValue("pages", apiMeta.pages);
        writer.writeNumberValue("total", apiMeta.total);
        writer.writeAdditionalData(apiMeta.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiModel(writer: SerializationWriter, apiModel: Partial<ApiModel> | undefined | null = {}) : void {
    if (apiModel) {
        writer.writeObjectValue<ApiAgreement>("agreement", apiModel.agreement, serializeApiAgreement);
        writer.writeDateValue("created_at", apiModel.createdAt);
        writer.writeStringValue("inference_name", apiModel.inferenceName);
        writer.writeStringValue("inference_version", apiModel.inferenceVersion);
        writer.writeBooleanValue("is_foundational", apiModel.isFoundational);
        writer.writeObjectValue<ApiModel_metadata>("metadata", apiModel.metadata, serializeApiModel_metadata);
        writer.writeStringValue("name", apiModel.name);
        writer.writeStringValue("parent_uuid", apiModel.parentUuid);
        writer.writeEnumValue<ApiModelProvider>("provider", apiModel.provider ?? ApiModelProviderObject.MODEL_PROVIDER_DIGITALOCEAN);
        writer.writeDateValue("updated_at", apiModel.updatedAt);
        writer.writeBooleanValue("upload_complete", apiModel.uploadComplete);
        writer.writeStringValue("url", apiModel.url);
        writer.writeStringValue("uuid", apiModel.uuid);
        writer.writeObjectValue<ApiModelVersion>("version", apiModel.version, serializeApiModelVersion);
        writer.writeAdditionalData(apiModel.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiModel_metadata(writer: SerializationWriter, apiModel_metadata: Partial<ApiModel_metadata> | undefined | null = {}) : void {
    if (apiModel_metadata) {
        writer.writeAdditionalData(apiModel_metadata.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiModelPublic(writer: SerializationWriter, apiModelPublic: Partial<ApiModelPublic> | undefined | null = {}) : void {
    if (apiModelPublic) {
        writer.writeObjectValue<ApiAgreement>("agreement", apiModelPublic.agreement, serializeApiAgreement);
        writer.writeDateValue("created_at", apiModelPublic.createdAt);
        writer.writeBooleanValue("is_foundational", apiModelPublic.isFoundational);
        writer.writeStringValue("name", apiModelPublic.name);
        writer.writeStringValue("parent_uuid", apiModelPublic.parentUuid);
        writer.writeDateValue("updated_at", apiModelPublic.updatedAt);
        writer.writeBooleanValue("upload_complete", apiModelPublic.uploadComplete);
        writer.writeStringValue("url", apiModelPublic.url);
        writer.writeStringValue("uuid", apiModelPublic.uuid);
        writer.writeObjectValue<ApiModelVersion>("version", apiModelPublic.version, serializeApiModelVersion);
        writer.writeAdditionalData(apiModelPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiModelVersion(writer: SerializationWriter, apiModelVersion: Partial<ApiModelVersion> | undefined | null = {}) : void {
    if (apiModelVersion) {
        writer.writeNumberValue("major", apiModelVersion.major);
        writer.writeNumberValue("minor", apiModelVersion.minor);
        writer.writeNumberValue("patch", apiModelVersion.patch);
        writer.writeAdditionalData(apiModelVersion.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiPages(writer: SerializationWriter, apiPages: Partial<ApiPages> | undefined | null = {}) : void {
    if (apiPages) {
        writer.writeStringValue("first", apiPages.first);
        writer.writeStringValue("last", apiPages.last);
        writer.writeStringValue("next", apiPages.next);
        writer.writeStringValue("previous", apiPages.previous);
        writer.writeAdditionalData(apiPages.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiRegenerateAgentAPIKeyOutput(writer: SerializationWriter, apiRegenerateAgentAPIKeyOutput: Partial<ApiRegenerateAgentAPIKeyOutput> | undefined | null = {}) : void {
    if (apiRegenerateAgentAPIKeyOutput) {
        writer.writeObjectValue<ApiAgentAPIKeyInfo>("api_key_info", apiRegenerateAgentAPIKeyOutput.apiKeyInfo, serializeApiAgentAPIKeyInfo);
        writer.writeAdditionalData(apiRegenerateAgentAPIKeyOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiSpacesDataSource(writer: SerializationWriter, apiSpacesDataSource: Partial<ApiSpacesDataSource> | undefined | null = {}) : void {
    if (apiSpacesDataSource) {
        writer.writeStringValue("bucket_name", apiSpacesDataSource.bucketName);
        writer.writeStringValue("item_path", apiSpacesDataSource.itemPath);
        writer.writeStringValue("region", apiSpacesDataSource.region);
        writer.writeAdditionalData(apiSpacesDataSource.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiStartKnowledgeBaseIndexingJobInputPublic(writer: SerializationWriter, apiStartKnowledgeBaseIndexingJobInputPublic: Partial<ApiStartKnowledgeBaseIndexingJobInputPublic> | undefined | null = {}) : void {
    if (apiStartKnowledgeBaseIndexingJobInputPublic) {
        writer.writeCollectionOfPrimitiveValues<string>("data_source_uuids", apiStartKnowledgeBaseIndexingJobInputPublic.dataSourceUuids);
        writer.writeStringValue("knowledge_base_uuid", apiStartKnowledgeBaseIndexingJobInputPublic.knowledgeBaseUuid);
        writer.writeAdditionalData(apiStartKnowledgeBaseIndexingJobInputPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiStartKnowledgeBaseIndexingJobOutput(writer: SerializationWriter, apiStartKnowledgeBaseIndexingJobOutput: Partial<ApiStartKnowledgeBaseIndexingJobOutput> | undefined | null = {}) : void {
    if (apiStartKnowledgeBaseIndexingJobOutput) {
        writer.writeObjectValue<ApiIndexingJob>("job", apiStartKnowledgeBaseIndexingJobOutput.job, serializeApiIndexingJob);
        writer.writeAdditionalData(apiStartKnowledgeBaseIndexingJobOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiUnlinkAgentFunctionOutput(writer: SerializationWriter, apiUnlinkAgentFunctionOutput: Partial<ApiUnlinkAgentFunctionOutput> | undefined | null = {}) : void {
    if (apiUnlinkAgentFunctionOutput) {
        writer.writeObjectValue<ApiAgent>("agent", apiUnlinkAgentFunctionOutput.agent, serializeApiAgent);
        writer.writeAdditionalData(apiUnlinkAgentFunctionOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiUnlinkAgentOutput(writer: SerializationWriter, apiUnlinkAgentOutput: Partial<ApiUnlinkAgentOutput> | undefined | null = {}) : void {
    if (apiUnlinkAgentOutput) {
        writer.writeStringValue("child_agent_uuid", apiUnlinkAgentOutput.childAgentUuid);
        writer.writeStringValue("parent_agent_uuid", apiUnlinkAgentOutput.parentAgentUuid);
        writer.writeAdditionalData(apiUnlinkAgentOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiUnlinkKnowledgeBaseOutput(writer: SerializationWriter, apiUnlinkKnowledgeBaseOutput: Partial<ApiUnlinkKnowledgeBaseOutput> | undefined | null = {}) : void {
    if (apiUnlinkKnowledgeBaseOutput) {
        writer.writeObjectValue<ApiAgent>("agent", apiUnlinkKnowledgeBaseOutput.agent, serializeApiAgent);
        writer.writeAdditionalData(apiUnlinkKnowledgeBaseOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiUpdateAgentAPIKeyInputPublic(writer: SerializationWriter, apiUpdateAgentAPIKeyInputPublic: Partial<ApiUpdateAgentAPIKeyInputPublic> | undefined | null = {}) : void {
    if (apiUpdateAgentAPIKeyInputPublic) {
        writer.writeStringValue("agent_uuid", apiUpdateAgentAPIKeyInputPublic.agentUuid);
        writer.writeStringValue("api_key_uuid", apiUpdateAgentAPIKeyInputPublic.apiKeyUuid);
        writer.writeStringValue("name", apiUpdateAgentAPIKeyInputPublic.name);
        writer.writeAdditionalData(apiUpdateAgentAPIKeyInputPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiUpdateAgentAPIKeyOutput(writer: SerializationWriter, apiUpdateAgentAPIKeyOutput: Partial<ApiUpdateAgentAPIKeyOutput> | undefined | null = {}) : void {
    if (apiUpdateAgentAPIKeyOutput) {
        writer.writeObjectValue<ApiAgentAPIKeyInfo>("api_key_info", apiUpdateAgentAPIKeyOutput.apiKeyInfo, serializeApiAgentAPIKeyInfo);
        writer.writeAdditionalData(apiUpdateAgentAPIKeyOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiUpdateAgentDeploymentVisbilityOutput(writer: SerializationWriter, apiUpdateAgentDeploymentVisbilityOutput: Partial<ApiUpdateAgentDeploymentVisbilityOutput> | undefined | null = {}) : void {
    if (apiUpdateAgentDeploymentVisbilityOutput) {
        writer.writeObjectValue<ApiAgent>("agent", apiUpdateAgentDeploymentVisbilityOutput.agent, serializeApiAgent);
        writer.writeAdditionalData(apiUpdateAgentDeploymentVisbilityOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiUpdateAgentDeploymentVisibilityInputPublic(writer: SerializationWriter, apiUpdateAgentDeploymentVisibilityInputPublic: Partial<ApiUpdateAgentDeploymentVisibilityInputPublic> | undefined | null = {}) : void {
    if (apiUpdateAgentDeploymentVisibilityInputPublic) {
        writer.writeStringValue("uuid", apiUpdateAgentDeploymentVisibilityInputPublic.uuid);
        writer.writeEnumValue<ApiDeploymentVisibility>("visibility", apiUpdateAgentDeploymentVisibilityInputPublic.visibility ?? ApiDeploymentVisibilityObject.VISIBILITY_UNKNOWN);
        writer.writeAdditionalData(apiUpdateAgentDeploymentVisibilityInputPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiUpdateAgentFunctionInputPublic(writer: SerializationWriter, apiUpdateAgentFunctionInputPublic: Partial<ApiUpdateAgentFunctionInputPublic> | undefined | null = {}) : void {
    if (apiUpdateAgentFunctionInputPublic) {
        writer.writeStringValue("agent_uuid", apiUpdateAgentFunctionInputPublic.agentUuid);
        writer.writeStringValue("description", apiUpdateAgentFunctionInputPublic.description);
        writer.writeStringValue("faas_name", apiUpdateAgentFunctionInputPublic.faasName);
        writer.writeStringValue("faas_namespace", apiUpdateAgentFunctionInputPublic.faasNamespace);
        writer.writeStringValue("function_name", apiUpdateAgentFunctionInputPublic.functionName);
        writer.writeStringValue("function_uuid", apiUpdateAgentFunctionInputPublic.functionUuid);
        writer.writeObjectValue<ApiUpdateAgentFunctionInputPublic_input_schema>("input_schema", apiUpdateAgentFunctionInputPublic.inputSchema, serializeApiUpdateAgentFunctionInputPublic_input_schema);
        writer.writeObjectValue<ApiUpdateAgentFunctionInputPublic_output_schema>("output_schema", apiUpdateAgentFunctionInputPublic.outputSchema, serializeApiUpdateAgentFunctionInputPublic_output_schema);
        writer.writeAdditionalData(apiUpdateAgentFunctionInputPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiUpdateAgentFunctionInputPublic_input_schema(writer: SerializationWriter, apiUpdateAgentFunctionInputPublic_input_schema: Partial<ApiUpdateAgentFunctionInputPublic_input_schema> | undefined | null = {}) : void {
    if (apiUpdateAgentFunctionInputPublic_input_schema) {
        writer.writeAdditionalData(apiUpdateAgentFunctionInputPublic_input_schema.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiUpdateAgentFunctionInputPublic_output_schema(writer: SerializationWriter, apiUpdateAgentFunctionInputPublic_output_schema: Partial<ApiUpdateAgentFunctionInputPublic_output_schema> | undefined | null = {}) : void {
    if (apiUpdateAgentFunctionInputPublic_output_schema) {
        writer.writeAdditionalData(apiUpdateAgentFunctionInputPublic_output_schema.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiUpdateAgentFunctionOutput(writer: SerializationWriter, apiUpdateAgentFunctionOutput: Partial<ApiUpdateAgentFunctionOutput> | undefined | null = {}) : void {
    if (apiUpdateAgentFunctionOutput) {
        writer.writeObjectValue<ApiAgent>("agent", apiUpdateAgentFunctionOutput.agent, serializeApiAgent);
        writer.writeAdditionalData(apiUpdateAgentFunctionOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiUpdateAgentInputPublic(writer: SerializationWriter, apiUpdateAgentInputPublic: Partial<ApiUpdateAgentInputPublic> | undefined | null = {}) : void {
    if (apiUpdateAgentInputPublic) {
        writer.writeStringValue("anthropic_key_uuid", apiUpdateAgentInputPublic.anthropicKeyUuid);
        writer.writeStringValue("description", apiUpdateAgentInputPublic.description);
        writer.writeStringValue("instruction", apiUpdateAgentInputPublic.instruction);
        writer.writeNumberValue("k", apiUpdateAgentInputPublic.k);
        writer.writeNumberValue("max_tokens", apiUpdateAgentInputPublic.maxTokens);
        writer.writeStringValue("model_uuid", apiUpdateAgentInputPublic.modelUuid);
        writer.writeStringValue("name", apiUpdateAgentInputPublic.name);
        writer.writeStringValue("project_id", apiUpdateAgentInputPublic.projectId);
        writer.writeCollectionOfPrimitiveValues<string>("tags", apiUpdateAgentInputPublic.tags);
        writer.writeNumberValue("temperature", apiUpdateAgentInputPublic.temperature);
        writer.writeNumberValue("top_p", apiUpdateAgentInputPublic.topP);
        writer.writeStringValue("uuid", apiUpdateAgentInputPublic.uuid);
        writer.writeAdditionalData(apiUpdateAgentInputPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiUpdateAgentOutput(writer: SerializationWriter, apiUpdateAgentOutput: Partial<ApiUpdateAgentOutput> | undefined | null = {}) : void {
    if (apiUpdateAgentOutput) {
        writer.writeObjectValue<ApiAgent>("agent", apiUpdateAgentOutput.agent, serializeApiAgent);
        writer.writeAdditionalData(apiUpdateAgentOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiUpdateAnthropicAPIKeyInputPublic(writer: SerializationWriter, apiUpdateAnthropicAPIKeyInputPublic: Partial<ApiUpdateAnthropicAPIKeyInputPublic> | undefined | null = {}) : void {
    if (apiUpdateAnthropicAPIKeyInputPublic) {
        writer.writeStringValue("api_key", apiUpdateAnthropicAPIKeyInputPublic.apiKey);
        writer.writeStringValue("api_key_uuid", apiUpdateAnthropicAPIKeyInputPublic.apiKeyUuid);
        writer.writeStringValue("name", apiUpdateAnthropicAPIKeyInputPublic.name);
        writer.writeAdditionalData(apiUpdateAnthropicAPIKeyInputPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiUpdateAnthropicAPIKeyOutput(writer: SerializationWriter, apiUpdateAnthropicAPIKeyOutput: Partial<ApiUpdateAnthropicAPIKeyOutput> | undefined | null = {}) : void {
    if (apiUpdateAnthropicAPIKeyOutput) {
        writer.writeObjectValue<ApiAnthropicAPIKeyInfo>("api_key_info", apiUpdateAnthropicAPIKeyOutput.apiKeyInfo, serializeApiAnthropicAPIKeyInfo);
        writer.writeAdditionalData(apiUpdateAnthropicAPIKeyOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiUpdateKnowledgeBaseInputPublic(writer: SerializationWriter, apiUpdateKnowledgeBaseInputPublic: Partial<ApiUpdateKnowledgeBaseInputPublic> | undefined | null = {}) : void {
    if (apiUpdateKnowledgeBaseInputPublic) {
        writer.writeStringValue("database_id", apiUpdateKnowledgeBaseInputPublic.databaseId);
        writer.writeStringValue("embedding_model_uuid", apiUpdateKnowledgeBaseInputPublic.embeddingModelUuid);
        writer.writeStringValue("name", apiUpdateKnowledgeBaseInputPublic.name);
        writer.writeStringValue("project_id", apiUpdateKnowledgeBaseInputPublic.projectId);
        writer.writeCollectionOfPrimitiveValues<string>("tags", apiUpdateKnowledgeBaseInputPublic.tags);
        writer.writeStringValue("uuid", apiUpdateKnowledgeBaseInputPublic.uuid);
        writer.writeAdditionalData(apiUpdateKnowledgeBaseInputPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiUpdateKnowledgeBaseOutput(writer: SerializationWriter, apiUpdateKnowledgeBaseOutput: Partial<ApiUpdateKnowledgeBaseOutput> | undefined | null = {}) : void {
    if (apiUpdateKnowledgeBaseOutput) {
        writer.writeObjectValue<ApiKnowledgeBase>("knowledge_base", apiUpdateKnowledgeBaseOutput.knowledgeBase, serializeApiKnowledgeBase);
        writer.writeAdditionalData(apiUpdateKnowledgeBaseOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiUpdateLinkedAgentInputPublic(writer: SerializationWriter, apiUpdateLinkedAgentInputPublic: Partial<ApiUpdateLinkedAgentInputPublic> | undefined | null = {}) : void {
    if (apiUpdateLinkedAgentInputPublic) {
        writer.writeStringValue("child_agent_uuid", apiUpdateLinkedAgentInputPublic.childAgentUuid);
        writer.writeStringValue("if_case", apiUpdateLinkedAgentInputPublic.ifCase);
        writer.writeStringValue("parent_agent_uuid", apiUpdateLinkedAgentInputPublic.parentAgentUuid);
        writer.writeStringValue("route_name", apiUpdateLinkedAgentInputPublic.routeName);
        writer.writeStringValue("uuid", apiUpdateLinkedAgentInputPublic.uuid);
        writer.writeAdditionalData(apiUpdateLinkedAgentInputPublic.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiUpdateLinkedAgentOutput(writer: SerializationWriter, apiUpdateLinkedAgentOutput: Partial<ApiUpdateLinkedAgentOutput> | undefined | null = {}) : void {
    if (apiUpdateLinkedAgentOutput) {
        writer.writeStringValue("child_agent_uuid", apiUpdateLinkedAgentOutput.childAgentUuid);
        writer.writeStringValue("parent_agent_uuid", apiUpdateLinkedAgentOutput.parentAgentUuid);
        writer.writeStringValue("uuid", apiUpdateLinkedAgentOutput.uuid);
        writer.writeAdditionalData(apiUpdateLinkedAgentOutput.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApiWebCrawlerDataSource(writer: SerializationWriter, apiWebCrawlerDataSource: Partial<ApiWebCrawlerDataSource> | undefined | null = {}) : void {
    if (apiWebCrawlerDataSource) {
        writer.writeStringValue("base_url", apiWebCrawlerDataSource.baseUrl);
        writer.writeEnumValue<ApiCrawlingOption>("crawling_option", apiWebCrawlerDataSource.crawlingOption ?? ApiCrawlingOptionObject.UNKNOWN);
        writer.writeBooleanValue("embed_media", apiWebCrawlerDataSource.embedMedia);
        writer.writeAdditionalData(apiWebCrawlerDataSource.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp(writer: SerializationWriter, app: Partial<App> | undefined | null = {}) : void {
    if (app) {
        writer.writeObjectValue<Apps_deployment>("active_deployment", app.activeDeployment, serializeApps_deployment);
        writer.writeObjectValue<Apps_deployment>("in_progress_deployment", app.inProgressDeployment, serializeApps_deployment);
        writer.writeObjectValue<Apps_deployment>("pending_deployment", app.pendingDeployment, serializeApps_deployment);
        writer.writeObjectValue<Apps_deployment>("pinned_deployment", app.pinnedDeployment, serializeApps_deployment);
        writer.writeObjectValue<Apps_region>("region", app.region, serializeApps_region);
        writer.writeObjectValue<App_spec>("spec", app.spec, serializeApp_spec);
        writer.writeAdditionalData(app.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_alert(writer: SerializationWriter, app_alert: Partial<App_alert> | undefined | null = {}) : void {
    if (app_alert) {
        writer.writeStringValue("component_name", app_alert.componentName);
        writer.writeCollectionOfPrimitiveValues<string>("emails", app_alert.emails);
        writer.writeEnumValue<App_alert_phase>("phase", app_alert.phase ?? App_alert_phaseObject.UNKNOWN);
        writer.writeObjectValue<App_alert_progress>("progress", app_alert.progress, serializeApp_alert_progress);
        writer.writeCollectionOfObjectValues<App_alert_slack_webhook>("slack_webhooks", app_alert.slackWebhooks, serializeApp_alert_slack_webhook);
        writer.writeObjectValue<App_alert_spec>("spec", app_alert.spec, serializeApp_alert_spec);
        writer.writeAdditionalData(app_alert.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_alert_progress(writer: SerializationWriter, app_alert_progress: Partial<App_alert_progress> | undefined | null = {}) : void {
    if (app_alert_progress) {
        writer.writeCollectionOfObjectValues<App_alert_progress_step>("steps", app_alert_progress.steps, serializeApp_alert_progress_step);
        writer.writeAdditionalData(app_alert_progress.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_alert_progress_step(writer: SerializationWriter, app_alert_progress_step: Partial<App_alert_progress_step> | undefined | null = {}) : void {
    if (app_alert_progress_step) {
        writer.writeDateValue("ended_at", app_alert_progress_step.endedAt);
        writer.writeStringValue("name", app_alert_progress_step.name);
        writer.writeObjectValue<App_alert_progress_step_reason>("reason", app_alert_progress_step.reason, serializeApp_alert_progress_step_reason);
        writer.writeDateValue("started_at", app_alert_progress_step.startedAt);
        writer.writeEnumValue<App_alert_progress_step_status>("status", app_alert_progress_step.status ?? App_alert_progress_step_statusObject.UNKNOWN);
        writer.writeAdditionalData(app_alert_progress_step.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_alert_progress_step_reason(writer: SerializationWriter, app_alert_progress_step_reason: Partial<App_alert_progress_step_reason> | undefined | null = {}) : void {
    if (app_alert_progress_step_reason) {
        writer.writeStringValue("code", app_alert_progress_step_reason.code);
        writer.writeStringValue("message", app_alert_progress_step_reason.message);
        writer.writeAdditionalData(app_alert_progress_step_reason.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_alert_slack_webhook(writer: SerializationWriter, app_alert_slack_webhook: Partial<App_alert_slack_webhook> | undefined | null = {}) : void {
    if (app_alert_slack_webhook) {
        writer.writeStringValue("channel", app_alert_slack_webhook.channel);
        writer.writeStringValue("url", app_alert_slack_webhook.url);
        writer.writeAdditionalData(app_alert_slack_webhook.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_alert_spec(writer: SerializationWriter, app_alert_spec: Partial<App_alert_spec> | undefined | null = {}) : void {
    if (app_alert_spec) {
        writer.writeBooleanValue("disabled", app_alert_spec.disabled);
        writer.writeEnumValue<App_alert_spec_operator>("operator", app_alert_spec.operator ?? App_alert_spec_operatorObject.UNSPECIFIED_OPERATOR);
        writer.writeEnumValue<App_alert_spec_rule>("rule", app_alert_spec.rule ?? App_alert_spec_ruleObject.UNSPECIFIED_RULE);
        writer.writeNumberValue("value", app_alert_spec.value);
        writer.writeEnumValue<App_alert_spec_window>("window", app_alert_spec.window ?? App_alert_spec_windowObject.UNSPECIFIED_WINDOW);
        writer.writeAdditionalData(app_alert_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_component_base(writer: SerializationWriter, app_component_base: Partial<App_component_base> | undefined | null = {}) : void {
    if (app_component_base) {
        writer.writeObjectValue<Apps_bitbucket_source_spec>("bitbucket", app_component_base.bitbucket, serializeApps_bitbucket_source_spec);
        writer.writeStringValue("build_command", app_component_base.buildCommand);
        writer.writeStringValue("dockerfile_path", app_component_base.dockerfilePath);
        writer.writeStringValue("environment_slug", app_component_base.environmentSlug);
        writer.writeCollectionOfObjectValues<App_variable_definition>("envs", app_component_base.envs, serializeApp_variable_definition);
        writer.writeObjectValue<Apps_git_source_spec>("git", app_component_base.git, serializeApps_git_source_spec);
        writer.writeObjectValue<Apps_github_source_spec>("github", app_component_base.github, serializeApps_github_source_spec);
        writer.writeObjectValue<Apps_gitlab_source_spec>("gitlab", app_component_base.gitlab, serializeApps_gitlab_source_spec);
        writer.writeObjectValue<Apps_image_source_spec>("image", app_component_base.image, serializeApps_image_source_spec);
        writer.writeCollectionOfObjectValues<App_log_destination_definition>("log_destinations", app_component_base.logDestinations, serializeApp_log_destination_definition);
        writer.writeStringValue("name", app_component_base.name);
        writer.writeStringValue("run_command", app_component_base.runCommand);
        writer.writeStringValue("source_dir", app_component_base.sourceDir);
        writer.writeAdditionalData(app_component_base.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_database_spec(writer: SerializationWriter, app_database_spec: Partial<App_database_spec> | undefined | null = {}) : void {
    if (app_database_spec) {
        writer.writeStringValue("cluster_name", app_database_spec.clusterName);
        writer.writeStringValue("db_name", app_database_spec.dbName);
        writer.writeStringValue("db_user", app_database_spec.dbUser);
        writer.writeEnumValue<App_database_spec_engine>("engine", app_database_spec.engine ?? App_database_spec_engineObject.UNSET);
        writer.writeStringValue("name", app_database_spec.name);
        writer.writeBooleanValue("production", app_database_spec.production);
        writer.writeStringValue("version", app_database_spec.version);
        writer.writeAdditionalData(app_database_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_domain_spec(writer: SerializationWriter, app_domain_spec: Partial<App_domain_spec> | undefined | null = {}) : void {
    if (app_domain_spec) {
        writer.writeStringValue("domain", app_domain_spec.domain);
        writer.writeEnumValue<App_domain_spec_minimum_tls_version>("minimum_tls_version", app_domain_spec.minimumTlsVersion);
        writer.writeEnumValue<App_domain_spec_type>("type", app_domain_spec.type ?? App_domain_spec_typeObject.UNSPECIFIED);
        writer.writeBooleanValue("wildcard", app_domain_spec.wildcard);
        writer.writeStringValue("zone", app_domain_spec.zone);
        writer.writeAdditionalData(app_domain_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_domain_validation(writer: SerializationWriter, app_domain_validation: Partial<App_domain_validation> | undefined | null = {}) : void {
    if (app_domain_validation) {
        writer.writeAdditionalData(app_domain_validation.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_egress_spec(writer: SerializationWriter, app_egress_spec: Partial<App_egress_spec> | undefined | null = {}) : void {
    if (app_egress_spec) {
        writer.writeEnumValue<App_egress_type_spec>("type", app_egress_spec.type ?? App_egress_type_specObject.AUTOASSIGN);
        writer.writeAdditionalData(app_egress_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_functions_spec(writer: SerializationWriter, app_functions_spec: Partial<App_functions_spec> | undefined | null = {}) : void {
    if (app_functions_spec) {
        writer.writeCollectionOfObjectValues<App_alert_spec>("alerts", app_functions_spec.alerts, serializeApp_alert_spec);
        writer.writeObjectValue<Apps_bitbucket_source_spec>("bitbucket", app_functions_spec.bitbucket, serializeApps_bitbucket_source_spec);
        writer.writeObjectValue<Apps_cors_policy>("cors", app_functions_spec.cors, serializeApps_cors_policy);
        writer.writeCollectionOfObjectValues<App_variable_definition>("envs", app_functions_spec.envs, serializeApp_variable_definition);
        writer.writeObjectValue<Apps_git_source_spec>("git", app_functions_spec.git, serializeApps_git_source_spec);
        writer.writeObjectValue<Apps_github_source_spec>("github", app_functions_spec.github, serializeApps_github_source_spec);
        writer.writeObjectValue<Apps_gitlab_source_spec>("gitlab", app_functions_spec.gitlab, serializeApps_gitlab_source_spec);
        writer.writeCollectionOfObjectValues<App_log_destination_definition>("log_destinations", app_functions_spec.logDestinations, serializeApp_log_destination_definition);
        writer.writeStringValue("name", app_functions_spec.name);
        writer.writeCollectionOfObjectValues<App_route_spec>("routes", app_functions_spec.routes, serializeApp_route_spec);
        writer.writeStringValue("source_dir", app_functions_spec.sourceDir);
        writer.writeAdditionalData(app_functions_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_ingress_spec(writer: SerializationWriter, app_ingress_spec: Partial<App_ingress_spec> | undefined | null = {}) : void {
    if (app_ingress_spec) {
        writer.writeCollectionOfObjectValues<App_ingress_spec_rule>("rules", app_ingress_spec.rules, serializeApp_ingress_spec_rule);
        writer.writeAdditionalData(app_ingress_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_ingress_spec_rule(writer: SerializationWriter, app_ingress_spec_rule: Partial<App_ingress_spec_rule> | undefined | null = {}) : void {
    if (app_ingress_spec_rule) {
        writer.writeObjectValue<App_ingress_spec_rule_routing_component>("component", app_ingress_spec_rule.component, serializeApp_ingress_spec_rule_routing_component);
        writer.writeObjectValue<Apps_cors_policy>("cors", app_ingress_spec_rule.cors, serializeApps_cors_policy);
        writer.writeObjectValue<App_ingress_spec_rule_match>("match", app_ingress_spec_rule.match, serializeApp_ingress_spec_rule_match);
        writer.writeObjectValue<App_ingress_spec_rule_routing_redirect>("redirect", app_ingress_spec_rule.redirect, serializeApp_ingress_spec_rule_routing_redirect);
        writer.writeAdditionalData(app_ingress_spec_rule.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_ingress_spec_rule_match(writer: SerializationWriter, app_ingress_spec_rule_match: Partial<App_ingress_spec_rule_match> | undefined | null = {}) : void {
    if (app_ingress_spec_rule_match) {
        writer.writeObjectValue<App_ingress_spec_rule_string_match>("path", app_ingress_spec_rule_match.path, serializeApp_ingress_spec_rule_string_match);
        writer.writeAdditionalData(app_ingress_spec_rule_match.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_ingress_spec_rule_routing_component(writer: SerializationWriter, app_ingress_spec_rule_routing_component: Partial<App_ingress_spec_rule_routing_component> | undefined | null = {}) : void {
    if (app_ingress_spec_rule_routing_component) {
        writer.writeStringValue("name", app_ingress_spec_rule_routing_component.name);
        writer.writeStringValue("preserve_path_prefix", app_ingress_spec_rule_routing_component.preservePathPrefix);
        writer.writeStringValue("rewrite", app_ingress_spec_rule_routing_component.rewrite);
        writer.writeAdditionalData(app_ingress_spec_rule_routing_component.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_ingress_spec_rule_routing_redirect(writer: SerializationWriter, app_ingress_spec_rule_routing_redirect: Partial<App_ingress_spec_rule_routing_redirect> | undefined | null = {}) : void {
    if (app_ingress_spec_rule_routing_redirect) {
        writer.writeStringValue("authority", app_ingress_spec_rule_routing_redirect.authority);
        writer.writeNumberValue("port", app_ingress_spec_rule_routing_redirect.port);
        writer.writeNumberValue("redirect_code", app_ingress_spec_rule_routing_redirect.redirectCode);
        writer.writeStringValue("scheme", app_ingress_spec_rule_routing_redirect.scheme);
        writer.writeStringValue("uri", app_ingress_spec_rule_routing_redirect.uri);
        writer.writeAdditionalData(app_ingress_spec_rule_routing_redirect.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_ingress_spec_rule_string_match(writer: SerializationWriter, app_ingress_spec_rule_string_match: Partial<App_ingress_spec_rule_string_match> | undefined | null = {}) : void {
    if (app_ingress_spec_rule_string_match) {
        writer.writeStringValue("prefix", app_ingress_spec_rule_string_match.prefix);
        writer.writeAdditionalData(app_ingress_spec_rule_string_match.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_job_spec(writer: SerializationWriter, app_job_spec: Partial<App_job_spec> | undefined | null = {}) : void {
    if (app_job_spec) {
        writer.writeObjectValue<App_job_spec_autoscaling>("autoscaling", app_job_spec.autoscaling, serializeApp_job_spec_autoscaling);
        writer.writeObjectValue<Apps_bitbucket_source_spec>("bitbucket", app_job_spec.bitbucket, serializeApps_bitbucket_source_spec);
        writer.writeStringValue("build_command", app_job_spec.buildCommand);
        writer.writeStringValue("dockerfile_path", app_job_spec.dockerfilePath);
        writer.writeStringValue("environment_slug", app_job_spec.environmentSlug);
        writer.writeCollectionOfObjectValues<App_variable_definition>("envs", app_job_spec.envs, serializeApp_variable_definition);
        writer.writeObjectValue<Apps_git_source_spec>("git", app_job_spec.git, serializeApps_git_source_spec);
        writer.writeObjectValue<Apps_github_source_spec>("github", app_job_spec.github, serializeApps_github_source_spec);
        writer.writeObjectValue<Apps_gitlab_source_spec>("gitlab", app_job_spec.gitlab, serializeApps_gitlab_source_spec);
        writer.writeObjectValue<Apps_image_source_spec>("image", app_job_spec.image, serializeApps_image_source_spec);
        writer.writeNumberValue("instance_count", app_job_spec.instanceCount);
        if ( typeof app_job_spec.instanceSizeSlug === "string") {
            writer.writeStringValue("instance_size_slug", app_job_spec.instanceSizeSlug as string);
        }
        writer.writeEnumValue<App_job_spec_kind>("kind", app_job_spec.kind ?? App_job_spec_kindObject.UNSPECIFIED);
        writer.writeCollectionOfObjectValues<App_log_destination_definition>("log_destinations", app_job_spec.logDestinations, serializeApp_log_destination_definition);
        writer.writeStringValue("name", app_job_spec.name);
        writer.writeStringValue("run_command", app_job_spec.runCommand);
        writer.writeStringValue("source_dir", app_job_spec.sourceDir);
        writer.writeObjectValue<App_job_spec_termination>("termination", app_job_spec.termination, serializeApp_job_spec_termination);
        writer.writeAdditionalData(app_job_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_job_spec_autoscaling(writer: SerializationWriter, app_job_spec_autoscaling: Partial<App_job_spec_autoscaling> | undefined | null = {}) : void {
    if (app_job_spec_autoscaling) {
        writer.writeNumberValue("max_instance_count", app_job_spec_autoscaling.maxInstanceCount);
        writer.writeObjectValue<App_job_spec_autoscaling_metrics>("metrics", app_job_spec_autoscaling.metrics, serializeApp_job_spec_autoscaling_metrics);
        writer.writeNumberValue("min_instance_count", app_job_spec_autoscaling.minInstanceCount);
        writer.writeAdditionalData(app_job_spec_autoscaling.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_job_spec_autoscaling_metrics(writer: SerializationWriter, app_job_spec_autoscaling_metrics: Partial<App_job_spec_autoscaling_metrics> | undefined | null = {}) : void {
    if (app_job_spec_autoscaling_metrics) {
        writer.writeObjectValue<App_job_spec_autoscaling_metrics_cpu>("cpu", app_job_spec_autoscaling_metrics.cpu, serializeApp_job_spec_autoscaling_metrics_cpu);
        writer.writeAdditionalData(app_job_spec_autoscaling_metrics.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_job_spec_autoscaling_metrics_cpu(writer: SerializationWriter, app_job_spec_autoscaling_metrics_cpu: Partial<App_job_spec_autoscaling_metrics_cpu> | undefined | null = {}) : void {
    if (app_job_spec_autoscaling_metrics_cpu) {
        writer.writeNumberValue("percent", app_job_spec_autoscaling_metrics_cpu.percent);
        writer.writeAdditionalData(app_job_spec_autoscaling_metrics_cpu.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param key The name of the property to write in the serialization.
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_job_spec_instance_size_slug(writer: SerializationWriter, key: string, app_job_spec_instance_size_slug: Parsable | App_job_spec_instance_size_slug | undefined) : void {
    if (app_job_spec_instance_size_slug === undefined || app_job_spec_instance_size_slug === null) return;
    if (typeof app_job_spec_instance_size_slug === "string" ) {
        writer.writeStringValue(undefined, app_job_spec_instance_size_slug as string);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_job_spec_termination(writer: SerializationWriter, app_job_spec_termination: Partial<App_job_spec_termination> | undefined | null = {}) : void {
    if (app_job_spec_termination) {
        writer.writeNumberValue("grace_period_seconds", app_job_spec_termination.gracePeriodSeconds);
        writer.writeAdditionalData(app_job_spec_termination.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_log_destination_datadog_spec(writer: SerializationWriter, app_log_destination_datadog_spec: Partial<App_log_destination_datadog_spec> | undefined | null = {}) : void {
    if (app_log_destination_datadog_spec) {
        writer.writeStringValue("api_key", app_log_destination_datadog_spec.apiKey);
        writer.writeStringValue("endpoint", app_log_destination_datadog_spec.endpoint);
        writer.writeAdditionalData(app_log_destination_datadog_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_log_destination_definition(writer: SerializationWriter, app_log_destination_definition: Partial<App_log_destination_definition> | undefined | null = {}) : void {
    if (app_log_destination_definition) {
        writer.writeObjectValue<App_log_destination_datadog_spec>("datadog", app_log_destination_definition.datadog, serializeApp_log_destination_datadog_spec);
        writer.writeObjectValue<App_log_destination_logtail_spec>("logtail", app_log_destination_definition.logtail, serializeApp_log_destination_logtail_spec);
        writer.writeStringValue("name", app_log_destination_definition.name);
        writer.writeObjectValue<App_log_destination_open_search_spec>("open_search", app_log_destination_definition.openSearch, serializeApp_log_destination_open_search_spec);
        writer.writeObjectValue<App_log_destination_papertrail_spec>("papertrail", app_log_destination_definition.papertrail, serializeApp_log_destination_papertrail_spec);
        writer.writeAdditionalData(app_log_destination_definition.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_log_destination_logtail_spec(writer: SerializationWriter, app_log_destination_logtail_spec: Partial<App_log_destination_logtail_spec> | undefined | null = {}) : void {
    if (app_log_destination_logtail_spec) {
        writer.writeStringValue("token", app_log_destination_logtail_spec.token);
        writer.writeAdditionalData(app_log_destination_logtail_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_log_destination_open_search_spec(writer: SerializationWriter, app_log_destination_open_search_spec: Partial<App_log_destination_open_search_spec> | undefined | null = {}) : void {
    if (app_log_destination_open_search_spec) {
        writer.writeObjectValue<App_log_destination_open_search_spec_basic_auth>("basic_auth", app_log_destination_open_search_spec.basicAuth, serializeApp_log_destination_open_search_spec_basic_auth);
        writer.writeStringValue("cluster_name", app_log_destination_open_search_spec.clusterName);
        writer.writeStringValue("endpoint", app_log_destination_open_search_spec.endpoint);
        writer.writeStringValue("index_name", app_log_destination_open_search_spec.indexName ?? "logs");
        writer.writeAdditionalData(app_log_destination_open_search_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_log_destination_open_search_spec_basic_auth(writer: SerializationWriter, app_log_destination_open_search_spec_basic_auth: Partial<App_log_destination_open_search_spec_basic_auth> | undefined | null = {}) : void {
    if (app_log_destination_open_search_spec_basic_auth) {
        writer.writeObjectValue("password", app_log_destination_open_search_spec_basic_auth.password);
        writer.writeStringValue("user", app_log_destination_open_search_spec_basic_auth.user);
        writer.writeAdditionalData(app_log_destination_open_search_spec_basic_auth.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_log_destination_papertrail_spec(writer: SerializationWriter, app_log_destination_papertrail_spec: Partial<App_log_destination_papertrail_spec> | undefined | null = {}) : void {
    if (app_log_destination_papertrail_spec) {
        writer.writeStringValue("endpoint", app_log_destination_papertrail_spec.endpoint);
        writer.writeAdditionalData(app_log_destination_papertrail_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_maintenance_spec(writer: SerializationWriter, app_maintenance_spec: Partial<App_maintenance_spec> | undefined | null = {}) : void {
    if (app_maintenance_spec) {
        writer.writeBooleanValue("archive", app_maintenance_spec.archive);
        writer.writeBooleanValue("enabled", app_maintenance_spec.enabled);
        writer.writeStringValue("offline_page_url", app_maintenance_spec.offlinePageUrl);
        writer.writeAdditionalData(app_maintenance_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_metrics_bandwidth_usage(writer: SerializationWriter, app_metrics_bandwidth_usage: Partial<App_metrics_bandwidth_usage> | undefined | null = {}) : void {
    if (app_metrics_bandwidth_usage) {
        writer.writeCollectionOfObjectValues<App_metrics_bandwidth_usage_details>("app_bandwidth_usage", app_metrics_bandwidth_usage.appBandwidthUsage, serializeApp_metrics_bandwidth_usage_details);
        writer.writeDateValue("date", app_metrics_bandwidth_usage.date);
        writer.writeAdditionalData(app_metrics_bandwidth_usage.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_metrics_bandwidth_usage_details(writer: SerializationWriter, app_metrics_bandwidth_usage_details: Partial<App_metrics_bandwidth_usage_details> | undefined | null = {}) : void {
    if (app_metrics_bandwidth_usage_details) {
        writer.writeStringValue("app_id", app_metrics_bandwidth_usage_details.appId);
        writer.writeStringValue("bandwidth_bytes", app_metrics_bandwidth_usage_details.bandwidthBytes);
        writer.writeAdditionalData(app_metrics_bandwidth_usage_details.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_metrics_bandwidth_usage_request(writer: SerializationWriter, app_metrics_bandwidth_usage_request: Partial<App_metrics_bandwidth_usage_request> | undefined | null = {}) : void {
    if (app_metrics_bandwidth_usage_request) {
        writer.writeCollectionOfPrimitiveValues<string>("app_ids", app_metrics_bandwidth_usage_request.appIds);
        writer.writeDateValue("date", app_metrics_bandwidth_usage_request.date);
        writer.writeAdditionalData(app_metrics_bandwidth_usage_request.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_propose(writer: SerializationWriter, app_propose: Partial<App_propose> | undefined | null = {}) : void {
    if (app_propose) {
        writer.writeStringValue("app_id", app_propose.appId);
        writer.writeObjectValue<App_spec>("spec", app_propose.spec, serializeApp_spec);
        writer.writeAdditionalData(app_propose.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_propose_response(writer: SerializationWriter, app_propose_response: Partial<App_propose_response> | undefined | null = {}) : void {
    if (app_propose_response) {
        writer.writeNumberValue("app_cost", app_propose_response.appCost);
        writer.writeBooleanValue("app_is_static", app_propose_response.appIsStatic);
        writer.writeBooleanValue("app_name_available", app_propose_response.appNameAvailable);
        writer.writeStringValue("app_name_suggestion", app_propose_response.appNameSuggestion);
        writer.writeNumberValue("app_tier_downgrade_cost", app_propose_response.appTierDowngradeCost);
        writer.writeStringValue("existing_static_apps", app_propose_response.existingStaticApps);
        writer.writeObjectValue<App_spec>("spec", app_propose_response.spec, serializeApp_spec);
        writer.writeAdditionalData(app_propose_response.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_response(writer: SerializationWriter, app_response: Partial<App_response> | undefined | null = {}) : void {
    if (app_response) {
        writer.writeObjectValue<App>("app", app_response.app, serializeApp);
        writer.writeAdditionalData(app_response.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_rollback_validation_condition(writer: SerializationWriter, app_rollback_validation_condition: Partial<App_rollback_validation_condition> | undefined | null = {}) : void {
    if (app_rollback_validation_condition) {
        writer.writeEnumValue<App_rollback_validation_condition_code>("code", app_rollback_validation_condition.code);
        writer.writeCollectionOfPrimitiveValues<string>("components", app_rollback_validation_condition.components);
        writer.writeStringValue("message", app_rollback_validation_condition.message);
        writer.writeAdditionalData(app_rollback_validation_condition.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_route_spec(writer: SerializationWriter, app_route_spec: Partial<App_route_spec> | undefined | null = {}) : void {
    if (app_route_spec) {
        writer.writeStringValue("path", app_route_spec.path);
        writer.writeBooleanValue("preserve_path_prefix", app_route_spec.preservePathPrefix);
        writer.writeAdditionalData(app_route_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_service_spec(writer: SerializationWriter, app_service_spec: Partial<App_service_spec> | undefined | null = {}) : void {
    if (app_service_spec) {
        writer.writeObjectValue<App_service_spec_autoscaling>("autoscaling", app_service_spec.autoscaling, serializeApp_service_spec_autoscaling);
        writer.writeObjectValue<Apps_bitbucket_source_spec>("bitbucket", app_service_spec.bitbucket, serializeApps_bitbucket_source_spec);
        writer.writeStringValue("build_command", app_service_spec.buildCommand);
        writer.writeObjectValue<Apps_cors_policy>("cors", app_service_spec.cors, serializeApps_cors_policy);
        writer.writeStringValue("dockerfile_path", app_service_spec.dockerfilePath);
        writer.writeStringValue("environment_slug", app_service_spec.environmentSlug);
        writer.writeCollectionOfObjectValues<App_variable_definition>("envs", app_service_spec.envs, serializeApp_variable_definition);
        writer.writeObjectValue<Apps_git_source_spec>("git", app_service_spec.git, serializeApps_git_source_spec);
        writer.writeObjectValue<Apps_github_source_spec>("github", app_service_spec.github, serializeApps_github_source_spec);
        writer.writeObjectValue<Apps_gitlab_source_spec>("gitlab", app_service_spec.gitlab, serializeApps_gitlab_source_spec);
        writer.writeObjectValue<App_service_spec_health_check>("health_check", app_service_spec.healthCheck, serializeApp_service_spec_health_check);
        writer.writeNumberValue("http_port", app_service_spec.httpPort);
        writer.writeObjectValue<Apps_image_source_spec>("image", app_service_spec.image, serializeApps_image_source_spec);
        writer.writeNumberValue("instance_count", app_service_spec.instanceCount);
        if ( typeof app_service_spec.instanceSizeSlug === "string") {
            writer.writeStringValue("instance_size_slug", app_service_spec.instanceSizeSlug as string);
        }
        writer.writeCollectionOfPrimitiveValues<number>("internal_ports", app_service_spec.internalPorts);
        writer.writeCollectionOfObjectValues<App_log_destination_definition>("log_destinations", app_service_spec.logDestinations, serializeApp_log_destination_definition);
        writer.writeStringValue("name", app_service_spec.name);
        writer.writeEnumValue<App_service_spec_protocol>("protocol", app_service_spec.protocol);
        writer.writeCollectionOfObjectValues<App_route_spec>("routes", app_service_spec.routes, serializeApp_route_spec);
        writer.writeStringValue("run_command", app_service_spec.runCommand);
        writer.writeStringValue("source_dir", app_service_spec.sourceDir);
        writer.writeObjectValue<App_service_spec_termination>("termination", app_service_spec.termination, serializeApp_service_spec_termination);
        writer.writeAdditionalData(app_service_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_service_spec_autoscaling(writer: SerializationWriter, app_service_spec_autoscaling: Partial<App_service_spec_autoscaling> | undefined | null = {}) : void {
    if (app_service_spec_autoscaling) {
        writer.writeNumberValue("max_instance_count", app_service_spec_autoscaling.maxInstanceCount);
        writer.writeObjectValue<App_service_spec_autoscaling_metrics>("metrics", app_service_spec_autoscaling.metrics, serializeApp_service_spec_autoscaling_metrics);
        writer.writeNumberValue("min_instance_count", app_service_spec_autoscaling.minInstanceCount);
        writer.writeAdditionalData(app_service_spec_autoscaling.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_service_spec_autoscaling_metrics(writer: SerializationWriter, app_service_spec_autoscaling_metrics: Partial<App_service_spec_autoscaling_metrics> | undefined | null = {}) : void {
    if (app_service_spec_autoscaling_metrics) {
        writer.writeObjectValue<App_service_spec_autoscaling_metrics_cpu>("cpu", app_service_spec_autoscaling_metrics.cpu, serializeApp_service_spec_autoscaling_metrics_cpu);
        writer.writeAdditionalData(app_service_spec_autoscaling_metrics.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_service_spec_autoscaling_metrics_cpu(writer: SerializationWriter, app_service_spec_autoscaling_metrics_cpu: Partial<App_service_spec_autoscaling_metrics_cpu> | undefined | null = {}) : void {
    if (app_service_spec_autoscaling_metrics_cpu) {
        writer.writeNumberValue("percent", app_service_spec_autoscaling_metrics_cpu.percent);
        writer.writeAdditionalData(app_service_spec_autoscaling_metrics_cpu.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_service_spec_health_check(writer: SerializationWriter, app_service_spec_health_check: Partial<App_service_spec_health_check> | undefined | null = {}) : void {
    if (app_service_spec_health_check) {
        writer.writeNumberValue("failure_threshold", app_service_spec_health_check.failureThreshold);
        writer.writeStringValue("http_path", app_service_spec_health_check.httpPath);
        writer.writeNumberValue("initial_delay_seconds", app_service_spec_health_check.initialDelaySeconds);
        writer.writeNumberValue("period_seconds", app_service_spec_health_check.periodSeconds);
        writer.writeNumberValue("port", app_service_spec_health_check.port);
        writer.writeNumberValue("success_threshold", app_service_spec_health_check.successThreshold);
        writer.writeNumberValue("timeout_seconds", app_service_spec_health_check.timeoutSeconds);
        writer.writeAdditionalData(app_service_spec_health_check.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param key The name of the property to write in the serialization.
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_service_spec_instance_size_slug(writer: SerializationWriter, key: string, app_service_spec_instance_size_slug: Parsable | App_service_spec_instance_size_slug | undefined) : void {
    if (app_service_spec_instance_size_slug === undefined || app_service_spec_instance_size_slug === null) return;
    if (typeof app_service_spec_instance_size_slug === "string" ) {
        writer.writeStringValue(undefined, app_service_spec_instance_size_slug as string);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_service_spec_termination(writer: SerializationWriter, app_service_spec_termination: Partial<App_service_spec_termination> | undefined | null = {}) : void {
    if (app_service_spec_termination) {
        writer.writeNumberValue("drain_seconds", app_service_spec_termination.drainSeconds);
        writer.writeNumberValue("grace_period_seconds", app_service_spec_termination.gracePeriodSeconds);
        writer.writeAdditionalData(app_service_spec_termination.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_spec(writer: SerializationWriter, app_spec: Partial<App_spec> | undefined | null = {}) : void {
    if (app_spec) {
        writer.writeCollectionOfObjectValues<App_database_spec>("databases", app_spec.databases, serializeApp_database_spec);
        writer.writeCollectionOfObjectValues<App_domain_spec>("domains", app_spec.domains, serializeApp_domain_spec);
        writer.writeObjectValue<App_egress_spec>("egress", app_spec.egress, serializeApp_egress_spec);
        writer.writeCollectionOfObjectValues<App_functions_spec>("functions", app_spec.functions, serializeApp_functions_spec);
        writer.writeObjectValue<App_ingress_spec>("ingress", app_spec.ingress, serializeApp_ingress_spec);
        writer.writeCollectionOfObjectValues<App_job_spec>("jobs", app_spec.jobs, serializeApp_job_spec);
        writer.writeObjectValue<App_maintenance_spec>("maintenance", app_spec.maintenance, serializeApp_maintenance_spec);
        writer.writeStringValue("name", app_spec.name);
        writer.writeEnumValue<App_spec_region>("region", app_spec.region);
        writer.writeCollectionOfObjectValues<App_service_spec>("services", app_spec.services, serializeApp_service_spec);
        writer.writeCollectionOfObjectValues<App_static_site_spec>("static_sites", app_spec.staticSites, serializeApp_static_site_spec);
        writer.writeCollectionOfObjectValues<App_worker_spec>("workers", app_spec.workers, serializeApp_worker_spec);
        writer.writeAdditionalData(app_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_static_site_spec(writer: SerializationWriter, app_static_site_spec: Partial<App_static_site_spec> | undefined | null = {}) : void {
    if (app_static_site_spec) {
        serializeApp_component_base(writer, app_static_site_spec)
        writer.writeStringValue("catchall_document", app_static_site_spec.catchallDocument);
        writer.writeObjectValue<Apps_cors_policy>("cors", app_static_site_spec.cors, serializeApps_cors_policy);
        writer.writeStringValue("error_document", app_static_site_spec.errorDocument ?? "404.html");
        writer.writeStringValue("index_document", app_static_site_spec.indexDocument ?? "index.html");
        writer.writeStringValue("output_dir", app_static_site_spec.outputDir);
        writer.writeCollectionOfObjectValues<App_route_spec>("routes", app_static_site_spec.routes, serializeApp_route_spec);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_variable_definition(writer: SerializationWriter, app_variable_definition: Partial<App_variable_definition> | undefined | null = {}) : void {
    if (app_variable_definition) {
        writer.writeStringValue("key", app_variable_definition.key);
        writer.writeEnumValue<App_variable_definition_scope>("scope", app_variable_definition.scope ?? App_variable_definition_scopeObject.RUN_AND_BUILD_TIME);
        writer.writeEnumValue<App_variable_definition_type>("type", app_variable_definition.type ?? App_variable_definition_typeObject.GENERAL);
        writer.writeStringValue("value", app_variable_definition.value);
        writer.writeAdditionalData(app_variable_definition.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_worker_spec(writer: SerializationWriter, app_worker_spec: Partial<App_worker_spec> | undefined | null = {}) : void {
    if (app_worker_spec) {
        writer.writeObjectValue<App_worker_spec_autoscaling>("autoscaling", app_worker_spec.autoscaling, serializeApp_worker_spec_autoscaling);
        writer.writeObjectValue<Apps_bitbucket_source_spec>("bitbucket", app_worker_spec.bitbucket, serializeApps_bitbucket_source_spec);
        writer.writeStringValue("build_command", app_worker_spec.buildCommand);
        writer.writeStringValue("dockerfile_path", app_worker_spec.dockerfilePath);
        writer.writeStringValue("environment_slug", app_worker_spec.environmentSlug);
        writer.writeCollectionOfObjectValues<App_variable_definition>("envs", app_worker_spec.envs, serializeApp_variable_definition);
        writer.writeObjectValue<Apps_git_source_spec>("git", app_worker_spec.git, serializeApps_git_source_spec);
        writer.writeObjectValue<Apps_github_source_spec>("github", app_worker_spec.github, serializeApps_github_source_spec);
        writer.writeObjectValue<Apps_gitlab_source_spec>("gitlab", app_worker_spec.gitlab, serializeApps_gitlab_source_spec);
        writer.writeObjectValue<Apps_image_source_spec>("image", app_worker_spec.image, serializeApps_image_source_spec);
        writer.writeNumberValue("instance_count", app_worker_spec.instanceCount);
        if ( typeof app_worker_spec.instanceSizeSlug === "string") {
            writer.writeStringValue("instance_size_slug", app_worker_spec.instanceSizeSlug as string);
        }
        writer.writeCollectionOfObjectValues<App_log_destination_definition>("log_destinations", app_worker_spec.logDestinations, serializeApp_log_destination_definition);
        writer.writeStringValue("name", app_worker_spec.name);
        writer.writeStringValue("run_command", app_worker_spec.runCommand);
        writer.writeStringValue("source_dir", app_worker_spec.sourceDir);
        writer.writeObjectValue<App_worker_spec_termination>("termination", app_worker_spec.termination, serializeApp_worker_spec_termination);
        writer.writeAdditionalData(app_worker_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_worker_spec_autoscaling(writer: SerializationWriter, app_worker_spec_autoscaling: Partial<App_worker_spec_autoscaling> | undefined | null = {}) : void {
    if (app_worker_spec_autoscaling) {
        writer.writeNumberValue("max_instance_count", app_worker_spec_autoscaling.maxInstanceCount);
        writer.writeObjectValue<App_worker_spec_autoscaling_metrics>("metrics", app_worker_spec_autoscaling.metrics, serializeApp_worker_spec_autoscaling_metrics);
        writer.writeNumberValue("min_instance_count", app_worker_spec_autoscaling.minInstanceCount);
        writer.writeAdditionalData(app_worker_spec_autoscaling.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_worker_spec_autoscaling_metrics(writer: SerializationWriter, app_worker_spec_autoscaling_metrics: Partial<App_worker_spec_autoscaling_metrics> | undefined | null = {}) : void {
    if (app_worker_spec_autoscaling_metrics) {
        writer.writeObjectValue<App_worker_spec_autoscaling_metrics_cpu>("cpu", app_worker_spec_autoscaling_metrics.cpu, serializeApp_worker_spec_autoscaling_metrics_cpu);
        writer.writeAdditionalData(app_worker_spec_autoscaling_metrics.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_worker_spec_autoscaling_metrics_cpu(writer: SerializationWriter, app_worker_spec_autoscaling_metrics_cpu: Partial<App_worker_spec_autoscaling_metrics_cpu> | undefined | null = {}) : void {
    if (app_worker_spec_autoscaling_metrics_cpu) {
        writer.writeNumberValue("percent", app_worker_spec_autoscaling_metrics_cpu.percent);
        writer.writeAdditionalData(app_worker_spec_autoscaling_metrics_cpu.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param key The name of the property to write in the serialization.
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_worker_spec_instance_size_slug(writer: SerializationWriter, key: string, app_worker_spec_instance_size_slug: Parsable | App_worker_spec_instance_size_slug | undefined) : void {
    if (app_worker_spec_instance_size_slug === undefined || app_worker_spec_instance_size_slug === null) return;
    if (typeof app_worker_spec_instance_size_slug === "string" ) {
        writer.writeStringValue(undefined, app_worker_spec_instance_size_slug as string);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApp_worker_spec_termination(writer: SerializationWriter, app_worker_spec_termination: Partial<App_worker_spec_termination> | undefined | null = {}) : void {
    if (app_worker_spec_termination) {
        writer.writeNumberValue("grace_period_seconds", app_worker_spec_termination.gracePeriodSeconds);
        writer.writeAdditionalData(app_worker_spec_termination.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_alert_response(writer: SerializationWriter, apps_alert_response: Partial<Apps_alert_response> | undefined | null = {}) : void {
    if (apps_alert_response) {
        writer.writeObjectValue<App_alert>("alert", apps_alert_response.alert, serializeApp_alert);
        writer.writeAdditionalData(apps_alert_response.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_assign_app_alert_destinations_request(writer: SerializationWriter, apps_assign_app_alert_destinations_request: Partial<Apps_assign_app_alert_destinations_request> | undefined | null = {}) : void {
    if (apps_assign_app_alert_destinations_request) {
        writer.writeCollectionOfPrimitiveValues<string>("emails", apps_assign_app_alert_destinations_request.emails);
        writer.writeCollectionOfObjectValues<App_alert_slack_webhook>("slack_webhooks", apps_assign_app_alert_destinations_request.slackWebhooks, serializeApp_alert_slack_webhook);
        writer.writeAdditionalData(apps_assign_app_alert_destinations_request.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_bitbucket_source_spec(writer: SerializationWriter, apps_bitbucket_source_spec: Partial<Apps_bitbucket_source_spec> | undefined | null = {}) : void {
    if (apps_bitbucket_source_spec) {
        writer.writeStringValue("branch", apps_bitbucket_source_spec.branch);
        writer.writeBooleanValue("deploy_on_push", apps_bitbucket_source_spec.deployOnPush);
        writer.writeStringValue("repo", apps_bitbucket_source_spec.repo);
        writer.writeAdditionalData(apps_bitbucket_source_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_cors_policy(writer: SerializationWriter, apps_cors_policy: Partial<Apps_cors_policy> | undefined | null = {}) : void {
    if (apps_cors_policy) {
        writer.writeBooleanValue("allow_credentials", apps_cors_policy.allowCredentials);
        writer.writeCollectionOfPrimitiveValues<string>("allow_headers", apps_cors_policy.allowHeaders);
        writer.writeCollectionOfPrimitiveValues<string>("allow_methods", apps_cors_policy.allowMethods);
        writer.writeCollectionOfObjectValues<Apps_string_match>("allow_origins", apps_cors_policy.allowOrigins, serializeApps_string_match);
        writer.writeCollectionOfPrimitiveValues<string>("expose_headers", apps_cors_policy.exposeHeaders);
        writer.writeStringValue("max_age", apps_cors_policy.maxAge);
        writer.writeAdditionalData(apps_cors_policy.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_create_app_request(writer: SerializationWriter, apps_create_app_request: Partial<Apps_create_app_request> | undefined | null = {}) : void {
    if (apps_create_app_request) {
        writer.writeStringValue("project_id", apps_create_app_request.projectId);
        writer.writeObjectValue<App_spec>("spec", apps_create_app_request.spec, serializeApp_spec);
        writer.writeAdditionalData(apps_create_app_request.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_create_deployment_request(writer: SerializationWriter, apps_create_deployment_request: Partial<Apps_create_deployment_request> | undefined | null = {}) : void {
    if (apps_create_deployment_request) {
        writer.writeBooleanValue("force_build", apps_create_deployment_request.forceBuild);
        writer.writeAdditionalData(apps_create_deployment_request.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_dedicated_egress_ip(writer: SerializationWriter, apps_dedicated_egress_ip: Partial<Apps_dedicated_egress_ip> | undefined | null = {}) : void {
    if (apps_dedicated_egress_ip) {
        writer.writeStringValue("id", apps_dedicated_egress_ip.id);
        writer.writeStringValue("ip", apps_dedicated_egress_ip.ip);
        writer.writeAdditionalData(apps_dedicated_egress_ip.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_delete_app_response(writer: SerializationWriter, apps_delete_app_response: Partial<Apps_delete_app_response> | undefined | null = {}) : void {
    if (apps_delete_app_response) {
        writer.writeStringValue("id", apps_delete_app_response.id);
        writer.writeAdditionalData(apps_delete_app_response.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_deployment(writer: SerializationWriter, apps_deployment: Partial<Apps_deployment> | undefined | null = {}) : void {
    if (apps_deployment) {
        writer.writeStringValue("cause", apps_deployment.cause);
        writer.writeStringValue("cloned_from", apps_deployment.clonedFrom);
        writer.writeDateValue("created_at", apps_deployment.createdAt);
        writer.writeCollectionOfObjectValues<Apps_deployment_functions>("functions", apps_deployment.functions, serializeApps_deployment_functions);
        writer.writeStringValue("id", apps_deployment.id);
        writer.writeCollectionOfObjectValues<Apps_deployment_job>("jobs", apps_deployment.jobs, serializeApps_deployment_job);
        writer.writeEnumValue<Apps_deployment_phase>("phase", apps_deployment.phase ?? Apps_deployment_phaseObject.UNKNOWN);
        writer.writeDateValue("phase_last_updated_at", apps_deployment.phaseLastUpdatedAt);
        writer.writeObjectValue<Apps_deployment_progress>("progress", apps_deployment.progress, serializeApps_deployment_progress);
        writer.writeCollectionOfObjectValues<Apps_deployment_service>("services", apps_deployment.services, serializeApps_deployment_service);
        writer.writeObjectValue<App_spec>("spec", apps_deployment.spec, serializeApp_spec);
        writer.writeCollectionOfObjectValues<Apps_deployment_static_site>("static_sites", apps_deployment.staticSites, serializeApps_deployment_static_site);
        writer.writeDateValue("updated_at", apps_deployment.updatedAt);
        writer.writeCollectionOfObjectValues<Apps_deployment_worker>("workers", apps_deployment.workers, serializeApps_deployment_worker);
        writer.writeAdditionalData(apps_deployment.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_deployment_functions(writer: SerializationWriter, apps_deployment_functions: Partial<Apps_deployment_functions> | undefined | null = {}) : void {
    if (apps_deployment_functions) {
        writer.writeStringValue("name", apps_deployment_functions.name);
        writer.writeStringValue("namespace", apps_deployment_functions.namespace);
        writer.writeStringValue("source_commit_hash", apps_deployment_functions.sourceCommitHash);
        writer.writeAdditionalData(apps_deployment_functions.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_deployment_job(writer: SerializationWriter, apps_deployment_job: Partial<Apps_deployment_job> | undefined | null = {}) : void {
    if (apps_deployment_job) {
        writer.writeStringValue("name", apps_deployment_job.name);
        writer.writeStringValue("source_commit_hash", apps_deployment_job.sourceCommitHash);
        writer.writeAdditionalData(apps_deployment_job.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_deployment_progress(writer: SerializationWriter, apps_deployment_progress: Partial<Apps_deployment_progress> | undefined | null = {}) : void {
    if (apps_deployment_progress) {
        writer.writeNumberValue("error_steps", apps_deployment_progress.errorSteps);
        writer.writeNumberValue("pending_steps", apps_deployment_progress.pendingSteps);
        writer.writeNumberValue("running_steps", apps_deployment_progress.runningSteps);
        writer.writeCollectionOfObjectValues<Apps_deployment_progress_step>("steps", apps_deployment_progress.steps, serializeApps_deployment_progress_step);
        writer.writeNumberValue("success_steps", apps_deployment_progress.successSteps);
        writer.writeCollectionOfObjectValues<Apps_deployment_progress_step>("summary_steps", apps_deployment_progress.summarySteps, serializeApps_deployment_progress_step);
        writer.writeNumberValue("total_steps", apps_deployment_progress.totalSteps);
        writer.writeAdditionalData(apps_deployment_progress.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_deployment_progress_step(writer: SerializationWriter, apps_deployment_progress_step: Partial<Apps_deployment_progress_step> | undefined | null = {}) : void {
    if (apps_deployment_progress_step) {
        writer.writeStringValue("component_name", apps_deployment_progress_step.componentName);
        writer.writeDateValue("ended_at", apps_deployment_progress_step.endedAt);
        writer.writeStringValue("message_base", apps_deployment_progress_step.messageBase);
        writer.writeStringValue("name", apps_deployment_progress_step.name);
        writer.writeObjectValue<Apps_deployment_progress_step_reason>("reason", apps_deployment_progress_step.reason, serializeApps_deployment_progress_step_reason);
        writer.writeDateValue("started_at", apps_deployment_progress_step.startedAt);
        writer.writeEnumValue<Apps_deployment_progress_step_status>("status", apps_deployment_progress_step.status ?? Apps_deployment_progress_step_statusObject.UNKNOWN);
        writer.writeCollectionOfObjectValues<Apps_deployment_progress_step_steps>("steps", apps_deployment_progress_step.steps, serializeApps_deployment_progress_step_steps);
        writer.writeAdditionalData(apps_deployment_progress_step.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_deployment_progress_step_reason(writer: SerializationWriter, apps_deployment_progress_step_reason: Partial<Apps_deployment_progress_step_reason> | undefined | null = {}) : void {
    if (apps_deployment_progress_step_reason) {
        writer.writeStringValue("code", apps_deployment_progress_step_reason.code);
        writer.writeStringValue("message", apps_deployment_progress_step_reason.message);
        writer.writeAdditionalData(apps_deployment_progress_step_reason.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_deployment_progress_step_steps(writer: SerializationWriter, apps_deployment_progress_step_steps: Partial<Apps_deployment_progress_step_steps> | undefined | null = {}) : void {
    if (apps_deployment_progress_step_steps) {
        writer.writeAdditionalData(apps_deployment_progress_step_steps.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_deployment_response(writer: SerializationWriter, apps_deployment_response: Partial<Apps_deployment_response> | undefined | null = {}) : void {
    if (apps_deployment_response) {
        writer.writeObjectValue<Apps_deployment>("deployment", apps_deployment_response.deployment, serializeApps_deployment);
        writer.writeAdditionalData(apps_deployment_response.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_deployment_service(writer: SerializationWriter, apps_deployment_service: Partial<Apps_deployment_service> | undefined | null = {}) : void {
    if (apps_deployment_service) {
        writer.writeStringValue("name", apps_deployment_service.name);
        writer.writeStringValue("source_commit_hash", apps_deployment_service.sourceCommitHash);
        writer.writeAdditionalData(apps_deployment_service.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_deployment_static_site(writer: SerializationWriter, apps_deployment_static_site: Partial<Apps_deployment_static_site> | undefined | null = {}) : void {
    if (apps_deployment_static_site) {
        writer.writeStringValue("name", apps_deployment_static_site.name);
        writer.writeStringValue("source_commit_hash", apps_deployment_static_site.sourceCommitHash);
        writer.writeAdditionalData(apps_deployment_static_site.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_deployment_worker(writer: SerializationWriter, apps_deployment_worker: Partial<Apps_deployment_worker> | undefined | null = {}) : void {
    if (apps_deployment_worker) {
        writer.writeStringValue("name", apps_deployment_worker.name);
        writer.writeStringValue("source_commit_hash", apps_deployment_worker.sourceCommitHash);
        writer.writeAdditionalData(apps_deployment_worker.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_deployments_response(writer: SerializationWriter, apps_deployments_response: Partial<Apps_deployments_response> | undefined | null = {}) : void {
    if (apps_deployments_response) {
        writer.writeCollectionOfObjectValues<Apps_deployment>("deployments", apps_deployments_response.deployments, serializeApps_deployment);
        writer.writeObjectValue<Page_links>("links", apps_deployments_response.links, serializePage_links);
        writer.writeObjectValue<Meta_properties>("meta", apps_deployments_response.meta, serializeMeta_properties);
        writer.writeAdditionalData(apps_deployments_response.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_domain(writer: SerializationWriter, apps_domain: Partial<Apps_domain> | undefined | null = {}) : void {
    if (apps_domain) {
        writer.writeStringValue("id", apps_domain.id);
        writer.writeEnumValue<Apps_domain_phase>("phase", apps_domain.phase ?? Apps_domain_phaseObject.UNKNOWN);
        writer.writeObjectValue<Apps_domain_progress>("progress", apps_domain.progress, serializeApps_domain_progress);
        writer.writeObjectValue<App_domain_spec>("spec", apps_domain.spec, serializeApp_domain_spec);
        writer.writeCollectionOfObjectValues<App_domain_validation>("validations", apps_domain.validations, serializeApp_domain_validation);
        writer.writeAdditionalData(apps_domain.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_domain_progress(writer: SerializationWriter, apps_domain_progress: Partial<Apps_domain_progress> | undefined | null = {}) : void {
    if (apps_domain_progress) {
        writer.writeCollectionOfObjectValues<Apps_domain_progress_steps>("steps", apps_domain_progress.steps, serializeApps_domain_progress_steps);
        writer.writeAdditionalData(apps_domain_progress.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_domain_progress_steps(writer: SerializationWriter, apps_domain_progress_steps: Partial<Apps_domain_progress_steps> | undefined | null = {}) : void {
    if (apps_domain_progress_steps) {
        writer.writeAdditionalData(apps_domain_progress_steps.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_get_exec_response(writer: SerializationWriter, apps_get_exec_response: Partial<Apps_get_exec_response> | undefined | null = {}) : void {
    if (apps_get_exec_response) {
        writer.writeStringValue("url", apps_get_exec_response.url);
        writer.writeAdditionalData(apps_get_exec_response.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_get_instance_size_response(writer: SerializationWriter, apps_get_instance_size_response: Partial<Apps_get_instance_size_response> | undefined | null = {}) : void {
    if (apps_get_instance_size_response) {
        writer.writeObjectValue<Apps_instance_size>("instance_size", apps_get_instance_size_response.instanceSize, serializeApps_instance_size);
        writer.writeAdditionalData(apps_get_instance_size_response.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_get_logs_response(writer: SerializationWriter, apps_get_logs_response: Partial<Apps_get_logs_response> | undefined | null = {}) : void {
    if (apps_get_logs_response) {
        writer.writeCollectionOfPrimitiveValues<string>("historic_urls", apps_get_logs_response.historicUrls);
        writer.writeStringValue("live_url", apps_get_logs_response.liveUrl);
        writer.writeAdditionalData(apps_get_logs_response.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_git_source_spec(writer: SerializationWriter, apps_git_source_spec: Partial<Apps_git_source_spec> | undefined | null = {}) : void {
    if (apps_git_source_spec) {
        writer.writeStringValue("branch", apps_git_source_spec.branch);
        writer.writeStringValue("repo_clone_url", apps_git_source_spec.repoCloneUrl);
        writer.writeAdditionalData(apps_git_source_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_github_source_spec(writer: SerializationWriter, apps_github_source_spec: Partial<Apps_github_source_spec> | undefined | null = {}) : void {
    if (apps_github_source_spec) {
        writer.writeStringValue("branch", apps_github_source_spec.branch);
        writer.writeBooleanValue("deploy_on_push", apps_github_source_spec.deployOnPush);
        writer.writeStringValue("repo", apps_github_source_spec.repo);
        writer.writeAdditionalData(apps_github_source_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_gitlab_source_spec(writer: SerializationWriter, apps_gitlab_source_spec: Partial<Apps_gitlab_source_spec> | undefined | null = {}) : void {
    if (apps_gitlab_source_spec) {
        writer.writeStringValue("branch", apps_gitlab_source_spec.branch);
        writer.writeBooleanValue("deploy_on_push", apps_gitlab_source_spec.deployOnPush);
        writer.writeStringValue("repo", apps_gitlab_source_spec.repo);
        writer.writeAdditionalData(apps_gitlab_source_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_image_source_spec(writer: SerializationWriter, apps_image_source_spec: Partial<Apps_image_source_spec> | undefined | null = {}) : void {
    if (apps_image_source_spec) {
        writer.writeObjectValue<Apps_image_source_spec_deploy_on_push>("deploy_on_push", apps_image_source_spec.deployOnPush, serializeApps_image_source_spec_deploy_on_push);
        writer.writeStringValue("digest", apps_image_source_spec.digest);
        writer.writeStringValue("registry", apps_image_source_spec.registry);
        writer.writeStringValue("registry_credentials", apps_image_source_spec.registryCredentials);
        writer.writeEnumValue<Apps_image_source_spec_registry_type>("registry_type", apps_image_source_spec.registryType);
        writer.writeStringValue("repository", apps_image_source_spec.repository);
        writer.writeStringValue("tag", apps_image_source_spec.tag ?? "latest");
        writer.writeAdditionalData(apps_image_source_spec.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_image_source_spec_deploy_on_push(writer: SerializationWriter, apps_image_source_spec_deploy_on_push: Partial<Apps_image_source_spec_deploy_on_push> | undefined | null = {}) : void {
    if (apps_image_source_spec_deploy_on_push) {
        writer.writeBooleanValue("enabled", apps_image_source_spec_deploy_on_push.enabled);
        writer.writeAdditionalData(apps_image_source_spec_deploy_on_push.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_instance_size(writer: SerializationWriter, apps_instance_size: Partial<Apps_instance_size> | undefined | null = {}) : void {
    if (apps_instance_size) {
        writer.writeStringValue("bandwidth_allowance_gib", apps_instance_size.bandwidthAllowanceGib);
        writer.writeStringValue("cpus", apps_instance_size.cpus);
        writer.writeEnumValue<Instance_size_cpu_type>("cpu_type", apps_instance_size.cpuType ?? Instance_size_cpu_typeObject.UNSPECIFIED);
        writer.writeBooleanValue("deprecation_intent", apps_instance_size.deprecationIntent);
        writer.writeStringValue("memory_bytes", apps_instance_size.memoryBytes);
        writer.writeStringValue("name", apps_instance_size.name);
        writer.writeBooleanValue("scalable", apps_instance_size.scalable);
        writer.writeBooleanValue("single_instance_only", apps_instance_size.singleInstanceOnly);
        writer.writeStringValue("slug", apps_instance_size.slug);
        writer.writeStringValue("tier_downgrade_to", apps_instance_size.tierDowngradeTo);
        writer.writeStringValue("tier_slug", apps_instance_size.tierSlug);
        writer.writeStringValue("tier_upgrade_to", apps_instance_size.tierUpgradeTo);
        writer.writeStringValue("usd_per_month", apps_instance_size.usdPerMonth);
        writer.writeStringValue("usd_per_second", apps_instance_size.usdPerSecond);
        writer.writeAdditionalData(apps_instance_size.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_list_alerts_response(writer: SerializationWriter, apps_list_alerts_response: Partial<Apps_list_alerts_response> | undefined | null = {}) : void {
    if (apps_list_alerts_response) {
        writer.writeCollectionOfObjectValues<App_alert>("alerts", apps_list_alerts_response.alerts, serializeApp_alert);
        writer.writeAdditionalData(apps_list_alerts_response.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_list_instance_sizes_response(writer: SerializationWriter, apps_list_instance_sizes_response: Partial<Apps_list_instance_sizes_response> | undefined | null = {}) : void {
    if (apps_list_instance_sizes_response) {
        writer.writeNumberValue("discount_percent", apps_list_instance_sizes_response.discountPercent);
        writer.writeCollectionOfObjectValues<Apps_instance_size>("instance_sizes", apps_list_instance_sizes_response.instanceSizes, serializeApps_instance_size);
        writer.writeAdditionalData(apps_list_instance_sizes_response.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_list_regions_response(writer: SerializationWriter, apps_list_regions_response: Partial<Apps_list_regions_response> | undefined | null = {}) : void {
    if (apps_list_regions_response) {
        writer.writeCollectionOfObjectValues<Apps_region>("regions", apps_list_regions_response.regions, serializeApps_region);
        writer.writeAdditionalData(apps_list_regions_response.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_region(writer: SerializationWriter, apps_region: Partial<Apps_region> | undefined | null = {}) : void {
    if (apps_region) {
        writer.writeAdditionalData(apps_region.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_response(writer: SerializationWriter, apps_response: Partial<Apps_response> | undefined | null = {}) : void {
    if (apps_response) {
        writer.writeCollectionOfObjectValues<App>("apps", apps_response.apps, serializeApp);
        writer.writeObjectValue<Page_links>("links", apps_response.links, serializePage_links);
        writer.writeObjectValue<Meta_properties>("meta", apps_response.meta, serializeMeta_properties);
        writer.writeAdditionalData(apps_response.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_restart_request(writer: SerializationWriter, apps_restart_request: Partial<Apps_restart_request> | undefined | null = {}) : void {
    if (apps_restart_request) {
        writer.writeCollectionOfPrimitiveValues<string>("components", apps_restart_request.components);
        writer.writeAdditionalData(apps_restart_request.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_rollback_app_request(writer: SerializationWriter, apps_rollback_app_request: Partial<Apps_rollback_app_request> | undefined | null = {}) : void {
    if (apps_rollback_app_request) {
        writer.writeStringValue("deployment_id", apps_rollback_app_request.deploymentId);
        writer.writeBooleanValue("skip_pin", apps_rollback_app_request.skipPin);
        writer.writeAdditionalData(apps_rollback_app_request.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_string_match(writer: SerializationWriter, apps_string_match: Partial<Apps_string_match> | undefined | null = {}) : void {
    if (apps_string_match) {
        writer.writeStringValue("exact", apps_string_match.exact);
        writer.writeStringValue("prefix", apps_string_match.prefix);
        writer.writeStringValue("regex", apps_string_match.regex);
        writer.writeAdditionalData(apps_string_match.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeApps_update_app_request(writer: SerializationWriter, apps_update_app_request: Partial<Apps_update_app_request> | undefined | null = {}) : void {
    if (apps_update_app_request) {
        writer.writeObjectValue<App_spec>("spec", apps_update_app_request.spec, serializeApp_spec);
        writer.writeBooleanValue("update_all_source_versions", apps_update_app_request.updateAllSourceVersions);
        writer.writeAdditionalData(apps_update_app_request.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAssociated_kubernetes_resource(writer: SerializationWriter, associated_kubernetes_resource: Partial<Associated_kubernetes_resource> | undefined | null = {}) : void {
    if (associated_kubernetes_resource) {
        writer.writeStringValue("id", associated_kubernetes_resource.id);
        writer.writeStringValue("name", associated_kubernetes_resource.name);
        writer.writeAdditionalData(associated_kubernetes_resource.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAssociated_kubernetes_resources(writer: SerializationWriter, associated_kubernetes_resources: Partial<Associated_kubernetes_resources> | undefined | null = {}) : void {
    if (associated_kubernetes_resources) {
        writer.writeCollectionOfObjectValues<Associated_kubernetes_resource>("load_balancers", associated_kubernetes_resources.loadBalancers, serializeAssociated_kubernetes_resource);
        writer.writeCollectionOfObjectValues<Associated_kubernetes_resource>("volumes", associated_kubernetes_resources.volumes, serializeAssociated_kubernetes_resource);
        writer.writeCollectionOfObjectValues<Associated_kubernetes_resource>("volume_snapshots", associated_kubernetes_resources.volumeSnapshots, serializeAssociated_kubernetes_resource);
        writer.writeAdditionalData(associated_kubernetes_resources.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAssociated_resource(writer: SerializationWriter, associated_resource: Partial<Associated_resource> | undefined | null = {}) : void {
    if (associated_resource) {
        writer.writeStringValue("cost", associated_resource.cost);
        writer.writeStringValue("id", associated_resource.id);
        writer.writeStringValue("name", associated_resource.name);
        writer.writeAdditionalData(associated_resource.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAssociated_resource_status(writer: SerializationWriter, associated_resource_status: Partial<Associated_resource_status> | undefined | null = {}) : void {
    if (associated_resource_status) {
        writer.writeDateValue("completed_at", associated_resource_status.completedAt);
        writer.writeObjectValue<Destroyed_associated_resource>("droplet", associated_resource_status.droplet, serializeDestroyed_associated_resource);
        writer.writeNumberValue("failures", associated_resource_status.failures);
        writer.writeObjectValue<Associated_resource_status_resources>("resources", associated_resource_status.resources, serializeAssociated_resource_status_resources);
        writer.writeAdditionalData(associated_resource_status.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAssociated_resource_status_resources(writer: SerializationWriter, associated_resource_status_resources: Partial<Associated_resource_status_resources> | undefined | null = {}) : void {
    if (associated_resource_status_resources) {
        writer.writeCollectionOfObjectValues<Destroyed_associated_resource>("floating_ips", associated_resource_status_resources.floatingIps, serializeDestroyed_associated_resource);
        writer.writeCollectionOfObjectValues<Destroyed_associated_resource>("reserved_ips", associated_resource_status_resources.reservedIps, serializeDestroyed_associated_resource);
        writer.writeCollectionOfObjectValues<Destroyed_associated_resource>("snapshots", associated_resource_status_resources.snapshots, serializeDestroyed_associated_resource);
        writer.writeCollectionOfObjectValues<Destroyed_associated_resource>("volumes", associated_resource_status_resources.volumes, serializeDestroyed_associated_resource);
        writer.writeCollectionOfObjectValues<Destroyed_associated_resource>("volume_snapshots", associated_resource_status_resources.volumeSnapshots, serializeDestroyed_associated_resource);
        writer.writeAdditionalData(associated_resource_status_resources.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAutoscale_pool(writer: SerializationWriter, autoscale_pool: Partial<Autoscale_pool> | undefined | null = {}) : void {
    if (autoscale_pool) {
        writer.writeNumberValue("active_resources_count", autoscale_pool.activeResourcesCount);
        writer.writeObjectValue<Autoscale_pool_dynamic_config | Autoscale_pool_static_config>("config", autoscale_pool.config, serializeAutoscale_pool_config);
        writer.writeDateValue("created_at", autoscale_pool.createdAt);
        writer.writeObjectValue<Current_utilization>("current_utilization", autoscale_pool.currentUtilization, serializeCurrent_utilization);
        writer.writeObjectValue<Autoscale_pool_droplet_template>("droplet_template", autoscale_pool.dropletTemplate, serializeAutoscale_pool_droplet_template);
        writer.writeStringValue("id", autoscale_pool.id);
        writer.writeStringValue("name", autoscale_pool.name);
        writer.writeEnumValue<Autoscale_pool_status>("status", autoscale_pool.status);
        writer.writeDateValue("updated_at", autoscale_pool.updatedAt);
        writer.writeAdditionalData(autoscale_pool.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAutoscale_pool_config(writer: SerializationWriter, autoscale_pool_config: Partial<Autoscale_pool_dynamic_config | Autoscale_pool_static_config> | undefined | null = {}) : void {
    serializeAutoscale_pool_dynamic_config(writer, autoscale_pool_config as Autoscale_pool_dynamic_config);
    serializeAutoscale_pool_static_config(writer, autoscale_pool_config as Autoscale_pool_static_config);
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAutoscale_pool_create(writer: SerializationWriter, autoscale_pool_create: Partial<Autoscale_pool_create> | undefined | null = {}) : void {
    if (autoscale_pool_create) {
        writer.writeObjectValue<Autoscale_pool_dynamic_config | Autoscale_pool_static_config>("config", autoscale_pool_create.config, serializeAutoscale_pool_create_config);
        writer.writeObjectValue<Autoscale_pool_droplet_template>("droplet_template", autoscale_pool_create.dropletTemplate, serializeAutoscale_pool_droplet_template);
        writer.writeStringValue("name", autoscale_pool_create.name);
        writer.writeAdditionalData(autoscale_pool_create.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAutoscale_pool_create_config(writer: SerializationWriter, autoscale_pool_create_config: Partial<Autoscale_pool_dynamic_config | Autoscale_pool_static_config> | undefined | null = {}) : void {
    serializeAutoscale_pool_dynamic_config(writer, autoscale_pool_create_config as Autoscale_pool_dynamic_config);
    serializeAutoscale_pool_static_config(writer, autoscale_pool_create_config as Autoscale_pool_static_config);
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAutoscale_pool_droplet_template(writer: SerializationWriter, autoscale_pool_droplet_template: Partial<Autoscale_pool_droplet_template> | undefined | null = {}) : void {
    if (autoscale_pool_droplet_template) {
        writer.writeStringValue("image", autoscale_pool_droplet_template.image);
        writer.writeBooleanValue("ipv6", autoscale_pool_droplet_template.ipv6);
        writer.writeStringValue("name", autoscale_pool_droplet_template.name);
        writer.writeStringValue("project_id", autoscale_pool_droplet_template.projectId);
        writer.writeEnumValue<Autoscale_pool_droplet_template_region>("region", autoscale_pool_droplet_template.region);
        writer.writeStringValue("size", autoscale_pool_droplet_template.size);
        writer.writeCollectionOfPrimitiveValues<string>("ssh_keys", autoscale_pool_droplet_template.sshKeys);
        writer.writeCollectionOfPrimitiveValues<string>("tags", autoscale_pool_droplet_template.tags);
        writer.writeStringValue("user_data", autoscale_pool_droplet_template.userData);
        writer.writeStringValue("vpc_uuid", autoscale_pool_droplet_template.vpcUuid);
        writer.writeBooleanValue("with_droplet_agent", autoscale_pool_droplet_template.withDropletAgent);
        writer.writeAdditionalData(autoscale_pool_droplet_template.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAutoscale_pool_dynamic_config(writer: SerializationWriter, autoscale_pool_dynamic_config: Partial<Autoscale_pool_dynamic_config> | undefined | null = {}) : void {
    if (autoscale_pool_dynamic_config) {
        writer.writeNumberValue("cooldown_minutes", autoscale_pool_dynamic_config.cooldownMinutes);
        writer.writeNumberValue("max_instances", autoscale_pool_dynamic_config.maxInstances);
        writer.writeNumberValue("min_instances", autoscale_pool_dynamic_config.minInstances);
        writer.writeNumberValue("target_cpu_utilization", autoscale_pool_dynamic_config.targetCpuUtilization);
        writer.writeNumberValue("target_memory_utilization", autoscale_pool_dynamic_config.targetMemoryUtilization);
        writer.writeAdditionalData(autoscale_pool_dynamic_config.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeAutoscale_pool_static_config(writer: SerializationWriter, autoscale_pool_static_config: Partial<Autoscale_pool_static_config> | undefined | null = {}) : void {
    if (autoscale_pool_static_config) {
        writer.writeNumberValue("target_number_instances", autoscale_pool_static_config.targetNumberInstances);
        writer.writeAdditionalData(autoscale_pool_static_config.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeBackup(writer: SerializationWriter, backup: Partial<Backup> | undefined | null = {}) : void {
    if (backup) {
        writer.writeDateValue("created_at", backup.createdAt);
        writer.writeNumberValue("size_gigabytes", backup.sizeGigabytes);
        writer.writeAdditionalData(backup.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeBackward_links(writer: SerializationWriter, backward_links: Partial<Backward_links> | undefined | null = {}) : void {
    if (backward_links) {
        writer.writeStringValue("first", backward_links.first);
        writer.writeStringValue("prev", backward_links.prev);
        writer.writeAdditionalData(backward_links.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeBalance(writer: SerializationWriter, balance: Partial<Balance> | undefined | null = {}) : void {
    if (balance) {
        writer.writeStringValue("account_balance", balance.accountBalance);
        writer.writeDateValue("generated_at", balance.generatedAt);
        writer.writeStringValue("month_to_date_balance", balance.monthToDateBalance);
        writer.writeStringValue("month_to_date_usage", balance.monthToDateUsage);
        writer.writeAdditionalData(balance.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeBilling_address(writer: SerializationWriter, billing_address: Partial<Billing_address> | undefined | null = {}) : void {
    if (billing_address) {
        writer.writeStringValue("address_line1", billing_address.addressLine1);
        writer.writeStringValue("address_line2", billing_address.addressLine2);
        writer.writeStringValue("city", billing_address.city);
        writer.writeStringValue("country_iso2_code", billing_address.countryIso2Code);
        writer.writeStringValue("created_at", billing_address.createdAt);
        writer.writeStringValue("postal_code", billing_address.postalCode);
        writer.writeStringValue("region", billing_address.region);
        writer.writeStringValue("updated_at", billing_address.updatedAt);
        writer.writeAdditionalData(billing_address.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeBilling_history(writer: SerializationWriter, billing_history: Partial<Billing_history> | undefined | null = {}) : void {
    if (billing_history) {
        writer.writeStringValue("amount", billing_history.amount);
        writer.writeDateValue("date", billing_history.date);
        writer.writeStringValue("description", billing_history.description);
        writer.writeStringValue("invoice_id", billing_history.invoiceId);
        writer.writeStringValue("invoice_uuid", billing_history.invoiceUuid);
        writer.writeEnumValue<Billing_history_type>("type", billing_history.type);
        writer.writeAdditionalData(billing_history.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeCa(writer: SerializationWriter, ca: Partial<Ca> | undefined | null = {}) : void {
    if (ca) {
        writer.writeAdditionalData(ca.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeCdn_endpoint(writer: SerializationWriter, cdn_endpoint: Partial<Cdn_endpoint> | undefined | null = {}) : void {
    if (cdn_endpoint) {
        writer.writeGuidValue("certificate_id", cdn_endpoint.certificateId);
        writer.writeStringValue("custom_domain", cdn_endpoint.customDomain);
        writer.writeStringValue("origin", cdn_endpoint.origin);
        writer.writeNumberValue("ttl", cdn_endpoint.ttl);
        writer.writeAdditionalData(cdn_endpoint.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeCertificate(writer: SerializationWriter, certificate: Partial<Certificate> | undefined | null = {}) : void {
    if (certificate) {
        writer.writeCollectionOfPrimitiveValues<string>("dns_names", certificate.dnsNames);
        writer.writeStringValue("name", certificate.name);
        writer.writeEnumValue<Certificate_type>("type", certificate.type);
        writer.writeAdditionalData(certificate.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeCertificate_create_base(writer: SerializationWriter, certificate_create_base: Partial<Certificate_create_base> | undefined | null = {}) : void {
    if (certificate_create_base) {
        writer.writeStringValue("name", certificate_create_base.name);
        writer.writeEnumValue<Certificate_create_base_type>("type", certificate_create_base.type);
        writer.writeAdditionalData(certificate_create_base.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeCertificate_request_custom(writer: SerializationWriter, certificate_request_custom: Partial<Certificate_request_custom> | undefined | null = {}) : void {
    if (certificate_request_custom) {
        serializeCertificate_create_base(writer, certificate_request_custom)
        writer.writeStringValue("certificate_chain", certificate_request_custom.certificateChain);
        writer.writeStringValue("leaf_certificate", certificate_request_custom.leafCertificate);
        writer.writeStringValue("private_key", certificate_request_custom.privateKey);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeCertificate_request_lets_encrypt(writer: SerializationWriter, certificate_request_lets_encrypt: Partial<Certificate_request_lets_encrypt> | undefined | null = {}) : void {
    if (certificate_request_lets_encrypt) {
        serializeCertificate_create_base(writer, certificate_request_lets_encrypt)
        writer.writeCollectionOfPrimitiveValues<string>("dns_names", certificate_request_lets_encrypt.dnsNames);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeCheck(writer: SerializationWriter, check: Partial<Check> | undefined | null = {}) : void {
    if (check) {
        writer.writeBooleanValue("enabled", check.enabled);
        writer.writeStringValue("name", check.name);
        if(check.regions)
        writer.writeCollectionOfEnumValues<Check_regions>("regions", check.regions);
        writer.writeStringValue("target", check.target);
        writer.writeEnumValue<Check_type>("type", check.type);
        writer.writeAdditionalData(check.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeCheck_updatable(writer: SerializationWriter, check_updatable: Partial<Check_updatable> | undefined | null = {}) : void {
    if (check_updatable) {
        writer.writeBooleanValue("enabled", check_updatable.enabled);
        writer.writeStringValue("name", check_updatable.name);
        if(check_updatable.regions)
        writer.writeCollectionOfEnumValues<Check_updatable_regions>("regions", check_updatable.regions);
        writer.writeStringValue("target", check_updatable.target);
        writer.writeEnumValue<Check_updatable_type>("type", check_updatable.type);
        writer.writeAdditionalData(check_updatable.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeCluster(writer: SerializationWriter, cluster: Partial<Cluster> | undefined | null = {}) : void {
    if (cluster) {
        writer.writeBooleanValue("auto_upgrade", cluster.autoUpgrade);
        writer.writeObjectValue<Cluster_autoscaler_configuration>("cluster_autoscaler_configuration", cluster.clusterAutoscalerConfiguration, serializeCluster_autoscaler_configuration);
        writer.writeStringValue("cluster_subnet", cluster.clusterSubnet);
        writer.writeObjectValue<Control_plane_firewall>("control_plane_firewall", cluster.controlPlaneFirewall, serializeControl_plane_firewall);
        writer.writeBooleanValue("ha", cluster.ha);
        writer.writeObjectValue<Maintenance_policy>("maintenance_policy", cluster.maintenancePolicy, serializeMaintenance_policy);
        writer.writeStringValue("name", cluster.name);
        writer.writeCollectionOfObjectValues<Kubernetes_node_pool>("node_pools", cluster.nodePools, serializeKubernetes_node_pool);
        writer.writeStringValue("region", cluster.region);
        writer.writeObjectValue<Routing_agent>("routing_agent", cluster.routingAgent, serializeRouting_agent);
        writer.writeStringValue("service_subnet", cluster.serviceSubnet);
        writer.writeBooleanValue("surge_upgrade", cluster.surgeUpgrade);
        writer.writeCollectionOfPrimitiveValues<string>("tags", cluster.tags);
        writer.writeStringValue("version", cluster.version);
        writer.writeGuidValue("vpc_uuid", cluster.vpcUuid);
        writer.writeAdditionalData(cluster.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeCluster_autoscaler_configuration(writer: SerializationWriter, cluster_autoscaler_configuration: Partial<Cluster_autoscaler_configuration> | undefined | null = {}) : void {
    if (cluster_autoscaler_configuration) {
        writer.writeStringValue("scale_down_unneeded_time", cluster_autoscaler_configuration.scaleDownUnneededTime);
        writer.writeNumberValue("scale_down_utilization_threshold", cluster_autoscaler_configuration.scaleDownUtilizationThreshold);
        writer.writeAdditionalData(cluster_autoscaler_configuration.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeCluster_registries(writer: SerializationWriter, cluster_registries: Partial<Cluster_registries> | undefined | null = {}) : void {
    if (cluster_registries) {
        writer.writeCollectionOfPrimitiveValues<string>("cluster_uuids", cluster_registries.clusterUuids);
        writer.writeAdditionalData(cluster_registries.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeCluster_status(writer: SerializationWriter, cluster_status: Partial<Cluster_status> | undefined | null = {}) : void {
    if (cluster_status) {
        writer.writeStringValue("message", cluster_status.message);
        writer.writeEnumValue<Cluster_status_state>("state", cluster_status.state);
        writer.writeAdditionalData(cluster_status.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeCluster_update(writer: SerializationWriter, cluster_update: Partial<Cluster_update> | undefined | null = {}) : void {
    if (cluster_update) {
        writer.writeBooleanValue("auto_upgrade", cluster_update.autoUpgrade);
        writer.writeObjectValue<Cluster_autoscaler_configuration>("cluster_autoscaler_configuration", cluster_update.clusterAutoscalerConfiguration, serializeCluster_autoscaler_configuration);
        writer.writeObjectValue<Control_plane_firewall>("control_plane_firewall", cluster_update.controlPlaneFirewall, serializeControl_plane_firewall);
        writer.writeBooleanValue("ha", cluster_update.ha);
        writer.writeObjectValue<Maintenance_policy>("maintenance_policy", cluster_update.maintenancePolicy, serializeMaintenance_policy);
        writer.writeStringValue("name", cluster_update.name);
        writer.writeObjectValue<Routing_agent>("routing_agent", cluster_update.routingAgent, serializeRouting_agent);
        writer.writeBooleanValue("surge_upgrade", cluster_update.surgeUpgrade);
        writer.writeCollectionOfPrimitiveValues<string>("tags", cluster_update.tags);
        writer.writeAdditionalData(cluster_update.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeClusterlint_request(writer: SerializationWriter, clusterlint_request: Partial<Clusterlint_request> | undefined | null = {}) : void {
    if (clusterlint_request) {
        writer.writeCollectionOfPrimitiveValues<string>("exclude_checks", clusterlint_request.excludeChecks);
        writer.writeCollectionOfPrimitiveValues<string>("exclude_groups", clusterlint_request.excludeGroups);
        writer.writeCollectionOfPrimitiveValues<string>("include_checks", clusterlint_request.includeChecks);
        writer.writeCollectionOfPrimitiveValues<string>("include_groups", clusterlint_request.includeGroups);
        writer.writeAdditionalData(clusterlint_request.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeClusterlint_results(writer: SerializationWriter, clusterlint_results: Partial<Clusterlint_results> | undefined | null = {}) : void {
    if (clusterlint_results) {
        writer.writeDateValue("completed_at", clusterlint_results.completedAt);
        writer.writeCollectionOfObjectValues<Clusterlint_results_diagnostics>("diagnostics", clusterlint_results.diagnostics, serializeClusterlint_results_diagnostics);
        writer.writeDateValue("requested_at", clusterlint_results.requestedAt);
        writer.writeStringValue("run_id", clusterlint_results.runId);
        writer.writeAdditionalData(clusterlint_results.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeClusterlint_results_diagnostics(writer: SerializationWriter, clusterlint_results_diagnostics: Partial<Clusterlint_results_diagnostics> | undefined | null = {}) : void {
    if (clusterlint_results_diagnostics) {
        writer.writeStringValue("check_name", clusterlint_results_diagnostics.checkName);
        writer.writeStringValue("message", clusterlint_results_diagnostics.message);
        writer.writeObjectValue<Clusterlint_results_diagnostics_object>("object", clusterlint_results_diagnostics.object, serializeClusterlint_results_diagnostics_object);
        writer.writeStringValue("severity", clusterlint_results_diagnostics.severity);
        writer.writeAdditionalData(clusterlint_results_diagnostics.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeClusterlint_results_diagnostics_object(writer: SerializationWriter, clusterlint_results_diagnostics_object: Partial<Clusterlint_results_diagnostics_object> | undefined | null = {}) : void {
    if (clusterlint_results_diagnostics_object) {
        writer.writeStringValue("kind", clusterlint_results_diagnostics_object.kind);
        writer.writeStringValue("name", clusterlint_results_diagnostics_object.name);
        writer.writeStringValue("namespace", clusterlint_results_diagnostics_object.namespace);
        writer.writeAdditionalData(clusterlint_results_diagnostics_object.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeConnection_pool(writer: SerializationWriter, connection_pool: Partial<Connection_pool> | undefined | null = {}) : void {
    if (connection_pool) {
        writer.writeObjectValue<Database_connection>("connection", connection_pool.connection, serializeDatabase_connection);
        writer.writeStringValue("db", connection_pool.db);
        writer.writeStringValue("mode", connection_pool.mode);
        writer.writeStringValue("name", connection_pool.name);
        writer.writeObjectValue<Database_connection>("private_connection", connection_pool.privateConnection, serializeDatabase_connection);
        writer.writeNumberValue("size", connection_pool.size);
        writer.writeObjectValue<Database_connection>("standby_connection", connection_pool.standbyConnection, serializeDatabase_connection);
        writer.writeObjectValue<Database_connection>("standby_private_connection", connection_pool.standbyPrivateConnection, serializeDatabase_connection);
        writer.writeStringValue("user", connection_pool.user);
        writer.writeAdditionalData(connection_pool.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeConnection_pool_update(writer: SerializationWriter, connection_pool_update: Partial<Connection_pool_update> | undefined | null = {}) : void {
    if (connection_pool_update) {
        writer.writeStringValue("db", connection_pool_update.db);
        writer.writeStringValue("mode", connection_pool_update.mode);
        writer.writeNumberValue("size", connection_pool_update.size);
        writer.writeStringValue("user", connection_pool_update.user);
        writer.writeAdditionalData(connection_pool_update.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeConnection_pools(writer: SerializationWriter, connection_pools: Partial<Connection_pools> | undefined | null = {}) : void {
    if (connection_pools) {
        writer.writeAdditionalData(connection_pools.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeControl_plane_firewall(writer: SerializationWriter, control_plane_firewall: Partial<Control_plane_firewall> | undefined | null = {}) : void {
    if (control_plane_firewall) {
        writer.writeCollectionOfPrimitiveValues<string>("allowed_addresses", control_plane_firewall.allowedAddresses);
        writer.writeBooleanValue("enabled", control_plane_firewall.enabled);
        writer.writeAdditionalData(control_plane_firewall.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeCreate_namespace(writer: SerializationWriter, create_namespace: Partial<Create_namespace> | undefined | null = {}) : void {
    if (create_namespace) {
        writer.writeStringValue("label", create_namespace.label);
        writer.writeStringValue("region", create_namespace.region);
        writer.writeAdditionalData(create_namespace.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeCreate_trigger(writer: SerializationWriter, create_trigger: Partial<Create_trigger> | undefined | null = {}) : void {
    if (create_trigger) {
        writer.writeStringValue("function", create_trigger.functionEscaped);
        writer.writeBooleanValue("is_enabled", create_trigger.isEnabled);
        writer.writeStringValue("name", create_trigger.name);
        writer.writeObjectValue<Scheduled_details>("scheduled_details", create_trigger.scheduledDetails, serializeScheduled_details);
        writer.writeStringValue("type", create_trigger.type);
        writer.writeAdditionalData(create_trigger.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeCredentials(writer: SerializationWriter, credentials: Partial<Credentials> | undefined | null = {}) : void {
    if (credentials) {
        writer.writeByteArrayValue("certificate_authority_data", credentials.certificateAuthorityData);
        writer.writeByteArrayValue("client_certificate_data", credentials.clientCertificateData);
        writer.writeByteArrayValue("client_key_data", credentials.clientKeyData);
        writer.writeDateValue("expires_at", credentials.expiresAt);
        writer.writeStringValue("server", credentials.server);
        writer.writeStringValue("token", credentials.token);
        writer.writeAdditionalData(credentials.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeCurrent_utilization(writer: SerializationWriter, current_utilization: Partial<Current_utilization> | undefined | null = {}) : void {
    if (current_utilization) {
        writer.writeNumberValue("cpu", current_utilization.cpu);
        writer.writeNumberValue("memory", current_utilization.memory);
        writer.writeAdditionalData(current_utilization.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDatabase(writer: SerializationWriter, database: Partial<Database> | undefined | null = {}) : void {
    if (database) {
        writer.writeStringValue("name", database.name);
        writer.writeAdditionalData(database.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDatabase_backup(writer: SerializationWriter, database_backup: Partial<Database_backup> | undefined | null = {}) : void {
    if (database_backup) {
        writer.writeDateValue("backup_created_at", database_backup.backupCreatedAt);
        writer.writeStringValue("database_name", database_backup.databaseName);
        writer.writeAdditionalData(database_backup.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDatabase_cluster(writer: SerializationWriter, database_cluster: Partial<Database_cluster> | undefined | null = {}) : void {
    if (database_cluster) {
        writer.writeObjectValue<Database_connection>("connection", database_cluster.connection, serializeDatabase_connection);
        writer.writeEnumValue<Database_cluster_engine>("engine", database_cluster.engine);
        writer.writeObjectValue<Database_maintenance_window>("maintenance_window", database_cluster.maintenanceWindow, serializeDatabase_maintenance_window);
        writer.writeStringValue("name", database_cluster.name);
        writer.writeNumberValue("num_nodes", database_cluster.numNodes);
        writer.writeObjectValue<Database_connection>("private_connection", database_cluster.privateConnection, serializeDatabase_connection);
        writer.writeStringValue("private_network_uuid", database_cluster.privateNetworkUuid);
        writer.writeGuidValue("project_id", database_cluster.projectId);
        writer.writeStringValue("region", database_cluster.region);
        writer.writeCollectionOfObjectValues<Firewall_rule>("rules", database_cluster.rules, serializeFirewall_rule);
        writer.writeStringValue("size", database_cluster.size);
        writer.writeObjectValue<Database_connection>("standby_connection", database_cluster.standbyConnection, serializeDatabase_connection);
        writer.writeObjectValue<Database_connection>("standby_private_connection", database_cluster.standbyPrivateConnection, serializeDatabase_connection);
        writer.writeNumberValue("storage_size_mib", database_cluster.storageSizeMib);
        writer.writeCollectionOfPrimitiveValues<string>("tags", database_cluster.tags);
        writer.writeObjectValue<Opensearch_connection>("ui_connection", database_cluster.uiConnection, serializeOpensearch_connection);
        writer.writeStringValue("version", database_cluster.version);
        writer.writeAdditionalData(database_cluster.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDatabase_cluster_resize(writer: SerializationWriter, database_cluster_resize: Partial<Database_cluster_resize> | undefined | null = {}) : void {
    if (database_cluster_resize) {
        writer.writeNumberValue("num_nodes", database_cluster_resize.numNodes);
        writer.writeStringValue("size", database_cluster_resize.size);
        writer.writeNumberValue("storage_size_mib", database_cluster_resize.storageSizeMib);
        writer.writeAdditionalData(database_cluster_resize.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDatabase_config(writer: SerializationWriter, database_config: Partial<Database_config> | undefined | null = {}) : void {
    if (database_config) {
        writer.writeObjectValue<Kafka_advanced_config | Mongo_advanced_config | Mysql_advanced_config | Opensearch_advanced_config | Postgres_advanced_config | Redis_advanced_config>("config", database_config.config, serializeDatabase_config_config);
        writer.writeAdditionalData(database_config.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDatabase_config_config(writer: SerializationWriter, database_config_config: Partial<Kafka_advanced_config | Mongo_advanced_config | Mysql_advanced_config | Opensearch_advanced_config | Postgres_advanced_config | Redis_advanced_config> | undefined | null = {}) : void {
    serializeKafka_advanced_config(writer, database_config_config as Kafka_advanced_config);
    serializeMongo_advanced_config(writer, database_config_config as Mongo_advanced_config);
    serializeMysql_advanced_config(writer, database_config_config as Mysql_advanced_config);
    serializeOpensearch_advanced_config(writer, database_config_config as Opensearch_advanced_config);
    serializePostgres_advanced_config(writer, database_config_config as Postgres_advanced_config);
    serializeRedis_advanced_config(writer, database_config_config as Redis_advanced_config);
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDatabase_connection(writer: SerializationWriter, database_connection: Partial<Database_connection> | undefined | null = {}) : void {
    if (database_connection) {
        writer.writeAdditionalData(database_connection.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDatabase_layout_option(writer: SerializationWriter, database_layout_option: Partial<Database_layout_option> | undefined | null = {}) : void {
    if (database_layout_option) {
        writer.writeNumberValue("num_nodes", database_layout_option.numNodes);
        writer.writeAdditionalData(database_layout_option.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDatabase_maintenance_window(writer: SerializationWriter, database_maintenance_window: Partial<Database_maintenance_window> | undefined | null = {}) : void {
    if (database_maintenance_window) {
        writer.writeStringValue("day", database_maintenance_window.day);
        writer.writeStringValue("hour", database_maintenance_window.hour);
        writer.writeAdditionalData(database_maintenance_window.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDatabase_metrics_credentials(writer: SerializationWriter, database_metrics_credentials: Partial<Database_metrics_credentials> | undefined | null = {}) : void {
    if (database_metrics_credentials) {
        writer.writeObjectValue<Databases_basic_auth_credentials>("credentials", database_metrics_credentials.credentials, serializeDatabases_basic_auth_credentials);
        writer.writeAdditionalData(database_metrics_credentials.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDatabase_replica(writer: SerializationWriter, database_replica: Partial<Database_replica> | undefined | null = {}) : void {
    if (database_replica) {
        writer.writeObjectValue<Database_connection>("connection", database_replica.connection, serializeDatabase_connection);
        writer.writeStringValue("name", database_replica.name);
        writer.writeObjectValue<Database_connection>("private_connection", database_replica.privateConnection, serializeDatabase_connection);
        writer.writeStringValue("private_network_uuid", database_replica.privateNetworkUuid);
        writer.writeStringValue("region", database_replica.region);
        writer.writeStringValue("size", database_replica.size);
        writer.writeNumberValue("storage_size_mib", database_replica.storageSizeMib);
        writer.writeCollectionOfPrimitiveValues<string>("tags", database_replica.tags);
        writer.writeAdditionalData(database_replica.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDatabase_service_endpoint(writer: SerializationWriter, database_service_endpoint: Partial<Database_service_endpoint> | undefined | null = {}) : void {
    if (database_service_endpoint) {
        writer.writeAdditionalData(database_service_endpoint.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDatabase_user(writer: SerializationWriter, database_user: Partial<Database_user> | undefined | null = {}) : void {
    if (database_user) {
        writer.writeObjectValue<Mysql_settings>("mysql_settings", database_user.mysqlSettings, serializeMysql_settings);
        writer.writeStringValue("name", database_user.name);
        writer.writeObjectValue<User_settings>("settings", database_user.settings, serializeUser_settings);
        writer.writeAdditionalData(database_user.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDatabase_version_availability(writer: SerializationWriter, database_version_availability: Partial<Database_version_availability> | undefined | null = {}) : void {
    if (database_version_availability) {
        writer.writeStringValue("end_of_availability", database_version_availability.endOfAvailability);
        writer.writeStringValue("end_of_life", database_version_availability.endOfLife);
        writer.writeStringValue("version", database_version_availability.version);
        writer.writeAdditionalData(database_version_availability.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDatabases_basic_auth_credentials(writer: SerializationWriter, databases_basic_auth_credentials: Partial<Databases_basic_auth_credentials> | undefined | null = {}) : void {
    if (databases_basic_auth_credentials) {
        writer.writeStringValue("basic_auth_password", databases_basic_auth_credentials.basicAuthPassword);
        writer.writeStringValue("basic_auth_username", databases_basic_auth_credentials.basicAuthUsername);
        writer.writeAdditionalData(databases_basic_auth_credentials.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDestination(writer: SerializationWriter, destination: Partial<Destination> | undefined | null = {}) : void {
    if (destination) {
        writer.writeObjectValue<Opensearch_config>("config", destination.config, serializeOpensearch_config);
        writer.writeStringValue("id", destination.id);
        writer.writeStringValue("name", destination.name);
        writer.writeEnumValue<Destination_type>("type", destination.type);
        writer.writeAdditionalData(destination.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDestination_omit_credentials(writer: SerializationWriter, destination_omit_credentials: Partial<Destination_omit_credentials> | undefined | null = {}) : void {
    if (destination_omit_credentials) {
        writer.writeObjectValue<Opensearch_config_omit_credentials>("config", destination_omit_credentials.config, serializeOpensearch_config_omit_credentials);
        writer.writeStringValue("id", destination_omit_credentials.id);
        writer.writeStringValue("name", destination_omit_credentials.name);
        writer.writeEnumValue<Destination_omit_credentials_type>("type", destination_omit_credentials.type);
        writer.writeAdditionalData(destination_omit_credentials.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDestination_request(writer: SerializationWriter, destination_request: Partial<Destination_request> | undefined | null = {}) : void {
    if (destination_request) {
        writer.writeObjectValue<Opensearch_config_request>("config", destination_request.config, serializeOpensearch_config_request);
        writer.writeStringValue("name", destination_request.name);
        writer.writeEnumValue<Destination_request_type>("type", destination_request.type);
        writer.writeAdditionalData(destination_request.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDestroy_associated_kubernetes_resources(writer: SerializationWriter, destroy_associated_kubernetes_resources: Partial<Destroy_associated_kubernetes_resources> | undefined | null = {}) : void {
    if (destroy_associated_kubernetes_resources) {
        writer.writeCollectionOfPrimitiveValues<string>("load_balancers", destroy_associated_kubernetes_resources.loadBalancers);
        writer.writeCollectionOfPrimitiveValues<string>("volumes", destroy_associated_kubernetes_resources.volumes);
        writer.writeCollectionOfPrimitiveValues<string>("volume_snapshots", destroy_associated_kubernetes_resources.volumeSnapshots);
        writer.writeAdditionalData(destroy_associated_kubernetes_resources.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDestroyed_associated_resource(writer: SerializationWriter, destroyed_associated_resource: Partial<Destroyed_associated_resource> | undefined | null = {}) : void {
    if (destroyed_associated_resource) {
        writer.writeDateValue("destroyed_at", destroyed_associated_resource.destroyedAt);
        writer.writeStringValue("error_message", destroyed_associated_resource.errorMessage);
        writer.writeStringValue("id", destroyed_associated_resource.id);
        writer.writeStringValue("name", destroyed_associated_resource.name);
        writer.writeAdditionalData(destroyed_associated_resource.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDisk_info(writer: SerializationWriter, disk_info: Partial<Disk_info> | undefined | null = {}) : void {
    if (disk_info) {
        writer.writeObjectValue<Disk_info_size>("size", disk_info.size, serializeDisk_info_size);
        writer.writeEnumValue<Disk_info_type>("type", disk_info.type);
        writer.writeAdditionalData(disk_info.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDisk_info_size(writer: SerializationWriter, disk_info_size: Partial<Disk_info_size> | undefined | null = {}) : void {
    if (disk_info_size) {
        writer.writeNumberValue("amount", disk_info_size.amount);
        writer.writeStringValue("unit", disk_info_size.unit);
        writer.writeAdditionalData(disk_info_size.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDocker_credentials(writer: SerializationWriter, docker_credentials: Partial<Docker_credentials> | undefined | null = {}) : void {
    if (docker_credentials) {
        writer.writeObjectValue<Docker_credentials_auths>("auths", docker_credentials.auths, serializeDocker_credentials_auths);
        writer.writeAdditionalData(docker_credentials.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDocker_credentials_auths(writer: SerializationWriter, docker_credentials_auths: Partial<Docker_credentials_auths> | undefined | null = {}) : void {
    if (docker_credentials_auths) {
        writer.writeObjectValue<Docker_credentials_auths_registryDigitaloceanCom>("registry.digitalocean.com", docker_credentials_auths.registryDigitaloceanCom, serializeDocker_credentials_auths_registryDigitaloceanCom);
        writer.writeAdditionalData(docker_credentials_auths.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDocker_credentials_auths_registryDigitaloceanCom(writer: SerializationWriter, docker_credentials_auths_registryDigitaloceanCom: Partial<Docker_credentials_auths_registryDigitaloceanCom> | undefined | null = {}) : void {
    if (docker_credentials_auths_registryDigitaloceanCom) {
        writer.writeStringValue("auth", docker_credentials_auths_registryDigitaloceanCom.auth);
        writer.writeAdditionalData(docker_credentials_auths_registryDigitaloceanCom.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDomain(writer: SerializationWriter, domain: Partial<Domain> | undefined | null = {}) : void {
    if (domain) {
        writer.writeStringValue("ip_address", domain.ipAddress);
        writer.writeStringValue("name", domain.name);
        writer.writeAdditionalData(domain.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDomain_record(writer: SerializationWriter, domain_record: Partial<Domain_record> | undefined | null = {}) : void {
    if (domain_record) {
        writer.writeStringValue("data", domain_record.data);
        writer.writeNumberValue("flags", domain_record.flags);
        writer.writeStringValue("name", domain_record.name);
        writer.writeNumberValue("port", domain_record.port);
        writer.writeNumberValue("priority", domain_record.priority);
        writer.writeStringValue("tag", domain_record.tag);
        writer.writeNumberValue("ttl", domain_record.ttl);
        writer.writeStringValue("type", domain_record.type);
        writer.writeNumberValue("weight", domain_record.weight);
        writer.writeAdditionalData(domain_record.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDomain_record_a(writer: SerializationWriter, domain_record_a: Partial<Domain_record_a> | undefined | null = {}) : void {
    if (domain_record_a) {
        serializeDomain_record(writer, domain_record_a)
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDomain_record_aaaa(writer: SerializationWriter, domain_record_aaaa: Partial<Domain_record_aaaa> | undefined | null = {}) : void {
    if (domain_record_aaaa) {
        serializeDomain_record(writer, domain_record_aaaa)
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDomain_record_caa(writer: SerializationWriter, domain_record_caa: Partial<Domain_record_caa> | undefined | null = {}) : void {
    if (domain_record_caa) {
        serializeDomain_record(writer, domain_record_caa)
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDomain_record_cname(writer: SerializationWriter, domain_record_cname: Partial<Domain_record_cname> | undefined | null = {}) : void {
    if (domain_record_cname) {
        serializeDomain_record(writer, domain_record_cname)
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDomain_record_mx(writer: SerializationWriter, domain_record_mx: Partial<Domain_record_mx> | undefined | null = {}) : void {
    if (domain_record_mx) {
        serializeDomain_record(writer, domain_record_mx)
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDomain_record_ns(writer: SerializationWriter, domain_record_ns: Partial<Domain_record_ns> | undefined | null = {}) : void {
    if (domain_record_ns) {
        serializeDomain_record(writer, domain_record_ns)
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDomain_record_soa(writer: SerializationWriter, domain_record_soa: Partial<Domain_record_soa> | undefined | null = {}) : void {
    if (domain_record_soa) {
        serializeDomain_record(writer, domain_record_soa)
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDomain_record_srv(writer: SerializationWriter, domain_record_srv: Partial<Domain_record_srv> | undefined | null = {}) : void {
    if (domain_record_srv) {
        serializeDomain_record(writer, domain_record_srv)
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDomain_record_txt(writer: SerializationWriter, domain_record_txt: Partial<Domain_record_txt> | undefined | null = {}) : void {
    if (domain_record_txt) {
        serializeDomain_record(writer, domain_record_txt)
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDomains(writer: SerializationWriter, domains: Partial<Domains> | undefined | null = {}) : void {
    if (domains) {
        writer.writeStringValue("certificate_id", domains.certificateId);
        writer.writeBooleanValue("is_managed", domains.isManaged);
        writer.writeStringValue("name", domains.name);
        writer.writeAdditionalData(domains.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet(writer: SerializationWriter, droplet: Partial<Droplet> | undefined | null = {}) : void {
    if (droplet) {
        writer.writeCollectionOfPrimitiveValues<number>("backup_ids", droplet.backupIds);
        writer.writeDateValue("created_at", droplet.createdAt);
        writer.writeNumberValue("disk", droplet.disk);
        writer.writeCollectionOfObjectValues<Disk_info>("disk_info", droplet.diskInfo, serializeDisk_info);
        writer.writeCollectionOfPrimitiveValues<string>("features", droplet.features);
        writer.writeObjectValue<Gpu_info>("gpu_info", droplet.gpuInfo, serializeGpu_info);
        writer.writeNumberValue("id", droplet.id);
        writer.writeObjectValue<Image>("image", droplet.image, serializeImage);
        writer.writeObjectValue<Kernel>("kernel", droplet.kernel, serializeKernel);
        writer.writeBooleanValue("locked", droplet.locked);
        writer.writeNumberValue("memory", droplet.memory);
        writer.writeStringValue("name", droplet.name);
        writer.writeObjectValue<Droplet_networks>("networks", droplet.networks, serializeDroplet_networks);
        writer.writeObjectValue<Droplet_next_backup_window>("next_backup_window", droplet.nextBackupWindow, serializeDroplet_next_backup_window);
        writer.writeObjectValue<Region>("region", droplet.region, serializeRegion);
        writer.writeObjectValue<Size>("size", droplet.size, serializeSize);
        writer.writeStringValue("size_slug", droplet.sizeSlug);
        writer.writeCollectionOfPrimitiveValues<number>("snapshot_ids", droplet.snapshotIds);
        writer.writeEnumValue<Droplet_status>("status", droplet.status);
        writer.writeCollectionOfPrimitiveValues<string>("tags", droplet.tags);
        writer.writeNumberValue("vcpus", droplet.vcpus);
        writer.writeCollectionOfPrimitiveValues<string>("volume_ids", droplet.volumeIds);
        writer.writeStringValue("vpc_uuid", droplet.vpcUuid);
        writer.writeAdditionalData(droplet.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet_action(writer: SerializationWriter, droplet_action: Partial<Droplet_action> | undefined | null = {}) : void {
    if (droplet_action) {
        writer.writeEnumValue<Droplet_action_type>("type", droplet_action.type);
        writer.writeAdditionalData(droplet_action.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet_action_change_backup_policy(writer: SerializationWriter, droplet_action_change_backup_policy: Partial<Droplet_action_change_backup_policy> | undefined | null = {}) : void {
    if (droplet_action_change_backup_policy) {
        serializeDroplet_action(writer, droplet_action_change_backup_policy)
        writer.writeObjectValue<Droplet_backup_policy>("backup_policy", droplet_action_change_backup_policy.backupPolicy, serializeDroplet_backup_policy);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet_action_change_kernel(writer: SerializationWriter, droplet_action_change_kernel: Partial<Droplet_action_change_kernel> | undefined | null = {}) : void {
    if (droplet_action_change_kernel) {
        serializeDroplet_action(writer, droplet_action_change_kernel)
        writer.writeNumberValue("kernel", droplet_action_change_kernel.kernel);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet_action_enable_backups(writer: SerializationWriter, droplet_action_enable_backups: Partial<Droplet_action_enable_backups> | undefined | null = {}) : void {
    if (droplet_action_enable_backups) {
        serializeDroplet_action(writer, droplet_action_enable_backups)
        writer.writeObjectValue<Droplet_backup_policy>("backup_policy", droplet_action_enable_backups.backupPolicy, serializeDroplet_backup_policy);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet_action_rebuild(writer: SerializationWriter, droplet_action_rebuild: Partial<Droplet_action_rebuild> | undefined | null = {}) : void {
    if (droplet_action_rebuild) {
        serializeDroplet_action(writer, droplet_action_rebuild)
        if ( typeof droplet_action_rebuild.image === "number") {
            writer.writeNumberValue("image", droplet_action_rebuild.image as number);
        }
        else if ( typeof droplet_action_rebuild.image === "string") {
            writer.writeStringValue("image", droplet_action_rebuild.image as string);
        }
    }
}
/**
 * Serializes information the current object
 * @param key The name of the property to write in the serialization.
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet_action_rebuild_image(writer: SerializationWriter, key: string, droplet_action_rebuild_image: Parsable | Droplet_action_rebuild_image | undefined) : void {
    if (droplet_action_rebuild_image === undefined || droplet_action_rebuild_image === null) return;
    if (typeof droplet_action_rebuild_image === "number" ) {
        writer.writeNumberValue(undefined, droplet_action_rebuild_image as number);
    }
    else if (typeof droplet_action_rebuild_image === "string" ) {
        writer.writeStringValue(undefined, droplet_action_rebuild_image as string);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet_action_rename(writer: SerializationWriter, droplet_action_rename: Partial<Droplet_action_rename> | undefined | null = {}) : void {
    if (droplet_action_rename) {
        serializeDroplet_action(writer, droplet_action_rename)
        writer.writeStringValue("name", droplet_action_rename.name);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet_action_resize(writer: SerializationWriter, droplet_action_resize: Partial<Droplet_action_resize> | undefined | null = {}) : void {
    if (droplet_action_resize) {
        serializeDroplet_action(writer, droplet_action_resize)
        writer.writeBooleanValue("disk", droplet_action_resize.disk);
        writer.writeStringValue("size", droplet_action_resize.size);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet_action_restore(writer: SerializationWriter, droplet_action_restore: Partial<Droplet_action_restore> | undefined | null = {}) : void {
    if (droplet_action_restore) {
        serializeDroplet_action(writer, droplet_action_restore)
        writer.writeNumberValue("image", droplet_action_restore.image);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet_action_snapshot(writer: SerializationWriter, droplet_action_snapshot: Partial<Droplet_action_snapshot> | undefined | null = {}) : void {
    if (droplet_action_snapshot) {
        serializeDroplet_action(writer, droplet_action_snapshot)
        writer.writeStringValue("name", droplet_action_snapshot.name);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet_backup_policy(writer: SerializationWriter, droplet_backup_policy: Partial<Droplet_backup_policy> | undefined | null = {}) : void {
    if (droplet_backup_policy) {
        writer.writeNumberValue("hour", droplet_backup_policy.hour);
        writer.writeEnumValue<Droplet_backup_policy_plan>("plan", droplet_backup_policy.plan);
        writer.writeEnumValue<Droplet_backup_policy_weekday>("weekday", droplet_backup_policy.weekday);
        writer.writeAdditionalData(droplet_backup_policy.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet_backup_policy_record(writer: SerializationWriter, droplet_backup_policy_record: Partial<Droplet_backup_policy_record> | undefined | null = {}) : void {
    if (droplet_backup_policy_record) {
        writer.writeBooleanValue("backup_enabled", droplet_backup_policy_record.backupEnabled);
        writer.writeObjectValue<Droplet_backup_policy>("backup_policy", droplet_backup_policy_record.backupPolicy, serializeDroplet_backup_policy);
        writer.writeNumberValue("droplet_id", droplet_backup_policy_record.dropletId);
        writer.writeObjectValue<Droplet_next_backup_window>("next_backup_window", droplet_backup_policy_record.nextBackupWindow, serializeDroplet_next_backup_window);
        writer.writeAdditionalData(droplet_backup_policy_record.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet_create(writer: SerializationWriter, droplet_create: Partial<Droplet_create> | undefined | null = {}) : void {
    if (droplet_create) {
        writer.writeObjectValue<Droplet_backup_policy>("backup_policy", droplet_create.backupPolicy, serializeDroplet_backup_policy);
        writer.writeBooleanValue("backups", droplet_create.backups);
        if ( typeof droplet_create.image === "number") {
            writer.writeNumberValue("image", droplet_create.image as number);
        }
        else if ( typeof droplet_create.image === "string") {
            writer.writeStringValue("image", droplet_create.image as string);
        }
        writer.writeBooleanValue("ipv6", droplet_create.ipv6);
        writer.writeBooleanValue("monitoring", droplet_create.monitoring);
        writer.writeBooleanValue("private_networking", droplet_create.privateNetworking);
        writer.writeStringValue("region", droplet_create.region);
        writer.writeStringValue("size", droplet_create.size);
        writer.writeCollectionOfPrimitiveValues<string>("ssh_keys", droplet_create.sshKeys);
        writer.writeCollectionOfPrimitiveValues<string>("tags", droplet_create.tags);
        writer.writeStringValue("user_data", droplet_create.userData);
        writer.writeCollectionOfPrimitiveValues<string>("volumes", droplet_create.volumes);
        writer.writeStringValue("vpc_uuid", droplet_create.vpcUuid);
        writer.writeBooleanValue("with_droplet_agent", droplet_create.withDropletAgent);
        writer.writeAdditionalData(droplet_create.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param key The name of the property to write in the serialization.
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet_create_image(writer: SerializationWriter, key: string, droplet_create_image: Parsable | Droplet_create_image | undefined) : void {
    if (droplet_create_image === undefined || droplet_create_image === null) return;
    if (typeof droplet_create_image === "number" ) {
        writer.writeNumberValue(undefined, droplet_create_image as number);
    }
    else if (typeof droplet_create_image === "string" ) {
        writer.writeStringValue(undefined, droplet_create_image as string);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet_multi_create(writer: SerializationWriter, droplet_multi_create: Partial<Droplet_multi_create> | undefined | null = {}) : void {
    if (droplet_multi_create) {
        serializeDroplet_create(writer, droplet_multi_create)
        writer.writeCollectionOfPrimitiveValues<string>("names", droplet_multi_create.names);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet_networks(writer: SerializationWriter, droplet_networks: Partial<Droplet_networks> | undefined | null = {}) : void {
    if (droplet_networks) {
        writer.writeCollectionOfObjectValues<Network_v4>("v4", droplet_networks.v4, serializeNetwork_v4);
        writer.writeCollectionOfObjectValues<Network_v6>("v6", droplet_networks.v6, serializeNetwork_v6);
        writer.writeAdditionalData(droplet_networks.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet_next_backup_window(writer: SerializationWriter, droplet_next_backup_window: Partial<Droplet_next_backup_window> | undefined | null = {}) : void {
    if (droplet_next_backup_window) {
        writer.writeDateValue("end", droplet_next_backup_window.end);
        writer.writeDateValue("start", droplet_next_backup_window.start);
        writer.writeAdditionalData(droplet_next_backup_window.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet_single_create(writer: SerializationWriter, droplet_single_create: Partial<Droplet_single_create> | undefined | null = {}) : void {
    if (droplet_single_create) {
        serializeDroplet_create(writer, droplet_single_create)
        writer.writeStringValue("name", droplet_single_create.name);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeDroplet_snapshot(writer: SerializationWriter, droplet_snapshot: Partial<Droplet_snapshot> | undefined | null = {}) : void {
    if (droplet_snapshot) {
        serializeSnapshots_base(writer, droplet_snapshot)
        writer.writeNumberValue("id", droplet_snapshot.id);
        writer.writeEnumValue<Droplet_snapshot_type>("type", droplet_snapshot.type);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeElasticsearch_logsink(writer: SerializationWriter, elasticsearch_logsink: Partial<Elasticsearch_logsink> | undefined | null = {}) : void {
    if (elasticsearch_logsink) {
        writer.writeStringValue("ca", elasticsearch_logsink.ca);
        writer.writeNumberValue("index_days_max", elasticsearch_logsink.indexDaysMax);
        writer.writeStringValue("index_prefix", elasticsearch_logsink.indexPrefix);
        writer.writeNumberValue("timeout", elasticsearch_logsink.timeout);
        writer.writeStringValue("url", elasticsearch_logsink.url);
        writer.writeAdditionalData(elasticsearch_logsink.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeError_with_root_causes(writer: SerializationWriter, error_with_root_causes: Partial<Error_with_root_causes> | undefined | null = {}) : void {
    if (error_with_root_causes) {
        writer.writeStringValue("error", error_with_root_causes.errorEscaped);
        writer.writeCollectionOfPrimitiveValues<string>("messages", error_with_root_causes.messages);
        writer.writeCollectionOfPrimitiveValues<string>("root_causes", error_with_root_causes.rootCauses);
        writer.writeAdditionalData(error_with_root_causes.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeErrorEscaped(writer: SerializationWriter, errorEscaped: Partial<ErrorEscaped> | undefined | null = {}) : void {
    if (errorEscaped) {
        writer.writeStringValue("id", errorEscaped.id);
        writer.writeStringValue("message", errorEscaped.messageEscaped);
        writer.writeStringValue("request_id", errorEscaped.requestId);
        writer.writeAdditionalData(errorEscaped.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeEvents_logs(writer: SerializationWriter, events_logs: Partial<Events_logs> | undefined | null = {}) : void {
    if (events_logs) {
        writer.writeStringValue("cluster_name", events_logs.clusterName);
        writer.writeStringValue("create_time", events_logs.createTime);
        writer.writeEnumValue<Events_logs_event_type>("event_type", events_logs.eventType);
        writer.writeStringValue("id", events_logs.id);
        writer.writeAdditionalData(events_logs.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeFirewall(writer: SerializationWriter, firewall: Partial<Firewall> | undefined | null = {}) : void {
    if (firewall) {
        serializeFirewall_rules(writer, firewall)
        writer.writeCollectionOfPrimitiveValues<number>("droplet_ids", firewall.dropletIds);
        writer.writeStringValue("name", firewall.name);
        writer.writeCollectionOfPrimitiveValues<string>("tags", firewall.tags);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeFirewall_pending_changes(writer: SerializationWriter, firewall_pending_changes: Partial<Firewall_pending_changes> | undefined | null = {}) : void {
    if (firewall_pending_changes) {
        writer.writeNumberValue("droplet_id", firewall_pending_changes.dropletId);
        writer.writeBooleanValue("removing", firewall_pending_changes.removing);
        writer.writeStringValue("status", firewall_pending_changes.status);
        writer.writeAdditionalData(firewall_pending_changes.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeFirewall_rule(writer: SerializationWriter, firewall_rule: Partial<Firewall_rule> | undefined | null = {}) : void {
    if (firewall_rule) {
        writer.writeEnumValue<Firewall_rule_type>("type", firewall_rule.type);
        writer.writeStringValue("uuid", firewall_rule.uuid);
        writer.writeStringValue("value", firewall_rule.value);
        writer.writeAdditionalData(firewall_rule.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeFirewall_rule_base(writer: SerializationWriter, firewall_rule_base: Partial<Firewall_rule_base> | undefined | null = {}) : void {
    if (firewall_rule_base) {
        writer.writeStringValue("ports", firewall_rule_base.ports);
        writer.writeEnumValue<Firewall_rule_base_protocol>("protocol", firewall_rule_base.protocol);
        writer.writeAdditionalData(firewall_rule_base.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeFirewall_rule_target(writer: SerializationWriter, firewall_rule_target: Partial<Firewall_rule_target> | undefined | null = {}) : void {
    if (firewall_rule_target) {
        writer.writeCollectionOfPrimitiveValues<string>("addresses", firewall_rule_target.addresses);
        writer.writeCollectionOfPrimitiveValues<number>("droplet_ids", firewall_rule_target.dropletIds);
        writer.writeCollectionOfPrimitiveValues<string>("kubernetes_ids", firewall_rule_target.kubernetesIds);
        writer.writeCollectionOfPrimitiveValues<string>("load_balancer_uids", firewall_rule_target.loadBalancerUids);
        writer.writeCollectionOfPrimitiveValues<string>("tags", firewall_rule_target.tags);
        writer.writeAdditionalData(firewall_rule_target.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeFirewall_rules(writer: SerializationWriter, firewall_rules: Partial<Firewall_rules> | undefined | null = {}) : void {
    if (firewall_rules) {
        writer.writeCollectionOfObjectValues<Firewall_rules_inbound_rules>("inbound_rules", firewall_rules.inboundRules, serializeFirewall_rules_inbound_rules);
        writer.writeCollectionOfObjectValues<Firewall_rules_outbound_rules>("outbound_rules", firewall_rules.outboundRules, serializeFirewall_rules_outbound_rules);
        writer.writeAdditionalData(firewall_rules.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeFirewall_rules_inbound_rules(writer: SerializationWriter, firewall_rules_inbound_rules: Partial<Firewall_rules_inbound_rules> | undefined | null = {}) : void {
    if (firewall_rules_inbound_rules) {
        serializeFirewall_rule_base(writer, firewall_rules_inbound_rules)
        writer.writeObjectValue<Firewall_rule_target>("sources", firewall_rules_inbound_rules.sources, serializeFirewall_rule_target);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeFirewall_rules_outbound_rules(writer: SerializationWriter, firewall_rules_outbound_rules: Partial<Firewall_rules_outbound_rules> | undefined | null = {}) : void {
    if (firewall_rules_outbound_rules) {
        serializeFirewall_rule_base(writer, firewall_rules_outbound_rules)
        writer.writeObjectValue<Firewall_rule_target>("destinations", firewall_rules_outbound_rules.destinations, serializeFirewall_rule_target);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeFloating_ip(writer: SerializationWriter, floating_ip: Partial<Floating_ip> | undefined | null = {}) : void {
    if (floating_ip) {
        writer.writeObjectValue<Droplet>("droplet", floating_ip.droplet, serializeDroplet);
        writer.writeStringValue("ip", floating_ip.ip);
        writer.writeBooleanValue("locked", floating_ip.locked);
        writer.writeGuidValue("project_id", floating_ip.projectId);
        writer.writeObjectValue<Region>("region", floating_ip.region, serializeRegion);
        writer.writeAdditionalData(floating_ip.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeFloating_ip_action_assign(writer: SerializationWriter, floating_ip_action_assign: Partial<Floating_ip_action_assign> | undefined | null = {}) : void {
    if (floating_ip_action_assign) {
        serializeFloatingIPsAction(writer, floating_ip_action_assign)
        writer.writeNumberValue("droplet_id", floating_ip_action_assign.dropletId);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeFloating_ip_action_unassign(writer: SerializationWriter, floating_ip_action_unassign: Partial<Floating_ip_action_unassign> | undefined | null = {}) : void {
    if (floating_ip_action_unassign) {
        serializeFloatingIPsAction(writer, floating_ip_action_unassign)
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeFloating_ip_createMember1(writer: SerializationWriter, floating_ip_createMember1: Partial<Floating_ip_createMember1> | undefined | null = {}) : void {
    if (floating_ip_createMember1) {
        writer.writeNumberValue("droplet_id", floating_ip_createMember1.dropletId);
        writer.writeAdditionalData(floating_ip_createMember1.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeFloating_ip_createMember2(writer: SerializationWriter, floating_ip_createMember2: Partial<Floating_ip_createMember2> | undefined | null = {}) : void {
    if (floating_ip_createMember2) {
        writer.writeGuidValue("project_id", floating_ip_createMember2.projectId);
        writer.writeStringValue("region", floating_ip_createMember2.region);
        writer.writeAdditionalData(floating_ip_createMember2.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeFloatingIPsAction(writer: SerializationWriter, floatingIPsAction: Partial<FloatingIPsAction> | undefined | null = {}) : void {
    if (floatingIPsAction) {
        writer.writeEnumValue<FloatingIPsAction_type>("type", floatingIPsAction.type);
        writer.writeAdditionalData(floatingIPsAction.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeForward_links(writer: SerializationWriter, forward_links: Partial<Forward_links> | undefined | null = {}) : void {
    if (forward_links) {
        writer.writeStringValue("last", forward_links.last);
        writer.writeStringValue("next", forward_links.next);
        writer.writeAdditionalData(forward_links.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeForwarding_rule(writer: SerializationWriter, forwarding_rule: Partial<Forwarding_rule> | undefined | null = {}) : void {
    if (forwarding_rule) {
        writer.writeStringValue("certificate_id", forwarding_rule.certificateId);
        writer.writeNumberValue("entry_port", forwarding_rule.entryPort);
        writer.writeEnumValue<Forwarding_rule_entry_protocol>("entry_protocol", forwarding_rule.entryProtocol);
        writer.writeNumberValue("target_port", forwarding_rule.targetPort);
        writer.writeEnumValue<Forwarding_rule_target_protocol>("target_protocol", forwarding_rule.targetProtocol);
        writer.writeBooleanValue("tls_passthrough", forwarding_rule.tlsPassthrough);
        writer.writeAdditionalData(forwarding_rule.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeGarbage_collection(writer: SerializationWriter, garbage_collection: Partial<Garbage_collection> | undefined | null = {}) : void {
    if (garbage_collection) {
        writer.writeNumberValue("blobs_deleted", garbage_collection.blobsDeleted);
        writer.writeDateValue("created_at", garbage_collection.createdAt);
        writer.writeNumberValue("freed_bytes", garbage_collection.freedBytes);
        writer.writeStringValue("registry_name", garbage_collection.registryName);
        writer.writeEnumValue<Garbage_collection_status>("status", garbage_collection.status);
        writer.writeDateValue("updated_at", garbage_collection.updatedAt);
        writer.writeStringValue("uuid", garbage_collection.uuid);
        writer.writeAdditionalData(garbage_collection.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeGenaiapiRegion(writer: SerializationWriter, genaiapiRegion: Partial<GenaiapiRegion> | undefined | null = {}) : void {
    if (genaiapiRegion) {
        writer.writeStringValue("inference_url", genaiapiRegion.inferenceUrl);
        writer.writeStringValue("region", genaiapiRegion.region);
        writer.writeBooleanValue("serves_batch", genaiapiRegion.servesBatch);
        writer.writeBooleanValue("serves_inference", genaiapiRegion.servesInference);
        writer.writeStringValue("stream_inference_url", genaiapiRegion.streamInferenceUrl);
        writer.writeAdditionalData(genaiapiRegion.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeGlb_settings(writer: SerializationWriter, glb_settings: Partial<Glb_settings> | undefined | null = {}) : void {
    if (glb_settings) {
        writer.writeObjectValue<Glb_settings_cdn>("cdn", glb_settings.cdn, serializeGlb_settings_cdn);
        writer.writeNumberValue("failover_threshold", glb_settings.failoverThreshold);
        writer.writeObjectValue<Glb_settings_region_priorities>("region_priorities", glb_settings.regionPriorities, serializeGlb_settings_region_priorities);
        writer.writeNumberValue("target_port", glb_settings.targetPort);
        writer.writeEnumValue<Glb_settings_target_protocol>("target_protocol", glb_settings.targetProtocol);
        writer.writeAdditionalData(glb_settings.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeGlb_settings_cdn(writer: SerializationWriter, glb_settings_cdn: Partial<Glb_settings_cdn> | undefined | null = {}) : void {
    if (glb_settings_cdn) {
        writer.writeBooleanValue("is_enabled", glb_settings_cdn.isEnabled);
        writer.writeAdditionalData(glb_settings_cdn.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeGlb_settings_region_priorities(writer: SerializationWriter, glb_settings_region_priorities: Partial<Glb_settings_region_priorities> | undefined | null = {}) : void {
    if (glb_settings_region_priorities) {
        writer.writeAdditionalData(glb_settings_region_priorities.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeGpu_info(writer: SerializationWriter, gpu_info: Partial<Gpu_info> | undefined | null = {}) : void {
    if (gpu_info) {
        writer.writeNumberValue("count", gpu_info.count);
        writer.writeStringValue("model", gpu_info.model);
        writer.writeObjectValue<Gpu_info_vram>("vram", gpu_info.vram, serializeGpu_info_vram);
        writer.writeAdditionalData(gpu_info.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeGpu_info_vram(writer: SerializationWriter, gpu_info_vram: Partial<Gpu_info_vram> | undefined | null = {}) : void {
    if (gpu_info_vram) {
        writer.writeNumberValue("amount", gpu_info_vram.amount);
        writer.writeStringValue("unit", gpu_info_vram.unit);
        writer.writeAdditionalData(gpu_info_vram.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeGrant(writer: SerializationWriter, grant: Partial<Grant> | undefined | null = {}) : void {
    if (grant) {
        writer.writeStringValue("bucket", grant.bucket);
        writer.writeStringValue("permission", grant.permission);
        writer.writeAdditionalData(grant.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeHealth_check(writer: SerializationWriter, health_check: Partial<Health_check> | undefined | null = {}) : void {
    if (health_check) {
        writer.writeNumberValue("check_interval_seconds", health_check.checkIntervalSeconds);
        writer.writeNumberValue("healthy_threshold", health_check.healthyThreshold);
        writer.writeStringValue("path", health_check.path ?? "/");
        writer.writeNumberValue("port", health_check.port);
        writer.writeEnumValue<Health_check_protocol>("protocol", health_check.protocol ?? Health_check_protocolObject.Http);
        writer.writeNumberValue("response_timeout_seconds", health_check.responseTimeoutSeconds);
        writer.writeNumberValue("unhealthy_threshold", health_check.unhealthyThreshold);
        writer.writeAdditionalData(health_check.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeHistory(writer: SerializationWriter, history: Partial<History> | undefined | null = {}) : void {
    if (history) {
        writer.writeDateValue("created_at", history.createdAt);
        writer.writeNumberValue("current_instance_count", history.currentInstanceCount);
        writer.writeNumberValue("desired_instance_count", history.desiredInstanceCount);
        writer.writeStringValue("history_event_id", history.historyEventId);
        writer.writeEnumValue<History_reason>("reason", history.reason);
        writer.writeEnumValue<History_status>("status", history.status);
        writer.writeDateValue("updated_at", history.updatedAt);
        writer.writeAdditionalData(history.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeImage(writer: SerializationWriter, image: Partial<Image> | undefined | null = {}) : void {
    if (image) {
        writer.writeDateValue("created_at", image.createdAt);
        writer.writeStringValue("description", image.description);
        writer.writeEnumValue<Distribution>("distribution", image.distribution);
        writer.writeStringValue("error_message", image.errorMessage);
        writer.writeNumberValue("min_disk_size", image.minDiskSize);
        writer.writeStringValue("name", image.name);
        writer.writeBooleanValue("public", image.public);
        if(image.regions)
        writer.writeCollectionOfEnumValues<Region_slug>("regions", image.regions);
        writer.writeNumberValue("size_gigabytes", image.sizeGigabytes);
        writer.writeStringValue("slug", image.slug);
        writer.writeEnumValue<Image_status>("status", image.status);
        writer.writeCollectionOfPrimitiveValues<string>("tags", image.tags);
        writer.writeEnumValue<Image_type>("type", image.type);
        writer.writeAdditionalData(image.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeImage_action_base(writer: SerializationWriter, image_action_base: Partial<Image_action_base> | undefined | null = {}) : void {
    if (image_action_base) {
        writer.writeEnumValue<Image_action_base_type>("type", image_action_base.type);
        writer.writeAdditionalData(image_action_base.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeImage_action_transfer(writer: SerializationWriter, image_action_transfer: Partial<Image_action_transfer> | undefined | null = {}) : void {
    if (image_action_transfer) {
        serializeImage_action_base(writer, image_action_transfer)
        writer.writeEnumValue<Region_slug>("region", image_action_transfer.region);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeImage_new_custom(writer: SerializationWriter, image_new_custom: Partial<Image_new_custom> | undefined | null = {}) : void {
    if (image_new_custom) {
        serializeImage_update(writer, image_new_custom)
        writer.writeEnumValue<Region_slug>("region", image_new_custom.region);
        writer.writeCollectionOfPrimitiveValues<string>("tags", image_new_custom.tags);
        writer.writeStringValue("url", image_new_custom.url);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeImage_update(writer: SerializationWriter, image_update: Partial<Image_update> | undefined | null = {}) : void {
    if (image_update) {
        writer.writeStringValue("description", image_update.description);
        writer.writeEnumValue<Distribution>("distribution", image_update.distribution);
        writer.writeStringValue("name", image_update.name);
        writer.writeAdditionalData(image_update.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeInvoice_item(writer: SerializationWriter, invoice_item: Partial<Invoice_item> | undefined | null = {}) : void {
    if (invoice_item) {
        writer.writeStringValue("amount", invoice_item.amount);
        writer.writeStringValue("description", invoice_item.description);
        writer.writeStringValue("duration", invoice_item.duration);
        writer.writeStringValue("duration_unit", invoice_item.durationUnit);
        writer.writeStringValue("end_time", invoice_item.endTime);
        writer.writeStringValue("group_description", invoice_item.groupDescription);
        writer.writeStringValue("product", invoice_item.product);
        writer.writeStringValue("project_name", invoice_item.projectName);
        writer.writeStringValue("resource_id", invoice_item.resourceId);
        writer.writeStringValue("resource_uuid", invoice_item.resourceUuid);
        writer.writeStringValue("start_time", invoice_item.startTime);
        writer.writeAdditionalData(invoice_item.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeInvoice_preview(writer: SerializationWriter, invoice_preview: Partial<Invoice_preview> | undefined | null = {}) : void {
    if (invoice_preview) {
        writer.writeStringValue("amount", invoice_preview.amount);
        writer.writeStringValue("invoice_id", invoice_preview.invoiceId);
        writer.writeStringValue("invoice_period", invoice_preview.invoicePeriod);
        writer.writeStringValue("invoice_uuid", invoice_preview.invoiceUuid);
        writer.writeStringValue("updated_at", invoice_preview.updatedAt);
        writer.writeAdditionalData(invoice_preview.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeInvoice_summary(writer: SerializationWriter, invoice_summary: Partial<Invoice_summary> | undefined | null = {}) : void {
    if (invoice_summary) {
        writer.writeStringValue("amount", invoice_summary.amount);
        writer.writeStringValue("billing_period", invoice_summary.billingPeriod);
        writer.writeObjectValue<Simple_charge>("credits_and_adjustments", invoice_summary.creditsAndAdjustments, serializeSimple_charge);
        writer.writeStringValue("invoice_id", invoice_summary.invoiceId);
        writer.writeStringValue("invoice_uuid", invoice_summary.invoiceUuid);
        writer.writeObjectValue<Simple_charge>("overages", invoice_summary.overages, serializeSimple_charge);
        writer.writeObjectValue<Product_usage_charges>("product_charges", invoice_summary.productCharges, serializeProduct_usage_charges);
        writer.writeObjectValue<Simple_charge>("taxes", invoice_summary.taxes, serializeSimple_charge);
        writer.writeObjectValue<Billing_address>("user_billing_address", invoice_summary.userBillingAddress, serializeBilling_address);
        writer.writeStringValue("user_company", invoice_summary.userCompany);
        writer.writeStringValue("user_email", invoice_summary.userEmail);
        writer.writeStringValue("user_name", invoice_summary.userName);
        writer.writeAdditionalData(invoice_summary.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKafka_advanced_config(writer: SerializationWriter, kafka_advanced_config: Partial<Kafka_advanced_config> | undefined | null = {}) : void {
    if (kafka_advanced_config) {
        writer.writeBooleanValue("auto_create_topics_enable", kafka_advanced_config.autoCreateTopicsEnable);
        writer.writeEnumValue<Kafka_advanced_config_compression_type>("compression_type", kafka_advanced_config.compressionType);
        writer.writeNumberValue("connections_max_idle_ms", kafka_advanced_config.connectionsMaxIdleMs);
        writer.writeNumberValue("default_replication_factor", kafka_advanced_config.defaultReplicationFactor);
        writer.writeNumberValue("group_initial_rebalance_delay_ms", kafka_advanced_config.groupInitialRebalanceDelayMs);
        writer.writeNumberValue("group_max_session_timeout_ms", kafka_advanced_config.groupMaxSessionTimeoutMs);
        writer.writeNumberValue("group_min_session_timeout_ms", kafka_advanced_config.groupMinSessionTimeoutMs);
        writer.writeNumberValue("log_cleaner_delete_retention_ms", kafka_advanced_config.logCleanerDeleteRetentionMs);
        writer.writeNumberValue("log_cleaner_max_compaction_lag_ms", kafka_advanced_config.logCleanerMaxCompactionLagMs);
        writer.writeNumberValue("log_cleaner_min_cleanable_ratio", kafka_advanced_config.logCleanerMinCleanableRatio);
        writer.writeNumberValue("log_cleaner_min_compaction_lag_ms", kafka_advanced_config.logCleanerMinCompactionLagMs);
        writer.writeEnumValue<Kafka_advanced_config_log_cleanup_policy>("log_cleanup_policy", kafka_advanced_config.logCleanupPolicy);
        writer.writeNumberValue("log_flush_interval_messages", kafka_advanced_config.logFlushIntervalMessages);
        writer.writeNumberValue("log_flush_interval_ms", kafka_advanced_config.logFlushIntervalMs);
        writer.writeNumberValue("log_index_interval_bytes", kafka_advanced_config.logIndexIntervalBytes);
        writer.writeNumberValue("log_index_size_max_bytes", kafka_advanced_config.logIndexSizeMaxBytes);
        writer.writeBooleanValue("log_message_downconversion_enable", kafka_advanced_config.logMessageDownconversionEnable);
        writer.writeNumberValue("log_message_timestamp_difference_max_ms", kafka_advanced_config.logMessageTimestampDifferenceMaxMs);
        writer.writeEnumValue<Kafka_advanced_config_log_message_timestamp_type>("log_message_timestamp_type", kafka_advanced_config.logMessageTimestampType);
        writer.writeBooleanValue("log_preallocate", kafka_advanced_config.logPreallocate);
        writer.writeNumberValue("log_retention_bytes", kafka_advanced_config.logRetentionBytes);
        writer.writeNumberValue("log_retention_hours", kafka_advanced_config.logRetentionHours);
        writer.writeNumberValue("log_retention_ms", kafka_advanced_config.logRetentionMs);
        writer.writeNumberValue("log_roll_jitter_ms", kafka_advanced_config.logRollJitterMs);
        writer.writeNumberValue("log_roll_ms", kafka_advanced_config.logRollMs);
        writer.writeNumberValue("log_segment_bytes", kafka_advanced_config.logSegmentBytes);
        writer.writeNumberValue("log_segment_delete_delay_ms", kafka_advanced_config.logSegmentDeleteDelayMs);
        writer.writeNumberValue("max_connections_per_ip", kafka_advanced_config.maxConnectionsPerIp);
        writer.writeNumberValue("max_incremental_fetch_session_cache_slots", kafka_advanced_config.maxIncrementalFetchSessionCacheSlots);
        writer.writeNumberValue("message_max_bytes", kafka_advanced_config.messageMaxBytes);
        writer.writeNumberValue("min_insync_replicas", kafka_advanced_config.minInsyncReplicas);
        writer.writeNumberValue("num_partitions", kafka_advanced_config.numPartitions);
        writer.writeNumberValue("offsets_retention_minutes", kafka_advanced_config.offsetsRetentionMinutes);
        writer.writeNumberValue("producer_purgatory_purge_interval_requests", kafka_advanced_config.producerPurgatoryPurgeIntervalRequests);
        writer.writeNumberValue("replica_fetch_max_bytes", kafka_advanced_config.replicaFetchMaxBytes);
        writer.writeNumberValue("replica_fetch_response_max_bytes", kafka_advanced_config.replicaFetchResponseMaxBytes);
        writer.writeNumberValue("socket_request_max_bytes", kafka_advanced_config.socketRequestMaxBytes);
        writer.writeNumberValue("transaction_remove_expired_transaction_cleanup_interval_ms", kafka_advanced_config.transactionRemoveExpiredTransactionCleanupIntervalMs);
        writer.writeNumberValue("transaction_state_log_segment_bytes", kafka_advanced_config.transactionStateLogSegmentBytes);
        writer.writeAdditionalData(kafka_advanced_config.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKafka_topic(writer: SerializationWriter, kafka_topic: Partial<Kafka_topic> | undefined | null = {}) : void {
    if (kafka_topic) {
        serializeKafka_topic_base(writer, kafka_topic)
        writer.writeEnumValue<Kafka_topic_state>("state", kafka_topic.state);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKafka_topic_base(writer: SerializationWriter, kafka_topic_base: Partial<Kafka_topic_base> | undefined | null = {}) : void {
    if (kafka_topic_base) {
        writer.writeStringValue("name", kafka_topic_base.name);
        writer.writeNumberValue("partition_count", kafka_topic_base.partitionCount);
        writer.writeNumberValue("replication_factor", kafka_topic_base.replicationFactor);
        writer.writeAdditionalData(kafka_topic_base.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKafka_topic_config(writer: SerializationWriter, kafka_topic_config: Partial<Kafka_topic_config> | undefined | null = {}) : void {
    if (kafka_topic_config) {
        writer.writeEnumValue<Kafka_topic_config_cleanup_policy>("cleanup_policy", kafka_topic_config.cleanupPolicy ?? Kafka_topic_config_cleanup_policyObject.Delete);
        writer.writeEnumValue<Kafka_topic_config_compression_type>("compression_type", kafka_topic_config.compressionType ?? Kafka_topic_config_compression_typeObject.Producer);
        writer.writeNumberValue("delete_retention_ms", kafka_topic_config.deleteRetentionMs);
        writer.writeNumberValue("file_delete_delay_ms", kafka_topic_config.fileDeleteDelayMs);
        writer.writeNumberValue("flush_messages", kafka_topic_config.flushMessages);
        writer.writeNumberValue("flush_ms", kafka_topic_config.flushMs);
        writer.writeNumberValue("index_interval_bytes", kafka_topic_config.indexIntervalBytes);
        writer.writeNumberValue("max_compaction_lag_ms", kafka_topic_config.maxCompactionLagMs);
        writer.writeNumberValue("max_message_bytes", kafka_topic_config.maxMessageBytes);
        writer.writeBooleanValue("message_down_conversion_enable", kafka_topic_config.messageDownConversionEnable);
        writer.writeEnumValue<Kafka_topic_config_message_format_version>("message_format_version", kafka_topic_config.messageFormatVersion ?? Kafka_topic_config_message_format_versionObject.ThreeZeroIV1);
        writer.writeEnumValue<Kafka_topic_config_message_timestamp_type>("message_timestamp_type", kafka_topic_config.messageTimestampType ?? Kafka_topic_config_message_timestamp_typeObject.Create_time);
        writer.writeNumberValue("min_cleanable_dirty_ratio", kafka_topic_config.minCleanableDirtyRatio);
        writer.writeNumberValue("min_compaction_lag_ms", kafka_topic_config.minCompactionLagMs);
        writer.writeNumberValue("min_insync_replicas", kafka_topic_config.minInsyncReplicas);
        writer.writeBooleanValue("preallocate", kafka_topic_config.preallocate);
        writer.writeNumberValue("retention_bytes", kafka_topic_config.retentionBytes);
        writer.writeNumberValue("retention_ms", kafka_topic_config.retentionMs);
        writer.writeNumberValue("segment_bytes", kafka_topic_config.segmentBytes);
        writer.writeNumberValue("segment_jitter_ms", kafka_topic_config.segmentJitterMs);
        writer.writeNumberValue("segment_ms", kafka_topic_config.segmentMs);
        writer.writeAdditionalData(kafka_topic_config.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKafka_topic_create(writer: SerializationWriter, kafka_topic_create: Partial<Kafka_topic_create> | undefined | null = {}) : void {
    if (kafka_topic_create) {
        serializeKafka_topic_base(writer, kafka_topic_create)
        writer.writeObjectValue<Kafka_topic_config>("config", kafka_topic_create.config, serializeKafka_topic_config);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKafka_topic_partition(writer: SerializationWriter, kafka_topic_partition: Partial<Kafka_topic_partition> | undefined | null = {}) : void {
    if (kafka_topic_partition) {
        writer.writeCollectionOfObjectValues<Kafka_topic_partition_consumer_groups>("consumer_groups", kafka_topic_partition.consumerGroups, serializeKafka_topic_partition_consumer_groups);
        writer.writeNumberValue("earliest_offset", kafka_topic_partition.earliestOffset);
        writer.writeNumberValue("id", kafka_topic_partition.id);
        writer.writeNumberValue("in_sync_replicas", kafka_topic_partition.inSyncReplicas);
        writer.writeNumberValue("size", kafka_topic_partition.size);
        writer.writeAdditionalData(kafka_topic_partition.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKafka_topic_partition_consumer_groups(writer: SerializationWriter, kafka_topic_partition_consumer_groups: Partial<Kafka_topic_partition_consumer_groups> | undefined | null = {}) : void {
    if (kafka_topic_partition_consumer_groups) {
        writer.writeStringValue("group_name", kafka_topic_partition_consumer_groups.groupName);
        writer.writeNumberValue("offset", kafka_topic_partition_consumer_groups.offset);
        writer.writeAdditionalData(kafka_topic_partition_consumer_groups.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKafka_topic_update(writer: SerializationWriter, kafka_topic_update: Partial<Kafka_topic_update> | undefined | null = {}) : void {
    if (kafka_topic_update) {
        writer.writeObjectValue<Kafka_topic_config>("config", kafka_topic_update.config, serializeKafka_topic_config);
        writer.writeNumberValue("partition_count", kafka_topic_update.partitionCount);
        writer.writeNumberValue("replication_factor", kafka_topic_update.replicationFactor);
        writer.writeAdditionalData(kafka_topic_update.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKafka_topic_verbose(writer: SerializationWriter, kafka_topic_verbose: Partial<Kafka_topic_verbose> | undefined | null = {}) : void {
    if (kafka_topic_verbose) {
        writer.writeObjectValue<Kafka_topic_config>("config", kafka_topic_verbose.config, serializeKafka_topic_config);
        writer.writeStringValue("name", kafka_topic_verbose.name);
        writer.writeCollectionOfObjectValues<Kafka_topic_partition>("partitions", kafka_topic_verbose.partitions, serializeKafka_topic_partition);
        writer.writeNumberValue("replication_factor", kafka_topic_verbose.replicationFactor);
        writer.writeEnumValue<Kafka_topic_verbose_state>("state", kafka_topic_verbose.state);
        writer.writeAdditionalData(kafka_topic_verbose.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKernel(writer: SerializationWriter, kernel: Partial<Kernel> | undefined | null = {}) : void {
    if (kernel) {
        writer.writeNumberValue("id", kernel.id);
        writer.writeStringValue("name", kernel.name);
        writer.writeStringValue("version", kernel.version);
        writer.writeAdditionalData(kernel.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKey(writer: SerializationWriter, key: Partial<Key> | undefined | null = {}) : void {
    if (key) {
        writer.writeCollectionOfObjectValues<Grant>("grants", key.grants, serializeGrant);
        writer.writeStringValue("name", key.name);
        writer.writeAdditionalData(key.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKey_create_response(writer: SerializationWriter, key_create_response: Partial<Key_create_response> | undefined | null = {}) : void {
    if (key_create_response) {
        serializeKey(writer, key_create_response)
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKubernetes_node_pool(writer: SerializationWriter, kubernetes_node_pool: Partial<Kubernetes_node_pool> | undefined | null = {}) : void {
    if (kubernetes_node_pool) {
        writer.writeBooleanValue("auto_scale", kubernetes_node_pool.autoScale);
        writer.writeNumberValue("count", kubernetes_node_pool.count);
        writer.writeObjectValue<Kubernetes_node_pool_labels>("labels", kubernetes_node_pool.labels, serializeKubernetes_node_pool_labels);
        writer.writeNumberValue("max_nodes", kubernetes_node_pool.maxNodes);
        writer.writeNumberValue("min_nodes", kubernetes_node_pool.minNodes);
        writer.writeStringValue("name", kubernetes_node_pool.name);
        writer.writeStringValue("size", kubernetes_node_pool.size);
        writer.writeCollectionOfPrimitiveValues<string>("tags", kubernetes_node_pool.tags);
        writer.writeCollectionOfObjectValues<Kubernetes_node_pool_taint>("taints", kubernetes_node_pool.taints, serializeKubernetes_node_pool_taint);
        writer.writeAdditionalData(kubernetes_node_pool.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKubernetes_node_pool_labels(writer: SerializationWriter, kubernetes_node_pool_labels: Partial<Kubernetes_node_pool_labels> | undefined | null = {}) : void {
    if (kubernetes_node_pool_labels) {
        writer.writeAdditionalData(kubernetes_node_pool_labels.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKubernetes_node_pool_taint(writer: SerializationWriter, kubernetes_node_pool_taint: Partial<Kubernetes_node_pool_taint> | undefined | null = {}) : void {
    if (kubernetes_node_pool_taint) {
        writer.writeEnumValue<Kubernetes_node_pool_taint_effect>("effect", kubernetes_node_pool_taint.effect);
        writer.writeStringValue("key", kubernetes_node_pool_taint.key);
        writer.writeStringValue("value", kubernetes_node_pool_taint.value);
        writer.writeAdditionalData(kubernetes_node_pool_taint.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKubernetes_node_pool_update(writer: SerializationWriter, kubernetes_node_pool_update: Partial<Kubernetes_node_pool_update> | undefined | null = {}) : void {
    if (kubernetes_node_pool_update) {
        writer.writeBooleanValue("auto_scale", kubernetes_node_pool_update.autoScale);
        writer.writeNumberValue("count", kubernetes_node_pool_update.count);
        writer.writeObjectValue<Kubernetes_node_pool_update_labels>("labels", kubernetes_node_pool_update.labels, serializeKubernetes_node_pool_update_labels);
        writer.writeNumberValue("max_nodes", kubernetes_node_pool_update.maxNodes);
        writer.writeNumberValue("min_nodes", kubernetes_node_pool_update.minNodes);
        writer.writeStringValue("name", kubernetes_node_pool_update.name);
        writer.writeCollectionOfPrimitiveValues<string>("tags", kubernetes_node_pool_update.tags);
        writer.writeCollectionOfObjectValues<Kubernetes_node_pool_taint>("taints", kubernetes_node_pool_update.taints, serializeKubernetes_node_pool_taint);
        writer.writeAdditionalData(kubernetes_node_pool_update.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKubernetes_node_pool_update_labels(writer: SerializationWriter, kubernetes_node_pool_update_labels: Partial<Kubernetes_node_pool_update_labels> | undefined | null = {}) : void {
    if (kubernetes_node_pool_update_labels) {
        writer.writeAdditionalData(kubernetes_node_pool_update_labels.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKubernetes_options(writer: SerializationWriter, kubernetes_options: Partial<Kubernetes_options> | undefined | null = {}) : void {
    if (kubernetes_options) {
        writer.writeObjectValue<Kubernetes_options_options>("options", kubernetes_options.options, serializeKubernetes_options_options);
        writer.writeAdditionalData(kubernetes_options.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKubernetes_options_options(writer: SerializationWriter, kubernetes_options_options: Partial<Kubernetes_options_options> | undefined | null = {}) : void {
    if (kubernetes_options_options) {
        writer.writeCollectionOfObjectValues<Kubernetes_region>("regions", kubernetes_options_options.regions, serializeKubernetes_region);
        writer.writeCollectionOfObjectValues<Kubernetes_size>("sizes", kubernetes_options_options.sizes, serializeKubernetes_size);
        writer.writeCollectionOfObjectValues<Kubernetes_version>("versions", kubernetes_options_options.versions, serializeKubernetes_version);
        writer.writeAdditionalData(kubernetes_options_options.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKubernetes_region(writer: SerializationWriter, kubernetes_region: Partial<Kubernetes_region> | undefined | null = {}) : void {
    if (kubernetes_region) {
        writer.writeStringValue("name", kubernetes_region.name);
        writer.writeStringValue("slug", kubernetes_region.slug);
        writer.writeAdditionalData(kubernetes_region.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKubernetes_size(writer: SerializationWriter, kubernetes_size: Partial<Kubernetes_size> | undefined | null = {}) : void {
    if (kubernetes_size) {
        writer.writeStringValue("name", kubernetes_size.name);
        writer.writeStringValue("slug", kubernetes_size.slug);
        writer.writeAdditionalData(kubernetes_size.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeKubernetes_version(writer: SerializationWriter, kubernetes_version: Partial<Kubernetes_version> | undefined | null = {}) : void {
    if (kubernetes_version) {
        writer.writeStringValue("kubernetes_version", kubernetes_version.kubernetesVersion);
        writer.writeStringValue("slug", kubernetes_version.slug);
        writer.writeCollectionOfPrimitiveValues<string>("supported_features", kubernetes_version.supportedFeatures);
        writer.writeAdditionalData(kubernetes_version.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeLb_firewall(writer: SerializationWriter, lb_firewall: Partial<Lb_firewall> | undefined | null = {}) : void {
    if (lb_firewall) {
        writer.writeCollectionOfPrimitiveValues<string>("allow", lb_firewall.allow);
        writer.writeCollectionOfPrimitiveValues<string>("deny", lb_firewall.deny);
        writer.writeAdditionalData(lb_firewall.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeLoad_balancer(writer: SerializationWriter, load_balancer: Partial<Load_balancer> | undefined | null = {}) : void {
    if (load_balancer) {
        serializeLoad_balancer_base(writer, load_balancer)
        writer.writeCollectionOfPrimitiveValues<number>("droplet_ids", load_balancer.dropletIds);
        writer.writeObjectValue<Load_balancer_region>("region", load_balancer.region, serializeLoad_balancer_region);
        writer.writeStringValue("tag", load_balancer.tag);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeLoad_balancer_base(writer: SerializationWriter, load_balancer_base: Partial<Load_balancer_base> | undefined | null = {}) : void {
    if (load_balancer_base) {
        writer.writeEnumValue<Load_balancer_base_algorithm>("algorithm", load_balancer_base.algorithm ?? Load_balancer_base_algorithmObject.Round_robin);
        writer.writeBooleanValue("disable_lets_encrypt_dns_records", load_balancer_base.disableLetsEncryptDnsRecords);
        writer.writeCollectionOfObjectValues<Domains>("domains", load_balancer_base.domains, serializeDomains);
        writer.writeBooleanValue("enable_backend_keepalive", load_balancer_base.enableBackendKeepalive);
        writer.writeBooleanValue("enable_proxy_protocol", load_balancer_base.enableProxyProtocol);
        writer.writeObjectValue<Lb_firewall>("firewall", load_balancer_base.firewall, serializeLb_firewall);
        writer.writeCollectionOfObjectValues<Forwarding_rule>("forwarding_rules", load_balancer_base.forwardingRules, serializeForwarding_rule);
        writer.writeObjectValue<Glb_settings>("glb_settings", load_balancer_base.glbSettings, serializeGlb_settings);
        writer.writeObjectValue<Health_check>("health_check", load_balancer_base.healthCheck, serializeHealth_check);
        writer.writeNumberValue("http_idle_timeout_seconds", load_balancer_base.httpIdleTimeoutSeconds);
        writer.writeStringValue("name", load_balancer_base.name);
        writer.writeEnumValue<Load_balancer_base_network>("network", load_balancer_base.network ?? Load_balancer_base_networkObject.EXTERNAL);
        writer.writeEnumValue<Load_balancer_base_network_stack>("network_stack", load_balancer_base.networkStack ?? Load_balancer_base_network_stackObject.IPV4);
        writer.writeStringValue("project_id", load_balancer_base.projectId);
        writer.writeBooleanValue("redirect_http_to_https", load_balancer_base.redirectHttpToHttps);
        writer.writeEnumValue<Load_balancer_base_size>("size", load_balancer_base.size ?? Load_balancer_base_sizeObject.LbSmall);
        writer.writeNumberValue("size_unit", load_balancer_base.sizeUnit);
        writer.writeObjectValue<Sticky_sessions>("sticky_sessions", load_balancer_base.stickySessions, serializeSticky_sessions);
        writer.writeCollectionOfPrimitiveValues<string>("target_load_balancer_ids", load_balancer_base.targetLoadBalancerIds);
        writer.writeEnumValue<Load_balancer_base_type>("type", load_balancer_base.type ?? Load_balancer_base_typeObject.REGIONAL);
        writer.writeGuidValue("vpc_uuid", load_balancer_base.vpcUuid);
        writer.writeAdditionalData(load_balancer_base.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeLoad_balancer_region(writer: SerializationWriter, load_balancer_region: Partial<Load_balancer_region> | undefined | null = {}) : void {
    if (load_balancer_region) {
        serializeRegion(writer, load_balancer_region)
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeLogsink_base(writer: SerializationWriter, logsink_base: Partial<Logsink_base> | undefined | null = {}) : void {
    if (logsink_base) {
        writer.writeStringValue("sink_name", logsink_base.sinkName);
        writer.writeEnumValue<Logsink_base_sink_type>("sink_type", logsink_base.sinkType);
        writer.writeAdditionalData(logsink_base.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeLogsink_base_verbose(writer: SerializationWriter, logsink_base_verbose: Partial<Logsink_base_verbose> | undefined | null = {}) : void {
    if (logsink_base_verbose) {
        writer.writeStringValue("sink_id", logsink_base_verbose.sinkId);
        writer.writeStringValue("sink_name", logsink_base_verbose.sinkName);
        writer.writeEnumValue<Logsink_base_verbose_sink_type>("sink_type", logsink_base_verbose.sinkType);
        writer.writeAdditionalData(logsink_base_verbose.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeLogsink_create(writer: SerializationWriter, logsink_create: Partial<Logsink_create> | undefined | null = {}) : void {
    if (logsink_create) {
        serializeLogsink_base(writer, logsink_create)
        writer.writeObjectValue<Elasticsearch_logsink | Opensearch_logsink | Rsyslog_logsink>("config", logsink_create.config, serializeLogsink_create_config);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeLogsink_create_config(writer: SerializationWriter, logsink_create_config: Partial<Elasticsearch_logsink | Opensearch_logsink | Rsyslog_logsink> | undefined | null = {}) : void {
    serializeElasticsearch_logsink(writer, logsink_create_config as Elasticsearch_logsink);
    serializeOpensearch_logsink(writer, logsink_create_config as Opensearch_logsink);
    serializeRsyslog_logsink(writer, logsink_create_config as Rsyslog_logsink);
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeLogsink_update(writer: SerializationWriter, logsink_update: Partial<Logsink_update> | undefined | null = {}) : void {
    if (logsink_update) {
        writer.writeObjectValue<Elasticsearch_logsink | Opensearch_logsink | Rsyslog_logsink>("config", logsink_update.config, serializeLogsink_update_config);
        writer.writeAdditionalData(logsink_update.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeLogsink_update_config(writer: SerializationWriter, logsink_update_config: Partial<Elasticsearch_logsink | Opensearch_logsink | Rsyslog_logsink> | undefined | null = {}) : void {
    serializeElasticsearch_logsink(writer, logsink_update_config as Elasticsearch_logsink);
    serializeOpensearch_logsink(writer, logsink_update_config as Opensearch_logsink);
    serializeRsyslog_logsink(writer, logsink_update_config as Rsyslog_logsink);
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeLogsink_verbose(writer: SerializationWriter, logsink_verbose: Partial<Logsink_verbose> | undefined | null = {}) : void {
    if (logsink_verbose) {
        serializeLogsink_base_verbose(writer, logsink_verbose)
        writer.writeObjectValue<Elasticsearch_logsink | Opensearch_logsink | Rsyslog_logsink>("config", logsink_verbose.config, serializeLogsink_verbose_config);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeLogsink_verbose_config(writer: SerializationWriter, logsink_verbose_config: Partial<Elasticsearch_logsink | Opensearch_logsink | Rsyslog_logsink> | undefined | null = {}) : void {
    serializeElasticsearch_logsink(writer, logsink_verbose_config as Elasticsearch_logsink);
    serializeOpensearch_logsink(writer, logsink_verbose_config as Opensearch_logsink);
    serializeRsyslog_logsink(writer, logsink_verbose_config as Rsyslog_logsink);
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeMaintenance_policy(writer: SerializationWriter, maintenance_policy: Partial<Maintenance_policy> | undefined | null = {}) : void {
    if (maintenance_policy) {
        writer.writeEnumValue<Maintenance_policy_day>("day", maintenance_policy.day);
        writer.writeStringValue("start_time", maintenance_policy.startTime);
        writer.writeAdditionalData(maintenance_policy.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeMember(writer: SerializationWriter, member: Partial<Member> | undefined | null = {}) : void {
    if (member) {
        writer.writeDateValue("created_at", member.createdAt);
        writer.writeObjectValue<Member_current_utilization>("current_utilization", member.currentUtilization, serializeMember_current_utilization);
        writer.writeNumberValue("droplet_id", member.dropletId);
        writer.writeStringValue("health_status", member.healthStatus);
        writer.writeEnumValue<Member_status>("status", member.status);
        writer.writeDateValue("updated_at", member.updatedAt);
        writer.writeAdditionalData(member.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeMember_current_utilization(writer: SerializationWriter, member_current_utilization: Partial<Member_current_utilization> | undefined | null = {}) : void {
    if (member_current_utilization) {
        writer.writeNumberValue("cpu", member_current_utilization.cpu);
        writer.writeNumberValue("memory", member_current_utilization.memory);
        writer.writeAdditionalData(member_current_utilization.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeMeta_properties(writer: SerializationWriter, meta_properties: Partial<Meta_properties> | undefined | null = {}) : void {
    if (meta_properties) {
        writer.writeNumberValue("total", meta_properties.total);
        writer.writeAdditionalData(meta_properties.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeMetrics(writer: SerializationWriter, metrics: Partial<Metrics> | undefined | null = {}) : void {
    if (metrics) {
        writer.writeObjectValue<Metrics_data>("data", metrics.data, serializeMetrics_data);
        writer.writeEnumValue<Metrics_status>("status", metrics.status);
        writer.writeAdditionalData(metrics.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeMetrics_data(writer: SerializationWriter, metrics_data: Partial<Metrics_data> | undefined | null = {}) : void {
    if (metrics_data) {
        writer.writeCollectionOfObjectValues<Metrics_result>("result", metrics_data.result, serializeMetrics_result);
        writer.writeEnumValue<Metrics_data_resultType>("resultType", metrics_data.resultType);
        writer.writeAdditionalData(metrics_data.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeMetrics_result(writer: SerializationWriter, metrics_result: Partial<Metrics_result> | undefined | null = {}) : void {
    if (metrics_result) {
        writer.writeObjectValue<Metrics_result_metric>("metric", metrics_result.metric, serializeMetrics_result_metric);
        writer.writeObjectValue("values", metrics_result.values);
        writer.writeAdditionalData(metrics_result.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeMetrics_result_metric(writer: SerializationWriter, metrics_result_metric: Partial<Metrics_result_metric> | undefined | null = {}) : void {
    if (metrics_result_metric) {
        writer.writeAdditionalData(metrics_result_metric.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeMongo_advanced_config(writer: SerializationWriter, mongo_advanced_config: Partial<Mongo_advanced_config> | undefined | null = {}) : void {
    if (mongo_advanced_config) {
        writer.writeEnumValue<Mongo_advanced_config_default_read_concern>("default_read_concern", mongo_advanced_config.defaultReadConcern ?? Mongo_advanced_config_default_read_concernObject.Local);
        writer.writeStringValue("default_write_concern", mongo_advanced_config.defaultWriteConcern ?? "majority");
        writer.writeNumberValue("slow_op_threshold_ms", mongo_advanced_config.slowOpThresholdMs);
        writer.writeNumberValue("transaction_lifetime_limit_seconds", mongo_advanced_config.transactionLifetimeLimitSeconds);
        writer.writeNumberValue("verbosity", mongo_advanced_config.verbosity);
        writer.writeAdditionalData(mongo_advanced_config.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeMysql_advanced_config(writer: SerializationWriter, mysql_advanced_config: Partial<Mysql_advanced_config> | undefined | null = {}) : void {
    if (mysql_advanced_config) {
        writer.writeNumberValue("backup_hour", mysql_advanced_config.backupHour);
        writer.writeNumberValue("backup_minute", mysql_advanced_config.backupMinute);
        writer.writeNumberValue("binlog_retention_period", mysql_advanced_config.binlogRetentionPeriod);
        writer.writeNumberValue("connect_timeout", mysql_advanced_config.connectTimeout);
        writer.writeStringValue("default_time_zone", mysql_advanced_config.defaultTimeZone);
        writer.writeNumberValue("group_concat_max_len", mysql_advanced_config.groupConcatMaxLen);
        writer.writeNumberValue("information_schema_stats_expiry", mysql_advanced_config.informationSchemaStatsExpiry);
        writer.writeNumberValue("innodb_change_buffer_max_size", mysql_advanced_config.innodbChangeBufferMaxSize);
        writer.writeNumberValue("innodb_flush_neighbors", mysql_advanced_config.innodbFlushNeighbors);
        writer.writeNumberValue("innodb_ft_min_token_size", mysql_advanced_config.innodbFtMinTokenSize);
        writer.writeStringValue("innodb_ft_server_stopword_table", mysql_advanced_config.innodbFtServerStopwordTable);
        writer.writeNumberValue("innodb_lock_wait_timeout", mysql_advanced_config.innodbLockWaitTimeout);
        writer.writeNumberValue("innodb_log_buffer_size", mysql_advanced_config.innodbLogBufferSize);
        writer.writeNumberValue("innodb_online_alter_log_max_size", mysql_advanced_config.innodbOnlineAlterLogMaxSize);
        writer.writeBooleanValue("innodb_print_all_deadlocks", mysql_advanced_config.innodbPrintAllDeadlocks);
        writer.writeNumberValue("innodb_read_io_threads", mysql_advanced_config.innodbReadIoThreads);
        writer.writeBooleanValue("innodb_rollback_on_timeout", mysql_advanced_config.innodbRollbackOnTimeout);
        writer.writeNumberValue("innodb_thread_concurrency", mysql_advanced_config.innodbThreadConcurrency);
        writer.writeNumberValue("innodb_write_io_threads", mysql_advanced_config.innodbWriteIoThreads);
        writer.writeNumberValue("interactive_timeout", mysql_advanced_config.interactiveTimeout);
        writer.writeEnumValue<Mysql_advanced_config_internal_tmp_mem_storage_engine>("internal_tmp_mem_storage_engine", mysql_advanced_config.internalTmpMemStorageEngine);
        writer.writeEnumValue<Mysql_advanced_config_log_output>("log_output", mysql_advanced_config.logOutput ?? Mysql_advanced_config_log_outputObject.NONE);
        writer.writeNumberValue("long_query_time", mysql_advanced_config.longQueryTime);
        writer.writeNumberValue("max_allowed_packet", mysql_advanced_config.maxAllowedPacket);
        writer.writeNumberValue("max_heap_table_size", mysql_advanced_config.maxHeapTableSize);
        writer.writeNumberValue("net_buffer_length", mysql_advanced_config.netBufferLength);
        writer.writeNumberValue("net_read_timeout", mysql_advanced_config.netReadTimeout);
        writer.writeNumberValue("net_write_timeout", mysql_advanced_config.netWriteTimeout);
        writer.writeBooleanValue("slow_query_log", mysql_advanced_config.slowQueryLog);
        writer.writeNumberValue("sort_buffer_size", mysql_advanced_config.sortBufferSize);
        writer.writeStringValue("sql_mode", mysql_advanced_config.sqlMode);
        writer.writeBooleanValue("sql_require_primary_key", mysql_advanced_config.sqlRequirePrimaryKey);
        writer.writeNumberValue("tmp_table_size", mysql_advanced_config.tmpTableSize);
        writer.writeNumberValue("wait_timeout", mysql_advanced_config.waitTimeout);
        writer.writeAdditionalData(mysql_advanced_config.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeMysql_settings(writer: SerializationWriter, mysql_settings: Partial<Mysql_settings> | undefined | null = {}) : void {
    if (mysql_settings) {
        writer.writeEnumValue<Mysql_settings_auth_plugin>("auth_plugin", mysql_settings.authPlugin);
        writer.writeAdditionalData(mysql_settings.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeNamespace_info(writer: SerializationWriter, namespace_info: Partial<Namespace_info> | undefined | null = {}) : void {
    if (namespace_info) {
        writer.writeStringValue("api_host", namespace_info.apiHost);
        writer.writeStringValue("created_at", namespace_info.createdAt);
        writer.writeStringValue("key", namespace_info.key);
        writer.writeStringValue("label", namespace_info.label);
        writer.writeStringValue("namespace", namespace_info.namespace);
        writer.writeStringValue("region", namespace_info.region);
        writer.writeStringValue("updated_at", namespace_info.updatedAt);
        writer.writeStringValue("uuid", namespace_info.uuid);
        writer.writeAdditionalData(namespace_info.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeNeighbor_ids(writer: SerializationWriter, neighbor_ids: Partial<Neighbor_ids> | undefined | null = {}) : void {
    if (neighbor_ids) {
        writer.writeObjectValue("neighbor_ids", neighbor_ids.neighborIds);
        writer.writeAdditionalData(neighbor_ids.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeNetwork_v4(writer: SerializationWriter, network_v4: Partial<Network_v4> | undefined | null = {}) : void {
    if (network_v4) {
        writer.writeStringValue("gateway", network_v4.gateway);
        writer.writeStringValue("ip_address", network_v4.ipAddress);
        writer.writeStringValue("netmask", network_v4.netmask);
        writer.writeEnumValue<Network_v4_type>("type", network_v4.type);
        writer.writeAdditionalData(network_v4.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeNetwork_v6(writer: SerializationWriter, network_v6: Partial<Network_v6> | undefined | null = {}) : void {
    if (network_v6) {
        writer.writeStringValue("gateway", network_v6.gateway);
        writer.writeStringValue("ip_address", network_v6.ipAddress);
        writer.writeNumberValue("netmask", network_v6.netmask);
        writer.writeEnumValue<Network_v6_type>("type", network_v6.type);
        writer.writeAdditionalData(network_v6.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeNode(writer: SerializationWriter, node: Partial<Node> | undefined | null = {}) : void {
    if (node) {
        writer.writeDateValue("created_at", node.createdAt);
        writer.writeStringValue("droplet_id", node.dropletId);
        writer.writeGuidValue("id", node.id);
        writer.writeStringValue("name", node.name);
        writer.writeObjectValue<Node_status>("status", node.status, serializeNode_status);
        writer.writeDateValue("updated_at", node.updatedAt);
        writer.writeAdditionalData(node.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeNode_status(writer: SerializationWriter, node_status: Partial<Node_status> | undefined | null = {}) : void {
    if (node_status) {
        writer.writeEnumValue<Node_status_state>("state", node_status.state);
        writer.writeAdditionalData(node_status.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeNotification(writer: SerializationWriter, notification: Partial<Notification> | undefined | null = {}) : void {
    if (notification) {
        writer.writeCollectionOfPrimitiveValues<string>("email", notification.email);
        writer.writeCollectionOfObjectValues<Notification_slack>("slack", notification.slack, serializeNotification_slack);
        writer.writeAdditionalData(notification.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeNotification_slack(writer: SerializationWriter, notification_slack: Partial<Notification_slack> | undefined | null = {}) : void {
    if (notification_slack) {
        writer.writeStringValue("channel", notification_slack.channel);
        writer.writeStringValue("url", notification_slack.url);
        writer.writeAdditionalData(notification_slack.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOneClicks(writer: SerializationWriter, oneClicks: Partial<OneClicks> | undefined | null = {}) : void {
    if (oneClicks) {
        writer.writeStringValue("slug", oneClicks.slug);
        writer.writeStringValue("type", oneClicks.type);
        writer.writeAdditionalData(oneClicks.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOneClicks_create(writer: SerializationWriter, oneClicks_create: Partial<OneClicks_create> | undefined | null = {}) : void {
    if (oneClicks_create) {
        writer.writeCollectionOfPrimitiveValues<string>("addon_slugs", oneClicks_create.addonSlugs);
        writer.writeStringValue("cluster_uuid", oneClicks_create.clusterUuid);
        writer.writeAdditionalData(oneClicks_create.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOnline_migration(writer: SerializationWriter, online_migration: Partial<Online_migration> | undefined | null = {}) : void {
    if (online_migration) {
        writer.writeStringValue("created_at", online_migration.createdAt);
        writer.writeStringValue("id", online_migration.id);
        writer.writeEnumValue<Online_migration_status>("status", online_migration.status);
        writer.writeAdditionalData(online_migration.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOpensearch_advanced_config(writer: SerializationWriter, opensearch_advanced_config: Partial<Opensearch_advanced_config> | undefined | null = {}) : void {
    if (opensearch_advanced_config) {
        writer.writeBooleanValue("action_auto_create_index_enabled", opensearch_advanced_config.actionAutoCreateIndexEnabled);
        writer.writeBooleanValue("action_destructive_requires_name", opensearch_advanced_config.actionDestructiveRequiresName);
        writer.writeNumberValue("cluster_max_shards_per_node", opensearch_advanced_config.clusterMaxShardsPerNode);
        writer.writeNumberValue("cluster_routing_allocation_node_concurrent_recoveries", opensearch_advanced_config.clusterRoutingAllocationNodeConcurrentRecoveries);
        writer.writeBooleanValue("enable_security_audit", opensearch_advanced_config.enableSecurityAudit);
        writer.writeNumberValue("http_max_content_length_bytes", opensearch_advanced_config.httpMaxContentLengthBytes);
        writer.writeNumberValue("http_max_header_size_bytes", opensearch_advanced_config.httpMaxHeaderSizeBytes);
        writer.writeNumberValue("http_max_initial_line_length_bytes", opensearch_advanced_config.httpMaxInitialLineLengthBytes);
        writer.writeNumberValue("indices_fielddata_cache_size_percentage", opensearch_advanced_config.indicesFielddataCacheSizePercentage);
        writer.writeNumberValue("indices_memory_index_buffer_size_percentage", opensearch_advanced_config.indicesMemoryIndexBufferSizePercentage);
        writer.writeNumberValue("indices_memory_max_index_buffer_size_mb", opensearch_advanced_config.indicesMemoryMaxIndexBufferSizeMb);
        writer.writeNumberValue("indices_memory_min_index_buffer_size_mb", opensearch_advanced_config.indicesMemoryMinIndexBufferSizeMb);
        writer.writeNumberValue("indices_queries_cache_size_percentage", opensearch_advanced_config.indicesQueriesCacheSizePercentage);
        writer.writeNumberValue("indices_query_bool_max_clause_count", opensearch_advanced_config.indicesQueryBoolMaxClauseCount);
        writer.writeNumberValue("indices_recovery_max_concurrent_file_chunks", opensearch_advanced_config.indicesRecoveryMaxConcurrentFileChunks);
        writer.writeNumberValue("indices_recovery_max_mb_per_sec", opensearch_advanced_config.indicesRecoveryMaxMbPerSec);
        writer.writeBooleanValue("ism_enabled", opensearch_advanced_config.ismEnabled);
        writer.writeBooleanValue("ism_history_enabled", opensearch_advanced_config.ismHistoryEnabled);
        writer.writeNumberValue("ism_history_max_age_hours", opensearch_advanced_config.ismHistoryMaxAgeHours);
        writer.writeNumberValue("ism_history_max_docs", opensearch_advanced_config.ismHistoryMaxDocs);
        writer.writeNumberValue("ism_history_rollover_check_period_hours", opensearch_advanced_config.ismHistoryRolloverCheckPeriodHours);
        writer.writeNumberValue("ism_history_rollover_retention_period_days", opensearch_advanced_config.ismHistoryRolloverRetentionPeriodDays);
        writer.writeBooleanValue("override_main_response_version", opensearch_advanced_config.overrideMainResponseVersion);
        writer.writeBooleanValue("plugins_alerting_filter_by_backend_roles_enabled", opensearch_advanced_config.pluginsAlertingFilterByBackendRolesEnabled);
        writer.writeCollectionOfPrimitiveValues<string>("reindex_remote_whitelist", opensearch_advanced_config.reindexRemoteWhitelist);
        writer.writeStringValue("script_max_compilations_rate", opensearch_advanced_config.scriptMaxCompilationsRate ?? "use-context");
        writer.writeNumberValue("search_max_buckets", opensearch_advanced_config.searchMaxBuckets);
        writer.writeNumberValue("thread_pool_analyze_queue_size", opensearch_advanced_config.threadPoolAnalyzeQueueSize);
        writer.writeNumberValue("thread_pool_analyze_size", opensearch_advanced_config.threadPoolAnalyzeSize);
        writer.writeNumberValue("thread_pool_force_merge_size", opensearch_advanced_config.threadPoolForceMergeSize);
        writer.writeNumberValue("thread_pool_get_queue_size", opensearch_advanced_config.threadPoolGetQueueSize);
        writer.writeNumberValue("thread_pool_get_size", opensearch_advanced_config.threadPoolGetSize);
        writer.writeNumberValue("thread_pool_search_queue_size", opensearch_advanced_config.threadPoolSearchQueueSize);
        writer.writeNumberValue("thread_pool_search_size", opensearch_advanced_config.threadPoolSearchSize);
        writer.writeNumberValue("thread_pool_search_throttled_queue_size", opensearch_advanced_config.threadPoolSearchThrottledQueueSize);
        writer.writeNumberValue("thread_pool_search_throttled_size", opensearch_advanced_config.threadPoolSearchThrottledSize);
        writer.writeNumberValue("thread_pool_write_queue_size", opensearch_advanced_config.threadPoolWriteQueueSize);
        writer.writeNumberValue("thread_pool_write_size", opensearch_advanced_config.threadPoolWriteSize);
        writer.writeAdditionalData(opensearch_advanced_config.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOpensearch_config(writer: SerializationWriter, opensearch_config: Partial<Opensearch_config> | undefined | null = {}) : void {
    if (opensearch_config) {
        writer.writeStringValue("cluster_name", opensearch_config.clusterName);
        writer.writeStringValue("cluster_uuid", opensearch_config.clusterUuid);
        writer.writeObjectValue<Opensearch_config_credentials>("credentials", opensearch_config.credentials, serializeOpensearch_config_credentials);
        writer.writeStringValue("endpoint", opensearch_config.endpoint);
        writer.writeStringValue("id", opensearch_config.id);
        writer.writeStringValue("index_name", opensearch_config.indexName);
        writer.writeNumberValue("retention_days", opensearch_config.retentionDays);
        writer.writeAdditionalData(opensearch_config.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOpensearch_config_credentials(writer: SerializationWriter, opensearch_config_credentials: Partial<Opensearch_config_credentials> | undefined | null = {}) : void {
    if (opensearch_config_credentials) {
        writer.writeStringValue("password", opensearch_config_credentials.password);
        writer.writeStringValue("username", opensearch_config_credentials.username);
        writer.writeAdditionalData(opensearch_config_credentials.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOpensearch_config_omit_credentials(writer: SerializationWriter, opensearch_config_omit_credentials: Partial<Opensearch_config_omit_credentials> | undefined | null = {}) : void {
    if (opensearch_config_omit_credentials) {
        writer.writeStringValue("cluster_name", opensearch_config_omit_credentials.clusterName);
        writer.writeStringValue("cluster_uuid", opensearch_config_omit_credentials.clusterUuid);
        writer.writeStringValue("endpoint", opensearch_config_omit_credentials.endpoint);
        writer.writeStringValue("id", opensearch_config_omit_credentials.id);
        writer.writeStringValue("index_name", opensearch_config_omit_credentials.indexName);
        writer.writeNumberValue("retention_days", opensearch_config_omit_credentials.retentionDays);
        writer.writeAdditionalData(opensearch_config_omit_credentials.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOpensearch_config_request(writer: SerializationWriter, opensearch_config_request: Partial<Opensearch_config_request> | undefined | null = {}) : void {
    if (opensearch_config_request) {
        writer.writeStringValue("cluster_name", opensearch_config_request.clusterName);
        writer.writeStringValue("cluster_uuid", opensearch_config_request.clusterUuid);
        writer.writeObjectValue<Opensearch_config_request_credentials>("credentials", opensearch_config_request.credentials, serializeOpensearch_config_request_credentials);
        writer.writeStringValue("endpoint", opensearch_config_request.endpoint);
        writer.writeStringValue("index_name", opensearch_config_request.indexName);
        writer.writeNumberValue("retention_days", opensearch_config_request.retentionDays);
        writer.writeAdditionalData(opensearch_config_request.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOpensearch_config_request_credentials(writer: SerializationWriter, opensearch_config_request_credentials: Partial<Opensearch_config_request_credentials> | undefined | null = {}) : void {
    if (opensearch_config_request_credentials) {
        writer.writeStringValue("password", opensearch_config_request_credentials.password);
        writer.writeStringValue("username", opensearch_config_request_credentials.username);
        writer.writeAdditionalData(opensearch_config_request_credentials.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOpensearch_connection(writer: SerializationWriter, opensearch_connection: Partial<Opensearch_connection> | undefined | null = {}) : void {
    if (opensearch_connection) {
        writer.writeAdditionalData(opensearch_connection.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOpensearch_index(writer: SerializationWriter, opensearch_index: Partial<Opensearch_index> | undefined | null = {}) : void {
    if (opensearch_index) {
        serializeOpensearch_index_base(writer, opensearch_index)
        writer.writeEnumValue<Opensearch_index_health>("health", opensearch_index.health);
        writer.writeEnumValue<Opensearch_index_status>("status", opensearch_index.status);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOpensearch_index_base(writer: SerializationWriter, opensearch_index_base: Partial<Opensearch_index_base> | undefined | null = {}) : void {
    if (opensearch_index_base) {
        writer.writeDateValue("created_time", opensearch_index_base.createdTime);
        writer.writeStringValue("index_name", opensearch_index_base.indexName);
        writer.writeNumberValue("number_of_replicas", opensearch_index_base.numberOfReplicas);
        writer.writeNumberValue("number_of_shards", opensearch_index_base.numberOfShards);
        writer.writeNumberValue("size", opensearch_index_base.size);
        writer.writeAdditionalData(opensearch_index_base.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOpensearch_logsink(writer: SerializationWriter, opensearch_logsink: Partial<Opensearch_logsink> | undefined | null = {}) : void {
    if (opensearch_logsink) {
        writer.writeStringValue("ca", opensearch_logsink.ca);
        writer.writeNumberValue("index_days_max", opensearch_logsink.indexDaysMax);
        writer.writeStringValue("index_prefix", opensearch_logsink.indexPrefix);
        writer.writeNumberValue("timeout", opensearch_logsink.timeout);
        writer.writeStringValue("url", opensearch_logsink.url);
        writer.writeAdditionalData(opensearch_logsink.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOptions(writer: SerializationWriter, options: Partial<Options> | undefined | null = {}) : void {
    if (options) {
        writer.writeObjectValue<Options_options>("options", options.options, serializeOptions_options);
        writer.writeObjectValue<Options_version_availability>("version_availability", options.versionAvailability, serializeOptions_version_availability);
        writer.writeAdditionalData(options.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOptions_options(writer: SerializationWriter, options_options: Partial<Options_options> | undefined | null = {}) : void {
    if (options_options) {
        writer.writeObjectValue<Options_options_kafka>("kafka", options_options.kafka, serializeOptions_options_kafka);
        writer.writeObjectValue<Options_options_mongodb>("mongodb", options_options.mongodb, serializeOptions_options_mongodb);
        writer.writeObjectValue<Options_options_mysql>("mysql", options_options.mysql, serializeOptions_options_mysql);
        writer.writeObjectValue<Options_options_opensearch>("opensearch", options_options.opensearch, serializeOptions_options_opensearch);
        writer.writeObjectValue<Options_options_pg>("pg", options_options.pg, serializeOptions_options_pg);
        writer.writeObjectValue<Options_options_redis>("redis", options_options.redis, serializeOptions_options_redis);
        writer.writeAdditionalData(options_options.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOptions_options_kafka(writer: SerializationWriter, options_options_kafka: Partial<Options_options_kafka> | undefined | null = {}) : void {
    if (options_options_kafka) {
        writer.writeAdditionalData(options_options_kafka.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOptions_options_mongodb(writer: SerializationWriter, options_options_mongodb: Partial<Options_options_mongodb> | undefined | null = {}) : void {
    if (options_options_mongodb) {
        writer.writeAdditionalData(options_options_mongodb.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOptions_options_mysql(writer: SerializationWriter, options_options_mysql: Partial<Options_options_mysql> | undefined | null = {}) : void {
    if (options_options_mysql) {
        writer.writeAdditionalData(options_options_mysql.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOptions_options_opensearch(writer: SerializationWriter, options_options_opensearch: Partial<Options_options_opensearch> | undefined | null = {}) : void {
    if (options_options_opensearch) {
        writer.writeAdditionalData(options_options_opensearch.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOptions_options_pg(writer: SerializationWriter, options_options_pg: Partial<Options_options_pg> | undefined | null = {}) : void {
    if (options_options_pg) {
        writer.writeAdditionalData(options_options_pg.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOptions_options_redis(writer: SerializationWriter, options_options_redis: Partial<Options_options_redis> | undefined | null = {}) : void {
    if (options_options_redis) {
        writer.writeAdditionalData(options_options_redis.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeOptions_version_availability(writer: SerializationWriter, options_version_availability: Partial<Options_version_availability> | undefined | null = {}) : void {
    if (options_version_availability) {
        writer.writeCollectionOfObjectValues<Database_version_availability>("kafka", options_version_availability.kafka, serializeDatabase_version_availability);
        writer.writeCollectionOfObjectValues<Database_version_availability>("mongodb", options_version_availability.mongodb, serializeDatabase_version_availability);
        writer.writeCollectionOfObjectValues<Database_version_availability>("mysql", options_version_availability.mysql, serializeDatabase_version_availability);
        writer.writeCollectionOfObjectValues<Database_version_availability>("opensearch", options_version_availability.opensearch, serializeDatabase_version_availability);
        writer.writeCollectionOfObjectValues<Database_version_availability>("pg", options_version_availability.pg, serializeDatabase_version_availability);
        writer.writeCollectionOfObjectValues<Database_version_availability>("redis", options_version_availability.redis, serializeDatabase_version_availability);
        writer.writeAdditionalData(options_version_availability.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializePage_links(writer: SerializationWriter, page_links: Partial<Page_links> | undefined | null = {}) : void {
    if (page_links) {
        writer.writeObjectValue<Backward_links | Forward_links | Page_links_pagesMember1>("pages", page_links.pages, serializePage_links_pages);
        writer.writeAdditionalData(page_links.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializePage_links_pages(writer: SerializationWriter, page_links_pages: Partial<Backward_links | Forward_links | Page_links_pagesMember1> | undefined | null = {}) : void {
    serializeBackward_links(writer, page_links_pages as Backward_links);
    serializeForward_links(writer, page_links_pages as Forward_links);
    serializePage_links_pagesMember1(writer, page_links_pages as Page_links_pagesMember1);
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializePage_links_pagesMember1(writer: SerializationWriter, page_links_pagesMember1: Partial<Page_links_pagesMember1> | undefined | null = {}) : void {
    if (page_links_pagesMember1) {
        writer.writeAdditionalData(page_links_pagesMember1.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializePgbouncer_advanced_config(writer: SerializationWriter, pgbouncer_advanced_config: Partial<Pgbouncer_advanced_config> | undefined | null = {}) : void {
    if (pgbouncer_advanced_config) {
        writer.writeNumberValue("autodb_idle_timeout", pgbouncer_advanced_config.autodbIdleTimeout);
        writer.writeNumberValue("autodb_max_db_connections", pgbouncer_advanced_config.autodbMaxDbConnections);
        writer.writeEnumValue<Pgbouncer_advanced_config_autodb_pool_mode>("autodb_pool_mode", pgbouncer_advanced_config.autodbPoolMode);
        writer.writeNumberValue("autodb_pool_size", pgbouncer_advanced_config.autodbPoolSize);
        if(pgbouncer_advanced_config.ignoreStartupParameters)
        writer.writeCollectionOfEnumValues<Pgbouncer_advanced_config_ignore_startup_parameters>("ignore_startup_parameters", pgbouncer_advanced_config.ignoreStartupParameters);
        writer.writeNumberValue("min_pool_size", pgbouncer_advanced_config.minPoolSize);
        writer.writeNumberValue("server_idle_timeout", pgbouncer_advanced_config.serverIdleTimeout);
        writer.writeNumberValue("server_lifetime", pgbouncer_advanced_config.serverLifetime);
        writer.writeBooleanValue("server_reset_query_always", pgbouncer_advanced_config.serverResetQueryAlways);
        writer.writeAdditionalData(pgbouncer_advanced_config.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializePostgres_advanced_config(writer: SerializationWriter, postgres_advanced_config: Partial<Postgres_advanced_config> | undefined | null = {}) : void {
    if (postgres_advanced_config) {
        writer.writeNumberValue("autovacuum_analyze_scale_factor", postgres_advanced_config.autovacuumAnalyzeScaleFactor);
        writer.writeNumberValue("autovacuum_analyze_threshold", postgres_advanced_config.autovacuumAnalyzeThreshold);
        writer.writeNumberValue("autovacuum_freeze_max_age", postgres_advanced_config.autovacuumFreezeMaxAge);
        writer.writeNumberValue("autovacuum_max_workers", postgres_advanced_config.autovacuumMaxWorkers);
        writer.writeNumberValue("autovacuum_naptime", postgres_advanced_config.autovacuumNaptime);
        writer.writeNumberValue("autovacuum_vacuum_cost_delay", postgres_advanced_config.autovacuumVacuumCostDelay);
        writer.writeNumberValue("autovacuum_vacuum_cost_limit", postgres_advanced_config.autovacuumVacuumCostLimit);
        writer.writeNumberValue("autovacuum_vacuum_scale_factor", postgres_advanced_config.autovacuumVacuumScaleFactor);
        writer.writeNumberValue("autovacuum_vacuum_threshold", postgres_advanced_config.autovacuumVacuumThreshold);
        writer.writeNumberValue("backup_hour", postgres_advanced_config.backupHour);
        writer.writeNumberValue("backup_minute", postgres_advanced_config.backupMinute);
        writer.writeNumberValue("bgwriter_delay", postgres_advanced_config.bgwriterDelay);
        writer.writeNumberValue("bgwriter_flush_after", postgres_advanced_config.bgwriterFlushAfter);
        writer.writeNumberValue("bgwriter_lru_maxpages", postgres_advanced_config.bgwriterLruMaxpages);
        writer.writeNumberValue("bgwriter_lru_multiplier", postgres_advanced_config.bgwriterLruMultiplier);
        writer.writeNumberValue("deadlock_timeout", postgres_advanced_config.deadlockTimeout);
        writer.writeEnumValue<Postgres_advanced_config_default_toast_compression>("default_toast_compression", postgres_advanced_config.defaultToastCompression);
        writer.writeNumberValue("idle_in_transaction_session_timeout", postgres_advanced_config.idleInTransactionSessionTimeout);
        writer.writeBooleanValue("jit", postgres_advanced_config.jit);
        writer.writeNumberValue("log_autovacuum_min_duration", postgres_advanced_config.logAutovacuumMinDuration);
        writer.writeEnumValue<Postgres_advanced_config_log_error_verbosity>("log_error_verbosity", postgres_advanced_config.logErrorVerbosity);
        writer.writeEnumValue<Postgres_advanced_config_log_line_prefix>("log_line_prefix", postgres_advanced_config.logLinePrefix);
        writer.writeNumberValue("log_min_duration_statement", postgres_advanced_config.logMinDurationStatement);
        writer.writeNumberValue("max_failover_replication_time_lag", postgres_advanced_config.maxFailoverReplicationTimeLag);
        writer.writeNumberValue("max_files_per_process", postgres_advanced_config.maxFilesPerProcess);
        writer.writeNumberValue("max_locks_per_transaction", postgres_advanced_config.maxLocksPerTransaction);
        writer.writeNumberValue("max_logical_replication_workers", postgres_advanced_config.maxLogicalReplicationWorkers);
        writer.writeNumberValue("max_parallel_workers", postgres_advanced_config.maxParallelWorkers);
        writer.writeNumberValue("max_parallel_workers_per_gather", postgres_advanced_config.maxParallelWorkersPerGather);
        writer.writeNumberValue("max_pred_locks_per_transaction", postgres_advanced_config.maxPredLocksPerTransaction);
        writer.writeNumberValue("max_prepared_transactions", postgres_advanced_config.maxPreparedTransactions);
        writer.writeNumberValue("max_replication_slots", postgres_advanced_config.maxReplicationSlots);
        writer.writeNumberValue("max_stack_depth", postgres_advanced_config.maxStackDepth);
        writer.writeNumberValue("max_standby_archive_delay", postgres_advanced_config.maxStandbyArchiveDelay);
        writer.writeNumberValue("max_standby_streaming_delay", postgres_advanced_config.maxStandbyStreamingDelay);
        writer.writeNumberValue("max_wal_senders", postgres_advanced_config.maxWalSenders);
        writer.writeNumberValue("max_worker_processes", postgres_advanced_config.maxWorkerProcesses);
        writer.writeObjectValue<Pgbouncer_advanced_config>("pgbouncer", postgres_advanced_config.pgbouncer, serializePgbouncer_advanced_config);
        writer.writeNumberValue("pg_partman_bgw.interval", postgres_advanced_config.pgPartmanBgwInterval);
        writer.writeStringValue("pg_partman_bgw.role", postgres_advanced_config.pgPartmanBgwRole);
        writer.writeEnumValue<Postgres_advanced_config_pg_stat_statementsTrack>("pg_stat_statements.track", postgres_advanced_config.pgStatStatementsTrack);
        writer.writeNumberValue("shared_buffers_percentage", postgres_advanced_config.sharedBuffersPercentage);
        writer.writeBooleanValue("stat_monitor_enable", postgres_advanced_config.statMonitorEnable);
        writer.writeEnumValue<Postgres_advanced_config_synchronous_replication>("synchronous_replication", postgres_advanced_config.synchronousReplication);
        writer.writeNumberValue("temp_file_limit", postgres_advanced_config.tempFileLimit);
        writer.writeObjectValue<Timescaledb_advanced_config>("timescaledb", postgres_advanced_config.timescaledb, serializeTimescaledb_advanced_config);
        writer.writeStringValue("timezone", postgres_advanced_config.timezone);
        writer.writeNumberValue("track_activity_query_size", postgres_advanced_config.trackActivityQuerySize);
        writer.writeEnumValue<Postgres_advanced_config_track_commit_timestamp>("track_commit_timestamp", postgres_advanced_config.trackCommitTimestamp);
        writer.writeEnumValue<Postgres_advanced_config_track_functions>("track_functions", postgres_advanced_config.trackFunctions);
        writer.writeEnumValue<Postgres_advanced_config_track_io_timing>("track_io_timing", postgres_advanced_config.trackIoTiming);
        writer.writeNumberValue("wal_sender_timeout", postgres_advanced_config.walSenderTimeout);
        writer.writeNumberValue("wal_writer_delay", postgres_advanced_config.walWriterDelay);
        writer.writeNumberValue("work_mem", postgres_advanced_config.workMem);
        writer.writeAdditionalData(postgres_advanced_config.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializePrevious_outage(writer: SerializationWriter, previous_outage: Partial<Previous_outage> | undefined | null = {}) : void {
    if (previous_outage) {
        writer.writeNumberValue("duration_seconds", previous_outage.durationSeconds);
        writer.writeStringValue("ended_at", previous_outage.endedAt);
        writer.writeStringValue("region", previous_outage.region);
        writer.writeStringValue("started_at", previous_outage.startedAt);
        writer.writeAdditionalData(previous_outage.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeProduct_charge_item(writer: SerializationWriter, product_charge_item: Partial<Product_charge_item> | undefined | null = {}) : void {
    if (product_charge_item) {
        writer.writeStringValue("amount", product_charge_item.amount);
        writer.writeStringValue("count", product_charge_item.count);
        writer.writeStringValue("name", product_charge_item.name);
        writer.writeAdditionalData(product_charge_item.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeProduct_usage_charges(writer: SerializationWriter, product_usage_charges: Partial<Product_usage_charges> | undefined | null = {}) : void {
    if (product_usage_charges) {
        writer.writeStringValue("amount", product_usage_charges.amount);
        writer.writeCollectionOfObjectValues<Product_charge_item>("items", product_usage_charges.items, serializeProduct_charge_item);
        writer.writeStringValue("name", product_usage_charges.name);
        writer.writeAdditionalData(product_usage_charges.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeProject(writer: SerializationWriter, project: Partial<Project> | undefined | null = {}) : void {
    if (project) {
        serializeProject_base(writer, project)
        writer.writeBooleanValue("is_default", project.isDefault);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeProject_assignment(writer: SerializationWriter, project_assignment: Partial<Project_assignment> | undefined | null = {}) : void {
    if (project_assignment) {
        writer.writeCollectionOfPrimitiveValues<string>("resources", project_assignment.resources);
        writer.writeAdditionalData(project_assignment.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeProject_base(writer: SerializationWriter, project_base: Partial<Project_base> | undefined | null = {}) : void {
    if (project_base) {
        writer.writeStringValue("description", project_base.description);
        writer.writeEnumValue<Project_base_environment>("environment", project_base.environment);
        writer.writeStringValue("name", project_base.name);
        writer.writeStringValue("purpose", project_base.purpose);
        writer.writeAdditionalData(project_base.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializePurge_cache(writer: SerializationWriter, purge_cache: Partial<Purge_cache> | undefined | null = {}) : void {
    if (purge_cache) {
        writer.writeCollectionOfPrimitiveValues<string>("files", purge_cache.files);
        writer.writeAdditionalData(purge_cache.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeRedis_advanced_config(writer: SerializationWriter, redis_advanced_config: Partial<Redis_advanced_config> | undefined | null = {}) : void {
    if (redis_advanced_config) {
        writer.writeEnumValue<Redis_advanced_config_redis_acl_channels_default>("redis_acl_channels_default", redis_advanced_config.redisAclChannelsDefault);
        writer.writeNumberValue("redis_io_threads", redis_advanced_config.redisIoThreads);
        writer.writeNumberValue("redis_lfu_decay_time", redis_advanced_config.redisLfuDecayTime);
        writer.writeNumberValue("redis_lfu_log_factor", redis_advanced_config.redisLfuLogFactor);
        writer.writeEnumValue<Redis_advanced_config_redis_maxmemory_policy>("redis_maxmemory_policy", redis_advanced_config.redisMaxmemoryPolicy);
        writer.writeStringValue("redis_notify_keyspace_events", redis_advanced_config.redisNotifyKeyspaceEvents);
        writer.writeNumberValue("redis_number_of_databases", redis_advanced_config.redisNumberOfDatabases);
        writer.writeEnumValue<Redis_advanced_config_redis_persistence>("redis_persistence", redis_advanced_config.redisPersistence);
        writer.writeNumberValue("redis_pubsub_client_output_buffer_limit", redis_advanced_config.redisPubsubClientOutputBufferLimit);
        writer.writeBooleanValue("redis_ssl", redis_advanced_config.redisSsl);
        writer.writeNumberValue("redis_timeout", redis_advanced_config.redisTimeout);
        writer.writeAdditionalData(redis_advanced_config.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeRegion(writer: SerializationWriter, region: Partial<Region> | undefined | null = {}) : void {
    if (region) {
        writer.writeBooleanValue("available", region.available);
        writer.writeObjectValue("features", region.features);
        writer.writeStringValue("name", region.name);
        writer.writeObjectValue("sizes", region.sizes);
        writer.writeStringValue("slug", region.slug);
        writer.writeAdditionalData(region.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeRegion_state(writer: SerializationWriter, region_state: Partial<Region_state> | undefined | null = {}) : void {
    if (region_state) {
        writer.writeEnumValue<Region_state_status>("status", region_state.status);
        writer.writeStringValue("status_changed_at", region_state.statusChangedAt);
        writer.writeNumberValue("thirty_day_uptime_percentage", region_state.thirtyDayUptimePercentage);
        writer.writeAdditionalData(region_state.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeRegional_state(writer: SerializationWriter, regional_state: Partial<Regional_state> | undefined | null = {}) : void {
    if (regional_state) {
        writer.writeObjectValue<Region_state>("eu_west", regional_state.euWest, serializeRegion_state);
        writer.writeObjectValue<Region_state>("us_east", regional_state.usEast, serializeRegion_state);
        writer.writeAdditionalData(regional_state.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeRegistry(writer: SerializationWriter, registry: Partial<Registry> | undefined | null = {}) : void {
    if (registry) {
        writer.writeStringValue("name", registry.name);
        writer.writeStringValue("region", registry.region);
        writer.writeObjectValue<Subscription>("subscription", registry.subscription, serializeSubscription);
        writer.writeAdditionalData(registry.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeRegistry_create(writer: SerializationWriter, registry_create: Partial<Registry_create> | undefined | null = {}) : void {
    if (registry_create) {
        writer.writeStringValue("name", registry_create.name);
        writer.writeEnumValue<Registry_create_region>("region", registry_create.region);
        writer.writeEnumValue<Registry_create_subscription_tier_slug>("subscription_tier_slug", registry_create.subscriptionTierSlug);
        writer.writeAdditionalData(registry_create.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeRepository(writer: SerializationWriter, repository: Partial<Repository> | undefined | null = {}) : void {
    if (repository) {
        writer.writeObjectValue<Repository_tag>("latest_tag", repository.latestTag, serializeRepository_tag);
        writer.writeStringValue("name", repository.name);
        writer.writeStringValue("registry_name", repository.registryName);
        writer.writeNumberValue("tag_count", repository.tagCount);
        writer.writeAdditionalData(repository.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeRepository_blob(writer: SerializationWriter, repository_blob: Partial<Repository_blob> | undefined | null = {}) : void {
    if (repository_blob) {
        writer.writeNumberValue("compressed_size_bytes", repository_blob.compressedSizeBytes);
        writer.writeStringValue("digest", repository_blob.digest);
        writer.writeAdditionalData(repository_blob.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeRepository_manifest(writer: SerializationWriter, repository_manifest: Partial<Repository_manifest> | undefined | null = {}) : void {
    if (repository_manifest) {
        writer.writeCollectionOfObjectValues<Repository_blob>("blobs", repository_manifest.blobs, serializeRepository_blob);
        writer.writeNumberValue("compressed_size_bytes", repository_manifest.compressedSizeBytes);
        writer.writeStringValue("digest", repository_manifest.digest);
        writer.writeStringValue("registry_name", repository_manifest.registryName);
        writer.writeStringValue("repository", repository_manifest.repository);
        writer.writeNumberValue("size_bytes", repository_manifest.sizeBytes);
        writer.writeCollectionOfPrimitiveValues<string>("tags", repository_manifest.tags);
        writer.writeDateValue("updated_at", repository_manifest.updatedAt);
        writer.writeAdditionalData(repository_manifest.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeRepository_tag(writer: SerializationWriter, repository_tag: Partial<Repository_tag> | undefined | null = {}) : void {
    if (repository_tag) {
        writer.writeNumberValue("compressed_size_bytes", repository_tag.compressedSizeBytes);
        writer.writeStringValue("manifest_digest", repository_tag.manifestDigest);
        writer.writeStringValue("registry_name", repository_tag.registryName);
        writer.writeStringValue("repository", repository_tag.repository);
        writer.writeNumberValue("size_bytes", repository_tag.sizeBytes);
        writer.writeStringValue("tag", repository_tag.tag);
        writer.writeDateValue("updated_at", repository_tag.updatedAt);
        writer.writeAdditionalData(repository_tag.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeRepository_v2(writer: SerializationWriter, repository_v2: Partial<Repository_v2> | undefined | null = {}) : void {
    if (repository_v2) {
        writer.writeObjectValue<Repository_manifest>("latest_manifest", repository_v2.latestManifest, serializeRepository_manifest);
        writer.writeNumberValue("manifest_count", repository_v2.manifestCount);
        writer.writeStringValue("name", repository_v2.name);
        writer.writeStringValue("registry_name", repository_v2.registryName);
        writer.writeNumberValue("tag_count", repository_v2.tagCount);
        writer.writeAdditionalData(repository_v2.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeReserved_ip(writer: SerializationWriter, reserved_ip: Partial<Reserved_ip> | undefined | null = {}) : void {
    if (reserved_ip) {
        writer.writeObjectValue<Droplet>("droplet", reserved_ip.droplet, serializeDroplet);
        writer.writeStringValue("ip", reserved_ip.ip);
        writer.writeBooleanValue("locked", reserved_ip.locked);
        writer.writeGuidValue("project_id", reserved_ip.projectId);
        writer.writeObjectValue<Region>("region", reserved_ip.region, serializeRegion);
        writer.writeAdditionalData(reserved_ip.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeReserved_ip_action_assign(writer: SerializationWriter, reserved_ip_action_assign: Partial<Reserved_ip_action_assign> | undefined | null = {}) : void {
    if (reserved_ip_action_assign) {
        serializeReserved_ip_action_type(writer, reserved_ip_action_assign)
        writer.writeNumberValue("droplet_id", reserved_ip_action_assign.dropletId);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeReserved_ip_action_type(writer: SerializationWriter, reserved_ip_action_type: Partial<Reserved_ip_action_type> | undefined | null = {}) : void {
    if (reserved_ip_action_type) {
        writer.writeEnumValue<Reserved_ip_action_type_type>("type", reserved_ip_action_type.type);
        writer.writeAdditionalData(reserved_ip_action_type.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeReserved_ip_action_unassign(writer: SerializationWriter, reserved_ip_action_unassign: Partial<Reserved_ip_action_unassign> | undefined | null = {}) : void {
    if (reserved_ip_action_unassign) {
        serializeReserved_ip_action_type(writer, reserved_ip_action_unassign)
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeReserved_ip_createMember1(writer: SerializationWriter, reserved_ip_createMember1: Partial<Reserved_ip_createMember1> | undefined | null = {}) : void {
    if (reserved_ip_createMember1) {
        writer.writeNumberValue("droplet_id", reserved_ip_createMember1.dropletId);
        writer.writeAdditionalData(reserved_ip_createMember1.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeReserved_ip_createMember2(writer: SerializationWriter, reserved_ip_createMember2: Partial<Reserved_ip_createMember2> | undefined | null = {}) : void {
    if (reserved_ip_createMember2) {
        writer.writeGuidValue("project_id", reserved_ip_createMember2.projectId);
        writer.writeStringValue("region", reserved_ip_createMember2.region);
        writer.writeAdditionalData(reserved_ip_createMember2.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeReserved_ipv6(writer: SerializationWriter, reserved_ipv6: Partial<Reserved_ipv6> | undefined | null = {}) : void {
    if (reserved_ipv6) {
        writer.writeObjectValue<Droplet>("droplet", reserved_ipv6.droplet, serializeDroplet);
        writer.writeStringValue("ip", reserved_ipv6.ip);
        writer.writeStringValue("region_slug", reserved_ipv6.regionSlug);
        writer.writeDateValue("reserved_at", reserved_ipv6.reservedAt);
        writer.writeAdditionalData(reserved_ipv6.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeReserved_ipv6_action_assign(writer: SerializationWriter, reserved_ipv6_action_assign: Partial<Reserved_ipv6_action_assign> | undefined | null = {}) : void {
    if (reserved_ipv6_action_assign) {
        serializeReserved_ipv6_action_type(writer, reserved_ipv6_action_assign)
        writer.writeNumberValue("droplet_id", reserved_ipv6_action_assign.dropletId);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeReserved_ipv6_action_type(writer: SerializationWriter, reserved_ipv6_action_type: Partial<Reserved_ipv6_action_type> | undefined | null = {}) : void {
    if (reserved_ipv6_action_type) {
        writer.writeEnumValue<Reserved_ipv6_action_type_type>("type", reserved_ipv6_action_type.type);
        writer.writeAdditionalData(reserved_ipv6_action_type.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeReserved_ipv6_action_unassign(writer: SerializationWriter, reserved_ipv6_action_unassign: Partial<Reserved_ipv6_action_unassign> | undefined | null = {}) : void {
    if (reserved_ipv6_action_unassign) {
        serializeReserved_ipv6_action_type(writer, reserved_ipv6_action_unassign)
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeReserved_ipv6_create(writer: SerializationWriter, reserved_ipv6_create: Partial<Reserved_ipv6_create> | undefined | null = {}) : void {
    if (reserved_ipv6_create) {
        writer.writeStringValue("region_slug", reserved_ipv6_create.regionSlug);
        writer.writeAdditionalData(reserved_ipv6_create.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeResource(writer: SerializationWriter, resource: Partial<Resource> | undefined | null = {}) : void {
    if (resource) {
        writer.writeDateValue("assigned_at", resource.assignedAt);
        writer.writeObjectValue<Resource_links>("links", resource.links, serializeResource_links);
        writer.writeEnumValue<Resource_status>("status", resource.status);
        writer.writeStringValue("urn", resource.urn);
        writer.writeAdditionalData(resource.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeResource_links(writer: SerializationWriter, resource_links: Partial<Resource_links> | undefined | null = {}) : void {
    if (resource_links) {
        writer.writeStringValue("self", resource_links.self);
        writer.writeAdditionalData(resource_links.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeRouting_agent(writer: SerializationWriter, routing_agent: Partial<Routing_agent> | undefined | null = {}) : void {
    if (routing_agent) {
        writer.writeBooleanValue("enabled", routing_agent.enabled);
        writer.writeAdditionalData(routing_agent.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeRsyslog_logsink(writer: SerializationWriter, rsyslog_logsink: Partial<Rsyslog_logsink> | undefined | null = {}) : void {
    if (rsyslog_logsink) {
        writer.writeStringValue("ca", rsyslog_logsink.ca);
        writer.writeStringValue("cert", rsyslog_logsink.cert);
        writer.writeEnumValue<Rsyslog_logsink_format>("format", rsyslog_logsink.format);
        writer.writeStringValue("key", rsyslog_logsink.key);
        writer.writeStringValue("logline", rsyslog_logsink.logline);
        writer.writeNumberValue("port", rsyslog_logsink.port);
        writer.writeStringValue("sd", rsyslog_logsink.sd);
        writer.writeStringValue("server", rsyslog_logsink.server);
        writer.writeBooleanValue("tls", rsyslog_logsink.tls);
        writer.writeAdditionalData(rsyslog_logsink.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeScheduled_details(writer: SerializationWriter, scheduled_details: Partial<Scheduled_details> | undefined | null = {}) : void {
    if (scheduled_details) {
        writer.writeObjectValue<Scheduled_details_body>("body", scheduled_details.body, serializeScheduled_details_body);
        writer.writeStringValue("cron", scheduled_details.cron);
        writer.writeAdditionalData(scheduled_details.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeScheduled_details_body(writer: SerializationWriter, scheduled_details_body: Partial<Scheduled_details_body> | undefined | null = {}) : void {
    if (scheduled_details_body) {
        writer.writeStringValue("name", scheduled_details_body.name);
        writer.writeAdditionalData(scheduled_details_body.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeSelective_destroy_associated_resource(writer: SerializationWriter, selective_destroy_associated_resource: Partial<Selective_destroy_associated_resource> | undefined | null = {}) : void {
    if (selective_destroy_associated_resource) {
        writer.writeCollectionOfPrimitiveValues<string>("floating_ips", selective_destroy_associated_resource.floatingIps);
        writer.writeCollectionOfPrimitiveValues<string>("reserved_ips", selective_destroy_associated_resource.reservedIps);
        writer.writeCollectionOfPrimitiveValues<string>("snapshots", selective_destroy_associated_resource.snapshots);
        writer.writeCollectionOfPrimitiveValues<string>("volumes", selective_destroy_associated_resource.volumes);
        writer.writeCollectionOfPrimitiveValues<string>("volume_snapshots", selective_destroy_associated_resource.volumeSnapshots);
        writer.writeAdditionalData(selective_destroy_associated_resource.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeSimple_charge(writer: SerializationWriter, simple_charge: Partial<Simple_charge> | undefined | null = {}) : void {
    if (simple_charge) {
        writer.writeStringValue("amount", simple_charge.amount);
        writer.writeStringValue("name", simple_charge.name);
        writer.writeAdditionalData(simple_charge.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeSink_resource(writer: SerializationWriter, sink_resource: Partial<Sink_resource> | undefined | null = {}) : void {
    if (sink_resource) {
        writer.writeStringValue("name", sink_resource.name);
        writer.writeStringValue("urn", sink_resource.urn);
        writer.writeAdditionalData(sink_resource.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeSinks_response(writer: SerializationWriter, sinks_response: Partial<Sinks_response> | undefined | null = {}) : void {
    if (sinks_response) {
        writer.writeObjectValue<Destination>("destination", sinks_response.destination, serializeDestination);
        writer.writeCollectionOfObjectValues<Sink_resource>("resources", sinks_response.resources, serializeSink_resource);
        writer.writeAdditionalData(sinks_response.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeSize(writer: SerializationWriter, size: Partial<Size> | undefined | null = {}) : void {
    if (size) {
        writer.writeBooleanValue("available", size.available);
        writer.writeStringValue("description", size.description);
        writer.writeNumberValue("disk", size.disk);
        writer.writeCollectionOfObjectValues<Disk_info>("disk_info", size.diskInfo, serializeDisk_info);
        writer.writeObjectValue<Gpu_info>("gpu_info", size.gpuInfo, serializeGpu_info);
        writer.writeNumberValue("memory", size.memory);
        writer.writeNumberValue("price_hourly", size.priceHourly);
        writer.writeNumberValue("price_monthly", size.priceMonthly);
        writer.writeCollectionOfPrimitiveValues<string>("regions", size.regions);
        writer.writeStringValue("slug", size.slug);
        writer.writeNumberValue("transfer", size.transfer);
        writer.writeNumberValue("vcpus", size.vcpus);
        writer.writeAdditionalData(size.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeSlack_details(writer: SerializationWriter, slack_details: Partial<Slack_details> | undefined | null = {}) : void {
    if (slack_details) {
        writer.writeStringValue("channel", slack_details.channel);
        writer.writeStringValue("url", slack_details.url);
        writer.writeAdditionalData(slack_details.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeSnapshots(writer: SerializationWriter, snapshots: Partial<Snapshots> | undefined | null = {}) : void {
    if (snapshots) {
        serializeSnapshots_base(writer, snapshots)
        writer.writeStringValue("id", snapshots.id);
        writer.writeStringValue("resource_id", snapshots.resourceId);
        writer.writeEnumValue<Snapshots_resource_type>("resource_type", snapshots.resourceType);
        writer.writeCollectionOfPrimitiveValues<string>("tags", snapshots.tags);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeSnapshots_base(writer: SerializationWriter, snapshots_base: Partial<Snapshots_base> | undefined | null = {}) : void {
    if (snapshots_base) {
        writer.writeDateValue("created_at", snapshots_base.createdAt);
        writer.writeNumberValue("min_disk_size", snapshots_base.minDiskSize);
        writer.writeStringValue("name", snapshots_base.name);
        writer.writeCollectionOfPrimitiveValues<string>("regions", snapshots_base.regions);
        writer.writeNumberValue("size_gigabytes", snapshots_base.sizeGigabytes);
        writer.writeAdditionalData(snapshots_base.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeSource_database(writer: SerializationWriter, source_database: Partial<Source_database> | undefined | null = {}) : void {
    if (source_database) {
        writer.writeBooleanValue("disable_ssl", source_database.disableSsl);
        writer.writeCollectionOfPrimitiveValues<string>("ignore_dbs", source_database.ignoreDbs);
        writer.writeObjectValue<Source_database_source>("source", source_database.source, serializeSource_database_source);
        writer.writeAdditionalData(source_database.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeSource_database_source(writer: SerializationWriter, source_database_source: Partial<Source_database_source> | undefined | null = {}) : void {
    if (source_database_source) {
        writer.writeStringValue("dbname", source_database_source.dbname);
        writer.writeStringValue("host", source_database_source.host);
        writer.writeStringValue("password", source_database_source.password);
        writer.writeNumberValue("port", source_database_source.port);
        writer.writeStringValue("username", source_database_source.username);
        writer.writeAdditionalData(source_database_source.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeSql_mode(writer: SerializationWriter, sql_mode: Partial<Sql_mode> | undefined | null = {}) : void {
    if (sql_mode) {
        writer.writeStringValue("sql_mode", sql_mode.sqlMode);
        writer.writeAdditionalData(sql_mode.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeSshKeys(writer: SerializationWriter, sshKeys: Partial<SshKeys> | undefined | null = {}) : void {
    if (sshKeys) {
        writer.writeStringValue("name", sshKeys.name);
        writer.writeStringValue("public_key", sshKeys.publicKey);
        writer.writeAdditionalData(sshKeys.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeState(writer: SerializationWriter, state: Partial<State> | undefined | null = {}) : void {
    if (state) {
        writer.writeObjectValue<Previous_outage>("previous_outage", state.previousOutage, serializePrevious_outage);
        writer.writeObjectValue<Regional_state>("regions", state.regions, serializeRegional_state);
        writer.writeAdditionalData(state.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeSticky_sessions(writer: SerializationWriter, sticky_sessions: Partial<Sticky_sessions> | undefined | null = {}) : void {
    if (sticky_sessions) {
        writer.writeStringValue("cookie_name", sticky_sessions.cookieName);
        writer.writeNumberValue("cookie_ttl_seconds", sticky_sessions.cookieTtlSeconds);
        writer.writeEnumValue<Sticky_sessions_type>("type", sticky_sessions.type ?? Sticky_sessions_typeObject.None);
        writer.writeAdditionalData(sticky_sessions.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeSubscription(writer: SerializationWriter, subscription: Partial<Subscription> | undefined | null = {}) : void {
    if (subscription) {
        writer.writeObjectValue<Subscription_tier_base>("tier", subscription.tier, serializeSubscription_tier_base);
        writer.writeAdditionalData(subscription.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeSubscription_tier_base(writer: SerializationWriter, subscription_tier_base: Partial<Subscription_tier_base> | undefined | null = {}) : void {
    if (subscription_tier_base) {
        writer.writeBooleanValue("allow_storage_overage", subscription_tier_base.allowStorageOverage);
        writer.writeNumberValue("included_bandwidth_bytes", subscription_tier_base.includedBandwidthBytes);
        writer.writeNumberValue("included_repositories", subscription_tier_base.includedRepositories);
        writer.writeNumberValue("included_storage_bytes", subscription_tier_base.includedStorageBytes);
        writer.writeNumberValue("monthly_price_in_cents", subscription_tier_base.monthlyPriceInCents);
        writer.writeStringValue("name", subscription_tier_base.name);
        writer.writeStringValue("slug", subscription_tier_base.slug);
        writer.writeNumberValue("storage_overage_price_in_cents", subscription_tier_base.storageOveragePriceInCents);
        writer.writeAdditionalData(subscription_tier_base.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeSupported_droplet_backup_policy(writer: SerializationWriter, supported_droplet_backup_policy: Partial<Supported_droplet_backup_policy> | undefined | null = {}) : void {
    if (supported_droplet_backup_policy) {
        writer.writeStringValue("name", supported_droplet_backup_policy.name);
        writer.writeCollectionOfPrimitiveValues<string>("possible_days", supported_droplet_backup_policy.possibleDays);
        writer.writeCollectionOfPrimitiveValues<number>("possible_window_starts", supported_droplet_backup_policy.possibleWindowStarts);
        writer.writeNumberValue("retention_period_days", supported_droplet_backup_policy.retentionPeriodDays);
        writer.writeNumberValue("window_length_hours", supported_droplet_backup_policy.windowLengthHours);
        writer.writeAdditionalData(supported_droplet_backup_policy.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeTags(writer: SerializationWriter, tags: Partial<Tags> | undefined | null = {}) : void {
    if (tags) {
        writer.writeStringValue("name", tags.name);
        writer.writeAdditionalData(tags.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeTags_metadata(writer: SerializationWriter, tags_metadata: Partial<Tags_metadata> | undefined | null = {}) : void {
    if (tags_metadata) {
        writer.writeNumberValue("count", tags_metadata.count);
        writer.writeStringValue("last_tagged_uri", tags_metadata.lastTaggedUri);
        writer.writeAdditionalData(tags_metadata.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeTags_resource(writer: SerializationWriter, tags_resource: Partial<Tags_resource> | undefined | null = {}) : void {
    if (tags_resource) {
        writer.writeCollectionOfObjectValues<Tags_resource_resources>("resources", tags_resource.resources, serializeTags_resource_resources);
        writer.writeAdditionalData(tags_resource.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeTags_resource_resources(writer: SerializationWriter, tags_resource_resources: Partial<Tags_resource_resources> | undefined | null = {}) : void {
    if (tags_resource_resources) {
        writer.writeStringValue("resource_id", tags_resource_resources.resourceId);
        writer.writeEnumValue<Tags_resource_resources_resource_type>("resource_type", tags_resource_resources.resourceType);
        writer.writeAdditionalData(tags_resource_resources.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeTags_resources(writer: SerializationWriter, tags_resources: Partial<Tags_resources> | undefined | null = {}) : void {
    if (tags_resources) {
        serializeTags_metadata(writer, tags_resources)
        writer.writeObjectValue<Tags_metadata>("databases", tags_resources.databases, serializeTags_metadata);
        writer.writeObjectValue<Tags_metadata>("droplets", tags_resources.droplets, serializeTags_metadata);
        writer.writeObjectValue<Tags_metadata>("imgages", tags_resources.imgages, serializeTags_metadata);
        writer.writeObjectValue<Tags_metadata>("volumes", tags_resources.volumes, serializeTags_metadata);
        writer.writeObjectValue<Tags_metadata>("volume_snapshots", tags_resources.volumeSnapshots, serializeTags_metadata);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeTimescaledb_advanced_config(writer: SerializationWriter, timescaledb_advanced_config: Partial<Timescaledb_advanced_config> | undefined | null = {}) : void {
    if (timescaledb_advanced_config) {
        writer.writeNumberValue("max_background_workers", timescaledb_advanced_config.maxBackgroundWorkers);
        writer.writeAdditionalData(timescaledb_advanced_config.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeTrigger_info(writer: SerializationWriter, trigger_info: Partial<Trigger_info> | undefined | null = {}) : void {
    if (trigger_info) {
        writer.writeStringValue("created_at", trigger_info.createdAt);
        writer.writeStringValue("function", trigger_info.functionEscaped);
        writer.writeBooleanValue("is_enabled", trigger_info.isEnabled);
        writer.writeStringValue("name", trigger_info.name);
        writer.writeStringValue("namespace", trigger_info.namespace);
        writer.writeObjectValue<Scheduled_details>("scheduled_details", trigger_info.scheduledDetails, serializeScheduled_details);
        writer.writeObjectValue<Trigger_info_scheduled_runs>("scheduled_runs", trigger_info.scheduledRuns, serializeTrigger_info_scheduled_runs);
        writer.writeStringValue("type", trigger_info.type);
        writer.writeStringValue("updated_at", trigger_info.updatedAt);
        writer.writeAdditionalData(trigger_info.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeTrigger_info_scheduled_runs(writer: SerializationWriter, trigger_info_scheduled_runs: Partial<Trigger_info_scheduled_runs> | undefined | null = {}) : void {
    if (trigger_info_scheduled_runs) {
        writer.writeStringValue("last_run_at", trigger_info_scheduled_runs.lastRunAt);
        writer.writeStringValue("next_run_at", trigger_info_scheduled_runs.nextRunAt);
        writer.writeAdditionalData(trigger_info_scheduled_runs.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeUpdate_endpoint(writer: SerializationWriter, update_endpoint: Partial<Update_endpoint> | undefined | null = {}) : void {
    if (update_endpoint) {
        writer.writeGuidValue("certificate_id", update_endpoint.certificateId);
        writer.writeStringValue("custom_domain", update_endpoint.customDomain);
        writer.writeNumberValue("ttl", update_endpoint.ttl);
        writer.writeAdditionalData(update_endpoint.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeUpdate_registry(writer: SerializationWriter, update_registry: Partial<Update_registry> | undefined | null = {}) : void {
    if (update_registry) {
        writer.writeBooleanValue("cancel", update_registry.cancel);
        writer.writeAdditionalData(update_registry.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeUpdate_trigger(writer: SerializationWriter, update_trigger: Partial<Update_trigger> | undefined | null = {}) : void {
    if (update_trigger) {
        writer.writeBooleanValue("is_enabled", update_trigger.isEnabled);
        writer.writeObjectValue<Scheduled_details>("scheduled_details", update_trigger.scheduledDetails, serializeScheduled_details);
        writer.writeAdditionalData(update_trigger.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeUser(writer: SerializationWriter, user: Partial<User> | undefined | null = {}) : void {
    if (user) {
        writer.writeObjectValue<User_kubernetes_cluster_user>("kubernetes_cluster_user", user.kubernetesClusterUser, serializeUser_kubernetes_cluster_user);
        writer.writeAdditionalData(user.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeUser_kubernetes_cluster_user(writer: SerializationWriter, user_kubernetes_cluster_user: Partial<User_kubernetes_cluster_user> | undefined | null = {}) : void {
    if (user_kubernetes_cluster_user) {
        writer.writeCollectionOfPrimitiveValues<string>("groups", user_kubernetes_cluster_user.groups);
        writer.writeStringValue("username", user_kubernetes_cluster_user.username);
        writer.writeAdditionalData(user_kubernetes_cluster_user.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeUser_settings(writer: SerializationWriter, user_settings: Partial<User_settings> | undefined | null = {}) : void {
    if (user_settings) {
        writer.writeCollectionOfObjectValues<User_settings_acl>("acl", user_settings.acl, serializeUser_settings_acl);
        writer.writeCollectionOfObjectValues<User_settings_opensearch_acl>("opensearch_acl", user_settings.opensearchAcl, serializeUser_settings_opensearch_acl);
        writer.writeBooleanValue("pg_allow_replication", user_settings.pgAllowReplication);
        writer.writeAdditionalData(user_settings.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeUser_settings_acl(writer: SerializationWriter, user_settings_acl: Partial<User_settings_acl> | undefined | null = {}) : void {
    if (user_settings_acl) {
        writer.writeStringValue("id", user_settings_acl.id);
        writer.writeEnumValue<User_settings_acl_permission>("permission", user_settings_acl.permission);
        writer.writeStringValue("topic", user_settings_acl.topic);
        writer.writeAdditionalData(user_settings_acl.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeUser_settings_opensearch_acl(writer: SerializationWriter, user_settings_opensearch_acl: Partial<User_settings_opensearch_acl> | undefined | null = {}) : void {
    if (user_settings_opensearch_acl) {
        writer.writeStringValue("index", user_settings_opensearch_acl.index);
        writer.writeEnumValue<User_settings_opensearch_acl_permission>("permission", user_settings_opensearch_acl.permission);
        writer.writeAdditionalData(user_settings_opensearch_acl.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeValidate_registry(writer: SerializationWriter, validate_registry: Partial<Validate_registry> | undefined | null = {}) : void {
    if (validate_registry) {
        writer.writeStringValue("name", validate_registry.name);
        writer.writeAdditionalData(validate_registry.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeVersion2(writer: SerializationWriter, version2: Partial<Version2> | undefined | null = {}) : void {
    if (version2) {
        writer.writeStringValue("version", version2.version);
        writer.writeAdditionalData(version2.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeVolume_action_post_attach(writer: SerializationWriter, volume_action_post_attach: Partial<Volume_action_post_attach> | undefined | null = {}) : void {
    if (volume_action_post_attach) {
        serializeVolume_action_post_base(writer, volume_action_post_attach)
        writer.writeNumberValue("droplet_id", volume_action_post_attach.dropletId);
        writer.writeCollectionOfPrimitiveValues<string>("tags", volume_action_post_attach.tags);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeVolume_action_post_base(writer: SerializationWriter, volume_action_post_base: Partial<Volume_action_post_base> | undefined | null = {}) : void {
    if (volume_action_post_base) {
        writer.writeEnumValue<Region_slug>("region", volume_action_post_base.region);
        writer.writeEnumValue<Volume_action_post_base_type>("type", volume_action_post_base.type);
        writer.writeAdditionalData(volume_action_post_base.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeVolume_action_post_detach(writer: SerializationWriter, volume_action_post_detach: Partial<Volume_action_post_detach> | undefined | null = {}) : void {
    if (volume_action_post_detach) {
        serializeVolume_action_post_base(writer, volume_action_post_detach)
        writer.writeNumberValue("droplet_id", volume_action_post_detach.dropletId);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeVolume_action_post_resize(writer: SerializationWriter, volume_action_post_resize: Partial<Volume_action_post_resize> | undefined | null = {}) : void {
    if (volume_action_post_resize) {
        serializeVolume_action_post_base(writer, volume_action_post_resize)
        writer.writeNumberValue("size_gigabytes", volume_action_post_resize.sizeGigabytes);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeVolume_base(writer: SerializationWriter, volume_base: Partial<Volume_base> | undefined | null = {}) : void {
    if (volume_base) {
        writer.writeStringValue("description", volume_base.description);
        writer.writeStringValue("name", volume_base.name);
        writer.writeNumberValue("size_gigabytes", volume_base.sizeGigabytes);
        writer.writeCollectionOfPrimitiveValues<string>("tags", volume_base.tags);
        writer.writeAdditionalData(volume_base.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeVolume_full(writer: SerializationWriter, volume_full: Partial<Volume_full> | undefined | null = {}) : void {
    if (volume_full) {
        serializeVolume_base(writer, volume_full)
        writer.writeStringValue("filesystem_label", volume_full.filesystemLabel);
        writer.writeStringValue("filesystem_type", volume_full.filesystemType);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeVolumeAction(writer: SerializationWriter, volumeAction: Partial<VolumeAction> | undefined | null = {}) : void {
    if (volumeAction) {
        serializeAction(writer, volumeAction)
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeVolumes_ext4(writer: SerializationWriter, volumes_ext4: Partial<Volumes_ext4> | undefined | null = {}) : void {
    if (volumes_ext4) {
        writer.writeStringValue("description", volumes_ext4.description);
        writer.writeStringValue("filesystem_label", volumes_ext4.filesystemLabel);
        writer.writeStringValue("filesystem_type", volumes_ext4.filesystemType);
        writer.writeStringValue("name", volumes_ext4.name);
        writer.writeEnumValue<Region_slug>("region", volumes_ext4.region);
        writer.writeNumberValue("size_gigabytes", volumes_ext4.sizeGigabytes);
        writer.writeStringValue("snapshot_id", volumes_ext4.snapshotId);
        writer.writeCollectionOfPrimitiveValues<string>("tags", volumes_ext4.tags);
        writer.writeAdditionalData(volumes_ext4.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeVolumes_xfs(writer: SerializationWriter, volumes_xfs: Partial<Volumes_xfs> | undefined | null = {}) : void {
    if (volumes_xfs) {
        writer.writeStringValue("description", volumes_xfs.description);
        writer.writeStringValue("filesystem_label", volumes_xfs.filesystemLabel);
        writer.writeStringValue("filesystem_type", volumes_xfs.filesystemType);
        writer.writeStringValue("name", volumes_xfs.name);
        writer.writeEnumValue<Region_slug>("region", volumes_xfs.region);
        writer.writeNumberValue("size_gigabytes", volumes_xfs.sizeGigabytes);
        writer.writeStringValue("snapshot_id", volumes_xfs.snapshotId);
        writer.writeCollectionOfPrimitiveValues<string>("tags", volumes_xfs.tags);
        writer.writeAdditionalData(volumes_xfs.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeVpc(writer: SerializationWriter, vpc: Partial<Vpc> | undefined | null = {}) : void {
    if (vpc) {
        writer.writeBooleanValue("default", vpc.defaultEscaped);
        writer.writeStringValue("description", vpc.description);
        writer.writeStringValue("ip_range", vpc.ipRange);
        writer.writeStringValue("name", vpc.name);
        writer.writeStringValue("region", vpc.region);
        writer.writeStringValue("urn", vpc.urn);
        writer.writeAdditionalData(vpc.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeVpc_member(writer: SerializationWriter, vpc_member: Partial<Vpc_member> | undefined | null = {}) : void {
    if (vpc_member) {
        writer.writeStringValue("created_at", vpc_member.createdAt);
        writer.writeStringValue("name", vpc_member.name);
        writer.writeStringValue("urn", vpc_member.urn);
        writer.writeAdditionalData(vpc_member.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeVpc_peering(writer: SerializationWriter, vpc_peering: Partial<Vpc_peering> | undefined | null = {}) : void {
    if (vpc_peering) {
        writer.writeStringValue("name", vpc_peering.name);
        writer.writeCollectionOfPrimitiveValues<Guid>("vpc_ids", vpc_peering.vpcIds);
        writer.writeAdditionalData(vpc_peering.additionalData);
    }
}
/**
 * Serializes information the current object
 * @param writer Serialization writer to use to serialize this model
 */
// @ts-ignore
export function serializeVpc_peering_updatable(writer: SerializationWriter, vpc_peering_updatable: Partial<Vpc_peering_updatable> | undefined | null = {}) : void {
    if (vpc_peering_updatable) {
        writer.writeStringValue("name", vpc_peering_updatable.name);
        writer.writeAdditionalData(vpc_peering_updatable.additionalData);
    }
}
export interface Simple_charge extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Total amount charged in USD
     */
    amount?: string | null;
    /**
     * Name of the charge
     */
    name?: string | null;
}
export interface Sink_resource extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * resource name
     */
    name?: string | null;
    /**
     * The uniform resource name (URN) for the resource in the format do:resource_type:resource_id.
     */
    urn?: string | null;
}
export interface Sinks_response extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The destination property
     */
    destination?: Destination | null;
    /**
     * List of resources identified by their URNs.
     */
    resources?: Sink_resource[] | null;
}
export interface Size extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * This is a boolean value that represents whether new Droplets can be created with this size.
     */
    available?: boolean | null;
    /**
     * A string describing the class of Droplets created from this size. For example: Basic, General Purpose, CPU-Optimized, Memory-Optimized, or Storage-Optimized.
     */
    description?: string | null;
    /**
     * The amount of disk space set aside for Droplets of this size. The value is represented in gigabytes.
     */
    disk?: number | null;
    /**
     * An array of objects containing information about the disks available to Droplets created with this size.
     */
    diskInfo?: Disk_info[] | null;
    /**
     * An object containing information about the GPU capabilities of Droplets created with this size.
     */
    gpuInfo?: Gpu_info | null;
    /**
     * The amount of RAM allocated to Droplets created of this size. The value is represented in megabytes.
     */
    memory?: number | null;
    /**
     * This describes the price of the Droplet size as measured hourly. The value is measured in US dollars.
     */
    priceHourly?: number | null;
    /**
     * This attribute describes the monthly cost of this Droplet size if the Droplet is kept for an entire month. The value is measured in US dollars.
     */
    priceMonthly?: number | null;
    /**
     * An array containing the region slugs where this size is available for Droplet creates.
     */
    regions?: string[] | null;
    /**
     * A human-readable string that is used to uniquely identify each size.
     */
    slug?: string | null;
    /**
     * The amount of transfer bandwidth that is available for Droplets created in this size. This only counts traffic on the public interface. The value is given in terabytes.
     */
    transfer?: number | null;
    /**
     * The number of CPUs allocated to Droplets of this size.
     */
    vcpus?: number | null;
}
export interface Slack_details extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Slack channel to notify of an alert trigger.
     */
    channel?: string | null;
    /**
     * Slack Webhook URL.
     */
    url?: string | null;
}
export interface Snapshots extends Parsable, Snapshots_base {
    /**
     * The unique identifier for the snapshot.
     */
    id?: string | null;
    /**
     * The unique identifier for the resource that the snapshot originated from.
     */
    resourceId?: string | null;
    /**
     * The type of resource that the snapshot originated from.
     */
    resourceType?: Snapshots_resource_type | null;
    /**
     * An array of Tags the snapshot has been tagged with.
     */
    tags?: string[] | null;
}
export interface Snapshots_base extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the snapshot was created.
     */
    createdAt?: Date | null;
    /**
     * The minimum size in GB required for a volume or Droplet to use this snapshot.
     */
    minDiskSize?: number | null;
    /**
     * A human-readable name for the snapshot.
     */
    name?: string | null;
    /**
     * An array of the regions that the snapshot is available in. The regions are represented by their identifying slug values.
     */
    regions?: string[] | null;
    /**
     * The billable size of the snapshot in gigabytes.
     */
    sizeGigabytes?: number | null;
}
export type Snapshots_resource_type = (typeof Snapshots_resource_typeObject)[keyof typeof Snapshots_resource_typeObject];
export interface Source_database extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Enables SSL encryption when connecting to the source database.
     */
    disableSsl?: boolean | null;
    /**
     * List of databases that should be ignored during migration.
     */
    ignoreDbs?: string[] | null;
    /**
     * The source property
     */
    source?: Source_database_source | null;
}
export interface Source_database_source extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name of the default database.
     */
    dbname?: string | null;
    /**
     * The FQDN pointing to the database cluster's current primary node.
     */
    host?: string | null;
    /**
     * The randomly generated password for the default user.
     */
    password?: string | null;
    /**
     * The port on which the database cluster is listening.
     */
    port?: number | null;
    /**
     * The default user for the database.
     */
    username?: string | null;
}
export interface Sql_mode extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A string specifying the configured SQL modes for the MySQL cluster.
     */
    sqlMode?: string | null;
}
export interface SshKeys extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A unique identifier that differentiates this key from other keys using  a format that SSH recognizes. The fingerprint is created when the key is added to your account.
     */
    fingerprint?: string | null;
    /**
     * A unique identification number for this key. Can be used to embed a  specific SSH key into a Droplet.
     */
    id?: number | null;
    /**
     * A human-readable display name for this key, used to easily identify the SSH keys when they are displayed.
     */
    name?: string | null;
    /**
     * The entire public key string that was uploaded. Embedded into the root user's `authorized_keys` file if you include this key during Droplet creation.
     */
    publicKey?: string | null;
}
export interface State extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The previous_outage property
     */
    previousOutage?: Previous_outage | null;
    /**
     * A map of region to regional state
     */
    regions?: Regional_state | null;
}
/**
 * An object specifying sticky sessions settings for the load balancer.
 */
export interface Sticky_sessions extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name of the cookie sent to the client. This attribute is only returned when using `cookies` for the sticky sessions type.
     */
    cookieName?: string | null;
    /**
     * The number of seconds until the cookie set by the load balancer expires. This attribute is only returned when using `cookies` for the sticky sessions type.
     */
    cookieTtlSeconds?: number | null;
    /**
     * An attribute indicating how and if requests from a client will be persistently served by the same backend Droplet. The possible values are `cookies` or `none`.
     */
    type?: Sticky_sessions_type | null;
}
export type Sticky_sessions_type = (typeof Sticky_sessions_typeObject)[keyof typeof Sticky_sessions_typeObject];
export interface Subscription extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The time at which the subscription was created.
     */
    createdAt?: Date | null;
    /**
     * The tier property
     */
    tier?: Subscription_tier_base | null;
    /**
     * The time at which the subscription was last updated.
     */
    updatedAt?: Date | null;
}
export interface Subscription_tier_base extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A boolean indicating whether the subscription tier supports additional storage above what is included in the base plan at an additional cost per GiB used.
     */
    allowStorageOverage?: boolean | null;
    /**
     * The amount of outbound data transfer included in the subscription tier in bytes.
     */
    includedBandwidthBytes?: number | null;
    /**
     * The number of repositories included in the subscription tier. `0` indicates that the subscription tier includes unlimited repositories.
     */
    includedRepositories?: number | null;
    /**
     * The amount of storage included in the subscription tier in bytes.
     */
    includedStorageBytes?: number | null;
    /**
     * The monthly cost of the subscription tier in cents.
     */
    monthlyPriceInCents?: number | null;
    /**
     * The name of the subscription tier.
     */
    name?: string | null;
    /**
     * The slug identifier of the subscription tier.
     */
    slug?: string | null;
    /**
     * The price paid in cents per GiB for additional storage beyond what is included in the subscription plan.
     */
    storageOveragePriceInCents?: number | null;
}
export interface Supported_droplet_backup_policy extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name of the Droplet backup plan.
     */
    name?: string | null;
    /**
     * The day of the week the backup will occur.
     */
    possibleDays?: string[] | null;
    /**
     * An array of integers representing the hours of the day that a backup canstart.
     */
    possibleWindowStarts?: number[] | null;
    /**
     * The number of days that a backup will be kept.
     */
    retentionPeriodDays?: number | null;
    /**
     * The number of hours that a backup window is open.
     */
    windowLengthHours?: number | null;
}
/**
 * A tag is a label that can be applied to a resource (currently Droplets, Images, Volumes, Volume Snapshots, and Database clusters) in order to better organize or facilitate the lookups and actions on it.Tags have two attributes: a user defined `name` attribute and an embedded `resources` attribute with information about resources that have been tagged.
 */
export interface Tags extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name of the tag. Tags may contain letters, numbers, colons, dashes, and underscores.There is a limit of 255 characters per tag.**Note:** Tag names are case stable, which means the capitalization you use when you first create a tag is canonical.When working with tags in the API, you must use the tag's canonical capitalization. For example, if you create a tag named "PROD", the URL to add that tag to a resource would be `https://api.digitalocean.com/v2/tags/PROD/resources` (not `/v2/tags/prod/resources`).Tagged resources in the control panel will always display the canonical capitalization. For example, if you create a tag named "PROD", you can tag resources in the control panel by entering "prod". The tag will still display with its canonical capitalization, "PROD".
     */
    name?: string | null;
    /**
     * An embedded object containing key value pairs of resource type and resource statistics. It also includes a count of the total number of resources tagged with the current tag as well as a `last_tagged_uri` attribute set to the last resource tagged with the current tag.
     */
    resources?: Tags_resources | null;
}
/**
 * Tagged Resource Statistics include metadata regarding the resource type that has been tagged.
 */
export interface Tags_metadata extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The number of tagged objects for this type of resource.
     */
    count?: number | null;
    /**
     * The URI for the last tagged object for this type of resource.
     */
    lastTaggedUri?: string | null;
}
export interface Tags_resource extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An array of objects containing resource_id and resource_type  attributes.
     */
    resources?: Tags_resource_resources[] | null;
}
export interface Tags_resource_resources extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The identifier of a resource.
     */
    resourceId?: string | null;
    /**
     * The type of the resource.
     */
    resourceType?: Tags_resource_resources_resource_type | null;
}
export type Tags_resource_resources_resource_type = (typeof Tags_resource_resources_resource_typeObject)[keyof typeof Tags_resource_resources_resource_typeObject];
/**
 * An embedded object containing key value pairs of resource type and resource statistics. It also includes a count of the total number of resources tagged with the current tag as well as a `last_tagged_uri` attribute set to the last resource tagged with the current tag.
 */
export interface Tags_resources extends Parsable, Tags_metadata {
    /**
     * Tagged Resource Statistics include metadata regarding the resource type that has been tagged.
     */
    databases?: Tags_metadata | null;
    /**
     * Tagged Resource Statistics include metadata regarding the resource type that has been tagged.
     */
    droplets?: Tags_metadata | null;
    /**
     * Tagged Resource Statistics include metadata regarding the resource type that has been tagged.
     */
    imgages?: Tags_metadata | null;
    /**
     * Tagged Resource Statistics include metadata regarding the resource type that has been tagged.
     */
    volumes?: Tags_metadata | null;
    /**
     * Tagged Resource Statistics include metadata regarding the resource type that has been tagged.
     */
    volumeSnapshots?: Tags_metadata | null;
}
/**
 * TimescaleDB extension configuration values
 */
export interface Timescaledb_advanced_config extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The number of background workers for timescaledb operations.  Set to the sum of your number of databases and the total number of concurrent background workers you want running at any given point in time.
     */
    maxBackgroundWorkers?: number | null;
}
export interface Trigger_info extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * UTC time string.
     */
    createdAt?: string | null;
    /**
     * Name of function(action) that exists in the given namespace.
     */
    functionEscaped?: string | null;
    /**
     * Indicates weather the trigger is paused or unpaused.
     */
    isEnabled?: boolean | null;
    /**
     * The trigger's unique name within the namespace.
     */
    name?: string | null;
    /**
     * A unique string format of UUID with a prefix fn-.
     */
    namespace?: string | null;
    /**
     * Trigger details for SCHEDULED type, where body is optional.
     */
    scheduledDetails?: Scheduled_details | null;
    /**
     * The scheduled_runs property
     */
    scheduledRuns?: Trigger_info_scheduled_runs | null;
    /**
     * String which indicates the type of trigger source like SCHEDULED.
     */
    type?: string | null;
    /**
     * UTC time string.
     */
    updatedAt?: string | null;
}
export interface Trigger_info_scheduled_runs extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Indicates last run time. null value indicates trigger not run yet.
     */
    lastRunAt?: string | null;
    /**
     * Indicates next run time. null value indicates trigger will not run.
     */
    nextRunAt?: string | null;
}
export interface Update_endpoint extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The ID of a DigitalOcean managed TLS certificate used for SSL when a custom subdomain is provided.
     */
    certificateId?: Guid | null;
    /**
     * The fully qualified domain name (FQDN) of the custom subdomain used with the CDN endpoint.
     */
    customDomain?: string | null;
    /**
     * The amount of time the content is cached by the CDN's edge servers in seconds. TTL must be one of 60, 600, 3600, 86400, or 604800. Defaults to 3600 (one hour) when excluded.
     */
    ttl?: number | null;
}
export interface Update_registry extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A boolean value indicating that the garbage collection should be cancelled.
     */
    cancel?: boolean | null;
}
export interface Update_trigger extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * Indicates weather the trigger is paused or unpaused.
     */
    isEnabled?: boolean | null;
    /**
     * Trigger details for SCHEDULED type, where body is optional.
     */
    scheduledDetails?: Scheduled_details | null;
}
export interface User extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The kubernetes_cluster_user property
     */
    kubernetesClusterUser?: User_kubernetes_cluster_user | null;
}
export interface User_kubernetes_cluster_user extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A list of in-cluster groups that the user belongs to.
     */
    groups?: string[] | null;
    /**
     * The username for the cluster admin user.
     */
    username?: string | null;
}
export interface User_settings extends AdditionalDataHolder, Parsable {
    /**
     * ACLs (Access Control Lists) specifying permissions on topics within a Kafka cluster.
     */
    acl?: User_settings_acl[] | null;
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * ACLs (Access Control Lists) specifying permissions on index within a OpenSearch cluster.
     */
    opensearchAcl?: User_settings_opensearch_acl[] | null;
    /**
     * For Postgres clusters, set to `true` for a user with replication rights.This option is not currently supported for other database engines.
     */
    pgAllowReplication?: boolean | null;
}
export interface User_settings_acl extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * An identifier for the ACL. Will be computed after the ACL is created/updated.
     */
    id?: string | null;
    /**
     * Permission set applied to the ACL. 'consume' allows for messages to be consumed from the topic. 'produce' allows for messages to be published to the topic. 'produceconsume' allows for both 'consume' and 'produce' permission. 'admin' allows for 'produceconsume' as well as any operations to administer the topic (delete, update).
     */
    permission?: User_settings_acl_permission | null;
    /**
     * A regex for matching the topic(s) that this ACL should apply to.
     */
    topic?: string | null;
}
export type User_settings_acl_permission = (typeof User_settings_acl_permissionObject)[keyof typeof User_settings_acl_permissionObject];
export interface User_settings_opensearch_acl extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A regex for matching the indexes that this ACL should apply to.
     */
    index?: string | null;
    /**
     * Permission set applied to the ACL. 'read' allows user to read from the index. 'write' allows for user to write to the index. 'readwrite' allows for both 'read' and 'write' permission. 'deny'(default) restricts user from performing any operation over an index. 'admin' allows for 'readwrite' as well as any operations to administer the index.
     */
    permission?: User_settings_opensearch_acl_permission | null;
}
export type User_settings_opensearch_acl_permission = (typeof User_settings_opensearch_acl_permissionObject)[keyof typeof User_settings_opensearch_acl_permissionObject];
export interface Validate_registry extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A globally unique name for the container registry. Must be lowercase and be composed only of numbers, letters and `-`, up to a limit of 63 characters.
     */
    name?: string | null;
}
export interface Version2 extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A string representing the version of the database engine in use for the cluster.
     */
    version?: string | null;
}
export interface Volume_action_post_attach extends Parsable, Volume_action_post_base {
    /**
     * The unique identifier for the Droplet the volume will be attached or detached from.
     */
    dropletId?: number | null;
    /**
     * A flat array of tag names as strings to be applied to the resource. Tag names may be for either existing or new tags.
     */
    tags?: string[] | null;
}
export interface Volume_action_post_base extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The slug identifier for the region where the resource will initially be  available.
     */
    region?: Region_slug | null;
    /**
     * The volume action to initiate.
     */
    type?: Volume_action_post_base_type | null;
}
export type Volume_action_post_base_type = (typeof Volume_action_post_base_typeObject)[keyof typeof Volume_action_post_base_typeObject];
export interface Volume_action_post_detach extends Parsable, Volume_action_post_base {
    /**
     * The unique identifier for the Droplet the volume will be attached or detached from.
     */
    dropletId?: number | null;
}
export interface Volume_action_post_resize extends Parsable, Volume_action_post_base {
    /**
     * The new size of the block storage volume in GiB (1024^3).
     */
    sizeGigabytes?: number | null;
}
export interface Volume_base extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the block storage volume was created.
     */
    createdAt?: string | null;
    /**
     * An optional free-form text field to describe a block storage volume.
     */
    description?: string | null;
    /**
     * An array containing the IDs of the Droplets the volume is attached to. Note that at this time, a volume can only be attached to a single Droplet.
     */
    dropletIds?: number[] | null;
    /**
     * The unique identifier for the block storage volume.
     */
    id?: string | null;
    /**
     * A human-readable name for the block storage volume. Must be lowercase and be composed only of numbers, letters and "-", up to a limit of 64 characters. The name must begin with a letter.
     */
    name?: string | null;
    /**
     * The size of the block storage volume in GiB (1024^3). This field does not apply  when creating a volume from a snapshot.
     */
    sizeGigabytes?: number | null;
    /**
     * A flat array of tag names as strings to be applied to the resource. Tag names may be for either existing or new tags.
     */
    tags?: string[] | null;
}
export interface Volume_full extends Parsable, Volume_base {
    /**
     * The label currently applied to the filesystem.
     */
    filesystemLabel?: string | null;
    /**
     * The type of filesystem currently in-use on the volume.
     */
    filesystemType?: string | null;
    /**
     * The region property
     */
    region?: Region | null;
}
export interface VolumeAction extends Action, Parsable {
}
export interface Volumes_ext4 extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the block storage volume was created.
     */
    createdAt?: string | null;
    /**
     * An optional free-form text field to describe a block storage volume.
     */
    description?: string | null;
    /**
     * An array containing the IDs of the Droplets the volume is attached to. Note that at this time, a volume can only be attached to a single Droplet.
     */
    dropletIds?: number[] | null;
    /**
     * The filesystem_label property
     */
    filesystemLabel?: string | null;
    /**
     * The name of the filesystem type to be used on the volume. When provided, the volume will automatically be formatted to the specified filesystem type. Currently, the available options are `ext4` and `xfs`. Pre-formatted volumes are automatically mounted when attached to Ubuntu, Debian, Fedora, Fedora Atomic, and CentOS Droplets created on or after April 26, 2018. Attaching pre-formatted volumes to other Droplets is not recommended.
     */
    filesystemType?: string | null;
    /**
     * The unique identifier for the block storage volume.
     */
    id?: string | null;
    /**
     * A human-readable name for the block storage volume. Must be lowercase and be composed only of numbers, letters and "-", up to a limit of 64 characters. The name must begin with a letter.
     */
    name?: string | null;
    /**
     * The slug identifier for the region where the resource will initially be  available.
     */
    region?: Region_slug | null;
    /**
     * The size of the block storage volume in GiB (1024^3). This field does not apply  when creating a volume from a snapshot.
     */
    sizeGigabytes?: number | null;
    /**
     * The unique identifier for the volume snapshot from which to create the volume.
     */
    snapshotId?: string | null;
    /**
     * A flat array of tag names as strings to be applied to the resource. Tag names may be for either existing or new tags.
     */
    tags?: string[] | null;
}
export interface Volumes_xfs extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the block storage volume was created.
     */
    createdAt?: string | null;
    /**
     * An optional free-form text field to describe a block storage volume.
     */
    description?: string | null;
    /**
     * An array containing the IDs of the Droplets the volume is attached to. Note that at this time, a volume can only be attached to a single Droplet.
     */
    dropletIds?: number[] | null;
    /**
     * The filesystem_label property
     */
    filesystemLabel?: string | null;
    /**
     * The name of the filesystem type to be used on the volume. When provided, the volume will automatically be formatted to the specified filesystem type. Currently, the available options are `ext4` and `xfs`. Pre-formatted volumes are automatically mounted when attached to Ubuntu, Debian, Fedora, Fedora Atomic, and CentOS Droplets created on or after April 26, 2018. Attaching pre-formatted volumes to other Droplets is not recommended.
     */
    filesystemType?: string | null;
    /**
     * The unique identifier for the block storage volume.
     */
    id?: string | null;
    /**
     * A human-readable name for the block storage volume. Must be lowercase and be composed only of numbers, letters and "-", up to a limit of 64 characters. The name must begin with a letter.
     */
    name?: string | null;
    /**
     * The slug identifier for the region where the resource will initially be  available.
     */
    region?: Region_slug | null;
    /**
     * The size of the block storage volume in GiB (1024^3). This field does not apply  when creating a volume from a snapshot.
     */
    sizeGigabytes?: number | null;
    /**
     * The unique identifier for the volume snapshot from which to create the volume.
     */
    snapshotId?: string | null;
    /**
     * A flat array of tag names as strings to be applied to the resource. Tag names may be for either existing or new tags.
     */
    tags?: string[] | null;
}
export interface Vpc extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A time value given in ISO8601 combined date and time format.
     */
    createdAt?: Date | null;
    /**
     * A boolean value indicating whether or not the VPC is the default network for the region. All applicable resources are placed into the default VPC network unless otherwise specified during their creation. The `default` field cannot be unset from `true`. If you want to set a new default VPC network, update the `default` field of another VPC network in the same region. The previous network's `default` field will be set to `false` when a new default VPC has been defined.
     */
    defaultEscaped?: boolean | null;
    /**
     * A free-form text field for describing the VPC's purpose. It may be a maximum of 255 characters.
     */
    description?: string | null;
    /**
     * A unique ID that can be used to identify and reference the VPC.
     */
    id?: Guid | null;
    /**
     * The range of IP addresses in the VPC in CIDR notation. Network ranges cannot overlap with other networks in the same account and must be in range of private addresses as defined in RFC1918. It may not be smaller than `/28` nor larger than `/16`. If no IP range is specified, a `/20` network range is generated that won't conflict with other VPC networks in your account.
     */
    ipRange?: string | null;
    /**
     * The name of the VPC. Must be unique and may only contain alphanumeric characters, dashes, and periods.
     */
    name?: string | null;
    /**
     * The slug identifier for the region where the VPC will be created.
     */
    region?: string | null;
    /**
     * The uniform resource name (URN) for the resource in the format do:resource_type:resource_id.
     */
    urn?: string | null;
}
export interface Vpc_member extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A time value given in ISO8601 combined date and time format that represents when the resource was created.
     */
    createdAt?: string | null;
    /**
     * The name of the resource.
     */
    name?: string | null;
    /**
     * The uniform resource name (URN) for the resource in the format do:resource_type:resource_id.
     */
    urn?: string | null;
}
export interface Vpc_peering extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * A time value given in ISO8601 combined date and time format.
     */
    createdAt?: Date | null;
    /**
     * A unique ID that can be used to identify and reference the VPC peering.
     */
    id?: Guid | null;
    /**
     * The name of the VPC peering. Must be unique within the team and may only contain alphanumeric characters and dashes.
     */
    name?: string | null;
    /**
     * The current status of the VPC peering.
     */
    status?: Vpc_peering_status | null;
    /**
     * An array of the two peered VPCs IDs.
     */
    vpcIds?: Guid[] | null;
}
export type Vpc_peering_status = (typeof Vpc_peering_statusObject)[keyof typeof Vpc_peering_statusObject];
export interface Vpc_peering_updatable extends AdditionalDataHolder, Parsable {
    /**
     * Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.
     */
    additionalData?: Record<string, unknown>;
    /**
     * The name of the VPC peering. Must be unique within the team and may only contain alphanumeric characters and dashes.
     */
    name?: string | null;
}
/**
 * This value is one of "active", "warning" or "locked".
 */
export const Account_statusObject = {
    Active: "active",
    Warning: "warning",
    Locked: "locked",
} as const;
/**
 * The current status of the action. This can be "in-progress", "completed", or "errored".
 */
export const Action_statusObject = {
    InProgress: "in-progress",
    Completed: "completed",
    Errored: "errored",
} as const;
/**
 * The comparison operator used against the alert's threshold.
 */
export const Alert_comparisonObject = {
    Greater_than: "greater_than",
    Less_than: "less_than",
} as const;
/**
 * Period of time the threshold must be exceeded to trigger the alert.
 */
export const Alert_periodObject = {
    Twom: "2m",
    Threem: "3m",
    Fivem: "5m",
    OneZerom: "10m",
    OneFivem: "15m",
    ThreeZerom: "30m",
    Oneh: "1h",
} as const;
export const Alert_policy_compareObject = {
    GreaterThan: "GreaterThan",
    LessThan: "LessThan",
} as const;
export const Alert_policy_request_compareObject = {
    GreaterThan: "GreaterThan",
    LessThan: "LessThan",
} as const;
export const Alert_policy_request_typeObject = {
    V1InsightsDropletLoad_1: "v1/insights/droplet/load_1",
    V1InsightsDropletLoad_5: "v1/insights/droplet/load_5",
    V1InsightsDropletLoad_15: "v1/insights/droplet/load_15",
    V1InsightsDropletMemory_utilization_percent: "v1/insights/droplet/memory_utilization_percent",
    V1InsightsDropletDisk_utilization_percent: "v1/insights/droplet/disk_utilization_percent",
    V1InsightsDropletCpu: "v1/insights/droplet/cpu",
    V1InsightsDropletDisk_read: "v1/insights/droplet/disk_read",
    V1InsightsDropletDisk_write: "v1/insights/droplet/disk_write",
    V1InsightsDropletPublic_outbound_bandwidth: "v1/insights/droplet/public_outbound_bandwidth",
    V1InsightsDropletPublic_inbound_bandwidth: "v1/insights/droplet/public_inbound_bandwidth",
    V1InsightsDropletPrivate_outbound_bandwidth: "v1/insights/droplet/private_outbound_bandwidth",
    V1InsightsDropletPrivate_inbound_bandwidth: "v1/insights/droplet/private_inbound_bandwidth",
    V1InsightsLbaasAvg_cpu_utilization_percent: "v1/insights/lbaas/avg_cpu_utilization_percent",
    V1InsightsLbaasConnection_utilization_percent: "v1/insights/lbaas/connection_utilization_percent",
    V1InsightsLbaasDroplet_health: "v1/insights/lbaas/droplet_health",
    V1InsightsLbaasTls_connections_per_second_utilization_percent: "v1/insights/lbaas/tls_connections_per_second_utilization_percent",
    V1InsightsLbaasIncrease_in_http_error_rate_percentage_5xx: "v1/insights/lbaas/increase_in_http_error_rate_percentage_5xx",
    V1InsightsLbaasIncrease_in_http_error_rate_percentage_4xx: "v1/insights/lbaas/increase_in_http_error_rate_percentage_4xx",
    V1InsightsLbaasIncrease_in_http_error_rate_count_5xx: "v1/insights/lbaas/increase_in_http_error_rate_count_5xx",
    V1InsightsLbaasIncrease_in_http_error_rate_count_4xx: "v1/insights/lbaas/increase_in_http_error_rate_count_4xx",
    V1InsightsLbaasHigh_http_request_response_time: "v1/insights/lbaas/high_http_request_response_time",
    V1InsightsLbaasHigh_http_request_response_time_50p: "v1/insights/lbaas/high_http_request_response_time_50p",
    V1InsightsLbaasHigh_http_request_response_time_95p: "v1/insights/lbaas/high_http_request_response_time_95p",
    V1InsightsLbaasHigh_http_request_response_time_99p: "v1/insights/lbaas/high_http_request_response_time_99p",
    V1DbaasAlertsLoad_15_alerts: "v1/dbaas/alerts/load_15_alerts",
    V1DbaasAlertsMemory_utilization_alerts: "v1/dbaas/alerts/memory_utilization_alerts",
    V1DbaasAlertsDisk_utilization_alerts: "v1/dbaas/alerts/disk_utilization_alerts",
    V1DbaasAlertsCpu_alerts: "v1/dbaas/alerts/cpu_alerts",
    V1DropletAutoscale_alertsCurrent_instances: "v1/droplet/autoscale_alerts/current_instances",
    V1DropletAutoscale_alertsTarget_instances: "v1/droplet/autoscale_alerts/target_instances",
    V1DropletAutoscale_alertsCurrent_cpu_utilization: "v1/droplet/autoscale_alerts/current_cpu_utilization",
    V1DropletAutoscale_alertsTarget_cpu_utilization: "v1/droplet/autoscale_alerts/target_cpu_utilization",
    V1DropletAutoscale_alertsCurrent_memory_utilization: "v1/droplet/autoscale_alerts/current_memory_utilization",
    V1DropletAutoscale_alertsTarget_memory_utilization: "v1/droplet/autoscale_alerts/target_memory_utilization",
    V1DropletAutoscale_alertsScale_up: "v1/droplet/autoscale_alerts/scale_up",
    V1DropletAutoscale_alertsScale_down: "v1/droplet/autoscale_alerts/scale_down",
} as const;
export const Alert_policy_request_windowObject = {
    Fivem: "5m",
    OneZerom: "10m",
    ThreeZerom: "30m",
    Oneh: "1h",
} as const;
export const Alert_policy_typeObject = {
    V1InsightsDropletLoad_1: "v1/insights/droplet/load_1",
    V1InsightsDropletLoad_5: "v1/insights/droplet/load_5",
    V1InsightsDropletLoad_15: "v1/insights/droplet/load_15",
    V1InsightsDropletMemory_utilization_percent: "v1/insights/droplet/memory_utilization_percent",
    V1InsightsDropletDisk_utilization_percent: "v1/insights/droplet/disk_utilization_percent",
    V1InsightsDropletCpu: "v1/insights/droplet/cpu",
    V1InsightsDropletDisk_read: "v1/insights/droplet/disk_read",
    V1InsightsDropletDisk_write: "v1/insights/droplet/disk_write",
    V1InsightsDropletPublic_outbound_bandwidth: "v1/insights/droplet/public_outbound_bandwidth",
    V1InsightsDropletPublic_inbound_bandwidth: "v1/insights/droplet/public_inbound_bandwidth",
    V1InsightsDropletPrivate_outbound_bandwidth: "v1/insights/droplet/private_outbound_bandwidth",
    V1InsightsDropletPrivate_inbound_bandwidth: "v1/insights/droplet/private_inbound_bandwidth",
    V1InsightsLbaasAvg_cpu_utilization_percent: "v1/insights/lbaas/avg_cpu_utilization_percent",
    V1InsightsLbaasConnection_utilization_percent: "v1/insights/lbaas/connection_utilization_percent",
    V1InsightsLbaasDroplet_health: "v1/insights/lbaas/droplet_health",
    V1InsightsLbaasTls_connections_per_second_utilization_percent: "v1/insights/lbaas/tls_connections_per_second_utilization_percent",
    V1InsightsLbaasIncrease_in_http_error_rate_percentage_5xx: "v1/insights/lbaas/increase_in_http_error_rate_percentage_5xx",
    V1InsightsLbaasIncrease_in_http_error_rate_percentage_4xx: "v1/insights/lbaas/increase_in_http_error_rate_percentage_4xx",
    V1InsightsLbaasIncrease_in_http_error_rate_count_5xx: "v1/insights/lbaas/increase_in_http_error_rate_count_5xx",
    V1InsightsLbaasIncrease_in_http_error_rate_count_4xx: "v1/insights/lbaas/increase_in_http_error_rate_count_4xx",
    V1InsightsLbaasHigh_http_request_response_time: "v1/insights/lbaas/high_http_request_response_time",
    V1InsightsLbaasHigh_http_request_response_time_50p: "v1/insights/lbaas/high_http_request_response_time_50p",
    V1InsightsLbaasHigh_http_request_response_time_95p: "v1/insights/lbaas/high_http_request_response_time_95p",
    V1InsightsLbaasHigh_http_request_response_time_99p: "v1/insights/lbaas/high_http_request_response_time_99p",
    V1DbaasAlertsLoad_15_alerts: "v1/dbaas/alerts/load_15_alerts",
    V1DbaasAlertsMemory_utilization_alerts: "v1/dbaas/alerts/memory_utilization_alerts",
    V1DbaasAlertsDisk_utilization_alerts: "v1/dbaas/alerts/disk_utilization_alerts",
    V1DbaasAlertsCpu_alerts: "v1/dbaas/alerts/cpu_alerts",
    V1DropletAutoscale_alertsCurrent_instances: "v1/droplet/autoscale_alerts/current_instances",
    V1DropletAutoscale_alertsTarget_instances: "v1/droplet/autoscale_alerts/target_instances",
    V1DropletAutoscale_alertsCurrent_cpu_utilization: "v1/droplet/autoscale_alerts/current_cpu_utilization",
    V1DropletAutoscale_alertsTarget_cpu_utilization: "v1/droplet/autoscale_alerts/target_cpu_utilization",
    V1DropletAutoscale_alertsCurrent_memory_utilization: "v1/droplet/autoscale_alerts/current_memory_utilization",
    V1DropletAutoscale_alertsTarget_memory_utilization: "v1/droplet/autoscale_alerts/target_memory_utilization",
    V1DropletAutoscale_alertsScale_up: "v1/droplet/autoscale_alerts/scale_up",
    V1DropletAutoscale_alertsScale_down: "v1/droplet/autoscale_alerts/scale_down",
} as const;
export const Alert_policy_windowObject = {
    Fivem: "5m",
    OneZerom: "10m",
    ThreeZerom: "30m",
    Oneh: "1h",
} as const;
/**
 * The type of alert.
 */
export const Alert_typeObject = {
    Latency: "latency",
    Down: "down",
    Down_global: "down_global",
    Ssl_expiry: "ssl_expiry",
} as const;
/**
 * The comparison operator used against the alert's threshold.
 */
export const Alert_updatable_comparisonObject = {
    Greater_than: "greater_than",
    Less_than: "less_than",
} as const;
/**
 * Period of time the threshold must be exceeded to trigger the alert.
 */
export const Alert_updatable_periodObject = {
    Twom: "2m",
    Threem: "3m",
    Fivem: "5m",
    OneZerom: "10m",
    OneFivem: "15m",
    ThreeZerom: "30m",
    Oneh: "1h",
} as const;
/**
 * The type of alert.
 */
export const Alert_updatable_typeObject = {
    Latency: "latency",
    Down: "down",
    Down_global: "down_global",
    Ssl_expiry: "ssl_expiry",
} as const;
export const ApiBatchJobPhaseObject = {
    BATCH_JOB_PHASE_UNKNOWN: "BATCH_JOB_PHASE_UNKNOWN",
    BATCH_JOB_PHASE_PENDING: "BATCH_JOB_PHASE_PENDING",
    BATCH_JOB_PHASE_RUNNING: "BATCH_JOB_PHASE_RUNNING",
    BATCH_JOB_PHASE_SUCCEEDED: "BATCH_JOB_PHASE_SUCCEEDED",
    BATCH_JOB_PHASE_FAILED: "BATCH_JOB_PHASE_FAILED",
    BATCH_JOB_PHASE_ERROR: "BATCH_JOB_PHASE_ERROR",
    BATCH_JOB_PHASE_CANCELLED: "BATCH_JOB_PHASE_CANCELLED",
} as const;
/**
 * Options for specifying how URLs found on pages should be handled. - UNKNOWN: Default unknown value - SCOPED: Only include the base URL. - PATH: Crawl the base URL and linked pages within the URL path. - DOMAIN: Crawl the base URL and linked pages within the same domain. - SUBDOMAINS: Crawl the base URL and linked pages for any subdomain.
 */
export const ApiCrawlingOptionObject = {
    UNKNOWN: "UNKNOWN",
    SCOPED: "SCOPED",
    PATH: "PATH",
    DOMAIN: "DOMAIN",
    SUBDOMAINS: "SUBDOMAINS",
} as const;
export const ApiDeploymentStatusObject = {
    STATUS_UNKNOWN: "STATUS_UNKNOWN",
    STATUS_WAITING_FOR_DEPLOYMENT: "STATUS_WAITING_FOR_DEPLOYMENT",
    STATUS_DEPLOYING: "STATUS_DEPLOYING",
    STATUS_RUNNING: "STATUS_RUNNING",
    STATUS_FAILED: "STATUS_FAILED",
    STATUS_WAITING_FOR_UNDEPLOYMENT: "STATUS_WAITING_FOR_UNDEPLOYMENT",
    STATUS_UNDEPLOYING: "STATUS_UNDEPLOYING",
    STATUS_UNDEPLOYMENT_FAILED: "STATUS_UNDEPLOYMENT_FAILED",
    STATUS_DELETED: "STATUS_DELETED",
} as const;
/**
 * - VISIBILITY_UNKNOWN: The status of the deployment is unknown - VISIBILITY_DISABLED: The deployment is disabled and will no longer service requests - VISIBILITY_PLAYGROUND: Deprecated: No longer a valid state - VISIBILITY_PUBLIC: The deployment is public and will service requests from the public internet - VISIBILITY_PRIVATE: The deployment is private and will only service requests from other agents, or through API keys
 */
export const ApiDeploymentVisibilityObject = {
    VISIBILITY_UNKNOWN: "VISIBILITY_UNKNOWN",
    VISIBILITY_DISABLED: "VISIBILITY_DISABLED",
    VISIBILITY_PLAYGROUND: "VISIBILITY_PLAYGROUND",
    VISIBILITY_PUBLIC: "VISIBILITY_PUBLIC",
    VISIBILITY_PRIVATE: "VISIBILITY_PRIVATE",
} as const;
export const ApiGuardrailTypeObject = {
    GUARDRAIL_TYPE_UNKNOWN: "GUARDRAIL_TYPE_UNKNOWN",
    GUARDRAIL_TYPE_JAILBREAK: "GUARDRAIL_TYPE_JAILBREAK",
    GUARDRAIL_TYPE_SENSITIVE_DATA: "GUARDRAIL_TYPE_SENSITIVE_DATA",
    GUARDRAIL_TYPE_CONTENT_MODERATION: "GUARDRAIL_TYPE_CONTENT_MODERATION",
} as const;
export const ApiModelProviderObject = {
    MODEL_PROVIDER_DIGITALOCEAN: "MODEL_PROVIDER_DIGITALOCEAN",
    MODEL_PROVIDER_ANTHROPIC: "MODEL_PROVIDER_ANTHROPIC",
} as const;
export const App_alert_phaseObject = {
    UNKNOWN: "UNKNOWN",
    PENDING: "PENDING",
    CONFIGURING: "CONFIGURING",
    ACTIVE: "ACTIVE",
    ERROREscaped: "ERROR",
} as const;
export const App_alert_progress_step_statusObject = {
    UNKNOWN: "UNKNOWN",
    PENDING: "PENDING",
    RUNNING: "RUNNING",
    ERROREscaped: "ERROR",
    SUCCESS: "SUCCESS",
} as const;
export const App_alert_spec_operatorObject = {
    UNSPECIFIED_OPERATOR: "UNSPECIFIED_OPERATOR",
    GREATER_THAN: "GREATER_THAN",
    LESS_THAN: "LESS_THAN",
} as const;
export const App_alert_spec_ruleObject = {
    UNSPECIFIED_RULE: "UNSPECIFIED_RULE",
    CPU_UTILIZATION: "CPU_UTILIZATION",
    MEM_UTILIZATION: "MEM_UTILIZATION",
    RESTART_COUNT: "RESTART_COUNT",
    DEPLOYMENT_FAILED: "DEPLOYMENT_FAILED",
    DEPLOYMENT_LIVE: "DEPLOYMENT_LIVE",
    DOMAIN_FAILED: "DOMAIN_FAILED",
    DOMAIN_LIVE: "DOMAIN_LIVE",
    FUNCTIONS_ACTIVATION_COUNT: "FUNCTIONS_ACTIVATION_COUNT",
    FUNCTIONS_AVERAGE_DURATION_MS: "FUNCTIONS_AVERAGE_DURATION_MS",
    FUNCTIONS_ERROR_RATE_PER_MINUTE: "FUNCTIONS_ERROR_RATE_PER_MINUTE",
    FUNCTIONS_AVERAGE_WAIT_TIME_MS: "FUNCTIONS_AVERAGE_WAIT_TIME_MS",
    FUNCTIONS_ERROR_COUNT: "FUNCTIONS_ERROR_COUNT",
    FUNCTIONS_GB_RATE_PER_SECOND: "FUNCTIONS_GB_RATE_PER_SECOND",
} as const;
export const App_alert_spec_windowObject = {
    UNSPECIFIED_WINDOW: "UNSPECIFIED_WINDOW",
    FIVE_MINUTES: "FIVE_MINUTES",
    TEN_MINUTES: "TEN_MINUTES",
    THIRTY_MINUTES: "THIRTY_MINUTES",
    ONE_HOUR: "ONE_HOUR",
} as const;
/**
 * - MYSQL: MySQL- PG: PostgreSQL- REDIS: Redis- MONGODB: MongoDB- KAFKA: Kafka- OPENSEARCH: OpenSearch
 */
export const App_database_spec_engineObject = {
    UNSET: "UNSET",
    MYSQL: "MYSQL",
    PG: "PG",
    REDIS: "REDIS",
    MONGODB: "MONGODB",
    KAFKA: "KAFKA",
    OPENSEARCH: "OPENSEARCH",
} as const;
/**
 * The minimum version of TLS a client application can use to access resources for the domain.  Must be one of the following values wrapped within quotations: `"1.2"` or `"1.3"`.
 */
export const App_domain_spec_minimum_tls_versionObject = {
    OneTwo: "1.2",
    OneThree: "1.3",
} as const;
/**
 * - DEFAULT: The default `.ondigitalocean.app` domain assigned to this app- PRIMARY: The primary domain for this app that is displayed as the default in the control panel, used in bindable environment variables, and any other places that reference an app's live URL. Only one domain may be set as primary.- ALIAS: A non-primary domain
 */
export const App_domain_spec_typeObject = {
    UNSPECIFIED: "UNSPECIFIED",
    DEFAULTEscaped: "DEFAULT",
    PRIMARY: "PRIMARY",
    ALIAS: "ALIAS",
} as const;
export const App_egress_type_specObject = {
    AUTOASSIGN: "AUTOASSIGN",
    DEDICATED_IP: "DEDICATED_IP",
} as const;
/**
 * - UNSPECIFIED: Default job type, will auto-complete to POST_DEPLOY kind.- PRE_DEPLOY: Indicates a job that runs before an app deployment.- POST_DEPLOY: Indicates a job that runs after an app deployment.- FAILED_DEPLOY: Indicates a job that runs after a component fails to deploy.
 */
export const App_job_spec_kindObject = {
    UNSPECIFIED: "UNSPECIFIED",
    PRE_DEPLOY: "PRE_DEPLOY",
    POST_DEPLOY: "POST_DEPLOY",
    FAILED_DEPLOY: "FAILED_DEPLOY",
} as const;
/**
 * A code identifier that represents the failing condition.Failing conditions:  - `incompatible_phase` - indicates that the deployment's phase is not suitable for rollback.  - `incompatible_result` - indicates that the deployment's result is not suitable for rollback.  - `exceeded_revision_limit` - indicates that the app has exceeded the rollback revision limits for its tier.  - `app_pinned` - indicates that there is already a rollback in progress and the app is pinned.  - `database_config_conflict` - indicates that the deployment's database config is different than the current config.  - `region_conflict` - indicates that the deployment's region differs from the current app region.  Warning conditions:  - `static_site_requires_rebuild` - indicates that the deployment contains at least one static site that will require a rebuild.  - `image_source_missing_digest` - indicates that the deployment contains at least one component with an image source that is missing a digest.
 */
export const App_rollback_validation_condition_codeObject = {
    Incompatible_phase: "incompatible_phase",
    Incompatible_result: "incompatible_result",
    Exceeded_revision_limit: "exceeded_revision_limit",
    App_pinned: "app_pinned",
    Database_config_conflict: "database_config_conflict",
    Region_conflict: "region_conflict",
    Static_site_requires_rebuild: "static_site_requires_rebuild",
    Image_source_missing_digest: "image_source_missing_digest",
} as const;
/**
 * The protocol which the service uses to serve traffic on the http_port.- `HTTP`: The app is serving the HTTP protocol. Default.- `HTTP2`: The app is serving the HTTP/2 protocol. Currently, this needs to be implemented in the service by serving HTTP/2 cleartext (h2c).
 */
export const App_service_spec_protocolObject = {
    HTTP: "HTTP",
    HTTP2: "HTTP2",
} as const;
/**
 * The slug form of the geographical origin of the app. Default: `nearest available`
 */
export const App_spec_regionObject = {
    Ams: "ams",
    Nyc: "nyc",
    Fra: "fra",
    Sfo: "sfo",
    Sgp: "sgp",
    Blr: "blr",
    Tor: "tor",
    Lon: "lon",
    Syd: "syd",
} as const;
/**
 * - RUN_TIME: Made available only at run-time- BUILD_TIME: Made available only at build-time- RUN_AND_BUILD_TIME: Made available at both build and run-time
 */
export const App_variable_definition_scopeObject = {
    UNSET: "UNSET",
    RUN_TIME: "RUN_TIME",
    BUILD_TIME: "BUILD_TIME",
    RUN_AND_BUILD_TIME: "RUN_AND_BUILD_TIME",
} as const;
/**
 * - GENERAL: A plain-text environment variable- SECRET: A secret encrypted environment variable
 */
export const App_variable_definition_typeObject = {
    GENERAL: "GENERAL",
    SECRET: "SECRET",
} as const;
export const Apps_dedicated_egress_ip_statusObject = {
    UNKNOWN: "UNKNOWN",
    ASSIGNING: "ASSIGNING",
    ASSIGNED: "ASSIGNED",
    REMOVED: "REMOVED",
} as const;
export const Apps_deployment_phaseObject = {
    UNKNOWN: "UNKNOWN",
    PENDING_BUILD: "PENDING_BUILD",
    BUILDING: "BUILDING",
    PENDING_DEPLOY: "PENDING_DEPLOY",
    DEPLOYING: "DEPLOYING",
    ACTIVE: "ACTIVE",
    SUPERSEDED: "SUPERSEDED",
    ERROREscaped: "ERROR",
    CANCELED: "CANCELED",
} as const;
export const Apps_deployment_progress_step_statusObject = {
    UNKNOWN: "UNKNOWN",
    PENDING: "PENDING",
    RUNNING: "RUNNING",
    ERROREscaped: "ERROR",
    SUCCESS: "SUCCESS",
} as const;
export const Apps_domain_phaseObject = {
    UNKNOWN: "UNKNOWN",
    PENDING: "PENDING",
    CONFIGURING: "CONFIGURING",
    ACTIVE: "ACTIVE",
    ERROREscaped: "ERROR",
} as const;
/**
 * - DOCKER_HUB: The DockerHub container registry type.- DOCR: The DigitalOcean container registry type.- GHCR: The Github container registry type.
 */
export const Apps_image_source_spec_registry_typeObject = {
    DOCKER_HUB: "DOCKER_HUB",
    DOCR: "DOCR",
    GHCR: "GHCR",
} as const;
/**
 * The datacenter in which all of the Droplets will be created.
 */
export const Autoscale_pool_droplet_template_regionObject = {
    Nyc1: "nyc1",
    Nyc2: "nyc2",
    Nyc3: "nyc3",
    Ams2: "ams2",
    Ams3: "ams3",
    Sfo1: "sfo1",
    Sfo2: "sfo2",
    Sfo3: "sfo3",
    Sgp1: "sgp1",
    Lon1: "lon1",
    Fra1: "fra1",
    Tor1: "tor1",
    Blr1: "blr1",
    Syd1: "syd1",
} as const;
/**
 * The current status of the autoscale pool.
 */
export const Autoscale_pool_statusObject = {
    Active: "active",
    Deleting: "deleting",
    ErrorEscaped: "error",
} as const;
/**
 * Type of billing history entry.
 */
export const Billing_history_typeObject = {
    ACHFailure: "ACHFailure",
    Adjustment: "Adjustment",
    AttemptFailed: "AttemptFailed",
    Chargeback: "Chargeback",
    Credit: "Credit",
    CreditExpiration: "CreditExpiration",
    Invoice: "Invoice",
    Payment: "Payment",
    Refund: "Refund",
    Reversal: "Reversal",
} as const;
/**
 * A string representing the type of the certificate. The value will be `custom` for a user-uploaded certificate or `lets_encrypt` for one automatically generated with Let's Encrypt.
 */
export const Certificate_create_base_typeObject = {
    Custom: "custom",
    Lets_encrypt: "lets_encrypt",
} as const;
/**
 * A string representing the current state of the certificate. It may be `pending`, `verified`, or `error`.
 */
export const Certificate_stateObject = {
    Pending: "pending",
    Verified: "verified",
    ErrorEscaped: "error",
} as const;
/**
 * A string representing the type of the certificate. The value will be `custom` for a user-uploaded certificate or `lets_encrypt` for one automatically generated with Let's Encrypt.
 */
export const Certificate_typeObject = {
    Custom: "custom",
    Lets_encrypt: "lets_encrypt",
} as const;
export const Check_regionsObject = {
    Us_east: "us_east",
    Us_west: "us_west",
    Eu_west: "eu_west",
    Se_asia: "se_asia",
} as const;
/**
 * The type of health check to perform.
 */
export const Check_typeObject = {
    Ping: "ping",
    Http: "http",
    Https: "https",
} as const;
export const Check_updatable_regionsObject = {
    Us_east: "us_east",
    Us_west: "us_west",
    Eu_west: "eu_west",
    Se_asia: "se_asia",
} as const;
/**
 * The type of health check to perform.
 */
export const Check_updatable_typeObject = {
    Ping: "ping",
    Http: "http",
    Https: "https",
} as const;
/**
 * A string indicating the current status of the cluster.
 */
export const Cluster_status_stateObject = {
    Running: "running",
    Provisioning: "provisioning",
    Degraded: "degraded",
    ErrorEscaped: "error",
    Deleted: "deleted",
    Upgrading: "upgrading",
    Deleting: "deleting",
} as const;
/**
 * A slug representing the database engine used for the cluster. The possible values are: "pg" for PostgreSQL, "mysql" for MySQL, "redis" for Redis, "mongodb" for MongoDB, "kafka" for Kafka, and "opensearch" for OpenSearch.
 */
export const Database_cluster_engineObject = {
    Pg: "pg",
    Mysql: "mysql",
    Redis: "redis",
    Mongodb: "mongodb",
    Kafka: "kafka",
    Opensearch: "opensearch",
} as const;
/**
 * A string representing the current status of the database cluster.
 */
export const Database_cluster_statusObject = {
    Creating: "creating",
    Online: "online",
    Resizing: "resizing",
    Migrating: "migrating",
    Forking: "forking",
} as const;
/**
 * A string representing the current status of the database cluster.
 */
export const Database_replica_statusObject = {
    Creating: "creating",
    Online: "online",
    Resizing: "resizing",
    Migrating: "migrating",
    Forking: "forking",
} as const;
/**
 * A string representing the database user's role. The value will be either"primary" or "normal".
 */
export const Database_user_roleObject = {
    Primary: "primary",
    Normal: "normal",
} as const;
export const DbaasClusterStatusObject = {
    CREATING: "CREATING",
    ONLINE: "ONLINE",
    POWEROFF: "POWEROFF",
    REBUILDING: "REBUILDING",
    REBALANCING: "REBALANCING",
    DECOMMISSIONED: "DECOMMISSIONED",
    FORKING: "FORKING",
    MIGRATING: "MIGRATING",
    RESIZING: "RESIZING",
    RESTORING: "RESTORING",
    POWERING_ON: "POWERING_ON",
    UNHEALTHY: "UNHEALTHY",
} as const;
/**
 * The destination type. `opensearch_dbaas` for a DigitalOcean managed OpenSearchcluster or `opensearch_ext` for an externally managed one.
 */
export const Destination_omit_credentials_typeObject = {
    Opensearch_dbaas: "opensearch_dbaas",
    Opensearch_ext: "opensearch_ext",
} as const;
/**
 * The destination type. `opensearch_dbaas` for a DigitalOcean managed OpenSearchcluster or `opensearch_ext` for an externally managed one.
 */
export const Destination_request_typeObject = {
    Opensearch_dbaas: "opensearch_dbaas",
    Opensearch_ext: "opensearch_ext",
} as const;
/**
 * The destination type. `opensearch_dbaas` for a DigitalOcean managed OpenSearchcluster or `opensearch_ext` for an externally managed one.
 */
export const Destination_typeObject = {
    Opensearch_dbaas: "opensearch_dbaas",
    Opensearch_ext: "opensearch_ext",
} as const;
/**
 * The type of disk. All Droplets contain a `local` disk. Additionally, GPU Droplets can also have a `scratch` disk for non-persistent data.
 */
export const Disk_info_typeObject = {
    Local: "local",
    Scratch: "scratch",
} as const;
/**
 * The name of a custom image's distribution. Currently, the valid values are  `Arch Linux`, `CentOS`, `CoreOS`, `Debian`, `Fedora`, `Fedora Atomic`,  `FreeBSD`, `Gentoo`, `openSUSE`, `RancherOS`, `Rocky Linux`, `Ubuntu`, and `Unknown`.  Any other value will be accepted but ignored, and `Unknown` will be used in its place.
 */
export const DistributionObject = {
    ArchLinux: "Arch Linux",
    CentOS: "CentOS",
    CoreOS: "CoreOS",
    Debian: "Debian",
    Fedora: "Fedora",
    FedoraAtomic: "Fedora Atomic",
    FreeBSD: "FreeBSD",
    Gentoo: "Gentoo",
    OpenSUSE: "openSUSE",
    RancherOS: "RancherOS",
    RockyLinux: "Rocky Linux",
    Ubuntu: "Ubuntu",
    Unknown: "Unknown",
} as const;
/**
 * The type of action to initiate for the Droplet.
 */
export const Droplet_action_typeObject = {
    Enable_backups: "enable_backups",
    Disable_backups: "disable_backups",
    Reboot: "reboot",
    Power_cycle: "power_cycle",
    Shutdown: "shutdown",
    Power_off: "power_off",
    Power_on: "power_on",
    Restore: "restore",
    Password_reset: "password_reset",
    Resize: "resize",
    Rebuild: "rebuild",
    Rename: "rename",
    Change_kernel: "change_kernel",
    Enable_ipv6: "enable_ipv6",
    Snapshot: "snapshot",
} as const;
/**
 * The backup plan used for the Droplet. The plan can be either `daily` or `weekly`.
 */
export const Droplet_backup_policy_planObject = {
    Daily: "daily",
    Weekly: "weekly",
} as const;
/**
 * The day of the week on which the backup will occur.
 */
export const Droplet_backup_policy_weekdayObject = {
    SUN: "SUN",
    MON: "MON",
    TUE: "TUE",
    WED: "WED",
    THU: "THU",
    FRI: "FRI",
    SAT: "SAT",
} as const;
/**
 * Describes the kind of image. It may be one of `snapshot` or `backup`. This specifies whether an image is a user-generated Droplet snapshot or automatically created Droplet backup.
 */
export const Droplet_snapshot_typeObject = {
    Snapshot: "snapshot",
    Backup: "backup",
} as const;
/**
 * A status string indicating the state of the Droplet instance. This may be "new", "active", "off", or "archive".
 */
export const Droplet_statusObject = {
    NewEscaped: "new",
    Active: "active",
    Off: "off",
    Archive: "archive",
} as const;
/**
 * Type of the event.
 */
export const Events_logs_event_typeObject = {
    Cluster_maintenance_perform: "cluster_maintenance_perform",
    Cluster_master_promotion: "cluster_master_promotion",
    Cluster_create: "cluster_create",
    Cluster_update: "cluster_update",
    Cluster_delete: "cluster_delete",
    Cluster_poweron: "cluster_poweron",
    Cluster_poweroff: "cluster_poweroff",
} as const;
/**
 * A string specifying the desired eviction policy for the Redis cluster.- `noeviction`: Don't evict any data, returns error when memory limit is reached.- `allkeys_lru:` Evict any key, least recently used (LRU) first.- `allkeys_random`: Evict keys in a random order.- `volatile_lru`: Evict keys with expiration only, least recently used (LRU) first.- `volatile_random`: Evict keys with expiration only in a random order.- `volatile_ttl`: Evict keys with expiration only, shortest time-to-live (TTL) first.
 */
export const Eviction_policy_modelObject = {
    Noeviction: "noeviction",
    Allkeys_lru: "allkeys_lru",
    Allkeys_random: "allkeys_random",
    Volatile_lru: "volatile_lru",
    Volatile_random: "volatile_random",
    Volatile_ttl: "volatile_ttl",
} as const;
/**
 * The type of traffic to be allowed. This may be one of `tcp`, `udp`, or `icmp`.
 */
export const Firewall_rule_base_protocolObject = {
    Tcp: "tcp",
    Udp: "udp",
    Icmp: "icmp",
} as const;
/**
 * The type of resource that the firewall rule allows to access the database cluster.
 */
export const Firewall_rule_typeObject = {
    Droplet: "droplet",
    K8s: "k8s",
    Ip_addr: "ip_addr",
    Tag: "tag",
    App: "app",
} as const;
/**
 * A status string indicating the current state of the firewall. This can be "waiting", "succeeded", or "failed".
 */
export const Firewall_statusObject = {
    Waiting: "waiting",
    Succeeded: "succeeded",
    Failed: "failed",
} as const;
/**
 * The type of action to initiate for the floating IP.
 */
export const FloatingIPsAction_typeObject = {
    Assign: "assign",
    Unassign: "unassign",
} as const;
/**
 * The protocol used for traffic to the load balancer. The possible values are: `http`, `https`, `http2`, `http3`, `tcp`, or `udp`. If you set the  `entry_protocol` to `udp`, the `target_protocol` must be set to `udp`.  When using UDP, the load balancer requires that you set up a health  check with a port that uses TCP, HTTP, or HTTPS to work properly.
 */
export const Forwarding_rule_entry_protocolObject = {
    Http: "http",
    Https: "https",
    Http2: "http2",
    Http3: "http3",
    Tcp: "tcp",
    Udp: "udp",
} as const;
/**
 * The protocol used for traffic from the load balancer to the backend Droplets. The possible values are: `http`, `https`, `http2`, `tcp`, or `udp`. If you set the `target_protocol` to `udp`, the `entry_protocol` must be set to  `udp`. When using UDP, the load balancer requires that you set up a health  check with a port that uses TCP, HTTP, or HTTPS to work properly.
 */
export const Forwarding_rule_target_protocolObject = {
    Http: "http",
    Https: "https",
    Http2: "http2",
    Tcp: "tcp",
    Udp: "udp",
} as const;
/**
 * The current status of this garbage collection.
 */
export const Garbage_collection_statusObject = {
    Requested: "requested",
    WaitingForWriteJWTsToExpire: "waiting for write JWTs to expire",
    ScanningManifests: "scanning manifests",
    DeletingUnreferencedBlobs: "deleting unreferenced blobs",
    Cancelling: "cancelling",
    Failed: "failed",
    Succeeded: "succeeded",
    Cancelled: "cancelled",
} as const;
/**
 * The protocol used for forwarding traffic from the load balancer to the target backends. The possible values are `http`, `https` and `http2`.
 */
export const Glb_settings_target_protocolObject = {
    Http: "http",
    Https: "https",
    Http2: "http2",
} as const;
/**
 * The protocol used for health checks sent to the backend Droplets. The possible values are `http`, `https`, or `tcp`.
 */
export const Health_check_protocolObject = {
    Http: "http",
    Https: "https",
    Tcp: "tcp",
} as const;
/**
 * The reason for the scaling event.
 */
export const History_reasonObject = {
    CONFIGURATION_CHANGE: "CONFIGURATION_CHANGE",
    SCALE_UP: "SCALE_UP",
    SCALE_DOWN: "SCALE_DOWN",
} as const;
/**
 * The status of the scaling event.
 */
export const History_statusObject = {
    In_progress: "in_progress",
    Success: "success",
    ErrorEscaped: "error",
} as const;
/**
 * The action to be taken on the image. Can be either `convert` or `transfer`.
 */
export const Image_action_base_typeObject = {
    Convert: "convert",
    Transfer: "transfer",
} as const;
/**
 * A status string indicating the state of a custom image. This may be `NEW`, `available`, `pending`, `deleted`, or `retired`.
 */
export const Image_statusObject = {
    NEWEscaped: "NEW",
    Available: "available",
    Pending: "pending",
    Deleted: "deleted",
    Retired: "retired",
} as const;
/**
 * Describes the kind of image. It may be one of `base`, `snapshot`, `backup`, `custom`, or `admin`. Respectively, this specifies whether an image is a DigitalOcean base OS image, user-generated Droplet snapshot, automatically created Droplet backup, user-provided virtual machine image, or an image used for DigitalOcean managed resources (e.g. DOKS worker nodes).
 */
export const Image_typeObject = {
    Base: "base",
    Snapshot: "snapshot",
    Backup: "backup",
    Custom: "custom",
    Admin: "admin",
} as const;
export const Instance_size_cpu_typeObject = {
    UNSPECIFIED: "UNSPECIFIED",
    SHARED: "SHARED",
    DEDICATED: "DEDICATED",
} as const;
/**
 * Specify the final compression type for a given topic. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'uncompressed' which is equivalent to no compression; and 'producer' which means retain the original compression codec set by the producer.
 */
export const Kafka_advanced_config_compression_typeObject = {
    Gzip: "gzip",
    Snappy: "snappy",
    Lz4: "lz4",
    Zstd: "zstd",
    Uncompressed: "uncompressed",
    Producer: "producer",
} as const;
/**
 * The default cleanup policy for segments beyond the retention window
 */
export const Kafka_advanced_config_log_cleanup_policyObject = {
    Delete: "delete",
    Compact: "compact",
    CompactDelete: "compact,delete",
} as const;
/**
 * Define whether the timestamp in the message is message create time or log append time.
 */
export const Kafka_advanced_config_log_message_timestamp_typeObject = {
    CreateTime: "CreateTime",
    LogAppendTime: "LogAppendTime",
} as const;
/**
 * The cleanup_policy sets the retention policy to use on log segments. 'delete' will discard old segments when retention time/size limits are reached. 'compact' will enable log compaction, resulting in retention of the latest value for each key.
 */
export const Kafka_topic_config_cleanup_policyObject = {
    Delete: "delete",
    Compact: "compact",
    Compact_delete: "compact_delete",
} as const;
/**
 * The compression_type specifies the compression type of the topic.
 */
export const Kafka_topic_config_compression_typeObject = {
    Producer: "producer",
    Gzip: "gzip",
    Snappy: "snappy",
    Iz4: "Iz4",
    Zstd: "zstd",
    Uncompressed: "uncompressed",
} as const;
/**
 * The message_format_version specifies the message format version used by the broker to append messages to the logs. The value of this setting is assumed to be 3.0-IV1 if the broker protocol version is 3.0 or higher. By setting a  particular message format version, all existing messages on disk must be smaller or equal to the specified version.
 */
export const Kafka_topic_config_message_format_versionObject = {
    ZeroEightZero: "0.8.0",
    ZeroEightOne: "0.8.1",
    ZeroEightTwo: "0.8.2",
    ZeroNineZero: "0.9.0",
    ZeroOneZeroZeroIV0: "0.10.0-IV0",
    ZeroOneZeroZeroIV1: "0.10.0-IV1",
    ZeroOneZeroOneIV0: "0.10.1-IV0",
    ZeroOneZeroOneIV1: "0.10.1-IV1",
    ZeroOneZeroOneIV2: "0.10.1-IV2",
    ZeroOneZeroTwoIV0: "0.10.2-IV0",
    ZeroOneOneZeroIV0: "0.11.0-IV0",
    ZeroOneOneZeroIV1: "0.11.0-IV1",
    ZeroOneOneZeroIV2: "0.11.0-IV2",
    OneZeroIV0: "1.0-IV0",
    OneOneIV0: "1.1-IV0",
    TwoZeroIV0: "2.0-IV0",
    TwoZeroIV1: "2.0-IV1",
    TwoOneIV0: "2.1-IV0",
    TwoOneIV1: "2.1-IV1",
    TwoOneIV2: "2.1-IV2",
    TwoTwoIV0: "2.2-IV0",
    TwoTwoIV1: "2.2-IV1",
    TwoThreeIV0: "2.3-IV0",
    TwoThreeIV1: "2.3-IV1",
    TwoFourIV0: "2.4-IV0",
    TwoFourIV1: "2.4-IV1",
    TwoFiveIV0: "2.5-IV0",
    TwoSixIV0: "2.6-IV0",
    TwoSevenIV0: "2.7-IV0",
    TwoSevenIV1: "2.7-IV1",
    TwoSevenIV2: "2.7-IV2",
    TwoEightIV0: "2.8-IV0",
    TwoEightIV1: "2.8-IV1",
    ThreeZeroIV0: "3.0-IV0",
    ThreeZeroIV1: "3.0-IV1",
    ThreeOneIV0: "3.1-IV0",
    ThreeTwoIV0: "3.2-IV0",
    ThreeThreeIV0: "3.3-IV0",
    ThreeThreeIV1: "3.3-IV1",
    ThreeThreeIV2: "3.3-IV2",
    ThreeThreeIV3: "3.3-IV3",
} as const;
/**
 * The message_timestamp_type specifies whether to use the message create time or log append time as the timestamp on a message.
 */
export const Kafka_topic_config_message_timestamp_typeObject = {
    Create_time: "create_time",
    Log_append_time: "log_append_time",
} as const;
/**
 * The state of the Kafka topic.
 */
export const Kafka_topic_stateObject = {
    Active: "active",
    Configuring: "configuring",
    Deleting: "deleting",
    Unknown: "unknown",
} as const;
/**
 * The state of the Kafka topic.
 */
export const Kafka_topic_verbose_stateObject = {
    Active: "active",
    Configuring: "configuring",
    Deleting: "deleting",
    Unknown: "unknown",
} as const;
/**
 * How the node reacts to pods that it won't tolerate. Available effect values are `NoSchedule`, `PreferNoSchedule`, and `NoExecute`.
 */
export const Kubernetes_node_pool_taint_effectObject = {
    NoSchedule: "NoSchedule",
    PreferNoSchedule: "PreferNoSchedule",
    NoExecute: "NoExecute",
} as const;
/**
 * This field has been deprecated. You can no longer specify an algorithm for load balancers.
 * @deprecated 
 */
export const Load_balancer_base_algorithmObject = {
    Round_robin: "round_robin",
    Least_connections: "least_connections",
} as const;
/**
 * A string indicating whether the load balancer will support IPv4 or both IPv4 and IPv6 networking. This property cannot be updated after creating the load balancer. Note that this feature is in private preview.
 */
export const Load_balancer_base_network_stackObject = {
    IPV4: "IPV4",
    DUALSTACK: "DUALSTACK",
} as const;
/**
 * A string indicating whether the load balancer should be external or internal. Internal load balancers have no public IPs and are only accessible to resources on the same VPC network. This property cannot be updated after creating the load balancer.
 */
export const Load_balancer_base_networkObject = {
    EXTERNAL: "EXTERNAL",
    INTERNAL: "INTERNAL",
} as const;
/**
 * This field has been replaced by the `size_unit` field for all regions except in AMS2, NYC2, and SFO1. Each available load balancer size now equates to the load balancer having a set number of nodes.* `lb-small` = 1 node* `lb-medium` = 3 nodes* `lb-large` = 6 nodesYou can resize load balancers after creation up to once per hour. You cannot resize a load balancer within the first hour of its creation.
 * @deprecated 
 */
export const Load_balancer_base_sizeObject = {
    LbSmall: "lb-small",
    LbMedium: "lb-medium",
    LbLarge: "lb-large",
} as const;
/**
 * A status string indicating the current state of the load balancer. This can be `new`, `active`, or `errored`.
 */
export const Load_balancer_base_statusObject = {
    NewEscaped: "new",
    Active: "active",
    Errored: "errored",
} as const;
/**
 * A string indicating whether the load balancer should be a standard regional HTTP load balancer, a regional network load balancer that routes traffic at the TCP/UDP transport layer, or a global load balancer.
 */
export const Load_balancer_base_typeObject = {
    REGIONAL: "REGIONAL",
    REGIONAL_NETWORK: "REGIONAL_NETWORK",
    GLOBAL: "GLOBAL",
} as const;
export const Logsink_base_sink_typeObject = {
    Rsyslog: "rsyslog",
    Elasticsearch: "elasticsearch",
    Opensearch: "opensearch",
} as const;
export const Logsink_base_verbose_sink_typeObject = {
    Rsyslog: "rsyslog",
    Elasticsearch: "elasticsearch",
    Opensearch: "opensearch",
} as const;
/**
 * The day of the maintenance window policy. May be one of `monday` through `sunday`, or `any` to indicate an arbitrary week day.
 */
export const Maintenance_policy_dayObject = {
    Any: "any",
    Monday: "monday",
    Tuesday: "tuesday",
    Wednesday: "wednesday",
    Thursday: "thursday",
    Friday: "friday",
    Saturday: "saturday",
    Sunday: "sunday",
} as const;
/**
 * The power status of the Droplet.
 */
export const Member_statusObject = {
    Provisioning: "provisioning",
    Active: "active",
    Deleting: "deleting",
    Off: "off",
} as const;
export const Metrics_data_resultTypeObject = {
    Matrix: "matrix",
} as const;
export const Metrics_statusObject = {
    Success: "success",
    ErrorEscaped: "error",
} as const;
/**
 * Specifies the default consistency behavior of reads from the database. Data that is returned from the query with may or may not have been acknowledged by all nodes in the replicaset depending on this value.  Learn more [here](https://www.mongodb.com/docs/manual/reference/read-concern/).
 */
export const Mongo_advanced_config_default_read_concernObject = {
    Local: "local",
    Available: "available",
    Majority: "majority",
} as const;
/**
 * The storage engine for in-memory internal temporary tables.
 */
export const Mysql_advanced_config_internal_tmp_mem_storage_engineObject = {
    TempTable: "TempTable",
    MEMORY: "MEMORY",
} as const;
/**
 * Defines the destination for logs. Can be `INSIGHTS`, `TABLE`, or both (`INSIGHTS,TABLE`), or `NONE` to disable logs. To specify both destinations, use `INSIGHTS,TABLE` (order matters). Default is NONE.
 */
export const Mysql_advanced_config_log_outputObject = {
    INSIGHTS: "INSIGHTS",
    TABLE: "TABLE",
    INSIGHTSTABLE: "INSIGHTS,TABLE",
    NONE: "NONE",
} as const;
/**
 * A string specifying the authentication method to be used for connectionsto the MySQL user account. The valid values are `mysql_native_password`or `caching_sha2_password`. If excluded when creating a new user, thedefault for the version of MySQL in use will be used. As of MySQL 8.0, thedefault is `caching_sha2_password`.
 */
export const Mysql_settings_auth_pluginObject = {
    Mysql_native_password: "mysql_native_password",
    Caching_sha2_password: "caching_sha2_password",
} as const;
/**
 * The type of the IPv4 network interface.
 */
export const Network_v4_typeObject = {
    Public: "public",
    Private: "private",
} as const;
/**
 * The type of the IPv6 network interface.**Note**: IPv6 private  networking is not currently supported.
 */
export const Network_v6_typeObject = {
    Public: "public",
} as const;
/**
 * A string indicating the current status of the node.
 */
export const Node_status_stateObject = {
    Provisioning: "provisioning",
    Running: "running",
    Draining: "draining",
    Deleting: "deleting",
} as const;
/**
 * The current status of the migration.
 */
export const Online_migration_statusObject = {
    Running: "running",
    Syncing: "syncing",
    Canceled: "canceled",
    ErrorEscaped: "error",
    Done: "done",
} as const;
/**
 * The health of the OpenSearch index.
 */
export const Opensearch_index_healthObject = {
    Unknown: "unknown",
    Green: "green",
    Yellow: "yellow",
    Red: "red",
} as const;
/**
 * The status of the OpenSearch index.
 */
export const Opensearch_index_statusObject = {
    Unknown: "unknown",
    Open: "open",
    Close: "close",
    None: "none",
} as const;
/**
 * PGBouncer pool mode
 */
export const Pgbouncer_advanced_config_autodb_pool_modeObject = {
    Session: "session",
    Transaction: "transaction",
    Statement: "statement",
} as const;
/**
 * Enum of parameters to ignore when given in startup packet.
 */
export const Pgbouncer_advanced_config_ignore_startup_parametersObject = {
    Extra_float_digits: "extra_float_digits",
    Search_path: "search_path",
} as const;
/**
 * Specifies the default TOAST compression method for values of compressible columns (the default is lz4).
 */
export const Postgres_advanced_config_default_toast_compressionObject = {
    Lz4: "lz4",
    Pglz: "pglz",
} as const;
/**
 * Controls the amount of detail written in the server log for each message that is logged.
 */
export const Postgres_advanced_config_log_error_verbosityObject = {
    TERSE: "TERSE",
    DEFAULTEscaped: "DEFAULT",
    VERBOSE: "VERBOSE",
} as const;
/**
 * Selects one of the available log-formats. These can support popular log analyzers like pgbadger, pganalyze, etc.
 */
export const Postgres_advanced_config_log_line_prefixObject = {
    PidPUserUDbDAppAClientH: "pid=%p,user=%u,db=%d,app=%a,client=%h",
    MPQUserUDbDAppA: "%m [%p] %q[user=%u,db=%d,app=%a]",
    TPL1UserUDbDAppAClientH: "%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h",
} as const;
/**
 * Controls which statements are counted. Specify 'top' to track top-level statements (those issued directly by clients), 'all' to also track nested statements (such as statements invoked within functions), or 'none' to disable statement statistics collection. The default value is top.
 */
export const Postgres_advanced_config_pg_stat_statementsTrackObject = {
    All: "all",
    Top: "top",
    None: "none",
} as const;
/**
 * Synchronous replication type. Note that the service plan also needs to support synchronous replication.
 */
export const Postgres_advanced_config_synchronous_replicationObject = {
    Off: "off",
    Quorum: "quorum",
} as const;
/**
 * Record commit time of transactions.
 */
export const Postgres_advanced_config_track_commit_timestampObject = {
    Off: "off",
    On: "on",
} as const;
/**
 * Enables tracking of function call counts and time used.
 */
export const Postgres_advanced_config_track_functionsObject = {
    All: "all",
    Pl: "pl",
    None: "none",
} as const;
/**
 * Enables timing of database I/O calls. This parameter is off by default, because it will repeatedly query the operating system for the current time, which may cause significant overhead on some platforms.
 */
export const Postgres_advanced_config_track_io_timingObject = {
    Off: "off",
    On: "on",
} as const;
/**
 * The environment of the project's resources.
 */
export const Project_base_environmentObject = {
    Development: "Development",
    Staging: "Staging",
    Production: "Production",
} as const;
/**
 * Determines default pub/sub channels' ACL for new users if ACL is not supplied. When this option is not defined, all_channels is assumed to keep backward compatibility. This option doesn't affect Redis configuration acl-pubsub-default.
 */
export const Redis_advanced_config_redis_acl_channels_defaultObject = {
    Allchannels: "allchannels",
    Resetchannels: "resetchannels",
} as const;
/**
 * A string specifying the desired eviction policy for the Redis cluster.- `noeviction`: Don't evict any data, returns error when memory limit is reached.- `allkeys-lru:` Evict any key, least recently used (LRU) first.- `allkeys-random`: Evict keys in a random order.- `volatile-lru`: Evict keys with expiration only, least recently used (LRU) first.- `volatile-random`: Evict keys with expiration only in a random order.- `volatile-ttl`: Evict keys with expiration only, shortest time-to-live (TTL) first.
 */
export const Redis_advanced_config_redis_maxmemory_policyObject = {
    Noeviction: "noeviction",
    AllkeysLru: "allkeys-lru",
    AllkeysRandom: "allkeys-random",
    VolatileLru: "volatile-lru",
    VolatileRandom: "volatile-random",
    VolatileTtl: "volatile-ttl",
} as const;
/**
 * Creates an RDB dump of the database every 10 minutes that can be used  to recover data after a node crash. The database does not create the  dump if no keys have changed since the last dump. When set to `off`,  the database cannot fork services, and data can be lost if a service  is restarted or powered off. DigitalOcean Managed Caching databases  do not support the Append Only File (AOF) persistence method.
 */
export const Redis_advanced_config_redis_persistenceObject = {
    Off: "off",
    Rdb: "rdb",
} as const;
/**
 * The slug identifier for the region where the resource will initially be  available.
 */
export const Region_slugObject = {
    Ams1: "ams1",
    Ams2: "ams2",
    Ams3: "ams3",
    Blr1: "blr1",
    Fra1: "fra1",
    Lon1: "lon1",
    Nyc1: "nyc1",
    Nyc2: "nyc2",
    Nyc3: "nyc3",
    Sfo1: "sfo1",
    Sfo2: "sfo2",
    Sfo3: "sfo3",
    Sgp1: "sgp1",
    Tor1: "tor1",
    Syd1: "syd1",
} as const;
export const Region_state_statusObject = {
    DOWN: "DOWN",
    UP: "UP",
    CHECKING: "CHECKING",
} as const;
/**
 * Slug of the region where registry data is stored. When not provided, a region will be selected.
 */
export const Registry_create_regionObject = {
    Nyc3: "nyc3",
    Sfo3: "sfo3",
    Ams3: "ams3",
    Sgp1: "sgp1",
    Fra1: "fra1",
} as const;
/**
 * The slug of the subscription tier to sign up for. Valid values can be retrieved using the options endpoint.
 */
export const Registry_create_subscription_tier_slugObject = {
    Starter: "starter",
    Basic: "basic",
    Professional: "professional",
} as const;
/**
 * The type of action to initiate for the reserved IP.
 */
export const Reserved_ip_action_type_typeObject = {
    Assign: "assign",
    Unassign: "unassign",
} as const;
/**
 * The type of action to initiate for the reserved IPv6.
 */
export const Reserved_ipv6_action_type_typeObject = {
    Assign: "assign",
    Unassign: "unassign",
} as const;
/**
 * The status of assigning and fetching the resources.
 */
export const Resource_statusObject = {
    Ok: "ok",
    Not_found: "not_found",
    Assigned: "assigned",
    Already_assigned: "already_assigned",
    Service_down: "service_down",
} as const;
/**
 * Message format used by the server, this can be either rfc3164 (the old BSD style message format), `rfc5424` (current syslog message format) or custom
 */
export const Rsyslog_logsink_formatObject = {
    Rfc5424: "rfc5424",
    Rfc3164: "rfc3164",
    Custom: "custom",
} as const;
/**
 * The type of resource that the snapshot originated from.
 */
export const Snapshots_resource_typeObject = {
    Droplet: "droplet",
    Volume: "volume",
} as const;
/**
 * An attribute indicating how and if requests from a client will be persistently served by the same backend Droplet. The possible values are `cookies` or `none`.
 */
export const Sticky_sessions_typeObject = {
    Cookies: "cookies",
    None: "none",
} as const;
/**
 * The type of the resource.
 */
export const Tags_resource_resources_resource_typeObject = {
    Droplet: "droplet",
    Image: "image",
    Volume: "volume",
    Volume_snapshot: "volume_snapshot",
} as const;
/**
 * Permission set applied to the ACL. 'consume' allows for messages to be consumed from the topic. 'produce' allows for messages to be published to the topic. 'produceconsume' allows for both 'consume' and 'produce' permission. 'admin' allows for 'produceconsume' as well as any operations to administer the topic (delete, update).
 */
export const User_settings_acl_permissionObject = {
    Admin: "admin",
    Consume: "consume",
    Produce: "produce",
    Produceconsume: "produceconsume",
} as const;
/**
 * Permission set applied to the ACL. 'read' allows user to read from the index. 'write' allows for user to write to the index. 'readwrite' allows for both 'read' and 'write' permission. 'deny'(default) restricts user from performing any operation over an index. 'admin' allows for 'readwrite' as well as any operations to administer the index.
 */
export const User_settings_opensearch_acl_permissionObject = {
    Deny: "deny",
    Admin: "admin",
    Read: "read",
    Readwrite: "readwrite",
    Write: "write",
} as const;
/**
 * The volume action to initiate.
 */
export const Volume_action_post_base_typeObject = {
    Attach: "attach",
    Detach: "detach",
    Resize: "resize",
} as const;
/**
 * The current status of the VPC peering.
 */
export const Vpc_peering_statusObject = {
    PROVISIONING: "PROVISIONING",
    ACTIVE: "ACTIVE",
    DELETING: "DELETING",
} as const;
/* tslint:enable */
/* eslint-enable */
